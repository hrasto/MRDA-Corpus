and uh uh hans - guenter will be here um i think by next next tuesday or so . 
uhhuh . 
oh okay . 
so he ' s he ' s going to be here for about three weeks . 
oh . 
that ' s nice . 
just for a visit ? 
and 
uh 
uh we ' ll see . 
we might might end up with some longer collaboration or something . 
huh . 
so he ' s going to look in on everything we ' re doing . 
cool . 
uhhuh . 
and give us his his thoughts . 
and so it ' ll be another another good person looking at things . 
oh . 
huh . 
that ' s his spectral subtraction group ? 
is that right ? 
yeah . 
oh okay . 
yeah . 
so i guess i should probably talk to him a bit too ? 
oh yeah . 
yeah . 
yeah . 
no he ' ll be around for three weeks . 
he ' s uh um very very easygoing . 
easy to talk to . 
and uh very interested in everything . 
really nice guy . 
yeah . 
yeah . 
yeah we met him in amsterdam . 
yeah . 
yeah he ' s been here before . 
i mean he ' s he ' s he ' s he ' s 
oh okay . 
i haven ' t noticed him . 
back when i was a grad student he was here for a uh uh a year or six months . 
nine months . 
something like that . 
something like that . 
yeah . 
yeah . 
yeah . 
he ' s he ' s done a couple stays here . 
huh . 
yeah . 
so um i guess we got lots to catch up on . 
and we haven ' t met for a couple of weeks . 
we didn ' t meet last week morgan . 
um i went around and talked to everybody . 
and it seemed like they they had some new results . 
but rather than them coming up and telling me i figured we should just wait a week and they can tell both you know all of us . 
so um 
why don ' t we why don ' t we start with you dave ? 
oh okay . 
and then um we can go on . 
so 
so um since we ' re looking at putting this um mean log magnitude spectral subtraction um into the smartkom system i did a test seeing if um it would work using past only and plus the present to calculate the mean . 
so i did a test um where i used twelve seconds from the past and the present frame to um calculate the mean . 
and 
twelve seconds . 
twelve twelve seconds back from the current frame . 
uh 
is that what you mean ? 
twelve seconds um counting back from the end of the current frame . 
yeah . 
okay . 
so it was um i think it was twenty one frames . 
okay . 
and that worked out to about twelve seconds . 
uhhuh . 
and compared to um using a twelve second centered window i think there was a drop in performance . 
but it was just a slight drop . 
uhhuh . 
huh . 
is is that right ? 
um 
yeah i mean it was pretty it was pretty tiny . 
uhhuh . 
yeah . 
so that was encouraging . 
and um 
that that um that ' s encouraging for for the idea of using it in an interactive system like smartkom . 
and um another issue i ' m i ' m thinking about is in the smartkom system . 
so say twelve seconds in the earlier test seemed like a good length of time . 
but what happens if you have less than twelve seconds ? 
and um 
so i before um back in may i did some experiments using say two seconds or four seconds or six seconds . 
in those i trained the models using mean subtraction with the means calculated over two seconds or four seconds or six seconds . 
and um 
here i was curious what if i trained the models using twelve seconds . 
but i i gave it a situation where the test set i was subtracted using two seconds or four seconds or six seconds . 
and um 
so i did that for about three different conditions . 
and um 
i mean i i think it was um four 
i think i think it was um something like four seconds and um six seconds and eight seconds . 
something like that . 
and it seems like it it it hurts compared to if you actually train the models using that same length of time . 
but it it doesn ' t hurt that much . 
um 
usually less than point five percent . 
although i think i did see one where it was a point eight percent or so rise in word error rate . 
but this is um where um even if i train on the uh model and mean subtracted it with the same length of time as in the test it the word error rate is around um ten percent or nine percent . 
so it doesn ' t seem like that big a a difference . 
but it but looking at it the other way isn ' t it what you ' re saying that it didn ' t help you to have the longer time for training ? 
if you were going to have a short time for 
that that ' s true . 
um 
i mean why would you do it if you knew that you were going to have short windows in testing ? 
yeah it seems like for your i mean in normal situations you would never get twelve seconds of speech . 
right ? 
you need twelve seconds in the past to estimate right ? 
i ' m not 
yeah . 
or or you ' re looking at six sec seconds in future and six in 
um twelve 
uh for the test it ' s just twelve seconds in the past . 
no total . 
no it ' s all . 
oh okay . 
is this twelve seconds of uh regardless of speech or silence ? 
or twelve seconds of speech ? 
of of speech . 
okay . 
uhhuh . 
the other thing um which maybe relates a little bit to something else we ' ve talked about in terms of windowing and so on is that um i wonder if you trained with twelve seconds and then when you were two seconds in you used two seconds . 
and when you were four seconds in you used four seconds . 
and when you were six 
and you basically build up to the twelve seconds . 
so that if you have very long utterances you have the best . 
yeah . 
but if you have shorter utterances you use what you can . 
right . 
and that ' s actually what we ' re planning to do in smartkom . 
okay . 
but 
yeah . 
so i so i guess the the question i was trying to get at with those experiments is does it matter what models you use . 
does it matter how much time you use to calculate the mean when you were um doing the training data . 
right . 
but i mean the other thing is that that ' s 
i mean the other way of looking at this going back to uh mean cepstral subtraction versus rasta kind of things is that you could look at mean cepstral subtraction . 
especially the way you ' re doing it uh as being a kind of filter . 
and so the other thing is just to design a filter . 
you know basically you ' re you ' re you ' re doing a high pass filter or a band pass filter of some sort . 
and and just design a filter . 
and then you know a filter will have a certain behavior . 
and you can look at the start up behavior when you start up with nothing . 
uhhuh . 
and and you know it will uh if you have an i . i . r . filter for instance it will um uh not behave in the steady state way that you would like it to behave until you get a long enough period . 
but um 
uh 
by just constraining yourself to have your filter be only a subtraction of the mean you ' re kind of you know tying your hands behind your back . 
because there ' s filters have all sorts of temporal and spectral behaviors . 
uhhuh . 
and the only thing you know consistent that we know about is that you want to get rid of the very low frequency component . 
huh . 
but do you really want to calculate the mean ? 
and you neglect all the silence regions or you just use everything that ' s twelve seconds ? 
and 
um 
you do you mean in my tests so far ? 
yeah . 
most of the silence has been cut out . 
okay . 
just there ' s just inter word silences . 
uhhuh . 
and they are like pretty short . 
pretty short . 
yeah . 
yeah . 
okay . 
yeah . 
uhhuh . 
so you really need a lot of speech to estimate the mean of it . 
well if i only use six seconds it still works pretty well . 
yeah . 
yeah . 
uhhuh . 
i saw in my test before . 
i was trying twelve seconds because that was the best in my test before . 
okay . 
and that increasing past twelve seconds didn ' t seem to help . 
huh . 
huh . 
um yeah . 
i guess it ' s something i need to play with more to decide how to set that up for the smartkom system . 
like maybe if i trained on six seconds it would work better when i only had two seconds or four seconds and 
yeah . 
yeah . 
and um 
okay . 
yeah and again if you take this filtering perspective and if you essentially have it build up over time 
i mean if you computed means over two and then over four and over six essentially what you ' re getting at is a kind of uh ramp up of a filter anyway . 
and so you may may just want to think of it as a filter . 
but uh if you do that then um in practice somebody using the smartkom system one would think if they ' re using it for a while it means that their first utterance instead of you know getting uh a forty percent error rate reduction they ' ll get a uh over what uh you ' d get without this uh um policy uh you get thirty percent . 
and then the second utterance that you give they get the full you know uh full benefit of it if it ' s this ongoing thing . 
oh . 
so you you cache the utterances ? 
that ' s how you get your 
uh 
well i ' m saying in practice yeah . 
uh . 
that ' s if somebody ' s using a system to ask for directions or something . 
okay . 
okay . 
you know they ' ll say something first . 
and and to begin with if it doesn ' t get them quite right maybe they ' ll come back and say excuse me . 
uhhuh . 
uh 
or some 
i mean it should have some policy like that anyway . 
uhhuh . 
and and uh 
uh in any event they might ask a second question . 
and it ' s not like what he ' s doing doesn ' t uh improve things . 
it does improve things . 
just not as much as he would like . 
and so uh there ' s a higher probability of it making an error uh in the first utterance . 
what would be really cool is if you could have 
uh this probably users would never like this . 
but if you had could have a system where before they began to use it they had to introduce themselves verbally . 
uhhuh . 
you know . 
yeah . 
hi . 
my name is so - and - so . 
i ' m from blah blah blah . 
and you could use that initial speech to do all these adaptations . 
uhhuh . 
and 
right . 
oh the other thing i guess which which 
uh 
i don ' t know much about as much as i should about the rest of the system . 
but but um 
couldn ' t you uh if you if you sort of did a first pass 
i don ' t know what kind of uh uh capability we have at the moment for for doing second passes on on uh uh some kind of little small lattice or a graph or confusion network or something . 
but if you did first pass with um the with either without the mean subtraction or with a a very short time one 
and then um once you uh actually had the whole utterance in if you did um the uh uh longer time version then based on everything that you had um and then at that point only used it to distinguish between you know top n . um possible utterances or something you you might it might not take very much time . 
i mean i know in the large vocabulary uh uh systems people were evaluating on in the past some people really pushed everything in to make it in one pass . 
but other people didn ' t and had multiple passes . 
and um 
the argument um against multiple passes was has often been but we want to this to be you know have a nice interactive response . 
and the counterargument to that which say uh b . b . n . i . think had was yeah . 
but our second responses are second uh passes and third passes are really really fast . 
uhhuh . 
so um if if your second pass takes a millisecond who cares ? 
um 
so um 
the the idea of the second pass would be waiting till you have more recorded speech ? 
or 
yeah . 
so if it turned out to be a problem that you didn ' t have enough speech because you need a longer longer window to do this processing then uh one tactic is you know looking at the larger system and not just at the front end stuff is to take in um the speech with some simpler mechanism or shorter time mechanism . 
uhhuh . 
um do the best you can and come up with some possible alternates of what might have been said . 
and uh either in the form of an n . best list or in the form of a lattice or or confusion network or whatever . 
uhhuh . 
and then the decoding of that is much much faster or can be much much faster if it isn ' t a big bushy network . 
and you can decode that now with speech that you ' ve actually processed using this longer time uh subtraction . 
huh . 
so i mean it ' s it ' s common that people do this sort of thing where they do more things that are more complex or require looking over more time whatever in some kind of second pass . 
uhhuh . 
okay . 
um and again if the second pass is really really fast uh another one i ' ve heard of is is in in connected digit stuff um going back and and through backtrace and finding regions that are considered to be a a digit but uh which have very low energy . 
uhhuh . 
okay . 
so uh i mean there ' s lots of things you can do in second passes at all sorts of levels . 
anyway i ' m throwing too many things out . 
but 
so is that uh that it ? 
i guess that ' s it . 
okay . 
uh do you want to go sunil ? 
yep . 
um so 
the last two weeks was like 
so i ' ve been working on that wiener filtering . 
and 
uh 
found that uh single like i just do a normal wiener filtering like the standard method of wiener filtering . 
and that doesn ' t actually give me any improvement over like 
i mean uh it actually improves over the baseline . 
but it ' s not like it doesn ' t meet something like fifty percent or something . 
so i ' ve been playing with the 
improves over the base line m . f . c . c . system ? 
yeah . 
yeah . 
yeah . 
yeah . 
so um 
so that ' s the improvement is somewhere around like thirty percent over the baseline . 
is that using in combination with something else ? 
no . 
with with a 
just just one stage wiener filter . 
which is a standard wiener filter . 
no no . 
but i mean in combination with our online normalization or with the l . d . a ? 
yeah yeah yeah yeah . 
so i just plug in the wiener filtering . 
oh okay . 
i mean in the in our system where 
oh okay . 
so i 
so does it does that mean it gets worse ? 
or 
no . 
it actually improves over the baseline of not having a wiener filter in the whole system . 
like i have an l . d . a . l . d . a . plus online normalization . 
yeah . 
and then i plug in the wiener filter in that . 
so it improves over not having the wiener filter . 
so it improves . 
but it it doesn ' t take it like beyond like thirty percent over the baseline . 
so 
but that ' s what i ' m confused about . 
because i think i thought that our system was more like forty percent without the wiener filtering . 
no . 
it ' s like uh 
huh . 
well these are not 
is this with the new v . a . d ? 
no it ' s the old v . a . d . 
so my baseline was uh nine 
this is like the baseline is ninety five point six eight and eighty nine and 
so i mean if you can do all these in word errors it ' s a lot a lot easier actually . 
what was that ? 
sorry ? 
if you do all these in word error rates it ' s a lot easier right ? 
oh . 
okay okay okay . 
okay . 
errors right i don ' t have . 
because then you can figure out the percentages . 
it ' s all accuracies . 
yeah . 
the baseline is something similar to 
a i mean 
the the the baseline that you are talking about is the m . f . c . c . baseline right ? 
the yeah . 
or 
there are two baselines . 
okay . 
so the baseline one baseline is m . f . c . c . baseline . 
uhhuh . 
that when i said thirty percent improvement it ' s like m . f . c . c . baseline . 
so so 
so what ' s it start on ? 
the m . f . c . c . baseline is is what ? 
is at what level . 
it ' s the 
it ' s just the mel frequency and that ' s it . 
no what ' s what ' s the number ? 
uh so i don ' t have that number here . 
okay okay okay . 
i have it here . 
uh it ' s the v . a . d . plus the baseline actually . 
i ' m talking about the the m . f . c . c . plus i do a frame dropping on it . 
so that ' s like the word error rate is like four point three . 
four point three . 
like ten point seven . 
what ' s ten point seven ? 
it ' s a medium 
okay sorry . 
there ' s a well well matched medium mismatched and a high matched . 
uh . 
so i don ' t have the like the 
yeah . 
okay . 
four point three . 
so 
ten point seven . 
and forty . 
and 
forty percent is the high mismatch . 
okay . 
and that becomes like four point three . 
not changed . 
yeah . 
it ' s like ten point one . 
still the same . 
and the high mismatch is like eighteen point five . 
eighteen point five . 
five . 
and what were you just describing ? 
oh the one is this one is just the baseline plus the uh wiener filter plugged into it . 
but where ' s the uh online normalization and so on ? 
oh . 
okay . 
so 
sorry . 
so with the with the online normalization the performance was um ten 
okay so it ' s like four point three . 
uh 
and again that ' s the the ten point uh four and twenty point one . 
that was with online normalization and l . d . a . 
so the well matched has like literally not changed by adding online or l . d . a . on it . 
but the 
i mean even the medium mismatch is pretty much the same . 
and the high mismatch was improved by twenty percent absolute . 
okay . 
and what kind of number 
and what are we talking about here ? 
is this t . i . digits ? 
it ' s the it ' s italian . 
or 
i ' m talking about italian . 
italian ? 
yeah . 
and what did 
so what was the um uh corresponding number say for um uh the alcatel system for instance ? 
huh . 
do you know ? 
yeah . 
so it looks to be um 
you have it ? 
yep . 
it ' s three point four . 
uh eight point uh seven . 
and uh thirteen point seven . 
okay . 
yep . 
okay . 
so thanks . 
uhhuh . 
okay . 
so 
uh this is the single stage wiener filter . 
with the noise estimation was based on first ten frames . 
uhhuh . 
actually i started with using the v . a . d . to estimate the noise . 
and then i found that it works . 
it doesn ' t work for finnish and spanish . 
because the v . a . d . endpoints are not good to estimate the noise . 
because it cuts into the speech sometimes . 
so i end up overestimating the noise and getting a worse result . 
uhhuh . 
so it works only for italian by for using a v . a . d . to estimate noise . 
it works for italian because the vad was trained on italian . 
uhhuh . 
so uh 
so this was uh 
and so this was giving 
um 
this this was like not improving a lot on this baseline of not having the wiener filter on it . 
and 
so 
uh i ran this stuff with one more stage of wiener filtering on it . 
but the second time what i did was i estimated the new wiener filter based on the cleaned up speech and did uh smoothing in the frequency to to reduce the variance . 
uhhuh . 
i mean i have i ' ve i ' ve observed there are like a lot of bumps in the frequency when i do this wiener filtering . 
which is more like a musical noise or something . 
and so by adding another stage of wiener filtering the results on the speechdat - car was like 
um 
so i still don ' t have the word error rate . 
i ' m sorry about it . 
but the overall improvement was like fifty six point four six . 
this was again using ten frames of noise estimate and two stage of wiener filtering . 
and the rest is like the l . d . a . and the online normalization all remaining the same . 
uh 
so this was like compared to uh uh fifty seven is what you got by using the french telecom system . 
right ? 
no i don ' t think so . 
is it on italian ? 
no . 
this is over the whole speechdat - car . 
so 
oh yeah fifty seven 
point 
right . 
yeah . 
so the new the new wiener filtering schema is like some fifty six point four six . 
which is like one percent still less than what you got using the french telecom system . 
uhhuh . 
uhhuh . 
but it ' s a pretty similar number in any event . 
it ' s very similar . 
yeah . 
but again you ' re you ' re more or less doing what they were doing . 
right ? 
it ' s it ' s different in a sense like 
i ' m actually cleaning up the cleaned up spectrum . 
which they ' re not doing . 
they ' re what they ' re doing is they have two stage stages of estimating the wiener filter . 
yeah . 
but the final filter what they do is they they take it to their time domain by doing an inverse fourier transform . 
uhhuh . 
and they filter the original signal using that filter . 
which is like final filter is acting on the input noisy speech rather than on the cleaned up . 
so this is more like i ' m doing wiener filter twice . 
but the only thing is that the second time i ' m actually smoothing the filter and then cleaning up the cleaned up spectrum first level . 
okay . 
and so that that ' s that ' s what the difference is . 
and actually i tried it on the original clean i mean the original spectrum where like i the second time i estimate the filter but actually clean up the noisy speech rather the first output of the first stage . 
and that doesn ' t seems to be a giving i mean that much improvement . 
i i didn ' t run it for the whole case . 
and 
and what i what i tried was by using the same thing 
but uh 
so we actually found that the vad is very like crucial . 
i mean just by changing the vad itself gives you the a lot of improvement . 
uhhuh . 
by instead of using the current vad if you just take up the vad output from the channel zero when instead of using channel zero and channel one . 
because that was the that was the reason why i was not getting a lot of improvement for estimating the noise . 
so i just used the channel zero vad to estimate the noise so that it gives me some reliable markers for this noise estimation . 
what ' s a channel zero vad ? 
i ' m i ' m confused about that . 
um 
so it ' s like 
so it ' s the close talking microphone . 
yeah . 
the close talking without 
oh oh oh oh . 
so because the channel zero and channel one are like the same speech but only i mean the same endpoints . 
but the only thing is that the speech is very noisy for channel one . 
so you can actually use the output of the channel zero for channel one for the vad . 
i mean that ' s like a cheating method . 
right . 
i mean 
so are they going to 
what are they doing to do ? 
do we know yet ? 
about as far as what they ' re what the rules are going to be and what we can use . 
yeah . 
so actually i received a a new document describing this . 
yeah that ' s 
and what they did finally is to huh uh not to align the utterances but to perform recognition . 
um only on the close talking microphone . 
and to take the result of the recognition to get the boundaries uh of speech . 
which is the channel zero . 
so it ' s not like that ' s being done in one place or one time . 
and 
that ' s that ' s just a rule . 
and we ' d you you were permitted to do that ? 
is is that it ? 
uh i think they will send um files . 
but we we don ' t well apparently 
oh so they will send files . 
so everybody will have the same boundaries to work with ? 
yeah . 
yeah . 
but actually their alignment actually is not seems to be improving in like on all cases . 
okay . 
oh 
yeah . 
so what happened here is that um the overall improvement that they have with this method 
so well to be more precise what they have is they have these alignments . 
and then they drop the beginning silence and and the end silence . 
but they keep uh two hundred milliseconds before speech and two hundred after speech . 
and they keep the speech pauses also . 
um 
and the overall improvement over the m . f . c . c . baseline 
so when they just uh add this frame dropping in addition it ' s uh forty percent right ? 
uhhuh . 
fourteen percent i mean . 
uhhuh . 
yeah . 
um 
which is 
which is 
um 
which is the overall improvement . 
but in some cases it doesn ' t improve at all . 
like uh do you remember which case ? 
uhhuh . 
it gives like negative well in in like some italian and t . i . digits . 
yeah . 
some . 
right ? 
right . 
yeah . 
so by using the endpointed speech actually it ' s worse than the baseline in some instances . 
huh . 
which could be due to the word pattern . 
yeah . 
yeah . 
the other thing also is that fourteen percent is less than what you obtain using a real v . a . d . 
yeah our neural net . 
so without cheating like this . 
yeah yeah . 
so 
uh 
so i think this shows that there is still work . 
uh well working on the v . a . d . is still still important i think . 
yeah . 
uh 
can i ask just a a high level question ? 
can you just say like one or two sentences about wiener filtering and why why are people doing that ? 
huh . 
what ' s what ' s the deal with that ? 
okay . 
so 
the wiener filter it ' s it ' s like it ' s like you try to minimize 
i mean so the basic principle of wiener filter is like you try to minimize the uh uh difference between the noisy signal and the clean signal . 
if you have two channels . 
like let ' s say you have a clean signal and you have an additional channel where you know what is the noisy signal . 
and then you try to minimize the error between these two . 
uhhuh . 
uhhuh . 
so that ' s the basic principle . 
and you get 
you can do that 
i mean if if you have only a noisy signal at a level which you you try to estimate the noise from the assuming that the first few frames are noise . 
or if you have a voice activity detector uh you estimate the noise spectrum . 
uhhuh . 
and then you 
do you assume the noise is the same ? 
yeah . 
in yeah after the speech starts . 
uhhuh . 
so 
but that ' s not the case in uh many many of our cases . 
but it works reasonably well . 
i see . 
and and then you what you do is you uh 
so again 
i can write down some of these 
oh okay . 
yeah . 
and then you do this 
uh this is the transfer function of the wiener filter . 
so s . f . is a clean speech spectrum power spectrum . 
uhhuh . 
and n . is the noisy power spectrum . 
and so this is the transfer function . 
right . 
actually i guess . 
and 
yeah . 
yeah . 
and then you multiply your noisy power spectrum with this . 
you get an estimate of the clean power spectrum . 
i see . 
okay . 
so 
but the thing is that you have to estimate the s . f . from the noisy spectrum what you have . 
so you estimate the n . f . from the initial noise portions . 
and then you subtract that from the current noisy spectrum to get an estimate of the s . f . 
so sometimes that becomes zero . 
because you you don ' t have a true estimate of the noise . 
so the filter will have like sometimes zeros in it . 
uhhuh . 
because some frequency values will be zeroed out because of that . 
and that creates a lot of discontinuities across the spectrum because the filter . 
so 
uh 
so that ' s what that was just the first stage of wiener filtering that i tried . 
so is this um basically uh similar to just regular spectral subtraction ? 
it 
it ' s all pretty related . 
yeah . 
yeah . 
it ' s it ' s there ' s a there ' s a whole class of techniques where you try in some sense to minimize the noise . 
uhhuh . 
and it ' s typically a mean square sense uh uh uh in in in some way . 
and uh uh spectral subtraction is is uh uh one approach to it . 
do people use the wiener filtering in combination with the spectral subtraction typically ? 
or is are they sort of competing techniques ? 
not seen . 
they are very similar techniques . 
yeah . 
so it ' s like i haven ' t seen anybody using wiener filter with spectral subtraction . 
oh okay . 
uhhuh . 
i see . 
i see . 
i mean in the long run you ' re doing the same thing . 
but but there you make different approximations . 
uhhuh . 
yeah . 
and in spectral subtraction for instance there ' s a a an estimation factor . 
huh . 
you sometimes will figure out what the noise is . 
and you ' ll multiply that noise spectrum times some constant and subtract that . 
rather than 
and sometimes people 
even though this really should be in the power domain sometimes people work in the magnitude domain because it it it works better . 
uhhuh . 
uh you know . 
so why did you choose uh wiener filtering over some other one of these other techniques ? 
uh the reason was like we had this choice of using spectral subtraction wiener filtering and there was one more thing which which i ' m trying is this sub space approach . 
so 
stephane is working on spectral subtraction . 
oh okay . 
so i picked up 
so you ' re sort of trying them all . 
yeah . 
we just wanted to have a few noise production compensation techniques . 
uh . 
i see . 
and then pick some from that . 
oh okay . 
i i mean 
uhhuh . 
pick one . 
yeah i mean there ' s carmen ' s working on another on the vector taylor series . 
yeah v . a . d . 
yeah . 
so they were just kind of trying to cover a bunch of different things with this task and see you know what are what are the issues for each of them . 
uh . 
okay . 
yeah . 
that makes sense . 
yeah . 
uhhuh . 
uhhuh . 
um 
cool . 
thanks . 
so 
yeah . 
so one of one of the things that i tried like i said was to remove those zeros in the filter by doing some smoothing of the filter . 
uhhuh . 
like you estimate the edge of square . 
and then you do a smoothing across the frequency so that those zeros get like flattened out . 
uhhuh . 
and that doesn ' t seems to be improving by trying it on the first time . 
so what i did was like i did this . 
and then you i plugged in the one more the same thing but with the smoothed filter the second time . 
and that seems to be working . 
uhhuh . 
uhhuh . 
so that ' s where i got like fifty six point five percent improvement on speechdat - car with that . 
and 
so the other thing what i tried was i used still the ten frames of noise estimate . 
but i used this channel zero vad to drop the frames . 
so i ' m not still not estimating . 
and that has taken the performance to like sixty seven percent in speechdat - car . 
which is which which like sort of shows that by using a proper vad you can just take it to further better levels . 
and 
so 
so that ' s sort of like you know best case performance ? 
yeah . 
so far i ' ve seen sixty seven 
i mean no . 
i haven ' t seen like sixty seven percent . 
and uh 
using the channel zero vad to estimate the noise also seems to be improving . 
but i don ' t have the results for all the cases with that . 
so i used channel zero vad to estimate noise as a lesser 2 x frame . 
which is like everywhere i use the channel zero v . a . d . 
and that seems to be the best combination uh rather than using a few frames to estimate and then drop a channel . 
so i ' m i ' m still a little confused . 
is that channel zero information going to be accessible during this test ? 
nnn 
no . 
this is just to test whether we can really improve by using a better vad . 
uhhuh . 
uhhuh . 
so 
i mean so this is like the noise compensation is fixed . 
uhhuh . 
but you make a better decision on the endpoints . 
that ' s like seems to be 
uhhuh . 
so we 
so i mean which which means like by using this technique what we improve just the vad . 
yes . 
we can just take the performance by another ten percent or better . 
okay . 
so that that was just the uh reason for doing that experiment . 
and um 
yeah but this all these things i have to still try it on the t . i . digits . 
which is like i ' m just running . 
and there seems to be not improving a a lot on the t . i . digits . 
so i ' m like investigating that why it ' s not . 
and 
um 
um 
well after that . 
so 
uh 
so the other the other thing is like i ' ve been i ' m doing all this stuff on the power spectrum . 
so 
tried this stuff on the mel as well . 
mel and the magnitude and mel magnitude and all those things . 
but it seems to be the power spectrum seems to be getting the best result . 
so one of one of reasons i thought like doing the averaging after the filtering using the mel filter bank that seems to be maybe helping rather than trying it on the mel filter filtered outputs . 
uhhuh . 
uhhuh . 
so just 
makes sense . 
yeah . 
that ' s that ' s the only thing that i could think of why why it ' s giving improvement on the mel . 
and yep . 
so that ' s it . 
uh how about the subspace stuff ? 
subspace i ' m i ' m like that ' s still in a little bit in the back burner . 
because i ' ve been putting a lot effort on this to make it work on tuning things and other stuff . 
okay . 
so 
i was like going parallely . 
but not much of improvement . 
i ' m just have some skeletons ready . 
need some more time for it . 
okay . 
huh . 
that it ? 
yep . 
yep . 
cool . 
do you want to go stephane ? 
uh yeah . 
so i ' ve been uh working still on the spectral subtraction . 
um 
so to to remind you a little bit of of what i did before is just to apply some spectral subtraction with an overestimation factor . 
also to get um an estimate of the noise uh spectrum . 
and subtract this estimation of the noise spectrum from the uh signal spectrum but subtracting more when the s . n . r . is is uh low . 
which is a technique that it ' s often used . 
subtracting more meaning 
so you overestimate the noise spectrum . 
you multiply the noise spectrum by a factor uh which depends on the s . n . r . 
oh okay . 
so above twenty d . b . 
i see . 
it ' s one so you just subtract the noise . 
uhhuh . 
and then it ' s 
generally well i use actually a linear uh function of the s . n . r . 
uhhuh . 
which is bounded to like two or three when the s . n . r . is below zero d . b . 
uhhuh . 
uhhuh . 
um doing just this uh either on the f . f . t . bins or on the mel bands um doesn ' t yield any improvement . 
oh . 
um uh what are you doing with negative uh powers ? 
yeah . 
so there is also a threshold of course . 
because after subtraction you can have negative energies . 
uhhuh . 
and 
so what i i just do is to put uh to to add to put the threshold first and then to add a small amount of noise . 
which right now is speech shaped . 
um 
speech shaped ? 
yeah . 
so it ' s it has the overall overall energy . 
uh 
it has the overall power spectrum of speech . 
so with a bump around one kilohertz . 
so when when you talk about there being something less than zero after subtracting the noise is that at a particular frequency bin ? 
uhhuh . 
yeah . 
there can be frequency bins with negative values . 
okay . 
and so when you say you ' re adding something that has the overall shape of speech is that in a in a particular frequency bin ? 
or you ' re adding something across all the frequencies when you get these negatives ? 
for each frequencies i i ' m adding some uh noise . 
but the the amount of the amount of noise i add is not the same for all the frequency bins . 
uh . 
okay . 
i gotcha . 
right . 
uh right now i don ' t think if it makes sense to add something that ' s speech shaped . 
because then you have silence portion that have some spectra similar to the the overall speech spectra . 
uhhuh . 
but 
yeah . 
so this is something i can still work on . 
so what does that mean ? 
but 
huh . 
i ' m trying to understand what it means when you do the spectral subtraction and you get a negative . 
it means that at that particular frequency range you subtracted more energy than there was actually 
that means that 
uhhuh . 
yeah . 
so so yeah you have an an estimation of the noise spectrum . 
but sometimes of course it ' s as the noise is not perfectly stationary . 
sometimes this estimation can be uh too small . 
so you don ' t subtract enough . 
but sometimes it can be too large also if if the noise uh energy in this particular frequency band drops for some reason . 
uhhuh . 
uhhuh . 
huh . 
so in in an ideal word world if the noise were always the same then when you subtracted it the worst that you would get would be a zero . 
i mean the lowest you would get would be a zero . 
right . 
because if there was no other energy there you ' re just subtracting exactly the noise . 
uhhuh . 
yeah . 
yep there ' s all there ' s all sorts of uh deviations from the ideal here . 
i mean for instance you ' re you ' re talking about the signal and noise um at a particular point . 
and even if something is sort of stationary in terms of statistics there ' s no guarantee that any particular instantiation or piece of it is exactly a particular number or bounded by a particular range . 
uhhuh . 
so you ' re figuring out from some chunk of of of the signal what you think the noise is . 
then you ' re subtracting that from another chunk . 
uhhuh . 
and there ' s absolutely no reason to think that you ' d know that it wouldn ' t uh be negative in some places . 
uhhuh . 
huh . 
uh on the other hand that just means that in some sense you ' ve made a mistake . 
because you certainly have subtracted a bigger number than is due to the noise . 
uhhuh . 
um also we speak the whole where all this stuff comes from is from an assumption that signal and noise are uncorrelated . 
and that certainly makes sense in in in a statistical interpretation that you know over um all possible realizations that they ' re uncorrelated . 
uhhuh . 
or assuming uh ergodicity that that um across time uh it ' s uncorrelated . 
but if you just look at a quarter second uh and you cross multiply the two things uh you could very well uh end up with something that sums to something that ' s not zero . 
so in fact the two signals could have some relation to one another . 
and so there ' s all sorts of deviations from ideal in this . 
and and given all that you could definitely end up with something that ' s negative . 
but if down the road you ' re making use of something as if it is a power spectrum um then it can be bad to have something negative . 
now the other thing i wonder about actually is what if you left it negative ? 
what happens ? 
i mean because 
is that the log ? 
um are you taking the log before you add them up to the mel ? 
after that . 
no . 
after . 
right . 
so the thing is i wonder how if you put your thresholds after that i wonder how often you would end up with uh with negative values . 
but you will 
but you end up reducing some neighboring frequency bins in the average right ? 
when you add the negative to the positive value . 
which is the true estimate . 
yeah . 
but nonetheless uh you know these are it ' s another kind of smoothing right ? 
that you ' re doing . 
yeah . 
right . 
so you ' ve done your best shot at figuring out what the noise should be . 
and now then you ' ve subtracted it off . 
and then after that instead of instead of uh uh leaving it as is and adding things adding up some neighbors you artificially push it up . 
huh . 
which is you know it ' s there ' s no particular reason that that ' s the right thing to do either . 
right ? 
yeah yeah . 
so um 
uh 
in fact what you ' d be doing is saying well we ' re we ' re we ' re going to definitely diminish the effect of this frequency in this little frequency bin in the in the overall mel summation . 
it ' s just a thought . 
i i don ' t know if it would be 
yeah . 
sort of the opposite of that would be if if you find out you ' re going to get a negative number you don ' t do the subtraction for that bin . 
uhhuh . 
that is true . 
nnn yeah . 
uhhuh . 
that would be almost the opposite . 
although 
right ? 
instead of leaving it negative you don ' t do it . 
if your if your subtraction ' s going to result in a negative number you you don ' t do subtraction in that . 
yeah . 
but that means that in a situation where you thought that that the bin was almost entirely noise you left it . 
yeah . 
we just 
uh 
yeah i ' m just saying that ' s like the opposite . 
yeah . 
yeah . 
well yeah that ' s that ' s the opposite . 
yeah . 
uhhuh . 
yeah . 
and yeah . 
some people also if it ' s a negative value they uh re compute it using interpolation from the edges and bins . 
for frames frequency bins . 
yeah . 
well there are different things that you can do . 
oh . 
people can also uh reflect it back up and essentially do a full wave rectification instead of a instead of half wave . 
oh . 
but it was just a thought that that it might be something to try . 
uhhuh . 
uhhuh . 
yep . 
well actually i tried something else based on this um is to to put some smoothing . 
um because it seems to to help or it seems to help the wiener filtering . 
uhhuh . 
and 
huh 
so what i did is uh some kind of nonlinear smoothing . 
actually i have a recursion that computes 
yeah let me go back a little bit . 
actually when you do spectral subtraction you can uh find this this equivalent in the in the spectral domain . 
you can uh compute 
you can say that your spectral subtraction is a filter . 
um and the gain of this filter is the um signal energy minus what you subtract divided by the signal energy . 
and this is a gain that varies over time and you know of course uh depending on the on the noise spectrum and on the speech spectrum . 
and 
what happen actually is that during low s . n . r . values the gain is close to zero . 
but it varies a lot . 
huh 
and this this is the cause of musical noise and all these the the fact you we go below zero one frame and then you can have an energy that ' s above zero . 
uhhuh . 
and 
huh . 
so the smoothing is i did a smoothing actually on this gain uh trajectory . 
but it ' s the smoothing is nonlinear in the sense that i tried to not smooth if the gain is high . 
because in this case we know that uh the estimate of the gain is correct . 
because we we are not close to to to zero . 
um and to do more smoothing if the gain is low . 
huh 
um 
yeah . 
so 
well . 
basically that ' s this idea . 
and it seems to give pretty good results . 
uh although i ' ve just just tested on italian and finnish . 
and on italian it seems my result seems to be a little bit better than the wiener filtering . 
uhhuh . 
right ? 
yeah the one you showed yesterday . 
right ? 
yeah . 
uh i don ' t know if you have these the detailed improvements for italian finnish and spanish there . 
or you have just have your own . 
no i don ' t have for each . 
i i just just have the final number here . 
uhhuh . 
so these numbers he was giving before with the four point three and the ten point one and so forth those were italian right ? 
yeah yeah yeah . 
yeah . 
uh 
so so no . 
i actually didn ' t give you the number which is the final one . 
uh no . 
we ' ve 
which is after two stages of wiener filtering . 
i mean that was i just well like the overall improvement is like fifty six point five . 
right . 
so 
uhhuh . 
i mean his number is still better than what i got in the two stages of wiener filtering . 
yeah . 
right . 
on italian . 
but on finnish it ' s a little bit worse apparently . 
uhhuh . 
um 
but do you have numbers in terms of word error rates on on italian ? so just so you have some sense of reference ? 
yeah . 
uh so it ' s uh three point uh eight . 
uhhuh . 
am i right ? 
oh okay . 
yeah right . 
okay . 
and then uh uh nine point uh one . 
uhhuh . 
and finally uh sixteen point five . 
and this is um spectral subtraction plus what ? 
plus plus nonlinear smoothing . 
well it ' s the system it ' s exactly the the same system as sunil tried . 
online normalization and l . d . a ? 
but 
yeah . 
yeah . 
yeah . 
but instead of double stage wiener filtering it ' s it ' s this smoothed spectral subtraction . 
um yeah . 
right . 
what is it the um france telecom system uses ? 
for do they use spectral subtraction or wiener filtering ? 
or 
they use spectral subtraction . 
right . 
for what ? 
french telecom . 
it it ' s wiener filtering . 
oh it ' s it ' s wiener filtering . 
am i right ? 
sorry . 
well it ' s some kind of wiener filtering . 
oh . 
yeah filtering . 
yeah it ' s not exactly wiener filtering . 
but some variant of wiener filtering . 
yeah . 
i see . 
yeah . 
yeah . 
plus uh i guess they have some sort of cepstral normalization as well . 
they have like 
uhhuh . 
yeah . 
the just noise compensation technique is a variant of wiener filtering . 
plus they do some some smoothing techniques on the final filter . 
the they actually do the filtering in the time domain . 
huh . 
yeah . 
so they would take this h . f . squared back taking inverse fourier transform . 
huh . 
and they convolve the time domain signal with that . 
oh i see . 
and they do some smoothing on that final filter impulse response . 
huh . 
but they also have two two different smoothing . 
one in the time domain . 
i mean i ' m i ' m . 
and one in the frequency domain by just taking the first um coefficients of the impulse response . 
but 
so basically it ' s similar . 
i mean what you did it ' s similar . 
it ' s similar in the smoothing . 
because you have also two two kind of smoothing . 
and 
one in the time domain . 
yeah . 
and one in the frequency domain . 
yeah . 
the frequency domain . 
yeah . 
does the smoothing in the time domain help 
um 
well do you get this musical noise stuff with wiener filtering ? 
or is that only with uh spectral subtraction ? 
no you get it with wiener filtering also . 
yeah . 
does the smoothing in the time domain help with that ? 
or some other smoothing ? 
oh no . 
you still end up with zeros in the spectrum . 
yeah . 
sometimes . 
i mean it ' s not clear that these musical noises hurt us in recognition . 
huh . 
we don ' t know if they do . 
huh . 
yeah . 
i mean they they sound bad . 
but we ' re not listening to it usually . 
uhhuh . 
yeah i know . 
uhhuh . 
huh . 
uh actually the the smoothing that i did do here reduced the musical noise . 
well it 
uhhuh . 
huh . 
yeah . 
yeah . 
the 
well i cannot you cannot hear 
well actually what i did not say is that this is not in the f . f . t . bins . 
this is in the mel frequency bands . 
um 
so 
it could be seen as a a a smoothing in the frequency domain because i used in mel bands in addition and then the other phase of smoothing in the time domain . 
huh . 
but when you look at the spectrogram if you don ' t have any smoothing you clearly see like in silence portions and at the beginning and end of speech you see spots of high energy randomly distributed over the the spectrogram . 
uhhuh . 
uhhuh . 
um 
that ' s the musical noise ? 
which is musical noise . 
uhhuh . 
yeah . 
if if it if you listen to it 
uh if you do this in the f . f . t . bins then you have spots of energy randomly distributing . 
and if you if you re synthesize these spot sounds as like sounds . 
uhhuh . 
uh 
and 
well none of these systems by the way have i mean you both are are working with um our system that does not have the neural net . 
right ? 
uhhuh . 
yep . 
yeah . 
okay . 
yeah . 
so one would hope presumably that the neural net part of it would would improve things further as as they did before . 
yeah . 
um 
yeah . 
although if if we um look at the result from the proposals one of the reason uh the system with the neural net was um more than well around five percent better is that it was much better on highly mismatched condition . 
i ' m thinking for instance on the t . i . digits trained on clean speech and tested on noisy speech . 
uhhuh . 
uh for this case the system with the neural net was much better . 
uhhuh . 
but not much on the in the other cases . 
yeah . 
and 
if we have no uh spectral subtraction or wiener filtering um the system is uh we thought the neural neural network is much better than before . 
even in these cases of high mismatch . 
so maybe the neural net will help less . 
but um 
maybe . 
could you train a neural net to do spectral subtraction ? 
yeah . 
it could do a nonlinear spectral subtraction . 
uhhuh . 
but i don ' t know if it 
i mean you have to figure out what your targets are . 
yeah . 
i was thinking if you had a clean version of the signal and and a noisy version and your targets were the m . f . uh you know whatever frequency bins 
uhhuh . 
right . 
uhhuh . 
yeah well that ' s not so much spectral subtraction then . 
uhhuh . 
but but but it ' s but at any rate yeah people 
uh 
people do that ? 
yeah . 
in fact we had visitors here who did that . 
i think when you were here way back when . 
uhhuh . 
huh . 
uh 
people done lots of experimentation over the years with training neural nets . 
and it ' s not a bad thing to do . 
it ' s another approach . 
huh . 
uhhuh . 
i mean it ' s it um 
the objection everyone always raises which has some truth to it is that um it ' s good for mapping from a particular noise to clean . 
but then you get a different noise . 
uhhuh . 
and the experiments we saw that visitors did here showed that it there was at least some um gentleness to the degradation when you switched to different noises . 
it did seem to help . 
so that you ' re right . 
that ' s another another way to go . 
how did it compare on i mean for for good cases where it it uh stuff that it was trained on ? 
did it do pretty well ? 
oh yeah . 
it did very well . 
huh . 
yeah . 
huh . 
uhhuh . 
um 
but to some extent that ' s kind of what we ' re doing . 
i mean we ' re not doing exactly that . 
we ' re not trying to generate good examples . 
but by trying to do the best classifier you possibly can for these little phonetic categories 
uhhuh . 
you could say it ' s sort of built in . 
it ' s 
yeah . 
it ' s kind of built into that . 
huh . 
and and that ' s why we have found that it it does help . 
uhhuh . 
um 
so 
um 
yeah i mean we ' ll just have to try it . 
but i i would i would i would imagine that it will help some . 
i mean it we ' ll just have to see whether it helps more or less the same . 
but i would imagine it would help some . 
uhhuh . 
so in any event all of this i was just confirming that all of this was with a simpler system . 
yeah . 
yeah . 
okay ? 
um 
yeah so this is the um 
well actually this was kind of the first try with this spectral subtraction plus smoothing . 
uhhuh . 
and i was kind of excited by the result . 
uhhuh . 
um then i started to optimize the different parameters . 
and 
uh the first thing i tried to optimize is the um time constant of the smoothing . 
and it seems that the one that i chose for the first experiment was the optimal one . 
so uh 
it ' s amazing how often that happens . 
um 
so this is the first thing . 
um 
yeah another thing that i it ' s important to mention is um that this has this has some additional latency . 
um 
because when i do the smoothing uh it ' s a recursion that estimated the means so of the of the gain curve . 
and 
this is a filter that has some latency . 
and i noticed that it ' s better if we take into account this latency . 
so instead of using the current estimated mean to uh subtract the current frame it ' s better to use an estimate that ' s somewhere in the future . 
um 
and that ' s what causes the latency ? 
yeah . 
uhhuh . 
okay . 
you mean the the mean is computed based on some frames in the future also ? 
or or no ? 
it ' s the recursion . 
so it ' s it ' s the center recursion . 
right ? 
uhhuh . 
um 
and the latency of this recursion is around fifty milliseconds . 
one five ? 
one five ? 
five zero ? 
five zero . 
yeah . 
five zero . 
um 
yeah . 
huh 
i ' m sorry . 
why why is that delay coming ? 
like you estimate the mean ? 
yeah . 
the mean estimation has some delay . 
right ? 
i mean the the filter that that estimates the mean has a time constant . 
oh yeah . 
it isn ' t 
okay . 
so it ' s like it looks into the future also . 
yeah . 
okay . 
what if you just look into the past ? 
it ' s uh not as good . 
it ' s not bad . 
how by how much ? 
um it helps a lot over the the baseline . 
but huh 
by how much ? 
it 
it ' s around three percent um relative . 
worse . 
yeah . 
yeah . 
um 
huh . 
huh 
so uh 
it ' s depending on how all this stuff comes out . 
we may or may not be able to add any latency . 
yeah but 
yeah . 
so yeah it depends . 
uh actually it ' s it ' s it ' s three percent . 
right . 
huh . 
yeah . 
but i don ' t think we have to worry too much on that right now while you 
uhhuh . 
um 
so 
yeah i mean i think the only thing is that 
i would worry about it a little . 
uhhuh . 
because if we completely ignore latency and then we discover that we really have to do something about it we ' re going to be find ourselves in a bind . 
uhhuh . 
so um 
you know maybe you could make it twenty five . 
yeah . 
you know what i mean ? 
oh yes . 
yeah just you know just be be a little conservative . 
because we may end up with this crunch where all of a sudden we have to cut the latency in half or something . 
uhhuh . 
yeah . 
okay . 
um 
so 
yeah there are other things in the um algorithm that i didn ' t uh a lot yet . 
oh . 
which 
sorry . 
a quick question just about the latency thing . 
if if there ' s another part of the system that causes a latency of a hundred milliseconds is this an additive thing ? 
or or is yours hidden in that ? 
uhhuh . 
no . 
uh 
it ' s it ' s added . 
it ' s additive . 
uhhuh . 
okay . 
we can 
okay . 
we can do something in parallel also in some like some cases like if you wanted to do voice activity detection . 
uhhuh . 
and we can do that in parallel with some other filtering you can do . 
huh . 
so you can make a decision on that voice activity detection . 
and then you decide whether you want to filter or not . 
yeah . 
but by then you already have the sufficient samples to do the filtering . 
uhhuh . 
so 
so sometimes you can do it anyway . 
i mean couldn ' t 
uh 
i 
couldn ' t you just also i mean if you know that the the largest latency in the system is two hundred milliseconds don ' t you couldn ' t you just buffer up that number of frames ? 
and then everything uses that buffer . 
yeah . 
and that way it ' s not additive . 
well in fact everything is sent over in buffers because of 
isn ' t it the t . c . p . buffer some 
you mean the the data the super frame or something ? 
uhhuh . 
yeah . 
yeah . 
yeah . 
yeah but that has a variable latency . 
because the last frame doesn ' t have any latency . 
uhhuh . 
and first frame has a twenty framed latency . 
so you can ' t rely on that latency all the time . 
yeah . 
because 
yeah . 
i mean the transmission over over the air interface is like a buffer . 
twenty frame . 
yeah . 
twenty four frames . 
yeah . 
so 
but the only thing is that the first frame in that twenty four frame buffer has a twenty four frame latency . 
and the last frame doesn ' t have any latency . 
uhhuh . 
because it just goes as 
yeah . 
yeah i wasn ' t thinking of that one in particular . 
but more of you know if if there is some part of your system that has to buffer twenty frames uh can ' t the other parts of the system draw out of that buffer and therefore not add to the latency ? 
yeah . 
yeah . 
and and that ' s sort of one of the 
all of that sort of stuff is things that they ' re debating in their standards committee . 
oh . 
huh ? 
uhhuh . 
yeah . 
so 
um 
there is uh these parameters that i still have to to look at . 
like i played a little bit with this overestimation factor . 
uh 
but i still have to to look more at this . 
um 
at the level of noise i add after uh i know that adding noise helped um the system just using spectral subtraction without smoothing . 
but i don ' t know right now if it ' s still important or not and if the level i choose before is still the right one . 
same thing for the shape of the the noise . 
maybe it would be better to add just white noise instead of speech shaped noise . 
that ' d be more like the j . rasta thing in a sense . 
uhhuh . 
yeah . 
um yep . 
uh and another thing is to 
yeah . 
for this i just use as noise estimate the mean uh spectrum of the first twenty frames of each utterance . 
i don ' t remember for this experiment what did you use for these two stage . 
i used ten just ten frames . 
the ten frames ? 
yeah because 
i mean the reason was like in t . i . digits i don ' t have a lot . 
i had twenty frames most of the time . 
uhhuh . 
um 
but so what ' s this result you told me about the fact that if you use more than ten frames you can improve by 
well that ' s that ' s using the channel zero . 
if i use a channel zero vad to estimate the noise . 
oh okay . 
which 
but this is ten frames plus plus 
channel zero dropping . 
channel 
uh no . 
these results with two stage wiener filtering is ten frames . 
huh . 
oh this 
but possibly more . 
i mean if channel one v . a . d . gives you 
yeah . 
uhhuh . 
yeah . 
yeah . 
okay . 
yeah . 
but in this experiment i did i didn ' t use any v . a . d . 
i just used the twenty first frame to estimate the noise . 
and so i expected it to be a little bit better if uh i use more more frames . 
um 
okay that ' s it for spectral subtraction . 
the second thing i was working on is to um try to look at noise estimation huh and using some technique that doesn ' t need voice activity detection . 
um 
and for this i simply used some code that uh i had from from belgium . 
which is technique that um takes a bunch of frame . 
um 
and for each frequency bands of this frame takes a look at the minima of the energy . 
and then average these minima and take this as an an energy estimate of the noise for this particular frequency band . 
and there is something more to this actually . 
what is done is that uh these minima are computed um based on um high resolution spectra . 
so i compute an f . f . t . based on the long uh signal frame . 
which is sixty four millisecond . 
so you have one minimum for each frequency ? 
what what i what i uh i do actually is to take a bunch of to take a tile on the spectrogram . 
and this tile is five hundred milliseconds long and two hundred hertz wide . 
huh . 
and this tile 
uh in this tile appears like the harmonics if you have a voiced sound . 
because it ' s it ' s the f . t . t . bins . 
and when you take the the minima of of these this tile 
when you don ' t have speech these minima will give you some noise level estimate . 
if you have voiced speech these minima will still give you some noise estimate because the minima are between the harmonics . 
and if you have other other kind of speech sounds then it ' s not the case . 
but if the time frame is long enough uh like five hundred milliseconds seems to be long enough you still have portions which uh are very close which minima are very close to the noise energy . 
i ' m confused . 
huh . 
you said five hundred milliseconds . 
but you said sixty four milliseconds . 
which is which ? 
what 
sixty four milliseconds is to compute the f . f . t . uh bins . 
the the f . f . t . 
yeah . 
yeah . 
um 
actually it ' s better to use sixty four milliseconds because um if you use thirty milliseconds then uh because of the this short windowing and at low pitch uh sounds the harmonics are not uh correctly separated . 
uhhuh . 
so if you take these minima it they will overestimate the noise a lot . 
so you take sixty four millisecond f . f . t . ' s and then you average them over five hundred ? 
or 
uh what do you do over five hundred ? 
so i take to i take a bunch of these sixty four millisecond frame to cover five hundred milliseconds . 
uh . 
okay . 
and then i look for the minima . 
i see . 
huh . 
on the on on the bunch of uh fifty frames right ? 
i see . 
huh . 
so the interest of this is that as with this technique you can estimate some reasonable noise spectra with only five hundred milliseconds of of signal . 
so if the the the noise varies a lot uh you can track better track the noise . 
uhhuh . 
which is not the case if you rely on the voice activity detector . 
so even if there are no speech pauses you can track the noise level . 
the only requirement is that you must have in these five hundred milliseconds segment you must have voiced sound at least . 
because this these will help you to to track the the noise level . 
um 
so what i did is just to simply replace the v . a . d . based uh noise estimate by this estimate . 
first on speechdat - car . 
well only on speechdat - car actually . 
and it ' s uh slightly worse . 
like one percent relative compared to the v . a . d . based estimates . 
um 
i think the reason why it ' s not better is that the speechdat - car noises are all stationary . 
um 
so 
there really is no need to have something that ' s adaptive . 
uhhuh . 
and uh 
well they are mainly stationary . 
um 
but i expect maybe some improvement on t . i . digits . 
because nnn in this case the noises are all sometimes very variable . 
uh so i have to test it . 
huh . 
but are you comparing with something 
i ' m i ' m a little confused again . 
it 
uh when you compare it with the v . a . d . based which v . a . 
uhhuh . 
it ' s 
is this is this the 
it ' s the france telecom based spectra uh wiener filtering and v . a . d . 
so it ' s their system . 
but just i replace their noise estimate by this one . 
oh you ' re not doing this with our system ? 
in i ' m not . 
no no . 
yeah . 
it ' s our system . 
but with just the wiener filtering from their system . 
right ? 
huh . 
okay . 
yeah . 
actually the best system that we still have is uh our system but with their noise compensation scheme . 
right ? 
right . 
so i ' m trying to improve on this and by by replacing their noise estimate by uh something that might be better . 
but 
okay . 
but the spectral subtraction scheme that you reported on also requires a a noise estimate . 
yeah . 
yeah . 
but i 
couldn ' t you try this for that ? 
do you think it might help ? 
not yet . 
because i did this in parallel . 
and i was working on one and the other . 
i see . 
i see . 
yeah . 
um 
yeah for for sure i will . 
yeah . 
i can try also huh the spectral subtraction . 
okay . 
so i ' m also using that new noise estimate technique on this wiener filtering what i ' m trying . 
uhhuh . 
so i i have like some experiments running i don ' t have the results . 
yeah . 
yeah . 
so 
i don ' t estimate the noise on the ten frames but use his estimate . 
uhhuh . 
yeah . 
um 
yeah . 
i um also implemented a um spectral whitening idea . 
which is in the um ericsson proposal . 
uh the idea is just to um flatten the log uh spectrum um and to flatten it more if the the probability of silence is higher . 
so in this way you can also reduce somewhat reduce the musical noise . 
and you reduce the variability if you have different noise shapes . 
because the the spectrum becomes more flat in the silence portions . 
um 
yeah . 
with this no improvement . 
uh but there are a lot of parameters that we can play with . 
and 
um 
actually this this could be seen as a soft version of the frame dropping . 
because um you could just put the threshold and say that below the threshold i will flatten completely flatten the the spectrum . 
and above this threshold uh keep the same spectrum . 
so it would be like frame dropping . 
because during the silence portions which are below the threshold of voice activity probability uh you would have some kind of dummy frame . 
which is a perfectly flat spectrum . 
and this uh whitening is something that ' s more soft because um you whiten you just uh have a function the whitening is a function of the speech probability . 
so it ' s not a hard decision . 
uhhuh . 
um 
so i think maybe it can be used together with frame dropping and when we are not sure about if it ' s speech or silence . 
well maybe it has something do with this . 
it ' s interesting . 
i mean um you know in in j . rasta we were essentially adding in uh white uh white noise dependent on our estimate of the noise . 
uhhuh . 
on the overall estimate of the noise . 
uh i think it never occurred to us to use a probability in there . 
uhhuh . 
you could imagine one that that that made use of where where the amount that you added in was uh a function of the probability of it being speech or noise . 
uhhuh . 
uhhuh . 
yeah 
yeah right now it ' s a constant that just depending on the the noise spectrum . 
there ' s 
yeah . 
uhhuh . 
because that that brings in sort of powers of classifiers that we don ' t really have in uh this other estimate . 
uhhuh . 
so it could be it could be interesting . 
uhhuh . 
uhhuh . 
what what what point does the uh system stop recording ? 
how much 
it ' ll keep going till i guess when they run out of disk space . 
it went a little long ? 
i mean disk 
but 
i think we ' re okay . 
so 
okay . 
yeah . 
uh 
yeah so there are with this technique there are some 
i just did something exactly the same as as the ericsson proposal . 
but um the probability of speech is not computed the same way . 
and i think for yeah for a lot of things actually a a good speech probability is important . 
like for frame dropping you improve like you can improve from ten percent as sunil showed if you use the channel zero speech probabilities . 
uhhuh . 
uhhuh . 
for this it might help . 
um 
uhhuh . 
so yeah . 
uh 
so yeah . 
the next thing i started to do is to uh try to develop a better voice activity detector . 
and 
um 
i 
um 
yeah for this i think we can maybe try to train the neural network for voice activity detection on all the data that we have including all the speechdat - car data . 
um 
and so i ' m starting to obtain alignments on these databases . 
um and the way i i do that is that i just use the h . t . k . system but i train it only on the close talking microphone . 
and then i aligned i obtained the viterbi alignment of the training utterances . 
um 
it seems to be 
uh 
actually what i observed is that for italian it doesn ' t seem there seems to be a problem . 
no . 
well . 
so it doesn ' t seems to help by their use of channel zero or channel one . 
because 
what ? 
uh you mean their the frame dropping right ? 
yeah . 
yeah it doesn ' t . 
yeah . 
so but actually the v . a . d . was trained on italian also . 
italian . 
so um 
the the current v . a . d . that we have was trained on uh spine right ? 
italian and t . i . digits with noise and 
t . i . digits . 
uh yeah . 
and it seems to work on italian but not on the finnish and spanish data . 
so maybe one reason is that finnish and spanish noise are different . 
and 
actually we observed we listened to some of the utterances and sometimes for finnish there is music in the recordings and strange things . 
right ? 
yeah . 
um 
yeah so the idea was to train all the databases and obtain an alignment to train on these databases . 
and um 
also to um try different kind of features uh as input to the v . a . d . network . 
and 
we came up with a bunch of features that we want to try . 
like um the spectral slope the um the degree degree of voicing with the features that uh we started to develop with carmen um with uh the correlation between bands and different kind of features . 
yeah . 
uhhuh . 
and yeah . 
the energy also . 
the energy . 
yeah of course . 
yeah . 
yeah right . 
yeah . 
okay . 
well hans - guenter will be here next week . 
so i think he ' ll be interested in all all of these things . 
and so . 
uhhuh . 
huh . 
okay . 
shall we uh do digits ? 
yeah . 
want to go ahead morgan ? 
sure . 
i think for two years we were two months uh away from being done . 
and what was that morgan ? 
what project ? 
uh the uh torrent chip . 
oh . 
yeah . 
we were two 
we were 
yeah . 
uh uh we went through it jim and i went through old emails at one point . 
and and for two years there was this thing saying yeah we ' re we ' re two months away from being done . 
it was very very believable schedules too . 
i mean we went through and with the schedules and we 
it was true for two years . 
yeah . 
oh yeah . 
it was very true . 
so should we just do the same kind of deal where we go around and do uh status report kind of things ? 
okay . 
and i guess when sunil gets here he can do his last or something . 
uhhuh . 
so 
yeah . 
so we probably should wait for him to come before we do his . 
okay . 
okay . 
that ' s a good idea . 
yeah . 
yeah . 
any objection ? 
do 
all in favor . 
okay . 
do you want to start morgan ? 
do you have anything ? 
or 
uh i don ' t do anything . 
i 
no i mean i i ' m involved in discussions with with people about what they ' re doing . 
but i think they ' re since they ' re here they can talk about it themselves . 
okay . 
so should i go so that uh 
yeah . 
why don ' t you go ahead barry ? 
you ' re going to talk about aurora stuff per se . 
okay . 
okay . 
um 
well this past week i ' ve just been uh getting down and dirty into writing my my proposal . 
so 
um 
huh . 
i just finished a section on uh on talking about these intermediate categories that i want to classify um as a as a middle step . 
and um 
i hope to hope to get this um a full rough draft done by uh monday so i can give it to morgan . 
when is your uh meeting ? 
um my meeting ? 
yeah . 
with uh 
oh oh you mean the the quals . 
the quals . 
yeah . 
uh the quals are happening in july twenty fifth . 
oh ! 
soon . 
yeah . 
d day . 
uhhuh . 
yeah . 
uhhuh . 
so is the idea you ' re going to do this paper ? 
and then you pass it out to everybody ahead of time ? 
and 
right right . 
so you write up a proposal and give it to people ahead of time . 
and you have a short presentation . 
and um 
and then um then everybody asks you questions . 
huh . 
yeah . 
i remember now . 
yep . 
so um 
i was just going to ask do you want to say any a little bit about it ? 
or 
oh . 
uh a little bit about 
huh . 
what you ' re what you ' re going to 
you said you were talking about the uh particular features that you were looking at . 
oh . 
the the 
or 
right . 
well i was 
um 
i think one of the perplexing problems is 
um 
for a while i was thinking that i had to come up with a complete set of intermediate features intermediate categories to to classify right away . 
but what i ' m thinking now is i would start with with a reasonable set . 
something something like um um like uh regular phonetic features . 
just to just to start off that way . 
and do some phone recognition . 
um build a system that uh classifies these um these uh these intermediate categories using uh multi band techniques . 
combine them and do phoneme recognition . 
look at 
then i would look at the errors produced in the phoneme recognition and say okay well i could probably reduce the errors if i included this extra feature or this extra intermediate category . 
that would that would reduce certain confusions over other confusions . 
and then and then reiterate . 
um build the intermediate classifiers . 
uh do phoneme recognition . 
look at the errors . 
and then postulate new or remove um intermediate categories . 
and then do it again . 
so you ' re going to use timit ? 
um for that for that part of the the process yeah i would use timit . 
uhhuh . 
and 
um 
then 
after after uh um doing timit 
right . 
um that ' s that ' s um that ' s just the the phone recognition task . 
uhhuh . 
yeah . 
uh i wanted to take a look at um things that i could model within word . 
so i would i would then shift the focus to um something like switchboard . 
uh where i ' d i would be able to um to model um intermediate categories that span across phonemes . 
not just within the phonemes themselves . 
uhhuh . 
um 
and then do the same process there um on on a large vocabulary task like switchboard . 
uh 
and for that 
for that part i would i ' d use the s r i recognizer . 
since it ' s already set up for for switchboard . 
and i ' d run some some sort of tandem style processing with uh my intermediate classifiers . 
oh so that ' s why you were interested in getting your own features into the s r i files . 
yeah that ' s why i i was asking about that . 
yeah . 
yeah . 
yeah . 
um 
and 
i guess that ' s that ' s it . 
any any questions ? 
sounds good . 
so you just have a few more weeks . 
huh ? 
um yeah . 
a few more . 
it ' s about a month from now ? 
it ' s a it ' s a month and and a week . 
yeah . 
yeah . 
so uh you want to go next dave ? 
and we ' ll do 
oh . 
okay . 
sure . 
so um 
last week i finally got results from the s r i system about this mean subtraction approach . 
and um we we got an improvement uh in word error rate training on the t i digits data set and testing on meeting recorder digits of um six percent to four point five percent . 
um on the on the far mike data . 
using p z m f . 
but um the near mike performance worsened um from one point two percent to two point four percent . 
and um 
why would that be um considering that we actually got an improvement in near mike performance using h t k ? 
and so 
uh with some input from uh andreas i have a theory in two parts . 
um 
first of all h t k sorry s the s r i system is doing channel adaptation . 
and so h t k wasn ' t 
um 
so this 
um 
this mean subtraction approach will do a kind of channel normalization . 
and so that might have given the h t k use of it a boost that wouldn ' t have been applied in the s r i case . 
and also um the andreas pointed out the s r i system is using more parameters . 
it ' s got finer grained acoustic models . 
so those finer grained acoustic models could be more sensitive to the artifacts in the re synthesized audio . 
um 
and me and barry were listening to the re synthesized audio . 
and sometimes it seems like you get of a bit of an echo of speech in the background . 
and so that seems like it could be difficult for training . 
because you could have different phones lined up with a different foreground phone um depending on the timing of the echo . 
so um 
i ' m going to try training on a larger data set . 
and then uh the system will have seen more examples of these artifacts and hopefully will be more robust to them . 
so i ' m planning to use the macrophone set of um read speech . 
and um 
huh 
i had another thought just now . 
which is uh remember we were talking before about we were talking in our meeting about uh this stuff that some of the other stuff that avendano did . 
where they were um getting rid of low energy sections . 
um 
uh 
if you 
if you did a high pass filtering as hirsch did in late eighties to reduce some of the effects of reverberation uh uh avendano and hermansky were arguing that uh perhaps one of the reasons for that working was may not have even been the filtering so much but the fact that when you filter a an all positive power spectrum you get some negative values . 
and you got to figure out what to do with them if you ' re going to continue treating this as a power spectrum . 
so what what hirsch did was uh set them to zero . 
set the negative values to zero . 
so if you imagine a a waveform that ' s all positive . 
which is the time trajectory of energy . 
um and uh shifting it downwards and then getting rid of the negative parts that ' s essentially throwing away the low energy things . 
and it ' s the low energy parts of the speech where the reverberation is most audible . 
you know you have the reverberation from higher energy things showing up in 
so in this case you have some artificially imposed reverberation like thing . 
i mean you ' re getting rid of some of the other effects of reverberation . 
but because you have these non causal windows you ' re getting these funny things coming in . 
uh at 
and 
um 
what if you did 
i mean there ' s nothing to say that the the processing for this re synthesis has to be restricted to trying to get it back to the original according to some equation . 
uhhuh . 
i mean you also could uh just try to make it nicer . 
uhhuh . 
and one of the things you could do is you could do some sort of v a d like thing . 
and you actually could take very low energy sections and set them to some some uh very low or or near zero value . 
uhhuh . 
i mean 
uh i ' m just saying if in fact it turns out that that these echoes that you ' re hearing are uh 
or pre echoes . 
whichever they are . 
are are uh part of what ' s causing the problem you actually could get rid of them . 
uhhuh . 
be pretty simple . 
okay . 
i mean you do it in a pretty conservative way . 
so that if you made a mistake you were more likely to keep in an echo than to throw out speech . 
huh . 
um what is the reverberation time like there ? 
in in this room ? 
on uh the the one what the in the speech that you are you are using like . 
uh 
yeah . 
i i i i don ' t know . 
so it ' s this room . 
it ' s uh 
oh this room . 
it ' s it ' s this room . 
okay . 
so 
so it ' s these are just microphone 
this close microphone and a distant microphone he ' s doing these different tests on . 
oh . 
uh we should do a measurement in here . 
i think we never have . 
i think it ' s i would guess uh point seven point eight seconds uh r t sixty . 
huh . 
something like that . 
uhhuh . 
but it ' s you know it ' s this room . 
so 
okay . 
uhhuh . 
uh 
but the other thing is he ' s putting in 
i was using the word reverberation in two ways . 
he ' s also putting in uh a 
he ' s taking out some reverberation . 
but he ' s putting in something . 
because he has averages over multiple windows stretching out to twelve seconds . 
which are then being subtracted from the speech . 
and since you know what you subtract sometimes you ' ll be you ' ll be subtracting from some larger number . 
and sometimes you won ' t . 
uhhuh uhhuh . 
and 
so you can end up with some components in it that are affected by things that are seconds away . 
uh and if it ' s a low energy portion you might actually hear some funny things . 
yeah . 
one thing um i noticed is that um the mean subtraction seems to make the p z m signals louder after they ' ve been re synthesized . 
so i was wondering is it possible that one reason it helped with the aurora baseline system is just as a kind of gain control ? 
because some of the p z m signals sound pretty quiet if you don ' t amplify them . 
uhhuh . 
i don ' t see why why your signal is louder after processing . 
because 
yeah i don ' t know why uh either . 
yeah . 
i don ' t think just multiplying the signal by two would have any effect . 
uhhuh . 
oh . 
okay . 
yeah . 
i mean i think if you really have louder signals what you mean is that you have better signal to noise ratio . 
well well 
so if what you ' re doing is improving the signal to noise ratio then it would be better . 
uhhuh . 
but just it being bigger if with the same signal to noise ratio 
it it wouldn ' t affect things . 
yeah . 
okay . 
no . 
well the system is use the absolute energy so it ' s a little bit dependent on on the signal level . 
but not so much i guess . 
well yeah . 
but it ' s trained and tested on the same thing . 
huh . 
uhhuh . 
so if the if the if you change in both training and test the absolute level by a factor of two it will have no effect . 
yeah . 
did you add this data to the training set for the aurora ? 
or you just tested on this ? 
uh 
um 
did i what ? 
sorry ? 
well morgan was just saying that uh as long as you do it in both training and testing it shouldn ' t have any effect . 
yeah . 
but i i was sort of under the impression that you just tested with this data . 
i 
i 
you didn ' t train it also . 
i 
right . 
i trained on clean t i digits . 
i i did the mean subtraction on clean t i digits . 
but i didn ' t i ' m not sure if it made the clean t i digits any louder . 
oh i see . 
i only remember noticing it made the um p z m signal louder . 
okay . 
well i don ' t understand then . 
yeah . 
huh . 
i don ' t know . 
if it ' s if it ' s like if it ' s trying to find a a reverberation filter it could be that this reverberation filter is making things quieter . 
and then if you take it out that taking it out makes things louder . 
i mean 
uh no . 
i mean uh there ' s there ' s nothing inherent about removing if you ' re really removing . 
nuh huh . 
the mean . 
uh uh then i don ' t see how that would make it louder . 
okay . 
yeah . 
i see . 
yeah . 
okay . 
so it might be just some 
so i should maybe listen to that stuff again . 
yeah . 
it might just be some artifact of the processing that that uh if you ' re 
uh yeah . 
oh okay . 
i don ' t know . 
i wonder if there could be something like uh for for the p z m data . 
uh you know if occasionally uh somebody hits the table or something you could get a spike . 
uh 
i ' m just wondering if there ' s something about the um you know doing the mean normalization where uh it it could cause you to have better signal to noise ratio . 
um 
well you know there is this . 
wait a minute . 
it it maybe 
if um 
subtracting the the mean log spectrum is is is like dividing by the spectrum . 
so depending what you divide by if your if your estimate is off and sometimes you ' re you ' re you ' re getting a small number you could make it bigger . 
uhhuh . 
uhhuh . 
so it ' s it ' s just a a question of 
there ' s it it could be that there ' s some normalization that ' s missing . 
or something . 
uhhuh . 
to make it 
uh you ' d think it shouldn ' t be larger . 
but maybe in practice it is . 
huh . 
that ' s something to think about . 
i don ' t know . 
i had a question about the system the s r i system . 
so you trained it on t i digits ? 
but except this it ' s exactly the same system as the one that was tested before and that was trained on macrophone . 
right ? 
so on t i digits it gives you one point two percent error rate . 
and on macrophone it ' s still o point eight . 
uh but is it exactly the same system ? 
uh 
i think so . 
if you ' re talking about the macrophone results that andreas had about um a week and a half ago i think it ' s the same system . 
huh . 
uhhuh . 
so you use v t uh vocal tract length normalization and um like m l l r transformations also ? 
uhhuh . 
and 
that ' s 
i ' m sorry . 
all that stuff . 
was his point eight percent uh a a result on testing on macrophone or or training ? 
it was training on macrophone and testing yeah on on meeting digits . 
oh . 
so that was done already . 
so we were 
uh and it ' s point eight . 
okay . 
uhhuh . 
okay . 
yeah . 
i i ' ve just been testing the new aurora front end with well aurora system actually . 
so front end and h t k um acoustic models on the meeting digits . 
and it ' s a little bit better than the previous system . 
we have i have two point seven percent error rate . 
and before with the system that was proposed it ' s what it was three point nine . 
so 
oh that ' s a lot better . 
we are getting better . 
so what 
with the with the h t k back end what we have for aurora ? 
and 
yeah . 
two point seven . 
i know in the meeting like . 
on the meeting we have two point seven . 
right . 
oh . 
that ' s with the new i i r filters ? 
uh yeah yeah . 
okay . 
so yeah . 
we have the new l d a filters . 
and 
i think maybe i didn ' t look but one thing that makes a difference is this d c offset compensation . 
uh uh do did you have a look at at the uh meeting digits if they have a d c component ? 
or 
i 
i didn ' t . 
no . 
oh . 
huh . 
no the d c component could be negligible . 
i mean if you are recording it through a mike . 
i mean any all of the mikes have the d c removal some capacitor sitting right in that bias it . 
yeah . 
but this 
uh uh uh no . 
because uh there ' s a sample and hold in the a to d . 
and these these typically do have a d c offset . 
oh okay . 
and and they can be surprisingly large . 
it depends on the electronics . 
oh . 
so it is the digital 
okay . 
it ' s the a to d that introduces the d c in . 
yeah the microphone isn ' t going to pass any d c . 
yeah yeah yeah . 
but but 
okay . 
you know unless 
actually there are instrumentation mikes that that do pass go down to d c . 
but but 
uhhuh . 
uh 
no it ' s the electronics . 
and they and 
uhhuh . 
then there ' s amplification afterwards . 
and you can get 
i think it was 
i think it was in the wall street journal data that that 
i can ' t remember one of the darpa things . 
there was this big d d c offset . 
uhhuh . 
we didn ' t we didn ' t know about for a while while we were messing with it . 
and we were getting these terrible results . 
and then we were talking to somebody and they said oh yeah didn ' t you know . 
everybody knows that . 
there ' s all this d c offset in 
so yes . 
you can have d c offset in the data . 
oh okay . 
okay . 
yeah . 
so was that was that everything dave ? 
oh . 
and i also um did some experiments about normalizing the phase . 
um 
so i i came up with a web page that people can take a look at . 
and um 
the interesting thing that i tried was um adam and morgan had this idea . 
um since my original attempts to um take the mean of the phase spectra over time and normalize using that by subtracting that off didn ' t work um so well that we thought that might be due to um problems with um the arithmetic of phases . 
they they add in this modulo two pi way . 
and 
um 
there ' s reason to believe that that approach of taking the mean of the phase spectrum wasn ' t really mathematically correct . 
so what i did instead is i took the mean of the f f t spectrum without taking the log or anything and then i took the phase of that . 
and i subtracted that phase off . 
to normalize . 
but that um didn ' t work either . 
see we have a different interpretation of this . 
he says it doesn ' t work . 
i said i think it works magnificently . 
but just not for the task we intended . 
uh it gets rid of the speech . 
uh gets rid of the speech . 
what does it leave ? 
uh it leaves you know it leaves the junk . 
i mean i i think it ' s it ' s tremendous . 
oh wow ! 
you see all he has to do is go back and reverse what he did before . 
and he ' s really got something . 
well could you take what was left over and then subtract that ? 
exactly . 
yeah . 
yeah you got it . 
yeah . 
so it ' s it ' s a general rule . 
oh it ' s 
just listen very carefully to what i say . 
and do the opposite . 
including what i just said . 
and yeah that ' s everything . 
all set ? 
do you want to go stephane ? 
um yeah . 
maybe concerning these still these meeting digits . 
i ' m more interested in trying to figure out what ' s still the difference between the s r i system and the aurora system . 
and 
um 
yeah so i think i will maybe train like gender dependent models . 
because this is also one big difference between the two systems . 
um 
the other differences were the fact that maybe the acoustic models of the s r i are more s r i system are more complex . 
but uh chuck you did some experiments with this . 
and 
it didn ' t seem to help in the h t k system . 
it was hard to to have some some improvement with this . 
um 
well it sounds like they also have 
he he ' s saying they have all these uh uh different kinds of adaptation . 
uhhuh . 
you know they have channel adaptation . 
yeah . 
they have speaker adaptation . 
right . 
yeah . 
yeah . 
yeah yeah . 
well there ' s also the normalization . 
like they do 
um 
i ' m not sure how they would do it when they ' re working with the digits . 
the vocal 
but like in the switchboard data there ' s um conversation side normalization for the non c zero components . 
and then utterance normalization for the c zero components . 
yeah . 
yeah this is another difference . 
their normalization works like on on the utterance levels . 
uhhuh . 
but we have to do it . 
we have a system that does it on line . 
so it might be 
right . 
it might be better with 
it might be worse if the channel is constant . 
yeah . 
or 
nnn . 
and the acoustic models are like triphone models or or is it the whole word ? 
s r i it ' s it ' s 
s r i . 
yeah . 
yeah . 
i guess it ' s triphones . 
it ' s triphone . 
i think it ' s probably more than that . 
huh . 
i mean so they they have i i think they use these uh uh genone things . 
so there ' s there ' s these kind of uh uh pooled models . 
and and they can go out to all sorts of dependencies . 
oh it ' s like the tied state . 
so 
uhhuh . 
they have tied states . 
and i think 
i i i don ' t i ' m i ' m just guessing here . 
okay . 
but i think i think they they don ' t just have triphones . 
i think they have a range of of uh dependencies . 
uhhuh . 
uhhuh . 
uhhuh . 
huh . 
and 
yeah . 
well . 
um 
well the first thing i that i want to do is just maybe these gender things . 
uh 
and maybe see with andreas if 
well i i don ' t know how much it helps what ' s the model . 
so 
so the stuff on the numbers you got the two point seven is that using the same training data that the s r i system used and got one point two ? 
that ' s right . 
so it ' s the clean t i digits training set . 
so exact same training data ? 
right . 
uhhuh . 
okay . 
i guess you used the clean training set . 
right . 
for with the s r i system . 
uhhuh . 
well . 
you know the the aurora baseline is set up with these um this version of the clean training set that ' s been filtered with this g seven one two filter . 
and 
um to train the s r i system on digits s andreas used the original t i digits . 
um under u doctor speech data t i digits . 
which don ' t have this filter . 
but i don ' t think there ' s any other difference . 
uhhuh . 
uhhuh . 
yeah . 
so is that uh are are these results comparable ? 
so you you were getting with the uh aurora baseline something like two point four percent on clean t i digits when uh training the s r i system with clean t r digits t i digits . 
right ? 
um uhhuh . 
and 
yeah . 
and so is your two point seven comparable ? 
where you ' re uh uh using uh the submitted system . 
yeah . 
i think so . 
yeah . 
okay . 
uhhuh . 
so it ' s about the same . 
it was one one point two . 
maybe a little worse . 
with the s r i system . 
i 
i ' m sorry . 
yeah . 
the complete s r i system is one point two . 
you you were h t k . 
yeah . 
right . 
okay . 
uhhuh . 
that ' s right . 
so 
okay . 
so the comparable number then uh for what you were talking about then since it was h t k would be the um two point 
it was four point something . 
right ? 
the h t k system with uh 
oh right right right right . 
do you mean the 
m f c c features . 
the baseline aurora two system trained on t i digits tested on meeting recorder near . 
i think we saw in it today . 
and it was about six point six percent . 
oh . 
right right right right . 
okay . 
all right . 
so 
so 
yeah . 
the only difference is the features right now . 
he ' s doing some different things . 
between this and 
yes . 
okay . 
good . 
so they are helping . 
uhhuh . 
that ' s good to hear . 
they are helping . 
yeah . 
yeah . 
um 
yeah . 
and another thing i i maybe would like to do is to just test the s r i system that ' s trained on macrophone . 
test it on uh the noisy t i digits . 
yeah . 
because i ' m still wondering where this improvement comes from . 
when you train on macrophone it seems better on meeting digits . 
but i wonder if it ' s just because maybe macrophone is acoustically closer to the meeting digits than than t i digit is . 
which is 
t i digits are very clean recorded digits . 
uhhuh . 
and 
uh 
you know it would also be interesting to see uh to do the regular aurora test . 
um 
but use the s r i system instead of h t k . 
that ' s 
yeah that ' s what i wanted just uh 
yeah . 
so just using the s r i system test it on and test it on aurora t i digits . 
right ? 
why not the full aurora uh test ? 
um 
yeah there is this problem of multilinguality yet . 
so we don ' t 
uhhuh . 
you ' d have to train the s r i system with with all the different languages . 
we would have to train on 
right . 
yeah . 
yeah . 
that ' s what i mean . 
so like 
it ' d be a lot of work . 
that ' s the only thing . 
yeah . 
it ' s 
huh . 
well i mean 
huh . 
uh 
uh 
i guess the work would be into getting the the files in the right formats or something . 
right ? 
i mean 
uhhuh . 
because when you train up the aurora system you ' re uh you ' re also training on all the data . 
that ' s right . 
yeah . 
i mean it ' s 
yeah . 
i see . 
oh so okay . 
right . 
i see what you mean . 
that ' s true . 
but i think that also when we ' ve had these meetings week after week oftentimes people have not done the full arrange of things . 
because on on whatever it is they ' re trying because it ' s a lot of work even just with the h t k . 
uhhuh . 
uhhuh . 
so it ' s it ' s a good idea . 
but it seems like it makes sense to do some pruning . 
uhhuh . 
first with a a test or two that makes sense for you . 
yeah . 
and then take the likely candidates and go further . 
yeah . 
uhhuh . 
yeah . 
but just testing on t i digits would already give us some information about what ' s going on . 
and 
uhhuh . 
uh yeah . 
okay . 
uh the next thing is this this v a d problem that 
um . 
um 
so i ' m just talking about the the curves that i i sent i sent you . 
so that shows that when the s n r decrease uh the current v a d approach doesn ' t drop much frames for some particular noises . 
uh which might be then noises that are closer to speech uh acoustically . 
just to clarify something for me . 
uhhuh . 
they were supposedly in the next evaluation they ' re going to be supplying us with boundaries . 
so does any of this matter ? 
i mean other than our interest in it . 
uh 
uh 
well . 
first of all the boundaries might be uh like we would have two hundred milliseconds or before and after speech . 
uh 
so removing more than that might still make a difference in the results . 
and 
do we i mean is there some reason that we think that ' s the case ? 
no . 
because we don ' t didn ' t looked that much at that . 
yeah . 
but still i think it ' s an interesting problem . 
and 
oh yeah . 
um 
yeah . 
but maybe we ' ll get some insight on that when when uh the gang gets back from crete . 
because there ' s lots of interesting problems of course . 
uhhuh . 
yeah . 
and then the thing is if if they really are going to have some means of giving us fairly tight uh boundaries then that won ' t be so much the issue . 
yeah . 
uhhuh . 
uhhuh . 
um 
but i don ' t know . 
because we were wondering whether that v a d is going to be like a realistic one or is it going to be some manual segmentation . 
and then like if if that v a d is going to be a realistic one then we can actually use their markers to shift the point around i mean the way we want . 
to find a 
uhhuh . 
i mean rather than keeping the twenty frames we can actually move the marker to a point which we find more suitable for us . 
but if that is going to be something like a manual uh segmenter then we can ' t use that information anymore . 
right . 
uhhuh . 
because that ' s not going to be the one that is used in the final evaluation . 
right . 
so we don ' t know what is the type of v a d which they ' re going to provide . 
yeah . 
yeah . 
and actually there ' s 
yeah . 
there ' s an uh i think it ' s still for even for the evaluation . 
uh it might still be interesting to work on this . 
because the boundaries apparently that they would provide is just um starting of speech and end of speech uh at the utterance level . 
and 
um 
with some some gap . 
so 
i mean with some pauses in the center . 
provided they meet that whatever the hang over time which they are talking . 
yeah . 
but when you have like uh five or six frames both 
yeah . 
then they will just fill fill it up . 
it it with 
i mean 
yeah . 
yeah . 
so if you could get at some of that uh 
so 
although that ' d be hard . 
yeah . 
it might be useful for like noise estimation and a lot of other things that we want to work on . 
but but 
yeah . 
yeah . 
right . 
okay . 
but 
huh 
yeah . 
so i did i just started to test putting together two v a d which was was not much work actually . 
um 
i re implemented a v a d that ' s very close to the um energy based v a d that uh the other aurora guys use . 
um 
so which is just putting a threshold on the noise energy . 
uhhuh . 
and detecting the first group of four frames that have a energy that ' s above this threshold . 
and 
uh 
from this point uh tagging the frames there as speech . 
so it removes the first silent portion portion of each utterance . 
and it really removes it . 
um 
still on the noises where our m l p v a d doesn ' t work a lot . 
huh . 
uh 
and 
because i would have thought that having some kind of spectral information 
uh 
uh 
you know in the old days people would use energy . 
and zero crossings for instance uh would give you some better performance . 
right ? 
because you might have low energy fricatives or or uh stop consonants or something like that . 
uhhuh . 
uh 
yeah . 
so your point is will be to use whatever 
oh that if you if you use purely energy and don ' t look at anything spectral then you don ' t have a good way of distinguishing between low energy speech components and nonspeech . 
uhhuh . 
and um 
just as a gross generalization most many nonspeech noises have a low pass kind of characteristic . 
some sort of slope . 
and and most um low energy speech components that are unvoiced have a a high pass kind of characteristic . 
uhhuh . 
an upward slope . 
yeah . 
so having some kind of a 
uh you know at the beginning of a of a of an s sound for instance just starting in it might be pretty low energy . 
uhhuh . 
but it will tend to have this high frequency component . 
whereas a a lot of rumble and background noises and so forth will be predominantly low frequency . 
uh you know by itself it ' s not enough to tell you . 
but it plus energy is sort of 
yeah . 
it plus energy plus timing information is sort of 
uhhuh . 
i mean if you look up in rabiner and schafer from like twenty five years ago or something that ' s sort of what they were using then . 
uhhuh . 
so it ' s it ' s not a 
uhhuh . 
huh . 
so yeah . 
it it might be that what i did is 
so removes like low um uh low energy uh speech frames . 
because the way i do it is i just i just combine the two decisions . 
so the one from the m l p and the one from the energy based with the with the and operator . 
so 
i only keep the frames where the two agree that it ' s speech . 
so if the energy based dropped dropped low energy speech huh they they are they are lost . 
huh . 
uhhuh . 
but still the way it ' s done right now it it helps on on the noises where it seems to help on the noises where our v a d was not very good . 
well i guess 
i mean 
one could imagine combining them in different ways . 
but but 
i guess what you ' re saying is that the the m l p based one has the spectral information . 
yeah . 
so 
but 
yeah . 
but the way it ' s combined is maybe done 
well yeah . 
well you can imagine 
the way i use a a and operator is 
so it i uh 
is 
the frames that are dropped by the energy based system are are uh dropped even if the um m l p decides to keep them . 
right . 
right . 
and that might not be optimal . 
but yeah . 
but 
uhhuh . 
but i mean i guess in principle what you ' d want to do is have a uh a probability estimated by each one . 
and and put them together . 
yeah . 
huh yeah . 
something that that i ' ve used in the past is um when just looking at the energy is to look at the derivative . 
and you make your decision when the derivative is increasing for so many frames . 
then you say that ' s beginning of speech . 
uhhuh . 
but i ' m i ' m trying to remember if that requires that you keep some amount of speech in a buffer . 
i guess it depends on how you do it . 
but i mean that ' s that ' s been a useful thing . 
yeah . 
uhhuh . 
uhhuh . 
yeah well everywhere has a delay associated with it . 
i mean you still have to always keep a buffer . 
uhhuh . 
then only make a decision because you still need to smooth the decision further . 
right . 
right . 
so that ' s always there . 
yeah . 
okay . 
well actually if i don ' t maybe don ' t want to work too much of on it right now . 
i just wanted to to see if it ' s what i observed was the was caused by this this v a d problem . 
and it seems to be the case . 
uhhuh . 
um 
uh the second thing is the this spectral subtraction . 
um 
um 
which i ' ve just started yesterday to launch a bunch of uh twenty five experiments . 
uh with different uh values for the parameters that are used . 
so 
it ' s the makhoul type spectral subtraction which use an over estimation factor . 
so we i subtract more um noise than the noise spectra that is estimated on the noise portion of the uh the utterances . 
so i tried several uh over estimation factors . 
and after subtraction i also add a constant noise . 
and i also try different uh noise uh values . 
and we ' ll see what happen . 
huh . 
uhhuh . 
okay . 
uhhuh . 
but still when we look at the 
um 
well it depends on the parameters that you use . 
but for moderate over estimation factors and moderate noise level that you add you have a lot of musical noise . 
um 
on the other hand when you subtract more and when you add more noise you get rid of this musical noise . 
but maybe you distort a lot of speech . 
so 
well . 
huh 
well it until now it doesn ' t seem to help . 
but 
we ' ll see . 
so the next thing maybe i what i will try to to do is just to try to smooth huh the um to smooth the the result of the subtraction . 
to get rid of the musical noise . 
using some kind of filter . 
or 
can smooth the s n r estimate also . 
yeah . 
right . 
huh 
your filter is a function of s n r huh ? 
yeah . 
so to get something that ' s would be closer to what you tried to do with wiener filtering . 
yeah . 
and 
uhhuh . 
yeah . 
actually it ' s 
uh 
uh 
i don ' t know . 
it ' s 
go ahead . 
and it ' s 
it 
go ahead . 
maybe you can 
i think it ' s 
that ' s it for me . 
okay . 
so uh 
i ' ve been playing with this wiener filter like . 
and there are there were some bugs in the program . 
so i was initially trying to clear them up . 
because one of the bug was i was assuming that always the vad uh the initial frames were silence . 
it always started in the silence state . 
but it wasn ' t for some utterances . 
so the it wasn ' t estimating the noise initially . 
and then it never estimated . 
because i assumed that it was always silence . 
uhhuh . 
so this is on speechdat car italian ? 
yeah . 
speechdat car italian . 
so in some cases there are also 
yeah . 
there ' re a few cases actually which i found later that there are . 
uhhuh . 
so that was one of the bugs that was there in estimating the noise . 
and uh so once it was cleared uh i ran a few experiments with different ways of smoothing the estimated clean speech and how estimated the noise and uh smoothing the s n r also . 
and so the the trend seems to be like uh smoothing the current estimate of the clean speech for deriving the s n r . 
which is like deriving the wiener filter . 
seems to be helping then updating it quite fast . 
using a very small time constant . 
so we ' ll have like a few results where the 
estimating the 
the more smoothing is helping . 
but still it ' s like it ' s still comparable to the baseline . 
i haven ' t got anything beyond the baseline . 
but that ' s like not using any wiener filter . 
and uh so i ' m i ' m trying a few more experiments with different time constants for smoothing the noise spectrum and smoothing the clean speech and smoothing s n r . 
so there are three time constants that i have . 
so i ' m just playing around . 
so one is fixed in the line like smoothing the clean speech is is helping . 
so i ' m not going to change it that much . 
but the way i ' m estimating the noise and the way i ' m estimating the s n r i ' m just trying trying a little bit . 
so that 
and the other thing is like putting a floor on the uh s n r . 
because that if 
some in some cases the clean speech is like when it ' s estimated it goes to very low values . 
so the s n r is like very low . 
and 
so that actually creates a lot of variance in the low energy region of the speech . 
so i ' m thinking of like putting a floor also for the s n r so that it doesn ' t vary a lot in the low energy regions . 
and uh so the results are like 
so far i ' ve been testing only with the baseline which is which doesn ' t have any l d a filtering and on line normalization . 
i just want to separate the the contributions out . 
so it ' s just vad plus the wiener filter plus the baseline system . 
which is uh just the spectral i mean the mel mel uh frequency coefficients . 
um 
and the other thing that i tried was but i just took of those uh carlos filters which hynek had . 
to see whether it really helps or not . 
i mean it was just a a run to see whether it really degrades or it helps . 
and 
it ' s it seems to be like it ' s not hurting a lot by just blindly picking up one filter . 
which is nothing but a four hertz a band pass filter on the cubic root of the power spectrum . 
so that was the filter that uh carlos had . 
and 
so 
yeah just just to see whether it really it ' s it ' s is it worth trying or not . 
so it doesn ' t seems to be degrading a lot on that . 
so there must be something that i can that can be done with that type of noise compensation also . 
which i guess i would ask carlos about that . 
i mean how how he derived those filters . 
and 
and where if he has any filters which are derived on o g i stories added with some type of noise which what we are using currently . 
or something like that . 
so maybe i ' ll 
this is cubic root of power spectra ? 
yeah . 
cubic root of power spectrum . 
so if you have this band pass filter you probably get you get negative values . 
right ? 
yeah . 
and i ' m like floating it to zeros right now . 
okay . 
so it has like the spectrogram has like 
uh 
it actually uh enhances the onset and offset of i mean the the begin and the end of the speech . 
so it ' s there seems to be like deep valleys in the begin and the end of like high energy regions . 
because the filter has like a sort of mexican hat type structure . 
uhhuh . 
so those are the regions where there are like 
uhhuh . 
when i look at the spectrogram there are those deep valleys on the begin and the end of the speech . 
but the rest of it seems to be like pretty nice . 
uhhuh . 
so 
that ' s something i observe using that filter . 
and 
yeah . 
there are a few 
very 
not a lot of 
because the filter doesn ' t have a really a deep negative portion . 
so that it ' s not really creating a lot of negative values in the cubic root . 
so 
i ' ll i ' ll continue with that for some 
i ' ll i ' ll maybe i ' ll ask carlos a little more about how to play with those filters . 
and but while making this wiener filter better . 
so 
yeah . 
that that ' s it morgan . 
uh 
last week you were also talking about building up the subspace stuff ? 
yeah . 
i i i would actually didn ' t get enough time to work on the subspace last week . 
it was mostly about finding those bugs . 
and 
you know things . 
okay . 
and i didn ' t work much on that . 
how about you carmen ? 
well i am still working with uh v t s . 
and one of the things that last week 
uh say here is that maybe the problem was with the diff . 
because the signal have different level of energy . 
huh . 
and maybe talking with stephane and with sunil we decide that maybe it was interesting to to apply on line normalization before applying v t s . 
but then we decided that that ' s it doesn ' t work absolutely because we modified also the noise . 
and 
well thinking about that we we then we decide that maybe is a good idea . 
we don ' t know . 
i don ' t 
i don ' t 
this is 
i didn ' t do the experiment yet to apply v t s in cepstral domain . 
the other thing is 
so so in 
and 
not 
and c zero would be a different 
so you could do a different normalization for c zero than for other things anyway . 
i mean the other thing i was going to suggest is that you could have two kinds of normalization with with uh different time constants . 
so 
uh 
you could do some normalization uh before the v t s . 
and then do some other normalization after . 
i don ' t know . 
but but c zero certainly acts differently than the others do . 
uh 
so that ' s 
uhhuh . 
well we decide to to to obtain the new expression if we work in the cepstral domain . 
and 
well i am working in that now . 
uhhuh . 
but i ' m not sure if that will be useful . 
i don ' t know . 
it ' s it ' s 
it ' s quite a lot it ' s a lot of work . 
well it ' s not too much . 
uhhuh . 
but this it ' s work . 
and i want to know if if we have some feeling that the result 
yeah . 
i i would like to know if 
i don ' t have any feeling if this will work better than apply v t s in cepstral domain will work better than apply in mel in filter bank domain . 
i i ' m not sure . 
i don ' t i don ' t know absolutely nothing . 
uhhuh . 
yeah well you ' re i think you ' re the first one here to work with v t s . 
so 
uh maybe we could call someone else up who has . 
ask them their opinion . 
uh 
uhhuh . 
i don ' t i don ' t have a good feeling for it . 
um 
pratibha . 
actually the v t s that you tested before was in the log domain . 
and so the codebook is kind of dependent on the level of the speech signal . 
yeah ? 
and 
so i expect it if if you have something that ' s independent of this i expect it to it to uh be a better model of speech . 
to have better 
and 
well . 
you you wouldn ' t even need to switch to cepstra . 
right ? 
i mean you can just sort of normalize the 
no . 
we could i mean remove the median . 
yeah . 
yeah . 
uhhuh . 
and then you have one number which is very dependent on the level because it is the level . 
and the other which isn ' t . 
uhhuh . 
yeah . 
but here also we would have to be careful about removing the mean of speech . 
and 
not of noise . 
because it ' s like first doing general normalization . 
and then noise removal . 
which is 
yeah . 
we 
i was thinking to to to estimate the noise with the first frames . 
and then apply the v a d . 
uhhuh . 
uhhuh . 
before the on line normalization . 
we we see . 
uhhuh . 
well . 
i am thinking about that and working about that . 
yeah . 
but i don ' t have result this week . 
sure . 
i mean one of the things we ' ve talked about maybe it might be time to start thinking about pretty soon is as we look at the pros and cons of these different methods how do they fit in with one another . 
because we ' ve talked about potentially doing some combination of a couple of them . 
uhhuh . 
maybe maybe pretty soon we ' ll have some sense of what their characteristics are . 
so we can see what should be combined . 
uhhuh . 
is that it ? 
okay . 
okay . 
why don ' t we read some digits ? 
yep . 
want to go ahead morgan ? 
sure . 
okay . 
so um 
i was going to try to get out of here like in half an hour . 
um 
because i really appreciate people coming . 
and the main thing that i was going to ask people to help with today is to give input on what kinds of database format we should use in starting to link up things like word transcripts and annotations of word transcripts . 
so anything that transcribers or discourse coders or whatever put in the signal with time marks for like words and phone boundaries and all the stuff we get out of the forced alignments and the recognizer . 
so we have this um 
i think a starting point is clearly the the channelized output of dave gelbart ' s program . 
which don brought a copy of . 
yeah . 
yeah i ' m i ' m familiar with that . 
i mean we i sort of already have developed an x . m . l . format for this sort of stuff . 
um 
which 
can i see it ? 
and so the only question is it the sort of thing that you want to use or not . 
have you looked at that ? 
i mean i had a web page up . 
right . 
so 
i actually mostly need to be able to link up or 
so 
it ' s it ' s a question both of what the representation is and 
you mean this ? 
i guess i am going to be standing up and drawing on the board . 
okay . 
yeah . 
so you should definitely . 
um so so it definitely had that as a concept . 
so it has a single timeline . 
uhhuh . 
and then you can have lots of different sections . 
each of which have i . d . ' s attached to it . 
and then you can refer from other sections to those i . d . ' s . 
if you want to . 
so that 
um 
so that you start with with a timeline tag . 
timeline . 
and then you have a bunch of times . 
i don ' t i don ' t remember exactly what my notation was . 
oh i remember seeing an example of this . 
but it 
right . 
right . 
yeah . 
yeah . 
t . equals one point three two . 
uh 
and then i i also had optional things like accuracy . 
and then i . d . equals t . one uh one seven . 
and then i also wanted to to be to be able to not specify specifically what the time was and just have a stamp . 
right . 
yeah so these are arbitrary assigned by a program . 
not not by a user . 
so you have a whole bunch of those . 
and then somewhere further down you might have something like an utterance tag . 
which has start equals t . seventeen . 
end equals t . eighteen . 
so what that ' s saying is we know it starts at this particular time . 
we don ' t know when it ends . 
okay . 
right ? 
but it ends at this t . eighteen . 
which may be somewhere else . 
we say there ' s another utterance . 
we don ' t know what the time actually is . 
but we know that it ' s the same time as this end time . 
huh . 
you know thirty eight . 
whatever you want . 
so you ' re essentially defining a lattice . 
okay . 
yes . 
exactly . 
yeah . 
and then uh and then these also have i . d . ' s . 
right ? 
so you could you could have some sort of other other tag later in the file that would be something like um oh i don ' t know uh noise type equals door slam . 
you know ? 
and then uh you could either say time equals a particular time mark or you could do other sorts of references . 
so or or you might have a prosody . 
prosody . 
right ? 
d . ? 
t . ? 
it ' s an o . instead of an i . . 
but the d . is good . 
you like the d . ? 
yeah . 
that ' s a good d . . 
um 
you know so you could have some sort of type here . 
and then you could have 
um 
the utterance that it ' s referring to could be u . seventeen or something like that . 
okay . 
so 
i mean that seems that seems great for all of the encoding of things with time . 
and 
oh well . 
um 
i i guess my question is more uh what what do you do with say a forced alignment ? 
i mean you ' ve got all these phone labels . 
and what do you do if you just conceptually if you get um transcriptions where the words are staying but the time boundaries are changing because you ' ve got a new recognition output ? 
or sort of what ' s the um sequence of going from the waveforms that stay the same the transcripts that may or may not change and then the utterance which where the time boundaries that may or may not change ? 
oh that ' s 
that ' s actually very nicely handled here . 
um 
because you could you could all you ' d have to change is the um time stamps in the timeline without without uh changing the i . d . ' s . 
and you ' d be able to propagate all of the the information ? 
right . 
that ' s the that ' s why you do that extra level of indirection . 
so that you can just change the timeline . 
except the timeline is going to be huge . 
if you say 
yes . 
yeah . 
yeah especially at the phone level . 
suppose you have a phone level alignment . 
the we we have phone level backtraces . 
you ' d have you ' d have 
yeah this 
i don ' t think i would do this for phone level . 
um 
i think for phone level you want to use some sort of binary representation . 
because it ' ll be too dense otherwise . 
okay . 
so if you were doing that and you had this sort of companion uh thing that gets called up for phone level uh what would that look like ? 
how would you 
i would use just an existing an existing way of doing it . 
huh . 
but but why not use it for phone level ? 
it ' s just a matter of it ' s just a matter of it being bigger . 
but if you have 
you know barring memory limitations uh i mean this is still the 
it ' s parsing limitations . 
i don ' t want to have this text file that you have to read in the whole thing to do something very simple for . 
oh no . 
you would use it only for purposes where you actually want the phone level information i ' d imagine . 
so you could have some file that configures how much information you want in your in your x . m . l . or something . 
right . 
i mean you ' d 
um 
because it does get very with 
i i am imagining you ' d have multiple versions of this depending on the information that you want . 
you 
right . 
um 
i ' m just 
what i ' m wondering is whether 
i think for word level this would be okay . 
yeah . 
yeah . 
for word level it ' s all right . 
definitely . 
uhhuh . 
for lower than word level you ' re talking about so much data that i just i don ' t know . 
i don ' t know if that 
i mean we actually have 
so one thing that don is doing is we ' re we ' re running for every frame you get a pitch value . 
lattices are big too . 
and not only one pitch value but different kinds of pitch values . 
depending on 
yeah i mean for something like that i would use p . file . 
or or any frame level stuff i would use p . file . 
meaning ? 
uh that ' s a well or something like it . 
it ' s uh icsi has a format for frame level representation of features . 
okay . 
um 
that you could call that you would tie into this representation with like an i . d . 
right . 
right . 
or or there ' s a there ' s a particular way in x . m . l . to refer to external resources . 
and 
okay . 
so you would say refer to this external file . 
um 
so that external file wouldn ' t be in 
so that might that might work . 
but what what ' s the advantage of doing that versus just putting it into this format ? 
more compact . 
which i think is is better . 
uhhuh . 
i mean if you did it at this 
i mean these are long meetings . 
and with for every frame 
you don ' t want to do it with that 
um 
anything at frame level you had better encode binary . 
or it ' s going to be really painful . 
or you just 
i mean i like text formats . 
um 
you can always uh g . zip them . 
and um you know decompress them on the fly if if space is really a concern . 
yeah i was 
i was thinking the advantage is that we can share this with other people . 
well but if you ' re talking about one per frame you ' re talking about gigabyte - size files . 
you ' re going to actually run out of space in your filesystem for one file . 
these are big files . 
these are really 
i mean 
right ? 
because you have a two - gigabyte limit on most o . s . ' s . 
right . 
okay . 
i would say 
okay so frame level is probably not a good idea . 
and it ' s 
but for phone level stuff it ' s perfectly 
like phones or syllables or anything like that . 
phones are every five frames though . 
so 
or something like that . 
but but but most of the frames are actually not speech . 
so 
you know people don ' t 
yeah . 
look at it words times the average the average number of phones in an english word is i don ' t know five maybe ? 
but we actually 
so look at it number of words times five . 
oh so you mean pause phones take up a lot of the 
that ' s not that not 
long pause phones . 
yep . 
exactly . 
yeah . 
okay . 
yeah . 
that ' s true . 
but you do have to keep them in there . 
yeah . 
so i think it it ' s debatable whether you want to do phone level in the same thing . 
okay . 
but i think anything at frame level even p . file is too verbose . 
okay . 
so 
i would use something tighter than p . files . 
do you are you familiar with it ? 
so 
i haven ' t seen this particular format . 
i mean i ' ve i ' ve used them . 
but 
i don ' t know what their structure is . 
okay . 
i ' ve forgot what the 
but wait a minute . 
p . file for each frame is storing a vector of cepstral or p . l . p . values . 
right ? 
it ' s whatever you want actually . 
right . 
so that what ' s nice about the p . file it 
built into it is the concept of frames utterances sentences that sort of thing that structure . 
and then also attached to it is an arbitrary vector of values . 
oh . 
and it can take different types . 
so it they don ' t all have to be floats . 
you know you can have integers and you can have doubles and all that sort of stuff . 
so that that sounds that sounds about what i 
um 
right ? 
and it has a header it has a header format that describes it to some extent . 
so 
the only problem with it is it ' s actually storing the utterance numbers and the frame numbers in the file . 
even though they ' re always sequential . 
and so it does waste a lot of space . 
huh . 
but it ' s still a lot tighter than than ascii . 
and we have a lot of tools already to deal with it . 
you do ? 
okay . 
is there some documentation on this somewhere ? 
yeah . 
there ' s a ton of it . 
okay . 
great . 
man pages and uh source code and me . 
so 
i mean that sounds good . 
i i was just looking for something 
i ' m not a database person . 
but something sort of standard enough that you know if we start using this we can give it out . 
other people can work on it . 
yeah it ' s not standard . 
or is it 
i mean it ' s something that we developed at icsi . 
but uh 
but it ' s been used here . 
but it ' s been used here . 
and people ' ve 
and and you know we have a well configured system that you can distribute for free . 
and 
i mean it must be the equivalent of whatever you guys used to store your computed features in right ? 
okay . 
yeah . 
we have 
actually we we use a generalization of the the sphere format . 
huh . 
um 
but 
yeah so there is something like that . 
but it ' s um probably not as 
and i think there ' s 
well what does h . t . k . do for features ? 
or does it even have a concept of features ? 
they it has its own 
i mean entropic has their own feature format that ' s called like s . s . d . or some s . f . or something like that . 
yeah . 
yeah . 
i ' m just wondering would it be worth while to use that instead ? 
huh ? 
yeah . 
this is exactly the kind of decision it ' s just whatever 
but i mean people don ' t typically share this kind of stuff right ? 
right . 
i mean 
they generate their own . 
actually i i just you know we we ' ve done this stuff on prosodics . 
yeah . 
and three or four places have asked for those prosodic files . 
and we just have an ascii uh output of frame by frame . 
uh right . 
which is fine . 
but it gets unwieldy to go in and and query these files with really huge files . 
right . 
i mean we could do it . 
i was just thinking if there ' s something that where all the frame values are 
and and again if you have a 
huh ? 
if you have a two hour long meeting that ' s going to 
they ' re they ' re they ' re quite large . 
and these are for ten minute switchboard conversations . 
yeah i mean they ' d be enormous . 
right . 
and 
so it ' s doable . 
it ' s just that you can only store a feature vector at frame by frame . 
and it doesn ' t have any kind of 
um 
is is the sharing part of this a pretty important consideration ? 
or does that just sort of uh a nice thing to have ? 
i i don ' t know enough about what we ' re going to do with the data . 
but i thought it would be good to get something that we can that other people can use or adopt for their own kinds of encoding . 
and just i mean we have to use we have to make some decision about what to do . 
yeah . 
and especially for the prosody work what what it ends up being is you get features from the signal . 
and of course those change every time your alignments change . 
so you rerun a recognizer . 
you want to recompute your features um and then keep the database up to date . 
right . 
or you change a word or you change a utterance boundary segment which is going to happen a lot . 
and so i wanted something where all of this can be done in a elegant way . 
and that if somebody wants to try something or compute something else that it can be done flexibly . 
um 
it doesn ' t have to be pretty . 
it just has to be you know easy to use and 
yeah the other thing 
we should look at atlas . 
the nist thing . 
oh . 
huh . 
and see if they have anything at that level . 
uh 
i mean i ' m not sure what to do about this with atlas . 
because they chose a different route . 
i chose something that 
there are sort of two choices . 
your your file format can know about know that you ' re talking about language and speech which is what i chose and time . 
or your file format can just be a graph representation . 
and then the application has to impose the structure on top . 
so what it looked like atlas chose is they chose the other way . 
which was their file format is just nodes and links . 
and you have to interpret what they mean yourself . 
and why did you not choose that type of approach ? 
uh because i knew that we were doing speech . 
and i thought it was better if you ' re looking at a raw file to be for the tags to say it ' s an utterance as opposed to the tag to say it ' s a link . 
okay . 
okay . 
but other than that are they compatible ? 
so but 
i mean you could sort of 
yeah . 
they ' re reasonably compatible . 
i mean you you could 
you could probably translate between them . 
yeah that ' s 
yep . 
so 
so 
well the other thing is if we choose to use atlas which maybe we should just do we should just throw this out before we invest a lot of time in it . 
okay . 
i don ' t 
so this is what the meeting ' s about . 
just sort of how to 
yeah . 
um because we need to come up with a database like this just to do our work . 
and i actually don ' t care as long as it ' s something useful to other people what we choose . 
yeah . 
so maybe it ' s maybe you know 
if if you have any idea of how to choose because i don ' t . 
the only thing 
yeah . 
do they already have tools ? 
i mean i i chose this for a couple reasons . 
one of them is that it ' s easy to parse . 
you don ' t need a full x . m . l . parser . 
it ' s very easy to just write a perl script to parse it . 
as long as uh each tag is on one line . 
exactly . 
exactly . 
which i always do . 
and you can have as much information in the tag as you want . 
right ? 
well i have it structured . 
right ? 
so each type tag has only particular items that it can take . 
can you but you can add to those structures if you 
sure . 
if you have more information . 
so what what nist would say is that instead of doing this you would say something like link start equals um you know some node i . d . 
yeah . 
so 
end equals some other node i . d . 
and then type would be utterance . 
huh . 
you know so it ' s very similar . 
so why would it be a a waste to do it this way if it ' s similar enough that we can always translate it ? 
it probably wouldn ' t be a waste . 
it would mean that at some point if we wanted to switch we ' d just have to translate everything . 
write a translator . 
but it 
but it but that sounds 
since they are developing a big 
but that ' s 
i don ' t think that ' s a big deal . 
as long as it is 
they ' re developing a big infrastructure . 
and so it seems to me that if if we want to use that we might as well go directly to what they ' re doing rather than 
if we want to 
do they already have something that ' s that would be useful for us in place ? 
yeah . 
see that ' s the question . 
i mean how stable is their 
are they ready to go ? 
the i looked at it 
or 
the last time i looked at it was a while ago . 
probably a year ago . 
huh . 
uh when we first started talking about this . 
and at that time at least it was still not very complete . 
and so specifically they didn ' t have any external format representation at that time . 
they just had the sort of conceptual node uh annotated transcription graph . 
which i really liked . 
and that ' s exactly what this stuff is based on . 
since then they ' ve developed their own external file format . 
which is uh you know this sort of this sort of thing . 
um and apparently they ' ve also developed a lot of tools . 
but i haven ' t looked at them . 
maybe i should . 
we should we should find out . 
i mean would the tools would the tools run on something like this if you can translate them anyway ? 
um what would would would what would worry me is that maybe we might miss a little detail . 
i mean that i guess it ' s a question that 
it ' s a hassle . 
uh yeah . 
if 
that would make it very difficult to translate from one to the other . 
okay . 
i i think if it ' s conceptually close and they already have or will have tools that everybody else will be using i mean it would be crazy to do something you know separate that 
okay . 
yeah we might as well . 
yep . 
yeah . 
so i ' ll i ' ll take a closer look at it . 
actually 
so it ' s 
that that would really be the question is just what you would feel is in the long run the best thing . 
and 
right . 
because once we start sort of doing this i don ' t we don ' t actually have enough time to probably have to rehash it out again . 
the 
yep . 
and 
the other thing the other way that i sort of established this was as easy translation to and from the transcriber format . 
right . 
um 
right . 
but 
i mean i like this . 
this is sort of intuitively easy to actually read . 
yep . 
as easy it could as it could be . 
but 
i suppose that as long as they have a type here that specifies utt 
um 
it ' s almost the same . 
it ' s yeah close enough that 
the the the the point is with this though is that you can ' t really add any supplementary information . 
right ? 
so if you suddenly decide that you want 
you have to make a different type . 
yeah . 
you ' d have to make a different type . 
so 
well if you look at it 
and um 
i guess in my mind i don ' t know enough jane would know better about the types of annotations . 
and and but i imagine that those are things that would well you guys mentioned this that could span any 
it could be in its own channel . 
it could span time boundaries of any type . 
right . 
it could be instantaneous . 
things like that . 
um 
and then from the recognition side we have backtraces at the phone level . 
if if it can handle that it could handle states or whatever . 
right . 
and then at the prosody - level we have frame sort of like cepstral feature files . 
yep . 
uh like these p . files or anything like that . 
and that ' s sort of the world of things that i 
and then we have the aligned channels of course . 
right . 
and 
it seems to me you want to keep the frame level stuff separate . 
yeah . 
i i definitely agree . 
and then 
and i wanted to find actually a a nicer format or a maybe a more compact format than what we used before . 
right . 
just because you ' ve got ten channels or whatever and two hours of a meeting . 
it ' s it ' s a lot of 
now now how would you how would you represent um multiple speakers in this framework ? 
huge . 
were you would just represent them as 
um 
you would have like a speaker tag or something ? 
there ' s a speaker tag up at the top which identifies them . 
and then each 
the way i had it is each turn or each utterance i don ' t even remember now had a speaker i . d . tag attached to it . 
uhhuh . 
okay . 
and in this format you would have a different tag . 
which which would uh be linked to the link . 
yeah . 
so so somewhere else you would have another thing that would be 
um 
let ' s see would it be a node or a link ? 
um 
and so so this one would have um an i . d . is link link seventy four or something like that . 
and then somewhere up here you would have a link that that uh you know was referencing l . seventy four and had speaker adam . 
uhhuh . 
actually it ' s the channel i think that 
is ? 
you know . 
or something like that . 
i mean 
well channel or speaker or whatever . 
yeah channel is what the channelized output 
it doesn ' t 
this isn ' t quite right . 
i have to look at it again . 
right . 
yeah but 
but but so how in the nist format do we express a hierarchical relationship between um say an utterance and the words within it ? 
so how do you tell that these are the words that belong to that utterance ? 
um you would have another structure lower down than this that would be saying they ' re all belonging to this i . d . 
uhhuh . 
so each thing refers to the utterance that it belongs to . 
right . 
so it ' s it ' s not it ' s sort of bottom up . 
and then each utterance could refer to a turn . 
and each turn could refer to something higher up . 
and what if you actually have 
so right now what you have as utterance um the closest thing that comes out of the channelized is the stuff between the segment boundaries that the transcribers put in or that thilo put in . 
which may or may not actually be like a it ' s usually not um the beginning and end of a sentence say . 
well that ' s why i didn ' t call it sentence . 
so 
right . 
um so it ' s like a segment or something . 
yeah . 
so 
i mean i assume this is possible that if you have someone annotates the punctuation or whatever when they transcribe you can say you know from for from the beginning of the sentence to the end of the sentence from the annotations this is a unit . 
even though it never actually 
it ' s only a unit by virtue of the annotations at the word level . 
sure . 
i mean so you would you would have yet another tag . 
and then that would get a tag somehow . 
you ' d have another tag which says this is of type sentence . 
okay . 
okay . 
and 
but it ' s just not overtly in the 
what 
okay . 
um because this is exactly the kind of 
so 
i think that should be possible as long as the 
but uh what i don ' t understand is where the where in this type of file that would be expressed . 
right . 
you would have another tag somewhere . 
it ' s well there ' re two ways of doing it . 
so it would just be floating before the sentence or floating after the sentence without a time mark . 
you could have some sort of link type . 
type equals sentence . 
and i . d . is s . whatever . 
and then lower down you could have an utterance . 
so the type is utterance equals utt . 
and you could either say that 
no . 
i don ' t know . 
i take that back . 
so here ' s the thing . 
um 
see because it ' s 
can you can you say that this is part of this ? 
hhh . 
it ' s 
you would just have a 
or do you say this is part of this ? 
i think 
but they ' re 
you would refer up to the sentence . 
well the thing 
they ' re actually overlapping each other sort of . 
so 
the thing is that something may be a part of one thing for one purpose and another thing of another purpose . 
right . 
you have to have another type then i guess . 
so 
um 
well . 
well i think i ' m i think i had better look at it again . 
let ' s let ' s so let ' s 
yeah . 
okay . 
so 
because i i ' m 
okay . 
so for instance 
there ' s one level there ' s one more level of indirection that i ' m forgetting . 
suppose you have a word sequence . 
and you have two different segmentations of that same word sequence . 
say one segmentation is in terms of um you know uh sentences . 
and another segmentation is in terms of um i don ' t know prosodic phrases . 
and let ' s say that they don ' t nest . 
so you know a prosodic phrase may cross two sentences or something . 
right . 
i don ' t know if that ' s true or not . 
but let ' s 
well it ' s definitely true with the segment . 
right . 
that ' s what i exactly what i meant by the utterances versus the sentence could be sort of 
yeah . 
so you want to be you want to say this this word is part of that sentence and this prosodic phrase . 
yeah . 
yeah . 
but the phrase is not part of the sentence . 
and neither is the sentence part of the phrase . 
right . 
i ' m pretty sure that you can do that . 
but i ' m forgetting the exact level of nesting . 
so you would have to have two different pointers from the word up one level up . 
one to the 
so so what you would end up having is a tag saying here ' s a word . 
and it starts here and it ends here . 
right . 
and then lower down you would say here ' s a prosodic boundary . 
and it has these words in it . 
and lower down you ' d have here ' s a sentence . 
right . 
right . 
and it has these words in it . 
so you would be able to go in and say you know give me all the words in the in the prosodic phrase . 
and give me all the words in the 
yep . 
yeah . 
so i think that ' s that would 
um okay . 
let me look at it again . 
uhhuh . 
okay . 
the the the other issue that you had was how do you actually efficiently extract um find and extract information in a structure of this type . 
so 
that ' s good . 
so you gave some examples like 
well . 
uh and i mean you guys might 
i don ' t know if this is premature . 
because i suppose once you get the representation you can do this . 
but the kinds of things i was worried about is 
no that ' s not clear . 
uh 
i mean yeah you sure you can do it . 
well okay . 
so if it 
but can you do it sort of you know it 
i mean i can ' t do it . 
but i can 
um 
you got to you got to do this you you ' re going to want to do this very quickly . 
well 
or else you ' ll spend all your time sort of searching through very complex data structures . 
right . 
you ' d need a sort of a paradigm for how to do it . 
but an example would be find all the cases in which adam started to talk while andreas was talking and his pitch was rising . 
andreas ' s pitch . 
that kind of thing . 
right . 
i mean that ' s going to be 
is the rising pitch a feature ? 
or is it going to be in the same file ? 
well the rising pitch will never be hand annotated . 
so the all the prosodic features are going to be automatically 
but the 
i mean that ' s going to be hard regardless . 
so they ' re going to be in those 
right ? 
because you ' re going to have to write a program that goes through your feature file and looks for rising pitches . 
yeah . 
so 
right . 
so normally what we would do is we would say what do we want to assign rising pitch to . 
are we going to assign it to words . 
are we going to just assign it to sort of 
when it ' s rising we have a begin end rise representation . 
but suppose we dump out this file . 
and we say uh for every word we just classify it as you know rise or fall or neither . 
okay . 
well in that case you would add that to this format . 
okay . 
so we would basically be sort of um taking the format and enriching it with things that we want to query in relation to the words that are already in the file . 
right . 
and then querying it . 
okay . 
you want sort of a grep that ' s that works at the structural on the structural representation . 
you have that . 
there ' s a standard again in x . m . l . specifically for searching x . m . l . documents structured x . x . m . l . documents where you can specify both the content and the structural position . 
yeah but it ' s it ' s not clear that that ' s 
if 
that ' s relative to the structure of the x . m . l . document . 
not to the structure of what you ' re representing in the document . 
you use it as a tool . 
you use it as a tool . 
not an end user . 
it ' s not an end user thing . 
right . 
it ' s it ' s you would use that to build your tool to do that sort of search . 
right . 
because here you ' re specifying a lattice . 
uh 
so the underlying that ' s the underlying data structure . 
but as long as the 
and you want to be able to search in that lattice . 
it ' s a graph . 
but 
that ' s different from searching through the text . 
but it seems like as long as the features that 
well . 
no no no . 
the whole point is that the text and the lattice are isomorphic . 
they represent each other completely . 
um 
so that 
i mean 
that ' s true if the features from your acoustics or whatever that are not explicitly in this are at the level of these types . 
hhh . 
that that if you can do that 
yeah but that ' s going to be the trouble no matter what . 
right ? 
no matter what format you choose you ' re going to have the you ' re going to have the difficulty of relating the the frame level features . 
that ' s right . 
that ' s true . 
that ' s why i was trying to figure out what ' s the best format for this representation . 
yep . 
and it ' s still going to be 
it ' s still going to be uh not direct . 
huh . 
you know it 
right . 
or another example was you know uh where in the language where in the word sequence are people interrupting . 
so 
i guess that one ' s actually easier . 
what about 
what about um the idea of using a relational database to uh store the information from the x . m . l ? 
so you would have 
x . m . l . basically would 
uh 
you you could use the x . m . l . to put the data in . 
and then when you get data out you put it back in x . m . l . 
so use x . m . l . as sort of the the transfer format . 
transfer . 
uh but then you store the data in the database . 
which allows you to do all kinds of good search things in there . 
the uh 
one of the things that atlas is doing is they ' re trying to define an a . p . i . which is independent of the back store . 
huh ? 
so that uh you could define a single a . p . i . and the the storage could be flat x . m . l . files or a database . 
uhhuh . 
my opinion on that is for the sort of stuff that we ' re doing i suspect it ' s overkill to do a full relational database that um just a flat file and uh search tools i bet will be enough . 
but 
but that ' s the advantage of atlas is that if we actually take decide to go that route completely and we program to their a . p . i . then if we wanted to add a database later it would be pretty easy . 
uhhuh . 
uhhuh . 
it seems like the kind of thing you ' d do if i don ' t know if people start adding all kinds of bells and whistles to the data . 
and so that might be 
i mean it ' d be good for us to know to use a format where we know we can easily um input that to some database if other people are using it . 
yep . 
something like that . 
i guess i ' m just a little hesitant to try to go whole hog on sort of the the whole framework that that nist is talking about with atlas and a database and all that sort of stuff . 
so 
because it ' s a big learning curve just to get going . 
huh . 
huh . 
whereas if we just do a flat file format sure it may not be as efficient . 
but everyone can program in perl and and use it . 
okay . 
right ? 
so as opposed to 
but this is 
i i ' m still um not convinced that you can do much at all on the text on the flat file that that you know the text representation . 
because the text representation is going to be uh not reflecting the structure of of your words and annotations . 
it ' s just it ' s 
well if it ' s not representing it then how do you recover it ? 
of course it ' s representing it . 
no . 
you you have to 
that ' s the whole point . 
what you have to do is you have to basically 
yeah you can use perl to read it in and construct a internal representation that is essentially a lattice . 
but the 
yeah . 
okay . 
and then 
well that was a different point . 
right ? 
so what i was saying is that 
right . 
but that ' s what you ' ll have to do . 
for perl if you want to just do perl . 
if you wanted to use the structured x . m . l . query language that ' s a different thing . 
and it ' s a set of tools that let you specify given the d . d . d . t . d . t . d . of the document um what sorts of structural searches you want to do . 
so you want to say that you know you ' re looking for um a tag within a tag within a particular tag that has this particular text in it um and uh refers to a particular value . 
and so the point isn ' t that an end user who is looking for a query like you specified wouldn ' t program it in this language . 
what you would do is someone would build a tool that used that as a library . 
so that they so that you wouldn ' t have to construct the internal representations yourself . 
is a 
see i think the kinds of questions at least in the next to the end of this year are there may be a lot of different ones . 
but they ' ll all have a similar nature . 
they ' ll be looking at either a word level prosodic uh an a value . 
like a continuous value . 
uhhuh . 
like the slope of something . 
but 
you know we ' ll do something where we some kind of data reduction where the prosodic features are sort uh either at the word level or at the segment level . 
right . 
or or something like that . 
they ' re not going to be at the phone level and they ' re not going to be at the frame level when we get done with sort of giving them simpler shapes and things . 
and so the main thing is just being able 
well i guess the two goals . 
um one that chuck mentioned is starting out with something that we don ' t have to start over that we don ' t have to throw away if other people want to extend it for other kinds of questions . 
right . 
and being able to at least get enough uh information out on where we condition the location of features on information that ' s in the kind of file that you put up there . 
and that would that would do it . 
i mean for me . 
yeah . 
i think that there are quick and dirty solutions . 
and then there are long - term big infrastructure solutions . 
and so we want to try to pick something that lets us do a little bit of both . 
in the between . 
right . 
and especially that the representation doesn ' t have to be thrown away . 
um 
right . 
even if your tools change . 
and so it seems to me that 
i mean i have to look at it again to see whether it can really do what we want . 
but if we use the atlas external file representation um it seems like it ' s rich enough that you could do quick tools just as i said in perl . 
yeah . 
and then later on if we choose to go up the learning curve we can use the whole atlas infrastructure . 
i mean that sounds good to me . 
which has all that built in . 
i i don ' t 
so 
if if you would look at that and let us know what you think 
sure . 
i mean i think we ' re sort of guinea pigs . 
because i i want to get the prosody work done . 
but i don ' t want to waste time you know getting the 
oh maybe 
yeah ? 
um 
well i wouldn ' t wait for the formats because anything you pick we ' ll be able to translate to another form . 
well 
okay . 
well maybe you should actually look at it yourself too to get a sense of what it is you ' ll you ' ll be dealing with . 
because um you know adam might have one opinion but you might have another . 
yeah . 
so 
yeah definitely . 
i think the more eyes look at this the better . 
especially if there ' s um you know if someone can help with at least the the setup of the right 
oh hi . 
hi jane . 
huh . 
the right representation . 
then you know i hope it won ' t 
we don ' t actually need the whole full - blown thing to be ready . 
can you 
oh well . 
so 
um 
so maybe if you guys can look at it and sort of see what 
sure . 
yeah . 
um 
i think we ' re we ' re we ' re actually just 
we ' re about done . 
yeah . 
wrapping up . 
huh . 
but 
um 
yeah . 
sorry it ' s a uh short meeting . 
but um 
well i don ' t know . 
is there anything else ? 
like 
i mean that helps me a lot . 
well i think the other thing we might want to look at is alternatives to p . file . 
but 
i mean the reason i like p . file is i ' m already familiar with it . 
we have expertise here . 
and so if we pick something else there ' s the learning curve problem . 
but i mean it is just something we developed at icsi . 
and so 
is there an is there an i . a . p . i ? 
yeah . 
okay . 
there ' s an a . p . i . for it . 
and uh 
there used to be a problem that they get too large . 
a bunch of libraries p . file utilities . 
and so basically the uh the filesystem wouldn ' t 
well that ' s going to be a problem no matter what . 
you have the two - gigabyte limit on the filesystem size . 
and we definitely hit that with broadcast news . 
maybe you could extend the a . p . i . to uh support uh like splitting up you know conceptually one file into smaller files on disk . 
so that you can essentially you know have arbitrarily long 
yep . 
most of the tools can handle that . 
so that 
yeah . 
we didn ' t do it at the a . p . i . level . 
we did it at the tool level . 
that that most many of them can you can specify several p . files . 
and they ' ll just be done sequentially . 
okay . 
so 
so i guess 
yeah . 
if if you and don can if you can show him the p . file stuff and see . 
sure . 
so this would be like for the f . zero . 
i mean if you do man p . file or apropos p . file you ' ll see a lot . 
true . 
i ' ve used the p . file i think . 
i ' ve looked at it at least briefly i think when we were doing something . 
what does the p . stand for anyway ? 
i have no idea . 
oh in there . 
i didn ' t i didn ' t develop it . 
you know it was i think it was dave johnson . 
so it ' s all part of the quicknet library . 
it has all the utilities for it . 
no p . files were around way before quicknet . 
oh were they ? 
p . files were were around when with um rap . 
uhhuh . 
right ? 
it ' s like the history of icsi . 
you worked with p . files . 
like 
uhhuh . 
no . 
i worked with p . files . 
yeah ? 
i don ' t remember what the p . is though . 
no . 
but there are they ' re 
the quicknet library has a bunch of things in it to handle p . files . 
yeah . 
so it works pretty well . 
and that isn ' t really i guess as important as the the main i don ' t know what you call it the the main sort of word level . 
neither do i . 
probably stands for phil . 
phil kohn . 
it ' s a phil file ? 
yeah . 
that ' s my guess . 
huh . 
okay . 
well that ' s really useful . 
i mean this is exactly the kind of thing that i wanted to settle . 
um 
so 
yeah i ' ve been meaning to look at the atlas stuff again anyway . 
great . 
so just keep 
yeah . 
i guess it ' s also sort of a political 
i mean if if you feel like that ' s a community that would be good to tie into anyway then it ' s sounds like it ' s worth doing . 
yeah i think it it 
i think there ' s 
and uh as i said i what i did with this stuff i based it on theirs . 
it ' s just they hadn ' t actually come up with an external format yet . 
so now that they have come up with a format it doesn ' t it seems pretty reasonable to use it . 
huh . 
but let me look at it again . 
okay . 
great . 
as i said that 
because we actually can start 
there ' s one level there ' s one more level of indirection . 
and i ' m just blanking on exactly how it works . 
i got to look at it again . 
i mean we can start with um i guess this input from dave ' s . 
which you had printed out the channelized input . 
because he has all of the channels . 
you know with the channels in the tag and stuff like that . 
yeah i ' ve seen it . 
so that would be directly 
yep . 
um 
easy easy to map . 
yeah . 
and so then it would just be a matter of getting making sure to handle the annotations that are you know not at the word level and um to import 
where are those annotations coming from ? 
well right now i jane would would 
uhhuh . 
yeah . 
are you talking about the overlap annotations ? 
yeah . 
any kind of annotation that like isn ' t already there . 
uh you know anything you can envision . 
yeah . 
so what i was imagining was um so dave says we can have unlimited numbers of green ribbons . 
and so put uh a a green ribbon on for an overlap code . 
and since we we 
i i think it ' s important to remain flexible regarding the time bins for now . 
and so it ' s nice to have 
however you know you want to have it uh uh located in the discourse . 
so 
um 
if we if we tie the overlap code to the first word in the overlap then you ' ll have a time marking . 
it won ' t it ' ll be independent of the time bins . 
however these evolve shrink or whatever . 
increase . 
or 
also you could have different time bins for different purposes . 
and having it tied to the first word in an overlap segment is unique uh you know anchored clear . 
and it would just end up on a separate ribbon . 
so the overlap coding is going to be easy with respect to that . 
right . 
you look puzzled . 
i i just i don ' t quite understand what these things are . 
okay . 
what the codes themselves ? 
uh 
well overlap codes . 
or the 
i ' m not sure what that 
well i mean is that 
well we don ' t have to go into the codes . 
it probably doesn ' t matter . 
we don ' t have to go into the codes . 
no i 
i mean it doesn ' t 
i mean that not for the topic of this meeting . 
but let me just 
no . 
the idea is just to have a separate green ribbon . 
you know . 
and and and let ' s say that this is a time bin . 
there ' s a word here . 
this is the first word of an overlapping segment of any length . 
overlapping with any other uh word uh segment of any length . 
and um 
then you can indicate that this here was perhaps a a backchannel . 
or you can say that it was um a usurping of the turn . 
or you can you know any any number of categories . 
but the fact is you have it time tagged in a way that ' s independent of the uh particular time bin that the word ends up in . 
if it ' s a large unit or a small unit or 
uhhuh . 
we change the boundaries of the units . 
right . 
it ' s still unique and and uh fits with the format . 
flexible all that . 
um 
it would be nice 
um 
uh this is sort of regarding uh uh it ' s related but not directly germane to the topic of discussion . 
but when it comes to annotations um you often find yourself in the situation where you have different annotations of the same say word sequence . 
yeah . 
okay ? 
yeah . 
and sometimes the word sequences even differ slightly because they were edited at one place but not the other . 
so once this data gets out there some people might start annotating this for i don ' t know dialogue acts or um you know topics or what the heck . 
you know . 
there ' s a zillion things that people might annotate this for . 
and the only thing that is really sort of common among all the the various versions of this data is the word sequence . 
yep . 
or approximately 
or the time . 
or the times . 
but see if you ' d annotate dialogue acts you don ' t necessarily want to or topics you don ' t really want to be dealing with time marks . 
i guess . 
you ' d it ' s much more efficient for them to just see the word sequence right ? 
uhhuh . 
i mean most people aren ' t as sophisticated as as we are here with you know uh time alignments and stuff . 
so 
so the the the point is 
should should we mention some names on the people who are 
right . 
so 
um 
the my point is that you ' re going to end up with uh word sequences that are differently annotated . 
and you want some tool uh that is able to sort of merge these different annotations back into a single uh version . 
okay ? 
um and we had this problem very massively uh at s . r . i . when we worked uh a while back on uh well on dialogue acts as well as uh you know 
um what was it ? 
uh 
well all the switchboard in it . 
utterance types . 
yeah . 
there ' s uh automatic uh punctuation and stuff like that . 
because we had one set of annotations that were based on uh one version of the transcripts with a particular segmentation . 
and then we had another version that was based on uh a different slightly edited version of the transcripts with a different segmentation . 
so we had these two different versions which were you know you could tell they were from the same source but they weren ' t identical . 
so it was extremely hard to reliably merge these two back together to correlate the information from the different annotations . 
yep . 
i i don ' t see any way that file formats are going to help us with that . 
no . 
it ' s it ' s all a question of semantic . 
no . 
but once you have a file format i can imagine writing not personally but someone writing a tool that is essentially an alignment tool um that mediates between various versions . 
uhhuh . 
yeah . 
and uh sort of like uh you know you have this thing in unix where you have uh diff . 
diff . 
w . diff or diff . 
there ' s the uh diff that actually tries to reconcile different two diffs based on the same original . 
yeah . 
is it s . diff ? 
yep . 
huh . 
something like that . 
um but operating on these lattices that are really what ' s behind this uh this annotation format . 
yep . 
so 
you could definitely do that with the 
there ' s actually a diff library you can use to do things like that that so you have different formats . 
so somewhere in the a . p . i . you would like to have like a merge or some some function that merges two two versions . 
yeah i think it ' s going to be very hard . 
any sort of structured anything when you try to merge is really really hard . 
right . 
because you 
the hard part isn ' t the file format . 
the hard part is specifying what you mean by merge . 
is 
exactly . 
but the one thing that would work here actually for that is more reliable than the utterances is the the speaker ons and offs . 
and that ' s very difficult . 
so if you have a good 
um 
but this is exactly what i mean is that that the problem 
yeah . 
you just have to know what to tie it to . 
yeah . 
exactly . 
the problem is saying what are the semantics . 
and 
what do you mean by merge . 
right right . 
right . 
so 
so so just to let you know what we where we kluged it by uh doing uh by doing hhh 
both were based on words . 
so we have two versions of the same words you know sprinkled with with different tags for annotations . 
and then you did diff . 
and we did diff . 
yeah . 
exactly . 
that ' s just what i thought . 
and that ' s how 
that ' s just how i would have done it . 
yeah . 
but you know it had lots of errors . 
and things would end up in the wrong order and so forth . 
uh 
so 
yep . 
um if you had a more 
uh 
it it was a kluge . 
because it was basically reducing everything to uh to uh uh to textual alignment . 
a textual . 
um 
so 
but 
isn ' t that something where whoever if if the people who are making changes say in the transcripts because this all happened when the transcripts were different um if they tie it to something like if they tied it to the acoustic segment if they 
you know what i mean ? 
then or if they tied it to an acoustic segment and we had the time marks that would help . 
but the problem is exactly as adam said that you get you know you don ' t have that information or it ' s lost in the merge somehow . 
yep . 
so 
well can i ask one question ? 
it it seems to me that um we will have an official version of the corpus which will be only one one version in terms of the words where the words are concerned . 
we ' d still have the the merging issue maybe if coding were done independently of the 
and you ' re going to get that . 
but but 
because if the data gets out people will do all kinds of things to it . 
and uh you know several years from now you might want to look into um the prosody of referring expressions . 
and someone at the university of who knows where has annotated the referring expressions . 
right . 
so you want to get that annotation and bring it back in line with your data . 
but unfortunately they ' ve also hand edited it . 
okay ? 
okay then 
but they ' ve also 
exactly . 
and so that ' s exactly what we should somehow when you distribute the data say that you know that have some way of knowing how to merge it back in and asking people to try to do that . 
yeah . 
yep . 
right . 
well then the 
what ' s what ' s wrong with doing times ? 
i agree . 
i 
that was what i was wondering . 
uh yeah time is the 
time is unique . 
well 
you were saying that you didn ' t think we should 
time is passing ! 
time time times are ephemeral . 
andreas was saying 
yeah . 
what if they haven ' t notated with them times ? 
yeah . 
he he ' s a language modeling person though . 
um 
so so imagine 
i think his his example is a good one . 
imagine that this person who developed the corpus of the referring expressions didn ' t include time . 
uhhuh . 
yeah . 
he included references to words . 
ach ! 
well then 
he said that at this word is when when it happened . 
yeah . 
or she . 
but then couldn ' t you just indirectly figure out the time tied to the word ? 
or she . 
but still they 
exactly . 
sure . 
yeah . 
but what if what if they change the words ? 
not 
well . 
but you ' d have some anchoring point . 
he couldn ' t have changed all the words . 
but can they change the words without changing the time of the word ? 
sure . 
but they could have changed it a little . 
the the point is that that they may have annotated it off a word transcript that isn ' t the same as our word transcript . 
so how do you merge it back in ? 
i understand what you ' re saying . 
huh . 
uhhuh . 
and i i guess the answer is um it ' s going to be different every time . 
it ' s it ' s just going to be 
yeah . 
yeah . 
you only know the boundaries of the 
it ' s exactly what i said before . 
which is that what do you mean by merge . 
so in this case where you have the words and you don ' t have the times well what do you mean by merge ? 
right . 
if you tell me what you mean i can write a program to do it . 
right . 
you can merge at the level of the representation that the other person preserved and that ' s it . 
right . 
and that ' s about all you can do . 
and beyond that all you know is is relative ordering . 
and sometimes even that is wrong . 
so so in so in this one you would have to do a best match between the word sequences . 
so 
uhhuh . 
extract the times from the best match of theirs to yours . 
and use that . 
and then infer that their time marks are somewhere in between . 
right . 
yeah exactly . 
but it could be that they just uh i mean it could be that they chunked they they lost certain utterances and all that stuff . 
right . 
exactly . 
so it could get very very ugly . 
or 
definitely . 
definitely . 
yeah . 
all right . 
well i guess i i didn ' t want to keep people too long . 
that ' s interesting . 
and adam wanted people 
i ' ll read the digits . 
if anyone else offers to that ' d be great . 
and 
uh well . 
if not i guess 
yeah . 
more digits the better . 
for for the for the benefit of science we ' ll read the digits . 
okay . 
thanks thanks a lot . 
this is 
it ' s really helpful . 
i mean adam and don will sort of meet . 
and i think that ' s great . 
very useful . 
that ' s a nice user interface dan . 
that ' s that ' s really something . 
very 
what does solo mean ? 
uh it means i was trying to think of things they put on real mixers that i should have on mine . 
uh . 
oh . 
but it ' s really good . 
the solo actually 
so you can feed it to the 
solo means you just 
ahh . 
feed it through the headphones for example . 
because it ' s actually you know it ' s it ' s how to it ' s what can i what application can i have for a for a uh a class method rather or a class you know a class procedure . 
can 
so the solo by satellite . 
then if you click on one of the other ones it clears that one . 
huh . 
oh . 
but it doesn ' t actually do anything else ? 
okay . 
doesn ' t do anything . 
no no . 
but i mean it ' s 
so you ' ve implemented radio buttons . 
it looks pretty slick though . 
that ' s great . 
yeah . 
can can we fast forward through this conversation ? 
so 
oh yeah that ' s right . 
yeah . 
the uh 
actually i think this thing is really cutting the blood flow . 
no . 
those 
i ' m going to pass out . 
wait . 
you ' re going to be you ' re going to be saying you know funnier things . 
this is a very sensual thing . 
yeah . 
i think a lot a lot of us ended up wearing it around your neck and then facing up . 
so leave it on . 
huh . 
i and uh just because there doesn ' t seem to be a good way to mount it . 
maybe this is a little better . 
yeah . 
that ' s really nice . 
i mean 
boy ! 
clearly i mean my impression is if i have to wear this thing you know more than five minutes uh uh uh i mean i i will be completely affected by it somehow . 
huh . 
so 
this this thing ? 
i wouldn ' t be 
yeah . 
or or just that one ? 
oh . 
that that one . 
yeah . 
the one i tried . 
i mean on on the temple ' s the pressure ? 
i ' d 
they really press my temples . 
uhhuh . 
oh yeah . 
otherwise my ear channels . 
that would give you a headache . 
what happened ? 
otherwise my joints here . 
i mean depending where i put it it press different things . 
huh . 
but that ' s a fine . 
i think we have to add that to the to the form they sign . 
i mean 
so 
so the 
yeah . 
so 
yes . 
that ' s right . 
i mean this this thing of course is probably you know acoustically more challenging . 
the medical . 
i think 
yeah . 
but i like this . 
oh yeah . 
but this is very comfortable . 
i mean i i could wear this without any difficulty . 
is it ? 
can you convert these ear ones to something comfortable ? 
i mean just by putting little 
they have so much pressure at it ' s 
but but there there i think is a you know 
i 
yeah this is just bad design this um this is . 
we we ' d we ' d have to buy new ones . 
huh . 
yeah . 
or 
yeah . 
i mean you can just use the microphone and take the headband off . 
the the other 
the other way i had it which might work is you put one over an ear . 
and then you can adjust the other one . 
uhoh . 
and that didn ' t that seemed to be pretty 
ouch ! 
that doesn ' t work for you ? 
no . 
anything which is distracting or painful is going to impact negatively with this . 
yeah . 
huh . 
but maybe the 
so so you see how jane ' s wearing it ? 
huh . 
that seems to work okay too . 
yeah . 
yeah . 
it ' s very comfortable . 
but i mean 
and you just have to bring it up . 
but at that point at that point it wouldn ' t be much different to to wear this or that . 
yeah . 
go to that . 
right . 
right . 
well except you can bring it quite a bit closer to your mouth . 
so 
hhh okay . 
but uh yeah . 
but it ' s not such a it ' s not such a directional microphone probably . 
i mean but probably this is designed in such a way that it should be closer . 
and this uh uh but this is designed to be worn like this to be worn like this . 
yeah . 
uhhuh . 
yeah . 
right . 
so 
yeah we maybe we should look into if we can buy a replacement . 
sure . 
if they ' re eighty bucks that might be worth doing because they ' re very uncomfortable . 
uhhuh . 
i mean i really like this . 
uh i i mean if i have to design the thing uh i i would rather you know use this type of thing than the other ones . 
well i mean what you ' d rather do is nothing at all . 
and also is 
wow . 
just trying to give you a hard transcription task . 
of course . 
but to get to get a good quality i mean if if you were listening to it downstairs that one ' s quite a bit lower quality . 
yeah . 
no . 
i ' m sorry . 
yeah . 
hey what where are ? 
yeah . 
what are you doing ? 
yeah yeah . 
yeah yeah i noticed that . 
do you do you know have you studied a click language ? 
so 
i noticed that . 
i don ' t 
but you know that that might be the challenging part . 
no i wish . 
no . 
wow . 
no . 
yeah . 
just studied phonetics in general . 
i mean because otherwise you are 
if it didn ' t if it didn ' t hurt you know if it was comfortable but you knew it was there would it bother you ? 
okay . 
i ' ll just take 
if it was comfortable okay . 
yeah . 
well well try this one on . 
because i actually think it sort of makes everybody act a little more professional . 
i didn ' t know that you could whistle that . 
okay . 
you ' re a very soft whistler . 
you ' re mostly able to do that without much air at all . 
actually i use something like this on on the telephone and it ' s very comfortable . 
yeah . 
i uh 
your telephone . 
aren ' t you ? 
i mean no . 
and people use it for cell phones . 
yeah it ' s weird . 
yeah . 
it ' s kind of uh 
and 
still i i i mean i ' m kind of more deaf on this ear whatever this is on . 
apical - alveolar kind of thing . 
yeah . 
i don ' t know . 
right . 
okay . 
because you ' ve got 
it ' s you know ? 
okay . 
uh i could wear it this way . 
wow that ' s amazing ! 
i don ' t know . 
i feel distracted . 
get a very high pitch that way too . 
and you get dogs to cock their heads and stuff . 
yeah it is . 
i mean it ' s my impression . 
yeah . 
i mean of course there is a lot more work to do with this one . 
it ' s really good . 
oh how fun ! 
because you can get really high . 
can you project it pretty well ? 
i mean 
but 
no . 
not too well . 
okay . 
okay . 
yeah . 
but they ' re just very very sensitive . 
but it ' s that you get enough of the high frequencies . 
i mean if if you want something really really nonintrusive really nonintrusive really something that 
yeah . 
that you really get you really get animals like 
fascinating . 
wow . 
uhhuh . 
yeah . 
well i guess my feeling is that this is for collecting a corpus not for an actual end user application . 
huh . 
and so i think a little bit of intrusion is not ridiculous . 
okay . 
okay . 
not for this for sure . 
no . 
i mean it ' s just but talking in general yeah that ' s uh 
so 
okay . 
i think you can ' t do any research otherwise . 
well 
what exactly is the purpose of the corpus ? 
yeah . 
i agree . 
it ' s just 
i mean you think you think if you 
what ' s the purpose of the 
training training speech recognition systems . 
it ' s too hard . 
it ' s too hard without . 
do you think this is going to be too too 
right . 
i think you should collect both simultaneously . 
but it will train them to the microphone characteristics of this 
we want to do both . 
and 
so so the the point is that if you if we try from the get go to do it off the p . z . m . we won ' t get anything . 
right . 
uhhuh . 
it ' s going to be too hard to do it without a 
yeah . 
yeah . 
forget it . 
yeah . 
you won ' t be able to align . 
yeah . 
so 
no i mean the 
absolutely . 
you won ' t be able to get grants . 
i agree . 
you won ' t be able to segment . 
yeah . 
you won ' t be able to do anything . 
yeah . 
yeah . 
you won ' t be able to get funding . 
so 
right . 
no . 
i ' m serious . 
hang on hang on ! 
yeah . 
i mean you won ' t be able to show any results . 
huh . 
so 
oh right right right . 
and with this with this you ' re saying you are also in that situation ? 
i mean 
well i mean we haven ' t done the the detail experiment . 
but just from listening to it it ' s pretty bad . 
it was pretty bad . 
yeah . 
yeah . 
it takes off quite a lot . 
whereas these are are very good . 
well yeah i mean that ' s really like having one of these almost . 
i mean that ' s why that ' s why if you if you use dragondictate or or viavoice or any of those others to do dictation you need to use these . 
so 
huh . 
yeah yeah yeah . 
huh . 
yeah . 
there ' s just no other way around it . 
somebody will design a comfortable close talking mike . 
i mean it ' s there are too many applications to for them not to not do that . 
uhhuh . 
well and as i said i find this one 
i mean it may not look like this . 
but 
i find this one is no problem at all . 
the only thing is a little bit of audio a a little bit of audio degradation in one ear . 
yeah . 
yeah it ' s 
yeah this one ' s fine . 
yeah yeah yeah yeah . 
right . 
and i get a little bit of peripheral vision . 
but other than that it ' s not bad at all . 
yeah . 
huh . 
those on the other hand are very uncomfortable . 
we could 
yeah . 
those are pretty bad . 
yeah . 
those are really bad . 
so 
can can ' t we buy an expander that you just 
uh 
i ' m actually finding this quite comfortable now that i ' ve got it i ' ve got it just right . 
that ' s right . 
i ' m surviving . 
it depends . 
yeah i ' ve 
i think you have you know he would . 
yeah i uh 
it ' s just 
i think he ' s about to pass out . 
that ' s why 
you guys gave up too soon . 
it must have numbed the areas . 
i think you just get used to it after five minutes . 
so i i guess 
you know maybe the problem is we got the kid ' s version . 
yeah . 
yeah . 
no we got a japanese version . 
you know that ' s that ' s it . 
sorry . 
and so and what about this one ? 
yeah . 
i mean this thing wearing that that can 
uh the 
it ' s wired . 
it ' s funny i i kind of like this . 
so it actually gets most of its strength from from you know the fact this thing ' s stuck in your ear . 
oh this would drive me crazy . 
huh . 
and yeah . 
oh . 
i absolutely . 
uh does it have a speaker ? 
uh i and originally 
people are very picky about this . 
does it have a speaker ? 
huh . 
or 
oh yeah it does . 
when i bought those things i originally got this version because plantronics makes uh you know an in the ear one . 
uh uhhuh . 
uhhuh . 
and i really liked it . 
but other people didn ' t . 
so it just depends . 
i guess you know i ' ve been using in the ear walkman headphones for you know a long time . 
yeah . 
huh . 
so i ' m kind of used to that weird sensation having something stuck in my ear . 
but if uh 
but that ' s painful . 
whereas i used speech recognition for about four years using one of these . 
if you ' re not used 
i can ' t 
so i ' m used to this . 
you do . 
i don ' t use it anymore . 
uh my hands got better . 
uhhuh . 
so i stopped using it . 
okay . 
but uh 
so for about four years i used dragondictate and naturallyspeaking . 
okay . 
really ? 
so you could actually produce like code ? 
to do all my work . 
oh you ' re a 
or 
yeah . 
yeah ? 
it was really a pain . 
code ? 
right . 
yeah . 
but i didn ' t have a choice . 
wow ! 
i mean i couldn ' t type . 
that ' s an interesting language model i ' m sure . 
uh 
so 
so 
huh . 
uh 
yeah . 
the market is a captive market . 
yeah . 
right . 
huh . 
uhhuh . 
yeah . 
in fact when i first came back to grad school that was a project i wanted to work on . 
voice environments for programmers . 
but we couldn ' t get any funding for it and my hands got better . 
so 
that ' s how i ended up working on this project instead . 
huh . 
huh . 
good . 
anyway . 
so yeah . 
so so what are you guys doing ? 
i don ' t know . 
yeah . 
what ' s your project ? 
well basically the the the original project looks a lot like you know the the your project . 
i mean basically we set up with this uh idea of the the the meeting the the mediated spaces idea in general . 
uhhuh . 
and then incarnated in this room that will be mediated somehow by you know a computer to access information to help along the meeting . 
and will be like two kind of uh main functions . 
one is the interaction with the computer . 
uhhuh . 
which as you said you know is your interaction with the p . d . a . in your case . 
where you kind of query it to ask for information et cetera . 
uhhuh . 
at the same time our process is somehow you know getting all this multi channel information doing some sort of you know cross uh channel you know cancellation and transcribing the individual streams . 
uhhuh . 
huh . 
not necessarily in real time . 
and the idea is you can eventually after the meeting query you know previous meetings . 
right . 
and 
and there is all this work on transcription . 
similar probably to what we do in switchboard but with better bandwidth . 
uhhuh . 
you know . 
but worse you know environmental conditions . 
worse acoustics . 
yeah . 
and then you know there is all all these issues about processing all this information you know transcription . 
huh . 
but then using you know prosody information to better you know segment endpoint . 
uh also using topic segmentation to help better classification of information or extraction of information . 
uhhuh . 
i mean 
we didn ' t dare to say it will be just in a p . d . a . you throw in the middle of a meeting . 
i ' m beginning to feel my heart beat now . 
yeah . 
so 
yeah . 
this is this is 
that that was daring . 
the p . d . a . one is very very ambitious . 
yeah . 
and it ' s also it ' s depending on not only that 
huh . 
uh not only does it depend on i . ram taping out and working as specified it also depends on writing vectorized speech recognition algorithms . 
huh . 
huh . 
yeah . 
yeah . 
which is non trivial . 
yeah . 
yeah . 
so 
yeah . 
but you know uh let ' s assume somehow the processor power is going to be there . 
whatever . 
i mean initially you may do a super computer for the transcription real time and then 
right i mean 
so so one of our 
huh . 
right . 
our back off policy on that if if there ' s problems with i . ram is it ' ll be a wireless link . 
yeah . 
uhhuh . 
right ? 
you ' ll dump the the dump the audio wirelessly to a network somewhere . 
yeah . 
yeah . 
i i mean uh we we kind of set up this concept like a year and a half ago . 
and you ' ll do the recognition . 
uhhuh . 
uhhuh . 
and at that time i said you know we said don ' t worry about the the compute power . 
i mean it will be somewhere you know . 
huh . 
yeah . 
well we we we ' ve had a lot of discussions about it . 
and i think 
uhhuh . 
maybe i think to some extent it comes down to a religious issue . 
my religion is personal computers are good and terminal mainframes are bad . 
and so if you can get away with it i don ' t want to have a terminal in my hand and a mainframe somewhere else . 
yeah . 
yeah yeah . 
um the too many things to can go wrong and you lack control . 
yeah . 
yeah . 
i think the p . c . revolution has shown how good it is if you can have the power yourself . 
yeah yeah . 
and so the i . ram project provided us a method of having a very powerful thing in your hand . 
uhhuh . 
and so we want to see what we can do with it . 
but we ' d also don ' t want the project to actually completely depend on it . 
so 
yeah . 
the project will go forward regardless of whether i . ram works or not . 
i mean our approach somehow i mean i believe it ' s probably you know complimentary in many ways is to focus on the actual deep technology that we have somehow in speech and basically make progress on you know the algorithms . 
right . 
and then you know it will run somewhere . 
i mean 
as you said to i mean we would like the idea to have it there . 
so 
but but our focus is basically to develop the algorithms to push the state of the art on this transcription task . 
uhhuh . 
and uh the other task probably is also you know challenging the the the querying uh the command control or you know i mean doing that in natural language . 
so 
right . 
uhhuh . 
right . 
so the so for us the meeting recorder project has a very similar uh approach . 
uhhuh . 
uhhuh . 
me personally for my p . h . d . thesis i ' m sort of doing the other way and seeing how much speech recognition can i do on this little unit . 
oh . 
i see . 
you really are challenged to do that . 
yep . 
to put as much power as you can in the p . d . a . 
yep . 
okay . 
uh our approach is you know we do whatever is necessary to do it . 
and you know some of it may go into something depending on you know your scalable power . 
that ' s right . 
so so the 
as i said the meeting recorder project 
so we have people at u . w . people here working on robust algorithms that will be running on work stations . 
yeah . 
they won ' t be running on i . ram . 
uhhuh . 
and then what i ' m trying to do is see how much of it i can put on i . ram . 
okay . 
huh . 
huh . 
well you know is eventually you will get all this you know uh higher and higher you know powers in these portable things . 
yeah it ' s not 
uhhuh . 
yeah . 
so as long as you have enough algorithms and technology to do something better if you have more processing power . 
right . 
i mean the the situation now in the speech community is that you know there is some boundary some limit in the performance . 
and no matter how much processing you throw in you don ' t get any better . 
that ' s right . 
we don ' t even know what to do with it . 
we don ' t need to 
huh . 
and so we are trying to push that . 
right . 
yeah . 
yeah . 
and then you have room to port whatever you can to you know smaller devices . 
yep . 
you get the wrong answer quicker basically . 
yeah we don ' t even know what to do with their cycles . 
don ' t you ? 
yeah . 
yeah . 
right . 
sorry i interrupt you . 
we 
i was going to say that um you know in terms 
so adam has a you know a particular agenda . 
um but obviously there are lots of other things . 
uhhuh . 
and you know it ' s the way that a project like this works . 
so that a group like this where we have students coming in you know it ' s it ' s meant to be sort of a long term thing that will get us data . 
uhhuh . 
and people will be able to come along and look at different aspects of it . 
so it ' s not clear you know whether someone at u . w . ' s going to look at um beam forming or whatever . 
but 
you know . 
it ' s it ' s a good property for us that there are a lot of different things you could do with it . 
and so it ' s we we haven ' t thought it through . 
huh . 
yeah . 
always . 
yeah yeah . 
but that ' s okay . 
you know it ' s kind of it ' s fair enough . 
like 
yeah . 
as an example we had a visitor who was working on speaker i . d . acoustic change detection . 
yeah . 
huh . 
yeah yeah yeah yeah . 
and he has a very good system for that . 
and and he wants to use this corpus . 
yeah . 
yeah . 
huh . 
exactly . 
so 
i mean it ' s one of the areas where kemal is going to work like you know speaker tracking and speaker i . d . 
yeah . 
huh . 
uhhuh . 
uhhuh . 
i mean 
you want to know . 
i mean if you have the people wired individually it probably is easier . 
oh it what ' s nice about 
but but you know in in the other situation you know . 
yeah . 
what ' s nice about getting this corpus is with the people wired you have a excellent baseline . 
yeah . 
yeah . 
right ? 
yeah . 
huh . 
you have a very easy problem and you can get the right answer to ground truth very easily . 
you can get the ground truth . 
yeah . 
yeah . 
and then you can degrade it by using the p . z . m . ' s . 
yeah yeah . 
huh . 
you can degrade it further by using those things . 
yeah yeah yeah . 
and and really see what you can do with a real system . 
so 
yeah for example when you go to your p . d . a . system it ' s uh really an awful open problem to determine how many speakers there are and where they change turns . 
that ' s right . 
huh . 
uh 
yeah . 
that ' s right . 
that ' s actually being that ' s one of the problems that ' s being addressed at this year ' s evaluation . 
uhhuh . 
uh 
oh really ? 
they ' re doing an unknown number ? 
which is taking place right now actually . 
huh . 
right . 
you you do need to figure out the number of speakers in the waveform . 
that ' s good . 
which uh evaluation of 
right . 
this is a nist evaluation . 
um 
of the speaker i . d . or something ? 
this 
uh right speaker verification . 
and what ' s the what so what has the data been ? 
what what what data are they using ? 
what is the 
uh switchboard . 
oh okay . 
switchboard and uh 
i i 
we 
well i mean 
we will also run some part of that uh evaluation too . 
but probably not that segmentation part . 
but i don ' t know if they are using a different data for that . 
but i mean it ' s while i say switchboard uh of course there ' s only two speakers . 
yeah . 
but um i don ' t know how they uh actually went about . 
um 
because they were saying some some some up to eight speakers maybe they 
maybe some other data for that part . 
uhhuh . 
you ' re right . 
i mean just mixing it wouldn ' t work because the channel characteristics are too different . 
no no . 
huh . 
yeah . 
so uh what we what we were working on here was parts of broadcast news . 
right . 
and so that that ' s a slightly strange task because they tend to be long segments . 
but they were they were parts that were interviews that he worked on . 
uhhuh . 
and uh 
no . 
we ' ve also uh done some of that as uh uh 
right . 
um i mean i have a so small uh hacked up system which sort of for for the broadcast news determines the approximate number of speakers and actually assigns some names to them . 
uhhuh . 
uhhuh . 
this is something we did for the maestro project uh for for rick . 
uhhuh . 
but um uh 
yeah uh for for broadcast news it works much better actually . 
it ' s uh 
yeah he had he got very good results . 
you do get uh like in an interview uh nice long segments . 
right . 
and 
right . 
yeah so i i tried his on his system on the meeting recorder stuff . 
um 
but of course we don ' t have any trained neural nets . 
or uh 
so so his system was based on our hybrid neural net system that we use for speech recognition . 
huh . 
and so uh i was using the broadcast news nets on this data . 
huh . 
so of course it didn ' t do didn ' t do tremendously well . 
and then the other problem also was that it doesn ' t handle overlap very well . 
his algorithm . 
yeah . 
i mean broadcast news is for this third party listener . 
huh . 
right ? 
right . 
right . 
so they you know if you were listening to an interview that sounded like this you know you ' d turn off your radio . 
yes . 
that ' s right with all the interrupts . 
right . 
so it ' s just got a 
it ' s a lot easier . 
yes . 
i think there are some programs in t . v . 
i ' ve been trying to get this from something like this from you know public cast . 
uh uh uh 
there are there are some with a lot of overlap . 
um uh yeah . 
and they but they they do it somehow they clean it up . 
yeah . 
i notice that they they they have some help with control of what person to pick up . 
mixing . 
yeah . 
uhhuh . 
i i mean there is some program at midnight somewhere . 
it ' s a bunch of like four people discussing . 
well 
and they it ' s a lot clean . 
like mclaughlin . 
yeah . 
i yeah . 
but the but the worst the worst case is politically incorrect where they don ' t really make any adjustments at all . 
probably . 
but yeah they they have 
uhhuh . 
and and it ' s hard to even follow what they ' re saying . 
uhhuh . 
it ' s just it ' s truly totally overlapped . 
right . 
yeah . 
uh yeah . 
yeah . 
i ' ve heard that that that sometimes . 
but it ' s it ' s okay though . 
i think in in 
it ' s still in the it ' s still in the format which is slightly more formal i think than you know completely informal conversational speech . 
so you don ' t think they they fill it at all with any you know 
okay . 
uhhuh . 
oh i ' m sure they do . 
they i ' m sure they have an audio engineer in the back . 
they 
they will do a bit . 
i am pretty sure they do . 
yeah . 
i mean it ' s it ' s it ' s still you know understandable . 
okay you guys are more in business that i am . 
but it 
the host probably gets uh you know gets a little bit more . 
yeah . 
my feeling is that when i when i when i ' ve seen that show it ' s like there there are sometimes people who totally take over the floor . 
gets a little boost . 
yeah yeah . 
and other people are trying to get in and they can never never get access . 
yeah . 
yeah yeah yeah . 
it depends very much on the mix . 
well but that ' s different than an audio engineer fiddling with the mixing parameters . 
yeah it ' s just i i know that there are periods where two people are talking in at the same time . 
right ? 
at the same time . 
yeah yeah yeah yeah yeah . 
and you ' re only able to hear um parts of the weaker voice . 
and you know that ' s it ' s a style . 
uhhuh . 
it ' s a style . 
uh but i but i ' ve seen debates where 
uhhuh . 
yeah yeah yeah . 
uhhuh . 
and you know it ' s apparently engaging people . 
uh it ' s been going on for a while now . 
yeah yeah . 
yeah . 
yeah in many cultures it ' s not bad manners to to speak on top of another one . 
yeah i was thinking if transcriber were invented in italy or something it would have been handling multiple 
sure . 
absolutely . 
it somehow 
yeah . 
or in new york . 
or in new york . 
in new york . 
high involve high high involvement style . 
yeah . 
yeah . 
right . 
huh . 
i mean could be reassuring . 
yeah . 
high involvement . 
you know ? 
that ' s that ' s a 
keep going . 
keep going . 
yeah . 
good way of saying it . 
that ' s what it ' s called . 
yeah . 
so what do we do ? 
well i mean 
it seems like there ' s a lot of overlap between our projects . 
i i i believe there is a lot of overlap . 
there 
yeah indeed . 
so it would be nice to work together . 
and would be great to to to basically take advantage of that to to make a synergy more than an overlap and you know help each other . 
uhhuh . 
huh . 
i i believe each group has you know depths in in different uh areas . 
we 
so 
i mean we clearly should collaborate for the best of everybody . 
huh . 
so is your intention to start collecting some meeting data ? 
uh 
i you know 
there are no final 
i mean the official decisions i guess have to be made in terms of resources to that . 
uhhuh . 
my personal opinion if you ask is that we should . 
because the only way 
i mean if i learn anything on speech in for the last you know 
more data is better . 
no no no . 
um you need a task to really you know improve your system for that particular environment . 
oh . 
uhhuh . 
so right now we are focusing our research on doing evaluation type of you know incremental you know improvements . 
so 
switchboard for instance . 
they have five is kind of 
okay you have two people talking . 
it ' s the closest thing . 
but we really should move into the you know data that reflects as much as possible the real scenario . 
huh . 
and that ' s a way to improve . 
right . 
uhhuh . 
and then you do improvement on that particular database . 
so even if we don ' t collect the data to train models we should collect data at least to evaluate progress . 
so what would be nice is if we could uh converge on on formats and conventions and so on . 
yeah . 
yeah . 
huh . 
yeah . 
and and software too . 
i think that ' s the 
and software . 
i mean things like rewriting this transcriber tool . 
i mean just 
yeah . 
yeah . 
and that that shouldn ' t be redone . 
right . 
yeah . 
right . 
yeah . 
huh . 
and the transcription conventions 
i uh uh it shouldn ' t be done . 
you ' d mentioned there was some possibility that somewhere else is going to you might contract out to do the transcription ? 
yes . 
we ' re talking about that right now . 
can 
i ' m not sure how much i should say about it . 
yeah that ' s what i was wondering . 
so that the 
okay . 
uh 
there ' s some possibility that we ' re going to get a third party company to do the transcription for us in exchange for the corpus . 
uhhuh . 
is that in exchange for access to the 
right . 
right . 
yeah . 
so one question . 
and 
i mean uh this this thing is also for you made on internal funding ? 
or i mean i know you ' re applying for some darpa funding . 
we have a little bit of darpa . 
oh you already got some . 
uh under the communicator project . 
okay . 
okay . 
so so that ' s part of it . 
and then uh part of it ' s on the i . ram group . 
okay . 
i . ram group is paying for part of it . 
and then part of it ' s just icsi general funds is paying for it as well . 
okay . 
and you ' re saying some of the infrastructure is um the a . t . and . t video conferencing . 
the infrastructure yeah they they were paid . 
yeah . 
but they don ' t expect anything in return . 
right . 
so 
they ' re just being very nice and good neighbors . 
a free gift . 
yeah . 
and 
and so they they basically wanted stuff anyway . 
okay . 
and then they just sort of allowed us to direct the audio portion of it to what we needed . 
huh . 
yeah . 
right . 
so 
and then uh u . w . 
i don ' t know if you mentioned this at the beginning . 
but the mari ' s group mari and morgan i i think what happened historically um 
oh i don ' t know how much i ' m supposed to say if this is being recorded . 
well anyway uh 
should we stop recording ? 
you are on the line . 
huh huh . 
um 
this would never go away . 
there ' s funding uh 
i i can pause if you want to say something that that ' s sensitive . 
i mean 
it ' s 
no it ' s okay . 
okay . 
um i ' ll tell you later . 
yeah . 
sorry listeners . 
and to our listening audience . 
that ' s to the listeners . 
yeah . 
too bad you weren ' t here . 
you know maybe thousands of people are listening to us now . 
well it does sort of make you 
because it ' s in the future . 
but you know sequentially maybe thousands . 
yeah . 
that ' s right . 
it could be . 
it ' s 
it ' s like you ' re behind closed doors . 
this could be the most popular corpus . 
but you have to 
yeah . 
that ' s right . 
it ' s so funny like we close the door and it ' s 
normally a note taker would know not to do that . 
okay . 
ha ! 
yeah . 
what i can do is say la la la la la la la la la . 
but that ' s only on one 
yeah . 
anyway u . w . is getting some funding from darpa on communicator uh with 
i know . 
but we can blend it for the public . 
uh . 
and that ' s sort of how i got involved . 
i mean morgan wanted me to sort of do something . 
i guess i my interest was sort of in the language and dialogue modeling and the turn overlaps and how to apply you know a language model a dialogue act model to actually feed down to do better recognition . 
so not just 
because i think it will be really difficult to do just speech recognition and then try to get some kind of meaning out of it . 
i think you have to have some kind of structure from the 
huh . 
feedback . 
i mean 
yeah . 
and 
so knowing that an utterance is really short and low volume you should be able to figure out it ' s a backchannel and things like that . 
anyway . 
apparently and you guys know more than i do there was some talk that you were going to build a portable version of this so that mari ' s group 
uhhuh . 
i i mean there ' s not a huge amount of funding in the way you know mari probably won ' t be able to do a ton of collection . 
but i was thinking if there were sort of prototype collection devices or standards then we could share data . 
uhhuh . 
huh . 
yeah . 
yeah . 
and we would have like a monopoly on that . 
i mean once you get three sites collecting data and each site can demo it and say it ' s at the other two sites . 
yeah . 
yeah . 
huh . 
which was would be really good for funding purposes . 
right . 
but that i don ' t really know . 
that ' s what i heard from morgan . 
yeah i know . 
that that ' s that ' s that that that portable thing ' s been mentioned . 
so 
we we talked about that and it was 
is that 
and according to morgan it ' s like happening . 
and 
well when i spoke with him he he really just said it was a money issue . 
but that was 
that it ' s certainly not any sort of intellectual property issue where we ' re perfectly willing to give people those boxes . 
okay . 
oh well . 
the boxes are cheap . 
right . 
um but you know can they afford to get a six channel sony wireless ? 
and can they afford the p . z . m . ' s ? 
and that sort of stuff . 
and he said something about a portable you know that they wouldn ' t have a dedicated room or something like like you guys have here . 
well 
i think i think somebody ' s got a unit which is something like the a . dat or something . 
which you know it ' s a device which will record onto tape uh multiple channels . 
oh . 
and so i think that was that was going to be 
and we were like someone actually has this knocking around . 
some company that we were going to uh was going to lend it to us something like this . 
okay . 
this is 
this is the same same company that may be doing the transcripts for us . 
the same it might be the same company or it might be a different company . 
may be giving us 
right . 
there ' s another company which also has a apparently has purchased a very a big multi channel thing . 
may be giving us 
uhhuh . 
um 
and so if we if they could lend us that we could imagine doing these kinds of recordings . 
i mean that you know that like you said the fundamental thing is it doesn ' t have to be this hardware . 
it ' s just the idea that you have multiple channels to synchronize data . 
right . 
huh . 
and then the post processing can be uniform and stuff like that . 
right . 
and it doesn ' t have you know different sides can do different pieces of it i think . 
so 
right . 
yeah . 
and it would also it would be really nice to be able to do it in other rooms . 
and 
because otherwise we ' re going to learn a lot about this air conditioning . 
exactly . 
yeah . 
right . 
and you ' ll get different kinds of conversations and different interactions . 
that was 
yes . 
and i think just having three different sites would be great . 
that ' d be great . 
yeah . 
i agree . 
just for sort of diversity . 
yeah . 
huh . 
and so . 
well . 
one thing that horacio hadn ' t mentioned is 
um 
i mean you were talking about uh the same the same sort of idea of just collecting a meeting and and looking at it afterwards . 
but the the thing that i ' m interested in and i ' m probably the one who ' s going to start doing the collection um is is having this situation where people are talking to each other and talking to a computer in the machine in in the room . 
right . 
um 
and 
so that ' s probably that ' s probably what 
that ' s going to be . 
that ' s certainly what ' s going to come out of uh of our group first . 
so so are you going to uh is there going to be some sort of mark for that ? 
uh um 
and it 
i mean are they going to say computer bring up a web page on 
or 
well . 
so you know what we ' re we ' re basically doing is is waiting to look at the pilot and see what people want to do . 
uhhuh . 
but it ' s going all be wizard of oz at first . 
so we ' re going to let them do what they want to do first and then see if we should um you know subsequent things . 
oh i see . 
uhhuh . 
try to try to constrain them . 
or not constrain them . 
or try try to figure that out . 
i ' m just thinking from a discourse point of view it ' d be very interesting to somehow mark i ' m talking to the computer . 
right . 
no it has to be has to be error complete . 
yeah . 
but you know what ? 
so the computer has to 
they don ' t say when they stop . 
that ' s one of them 
right . 
pardon ? 
they don ' t say you know i ' m done computer . 
they only mark the beginnings . 
yeah . 
huh . 
yeah . 
yeah yeah . 
well there might be a different style of um a different actually style of interaction . 
so 
and it ' s all of these things is a 
it uh there are very 
computer show me a web page on x . return . 
yeah . 
it is exactly these things that i mentioned . 
yeah . 
this is these are the main things that i ' m interested in . 
very interesting . 
exactly these . 
and actually mari ' s 
when when do you know when you ' re starting and when you know you ' re ending . 
no but no but 
but it ' s like you know if it really was an intelligent assistant sitting there you could say oh perhaps the computer could show us this . 
and you ' d be talking to someone else . 
but the computer ' s meant to be listening and so saying oh . 
it means me . 
you know i i should i should do something now . 
yes certainly . 
are you talking to me ? 
are you talking to me ? 
but there might be uh neat ways you can do this that are not natural but they become very easy . 
huh . 
so like saying like hal ? 
and that 
so 
yeah . 
huh . 
so 
right . 
so we want to we want to look at exactly those sorts of things . 
i i think 
yeah . 
of of us at least in the beginning is going to have a number of different characteristics . 
erase that part . 
it ' s not going to be natural . 
it ' s not going to be a regular meeting . 
it ' s going to be an artificial situation because we ' re going to have to you know mock up some back end . 
um 
so the kinds of you know the kinds of speech is the speech is going to be slightly different . 
people are going to be in an unnatural task . 
we ' re we ' re going to be trying to figure out how they ' re going to 
but you can still collect the multiple microphones in a similar way and transcribe . 
but 
but we will have the you know we ' ll we ' ll have all this all the microphones set up all the same . 
huh . 
so the 
and 
that ' d be cool actually . 
yeah . 
i mean that ' s the question . 
if if we are collecting these at different sites different kinds of tasks different people what is there that ' s going to be uniform about this collection ? 
uhhuh . 
right . 
and part of it will be well this combination of close talking and uh and uh environmental mikes . 
huh . 
and and then part of it will just be the data presentation . 
you know maybe if if we have common transcription standards and you know that it ' s all transcribed . 
or 
there ' s there ' s some integration of the standards thing . 
right . 
but i mean i as long as that makes sense then it ' s nice to have a variety of tasks right ? 
to have sort of you know different 
yeah i mean i think the formats would be similar . 
and yeah . 
and if your task is to just sort of you know generally do um summary and uh and large vocabulary speech recognition over the thing then it doesn ' t matter that much which uh that there ' s much a difference . 
right . 
yeah . 
but i think having the the idea of the computer sort of in there forces you to create a a log file format that can handle these other devices . 
huh . 
right . 
right . 
i mean you were talking about the penn . 
and 
and so . 
i i think it ' s 
the formatting is really one of the biggest issues . 
x . m . l . 
that solves everything . 
you know . 
not not the transcript formatting but the audio formatting and the sort of figuring out how to synchronize all of these um pieces . 
uhhuh . 
that ' s right . 
we ' re going to make 
and what kind of software you can use for post processing all of them . 
yeah . 
right . 
someone will make some assumption that ' s different than someone else . 
yeah . 
yeah which 
and then we suddenly won ' t be able to interoperate . 
well just just the fact that people are making different assumptions is quite an interesting problem . 
yep . 
uhhuh . 
you know it ' s quite an interesting issue . 
so that ' s something we should try to 
that brings up 
huh . 
yeah . 
i ' m not sure what i mean what ' s a good solution than that other than trying to keep in touch with each other . 
but 
yeah . 
well if we ' re going to have if we ' re going to 
there ' s an opportunity to share tools . 
right ? 
if we 
right . 
we could have like you know some periodic meetings . 
huh . 
and like uh 
yeah . 
yeah . 
or phone meetings . 
or even 
phone meetings or something . 
or meetings like this with about the meetings . 
uhhuh . 
yeah . 
i mean meetings like this are good because we can actually record them . 
you know with a with a telephone . 
yeah . 
at the same time we contribute to the database collection . 
yep . 
yeah . 
contribute the data . 
absolutely . 
no i ' m serious . 
and uh 
even if we don ' t make any decisions we ' ll have a lot of data . 
that ' s right . 
but it will be all documented . 
sorry . 
yes . 
yeah actually we could do that at our site too . 
even though that ' s not what i ' m normally going to be collecting . 
right . 
but there ' s no reason we can ' t collect that . 
and uh then you ' d have a more your normal kind of meeting . 
right . 
so 
when you ' re talking about your artificial meetings they are going to be goal directed though . 
right . 
so they ' re going to say you ' re you ' re having a meeting to do this . 
they ' re going to be goal directed . 
you ' re supposed to 
yeah you know you ' re supposed to you ' re a budget meeting or something . 
and you have a spreadsheet up there . 
and everybody has to sort of work out the you know some particular goal of where to allocate money . 
and they can ask the computer to switch things around in different columns or something like that . 
uhhuh . 
but everybody 
and actually another characteristic is that we ' re only dealing with three people . 
oh . 
um 
so that will be different . 
yeah . 
huh . 
so 
how is that ? 
three total ? 
we ' re going to start with just three people . 
yeah . 
is that the channel limitation cutting in ? 
um i think it ' s mainly it ' s partly channel limitation . 
because we want to we want to double mike everybody . 
huh . 
um it ' s also to a large extent 
oh right . 
oh . 
um 
and we have eight channels . 
um 
it ' s also i think uh sort of what came up i think when even liz was uh involved a little while ago with and christine i think just in terms of the thinking of the subjects and trying to have enough people . 
we sort of wanted to you know encourage like everybody to talk . 
try to figure out some way that everybody would be able to participate . 
and 
so if 
yeah . 
you ' re double miking everyone . 
so that ' s a close talking and a lapel and then two environmental mikes . 
a 
two of . 
is that right ? 
yes . 
that was that was the idea . 
yeah . 
uh but 
uhhuh . 
i don ' t know . 
huh . 
that was you know we ' re not uh planning to do anything with with all that like right away . 
so if there were is there you know we we ' re happy to take input on that . 
right . 
is it the three i see ? 
well if you uh 
and also i very much want to find out about the you know the specs on the board that you have in the in the in the p . c . i . card . 
uhhuh . 
because i think we might want to go with that . 
uhhuh . 
huh . 
i want to ask one question though . 
so is is it the same three people each time or a different three people ? 
yeah . 
no no . 
we ' re we ' re hoping to just bring in different groups of three people apiece . 
okay okay . 
that ' s good . 
and do you have the same agenda although there ' s a goal ? 
is there one goal or several goals ? 
because that ' ll would be more interesting data if there is like . 
uh 
in a given in a given meeting ? 
i mean a budget meeting is a classic example of where every comes in pursuit of a different goal . 
yeah yeah . 
what we ' re what we ' re trying to do is not make it too uh you know not make it too um artificial . 
you know . 
not like say okay . 
huh let ' s role play . 
your you know you do this you want to 
right . 
but rather give them an actual task . 
well there can be like a problem solution kind of thing where they would actually you know they have to come to one solution . 
so actually have 
yeah . 
and they all just have their own they just happen to have their own opinions . 
right . 
and another possible thing that we ' re thinking of is something like uh you know we have these regular wednesday lunches . 
right . 
and you got to plan a menu right ? 
so everybody has things that they like . 
well some people speak with their mouth full you know that ' s a . 
and uh 
yeah that 
but a lot of the 
right . 
no . 
that is uh 
we we we ' ve thought about doing 
delete that part . 
none of that . 
no eating during meetings . 
right right right . 
yes . 
or drinking . 
maybe salivating if you ' re thinking about the food . 
but it 
getting getting coffee on these is definitely a bad thing . 
not with these around . 
um 
that ' s 
oh right . 
so so i one question . 
yeah . 
yeah . 
i i mean i haven ' t been in these uh you know preliminary decision meetings . 
but i don ' t know what ' s the idea for the computer interaction . 
i mean it ' s going to be a real computer as in wizard of oz ? 
wizard of oz . 
okay . 
so the idea is we want to start off with a somewhat simple back end . 
uh what ' s 
and we ' re thinking of um agentifying an excel spreadsheet and having like some kind of spreadsheet 
so basically what people will see a spreadsheet and they can ask it to move numbers around . 
so 
we thought that would be a be a useful kind of task for budget meetings or that kind of thing . 
and so it will be a real computer recognition . 
so starting off we would start off definitely with a wizard of oz task . 
oh okay . 
but it would be something 
so a real computer but a uh someone driving it . 
uh yes . 
okay okay okay . 
huh . 
but it would be something uh but everything would be an agent . 
uhhuh . 
and so it just be you know we wouldn ' t have the recognition grammar to begin with . 
okay . 
we wouldn ' t have the n . l . grammar to begin with . 
yeah . 
but these are all components that are obvious to us how to build . 
yeah yeah yeah yeah yeah . 
nothing nothing that ' s sort of far in the future . 
huh . 
yeah . 
it ' s just a matter of of work . 
so somebody will be playing the recognizer . 
and then other agents will be doing their task independently . 
yeah . 
okay . 
so 
sort of 
right . 
something that can be built up you know relatively quickly . 
and makes sense how to do . 
so a fairly simple back end . 
yeah . 
um 
good . 
yeah . 
i i think that ' s close enough to what we ' re interested in that it would it ' d be useful for training uh the acoustic models without any question . 
oh yeah . 
yeah sure . 
uhhuh . 
yeah definitely . 
you you plan to to train actually models based on this data . 
huh . 
that ' s good . 
oh absolutely . 
yeah . 
great . 
yeah because if you don ' t the the accuracy ' s going to be horrendously bad . 
in 
huh . 
right . 
yeah yeah . 
and this is just um training them using the um the head mounted data initially ? 
so 
or i mean is the intention to do some 
i think 
well we ' ll definitely need to do both . 
no . 
i think the idea is to train on the uh on these mikes but use these to get the alignments that we ' re going to train to . 
right . 
okay . 
right . 
understood . 
uhhuh . 
right . 
right ? 
you ' re not intending to do any 
you said you weren ' t going to planning to do any beam forming as such . 
but you ' re not intending to do any signal processing or uh or uh uh the sort of acoustic modeling of the environment or microphones or anything else ? 
i don ' t know . 
it it really 
because that ' s actually my interest at the moment so . 
it will really depend on if we have someone who really wants to do that . 
huh . 
right right . 
yeah . 
so 
yeah . 
well also i mean i i i suspect that it may we may not be able to get anywhere without doing something . 
yeah yeah . 
right ? 
so 
yeah . 
we may end up having to do that . 
well it ' s 
just as an example i ' ve done some very simple digits recognitions . 
where uh i said if i had known we were having this meeting i would have done this before . 
uh 
having people read digit strings . 
that was morgan . 
because digits are much easier . 
huh . 
um 
oh that ' s really interesting . 
and just combining just doing 
we ' re starting off with digit stuff too for for for our different for for this um endpointing stuff . 
huh . 
yeah . 
of course . 
yeah . 
uhhuh . 
but uh just mixing the 
yeah . 
just doing multi stream on the different mikes helped enormously . 
and i was a little surprised . 
huh huh . 
right . 
yeah so you so you 
why why is that ? 
so you ' re having 
why ? 
why ? 
i have no idea . 
because they ' re a little different . 
sorry . 
when you say multi stream you mean 
hang on . 
you mean you 
the microphones are different ? 
you mean uh to combining the the posteriors on full band recognition like from from three different or four different mikes . 
uhhuh . 
uhhuh . 
right . 
right . 
cool . 
huh . 
huh . 
and that actually helped . 
that ' s interesting . 
that gave several percent improvement . 
right . 
yeah . 
absolute . 
so that uh 
i think just just having stereo will help . 
because they ' re a little different . 
yeah . 
you get a little slightly different estimators . 
huh . 
yeah . 
and uh 
uh you combine them together and you do a little better . 
so basically if you plan on really training collecting a database uh for database for training i mean you are talking about you know twenty thousand or forty thousand sentences . 
things like that . 
right . 
so that the 
it ' s something like tens of hours . 
uhhuh . 
tens of hours of data i think . 
tens of hours . 
yeah . 
uhhuh . 
so our initial plan for icsi was to do forty hours . 
yeah . 
okay . 
and then u . w . is talking about doing an additional sixty to a hundred hours if they have the money . 
uhhuh . 
that 
if they can actually do it . 
yeah . 
really ? 
that ' s pretty 
huh . 
huh . 
i mean that ' s what they had said before . 
that ' s 
but i guess that was more ambitious . 
we were thinking something like you know ten hours to begin with . 
they were going to 
there was a difference in the amount of money awarded from the beginning to 
huh . 
it ' s about 
uhhuh . 
uhhuh . 
well the other thing too is i mean if if you have the equipment then it could be different . 
um 
but i mean 
yeah . 
recording it ' s easy . 
then the recording is easy . 
and maybe maybe they 
yeah recording is 
right . 
it ' s transcription that ' s a pain . 
it ' s transcription and processing yeah . 
so so 
oh the 
right . 
right . 
yeah . 
that ' s actually that ' s the other thing . 
we weren ' t 
yeah . 
huh . 
okay but you have to put on a you have to put on a mike . 
so so 
i think we ' ve run it 
well uh 
oh . 
we ' re out of mikes . 
i ' d give you my mike . 
not quite . 
but 
you can have my mike . 
yeah yeah . 
it ' s not we we it ' s a 
it ' s not a speaker phone is it ? 
don ' t don ' t switch mikes . 
don ' t switch mikes . 
oh i ' m not allowed to . 
that ' s way too confusing . 
we 
okay . 
alrighty . 
we need to uh 
so i mean clearly if everybody ' s collecting data to train on maybe we should do something . 
uh 
one thing i should point out we were we were not planning on doing transcription of the full thing right away . 
because that ' s not i mean i was initially interested in just the speech that was directed at the computer . 
uhhuh . 
uhhuh . 
uhhuh . 
huh . 
and so we were not planning on doing the transcribing the entire thing . 
right . 
okay . 
but i mean that ' s something to talk about . 
but if you had the data and we had a a company . 
but perhaps the company a company that might uh 
if you wanted if you wanted to transcribe you have the . 
yes you ' ll be fine . 
i didn ' t know whether i should name the company that may be providing us transcription or not . 
yeah . 
yeah . 
there 
no . 
if you doubt don ' t do it . 
because we ' re very naturalistic here . 
yeah . 
but it um and there will be a lot of people to people talk in those meetings i bet with even three people . 
so 
so what is the company ? 
so 
i heard a 
i . b . m . 
yeah . 
so we ' ve been we ' ve been trying we ' ve been trying to work with them for a while on these projects . 
i guessed it from the clue . 
uh ! 
yeah . 
uh . 
okay . 
and they don ' t 
it ' s hard for them to give us money . 
but they they seem to be willing to give us time . 
uhhuh . 
and so one of the potentials is for them to do transcription in exchange for access to the corpus . 
yeah . 
so basically it seems to be like uh 
i mean if everybody was in the universities collecting data we are you are i mean sharing the data and making a bigger corpus is going to be you know a benefit for everybody . 
it would be great . 
huh huh . 
oh yeah . 
yeah . 
yes . 
absolutely . 
yeah . 
i think that would be excellent . 
and uh it will really help the design too . 
uhhuh . 
it ' ll keep it from being too specific to somebody ' s set up or task . 
yeah . 
should we should we interpret what he says ? 
morgan said yes . 
oh do we 
that ' s right . 
morgan says 
morgan says thumbs up . 
there we go . 
right right . 
um 
but how much how valuable 
given that you ' re interested in this computer directed data and we ' re not going to have any of that ? 
well that ' s me personally . 
our group in general as horacio was saying is also interested in some of the same general issues . 
yeah . 
i see . 
yeah . 
well and i think that 
huh . 
um 
yeah . 
and i ' m also interested in prosody um use you know used over person to person stuff . 
like segment and helping for segmentation and stuff . 
right . 
yeah so we have some ideas there but not enough data to train . 
so 
right . 
uhhuh . 
so harry and kemal and i probably . 
so actually having different kinds of conversations is really helpful too . 
uhhuh . 
because to to make these models robust . 
you don ' t want to train on just a few people ' s voices . 
because then you ' ll just learn the their prosodic patterns . 
huh . 
right . 
huh . 
that ' s not what we want . 
uhhuh . 
so so how are you going to get ground truth on that ? 
so so we should 
that is from the transcription and from the speaker segmentation . 
that ' s not hard . 
uhhuh . 
i think the hard part is getting enough training data and 
uhhuh . 
you also need normalization data . 
so you ' re sort of iteratively normalizing as you go through the 
so 
but anyway what i was going to say is that although we ' re not going to have speech directed to a computer my expectation is that the acoustic models will be very similar . 
the language models probably won ' t be . 
the language models yeah . 
actually the acoustic may not be either . 
so it ' s 
really ? 
yeah i if it ' s wizard of oz i think it will be . 
oh sure . 
if they know that 
yeah if it ' s very good . 
yeah . 
that ' s true . 
yeah . 
if it makes mistakes it ' ll be different though . 
yeah . 
on the language model we ' re 
i think it 
huh right . 
huh . 
the language model will be certainly be different . 
uh we ' re we ' re going to be using the same thing that we ' ve done in the past . 
but 
which is you know we need a natural language grammar written anyway . 
it ' s written in unification grammar framework . 
uhhuh . 
um but with context free grammar power . 
and so it ' s just changed directly into something the recognizer recognizes off of directly with with no 
um 
and you ' re going to hand hand code that ? 
it ' s it ' s it ' s hand coded . 
because we need we need to write the natural language grammar anyway to understand . 
so it ' s it ' s a small you know atis - sized type task . 
oh i i uh 
sure sure sure sure . 
i see . 
huh . 
so 
yeah that ' s that ' s the way we ' ve been approaching it . 
right if you want to interpret it you uh need to do do that anyway . 
uh if we if we ' re 
yeah we you know . 
if we ' re going to be able to interpret it then i mean if we ' re not going to be able to interpret that then it ' s not going to do us much good anyway to recognize it . 
so we might as well go directly from the natural language grammar . 
is it is it going to be like an h . p . s . g . kind of grammar ? 
it is a unification base . 
it ' s not it ' s not as as theoretically bound as h . p . s . g . in particular . 
although the couple of people that we have working on it have h . p . s . g . backgrounds . 
i see . 
so what ' s your time frame look like for doing meetings actually starting to record some ? 
i guess 
it ' s all up to when i have free time . 
yeah . 
i mean 
except 
anybody else want to work on this by the way horacio ? 
uhhuh . 
well 
well indeed . 
i mean most people you know after this evaluation and conference should be working on these type of things at least . 
huh . 
uhhuh . 
yeah . 
you know . 
well i know they ' re all working on mediated spaces . 
but there ' s a lotta aspects to that to that project . 
yeah . 
yeah . 
yeah but but eventually i mean will be people working on uh kind of recognition aspects and uh you know and and and in core technology . 
so i mean recognition technology and also core you know algorithms et cetera . 
and for those people to have these data will be you know the best way to you know develop the systems to an . 
right . 
uhhuh . 
well the the reason i ' m asking is that it ' s certainly better to get in early with standards and data formats and conventions . 
yeah . 
yeah . 
yeah . 
yes . 
definitely . 
yes . 
so probably uh on the 
um 
well so we haven ' t even you know we haven ' t collected a byte yet . 
right . 
that ' s actually why i called this meeting . 
so 
because i mean you ' re both working on it and with you know different sampling rates and these silly things like that . 
well yeah . 
it ' s a it ' s excellent excellent . 
huh huh . 
right . 
yeah . 
yeah . 
that ' s right . 
huh . 
i mean just just just agreeing on a sampling rate and a number of bits and uh header formats and all that . 
yeah . 
so 
and we have the same sampling rate . 
yeah . 
sampling rate in the end . 
what ? 
one one thing we do know is that we ' re we ' re all producing nist sphere files in in uh uh in the standard format . 
yeah . 
oh . 
okay . 
nist headers . 
sixteen bit sixteen kilohertz . 
sixteen bit sixteen kilohertz . 
bits sixteen k . . 
okay 
uh good good . 
so at the end we ' re all 
yeah . 
and the amazing thing is that even even you know the entire way through we ' re actually using some very very similar stuff . 
big endian little endian ? 
yeah . 
okay . 
well i just made that up . 
and so 
but 
yeah . 
um 
well but that ' s that was coincidence right ? 
so . 
but that 
yeah it ' s coincidence that it ' s very fortunate because 
yes . 
yeah yeah . 
that ' s right . 
not but 
but you have different you we ' re going to have different you know hardware and and 
yeah . 
yeah . 
we actually have yeah quite similar hardware as it turns out . 
it ' s similar . 
but not quite the same . 
okay . 
but it but it 
so 
which is it ' s it ' s very good . 
yeah . 
yeah . 
so 
um so we ' re actually 
so the bit we ' re a bit deficient in as we 
so i i think probably the biggest thing would 
well no . 
that that wouldn ' t be true . 
if you ' re not going to transcribe it yourself then you ' re not going to care too much about our transcription conventions . 
actually that ' s the transcription conventions i was talking about this with jane it ' s really important to people at least like me who want to know um certain uh who are looking at aspects that are sort of they ' re not words but they ' re structural things you ' re trying to recognize . 
well . 
uh 
right of it . 
uhhuh . 
and also i guess for the speaker . 
people interested in the speaker separation . 
because what you call a turn and the end of a turn and that it it ' s horribly confused if you don ' t sort of 
huh . 
it ' s inherently hard . 
and so you have to make some simplifications . 
and different people make different simplifications . 
uhhuh . 
and then you can ' t compare them at all . 
which is what the literature is sort of like now . 
so um and then there ' s the issue of recognizer dictionaries and nonstandard forms and things like that that have to be mapped . 
yeah . 
so going to versus going to and that kind of thing . 
right . 
i mean all those issues yeah i ' m sure we 
uhhuh . 
huh . 
i mean like i say i ' m i ' m personally not interested in those for my particular aspect of the project . 
they ' re not hard . 
but 
but s . r . i . in general is is the 
but we definitely will be interested in some language and dialogue . 
yeah . 
and i don ' t know maybe we will end up transcribing 
uhhuh . 
if if horacio wants you know wants that done maybe that ' ll be maybe we ' ll end up doing that . 
so 
well . 
and u . w . is also probably going to be interested in that too . 
the dialogue kinds of things . 
so 
well so it ' s a 
you know . 
so it seems like um if you and jane 
is is morgan nodding his head ? 
yeah . 
yeah . 
okay . 
so if you and jane keep keep in touch about transcription conventions that would be very helpful . 
yeah . 
yeah . 
yeah that ' s originally we should thank jane . 
right . 
because that ' s how i originally she showed me some transcripts and i thought wow . 
yeah . 
i mean it ' s kind of amazing too that you know the transcription tool we just converged on the same 
uhhuh . 
this is great . 
yep . 
oh yeah . 
yeah yeah to study using the same thing . 
all these things were very very similar . 
yeah . 
you were also thinking about the same tool ? 
that ' s interesting . 
yeah . 
it ' s 
we we we were going to use the same tool . 
wow ! 
but what if you had like written the the tcl kluge or something and then both done the same ? 
we we set up that tool already . 
yeah . 
already ? 
yeah . 
huh . 
that ' s right . 
well the i mean and in some ways that does change the uh the economics of doing that . 
i mean it ' s 
can you do that ? 
right . 
but um 
huh . 
it ' s much more worth while to do if someone else is going to use it . 
yeah . 
yeah . 
yeah . 
yeah . 
yeah . 
although again if this now named company is the one who ' s going to do the transcription i i suspect they have in house tools that they ' ll end up using . 
that ' s right . 
uhhuh . 
uhhuh . 
but we still 
yeah . 
uhhuh . 
but you still need something that can display these channels . 
that ' s interesting . 
right we need we need some kind of browsing . 
better than what it can do i mean . 
yeah . 
it ' s 
and then i guess 
who is the contact at u . w ? 
like 
morgan ? 
morgan doesn ' t have a microphone . 
but is it is it 
that ' s all right . 
he ' s allowed to speak . 
he can talk anyway . 
he 
i mean mari and 
well he could be reached he could be reached by the far field . 
yeah . 
couldn ' t he ? 
mari or or or katrin or jeff or 
yeah . 
yeah . 
i mean both i think both jeff and katrin have some time on this . 
no on the on the darpa project who would be sort of contacts for mari . 
and if mari ' s too busy then 
huh . 
okay . 
huh . 
yeah . 
huh . 
i was . 
uhhuh . 
i don ' t think we have any problem . 
i mean we had certainly in our you know the proposal that we tried to make to n . s . f . we were assuming we would distribute this through the l . d . c . 
no . 
yeah . 
yeah . 
i i mean 
this this is something that requires a bootstrap . 
l . d . c . is what we were thinking too . 
yeah . 
uhhuh . 
yeah . 
so we have no problem with that . 
i mean there is no l . d . c . database . 
yeah . 
uhhuh . 
there is at least we have to share the data i mean . 
huh . 
that ' s the bottom line . 
i i mean i think eventually l . d . c . could be very interested in it . 
uh 
especially if you have a tool that can do this . 
yeah . 
yeah . 
i mean there isn ' t one . 
huh . 
and and the data . 
so maybe it ' ll we can actually 
yeah . 
you can sell corpora eventually to the l . d . c . 
and you can get time student time to clean up the corpus and things . 
huh . 
so 
yeah . 
uhhuh . 
yep . 
right . 
i wanted to ask one question about the the nature of the design . 
it ' s terrific . 
given that the overlaps are up up uh where the difficulty comes in a bunch of areas um whether it would be useful to have some of the sessions have like an additional rule ? 
where if a person you know the that there ' s someone who recognizes people to speak or something like that to cut down on the 
so you then you have the meeting context . 
you have multiple channels . 
you have the microphones varying the way you want them to vary . 
but you ' d cut down substantially on the overlaps . 
it wouldn ' t be for all meetings . 
but whether maybe just sprinkled through there once in a while something like that might be useful or not . 
just wanted to raise that . 
i don ' t know . 
i mean it ' s difficult because you want it to be real speech right ? 
and also it ' s not clear how well people can even adjust to even adjust to that kind of rule . 
uhhuh . 
yeah . 
i mean it those those kinds of things are sort of the kind of things that we were thinking of of trying . 
but if there 
robert ' s rules . 
yeah . 
because we are having we do have a more artificial environment again . 
uhhuh . 
we ' re trying something totally new . 
having people speak to the computer . 
i don ' t think we talked about that in particular . 
because we didn ' t we haven ' t done any pilots . 
we haven ' t seen this incredibly difficult data of overlapping . 
but this is 
uh christine helverson who ' s working on this with me from the um aspect of user you know usability and stuff would you know 
she ' s interested in these sorts of things . 
what what can you ask people to do that um that they can reliably do and without too much you know cognitive load um that can help things out . 
or you know those sorts of issues . 
so 
i don ' t know . 
maybe it ' s something that could fit easier in in our context than in a general meeting context . 
i don ' t know . 
well what i can say is that sometimes you know if if if we were to have this kind of coordination thing some some of the overlap is due to someone wanting to claim the floor at a certain point . 
well i think that 
uhhuh . 
without knowing that other people have the same desire at the same point in time . 
and if and if you were to have someone who was like a moderator then you raise your hand the moderator would say you first . 
just have a button . 
you know . 
or yeah . 
press the button . 
and ring the buzzer . 
and and i think you know there are always going to be backchannels . 
i think that ' s natural and lovely . 
uhhuh . 
uhhuh . 
but these these overlaps that are due to people not knowing other people want to leap in at the same time and and wanting to coordinate you know i think that uh it could be lessened . 
huh . 
i don ' t know . 
not eliminated entirely . 
there are certainly formal meeting settings where that ' s what ' s happens . 
that you know robert ' s rules of order and all that . 
yeah . 
right . 
uh so that ' s not something we had thought about before . 
but i think it it it certainly is another type of meeting that could be done . 
yeah . 
uhhuh . 
uh no . 
i didn ' t . 
i didn ' t know we were going to be recording this meeting . 
we 
so i didn ' t . 
no . 
yeah in general . 
yes . 
in the other meetings we have . 
yeah . 
yeah . 
and they ' ve been collecting digits too . 
okay . 
so that ' s another thing we should talk about is making sure that we ' re doing it in the same way . 
uhhuh . 
we for a for a completely different reason i assume . 
huh . 
but 
so i i 
and and not within a not within a big room . 
just uh 
yeah . 
huh . 
that ' s a good idea . 
yeah if i had known and here we have all these new speakers i could have gotten lots of digits in . 
yeah . 
but 
but sorry . 
so you connect you collect digits in conversation ? 
or or 
no no i have people read them . 
yeah yeah . 
we we give people a list of digits . 
and they have to like put them into their discussion . 
uh 
like say five one seven seven three . 
seven . 
you ' re encouraged to you know just utter digits once in a while . 
i was thinking 
yeah . 
never mind . 
you say hey . 
i ' m getting attacked . 
by the way eight . 
uhhuh . 
huh . 
so you don ' t need the meeting for that . 
you can just sit me in this room and set up all the microphones . 
but you need the room and the set up . 
right . 
okay . 
right right . 
right . 
yeah we ' re doing digits 
okay . 
yeah . 
yeah we ' re not doing digits in the in the room set up at all . 
we ' re doing it for a 
i mean 
one of the specific things i ' m interested in is knowing um is the open mike issue . 
when you ' re talking to the computer knowing when you ' re done speaking . 
and so i ' m interested in in well interested in looking at prosody . 
um 
oh cool . 
and so we ' re just having we ' re just doing lists of digits to see when people pause to know you know there was a big gap in time here . 
but they you know we can tell prosodically they weren ' t done . 
so 
yeah . 
i i think that ' s a really good idea . 
huh . 
but but there is 
but there is also this fascinating prosodic thing that goes on . 
to always 
yeah . 
because you what we we have is like these lists of ten digit strings or twenty digit strings . 
and they ' re like one one to five or one to seven digits . 
and people read through them . 
and you know we ' re saying well we won ' t to be able to separate them . 
so please pause between . 
but it ' s very people don ' t like doing that . 
and so there is this prosodic thing which is which is indicating when the pauses between these digit strings . 
and then when they finish the actual the whole sheet there ' s this nice wonderful yeah phrase . 
huh huh . 
oh yeah . 
yeah . 
nice falling . 
oh yeah . 
declination yeah . 
right . 
yeah . 
if you definitely shouldn ' t use your last sample . 
right . 
and it 
so 
i mean people that do prosody work they add a few at the end . 
right . 
oh . 
i hadn ' t thought about that . 
because otherwise people will 
huh . 
oh right . 
i hadn ' t even thought about throwing out the last couple . 
yeah . 
yeah . 
no but that that is beautiful . 
definitely should . 
uhhuh . 
because then you can get this f . zero floor for each of the speakers . 
uhhuh . 
oh right . 
just look at the very last look at the very end . 
just from that . 
right . 
yeah . 
yeah . 
yeah . 
yeah . 
yeah yeah . 
don ' t throw it away . 
but don ' t use it in your training . 
your your junk is our uh training data . 
treat especially 
huh . 
yeah . 
cool . 
no that ' s a really good idea . 
to have some standard 
i mean especially if the different sites can do something like that . 
you ' ll at least be able to see whether difficulty across site is due to you know the lexicon version . 
and 
right . 
right . 
uh 
there ' ll be a common 
that ' d be great . 
yeah . 
yeah that ' s a good idea . 
funny . 
huh . 
that ' s a good idea . 
oh . 
that ' s the reason . 
you should definitely 
uhhuh . 
uhhuh . 
it ' s some kind of calibration uh for uh many of these tests . 
yeah . 
right . 
huh . 
the only thing i don ' t like about it is that it ' s not phonetically very rich . 
right . 
well you could have t . i . you know she put her dirty laundry in the clean clean bathwater whatever . 
but 
yeah . 
that ' s right . 
timit . 
so we actually talked about that . 
yeah . 
it ' s plenty bad . 
it ' s plenty bad just with digits . 
huh . 
yeah . 
huh . 
although i haven ' t trained any nets on it . 
i ' ve just been using existing digits or broadcast news nets . 
since we don ' t have enough data yet . 
and what are these what are the digit strings are from t . i . digits and uh 
one seven eight two three one three seven eight four . 
uh 
yeah . 
it ' s t . i . digit strings . 
i don ' t 
that sort of thing . 
uh 
that ' s right . 
this we could each make up a string . 
yeah . 
it ' s actually 
how how long are how long chunks are they ? 
but what were they ? 
it ' s like but from one to one to nine digits . 
they vary from 
one two three four . 
it is actually the the actual digit strings from t . i . digits . 
okay . 
i i just extracted exactly the same ones . 
yeah i ' ve never looked over the t . i . digits corpus . 
okay . 
have we all memorized these ? 
up a bit . 
i don ' t know . 
so 
maybe we know them . 
yeah . 
that ' s like the timit sentences . 
right . 
yeah . 
yeah . 
greasy wash water . 
i know the numbers that were used . 
oh . 
in one ear . 
but i don ' t remember the combinations . 
the order . 
yeah . 
just the order . 
okay . 
but so i have a bunch of tools for generating these and for helping transcribe them . 
since you know what you know what the transcript is you don ' t have to type it in you just have to segment it . 
uhhuh . 
so i have tools for doing that . 
using x . x . waves tcl t . k . perl and maybe some c . programs too . 
we could do some digits . 
well i i don ' t have any of the print outs . 
okay . 
i i print them out as i need them . 
so what i should do is just print out a whole stack and leave them up here . 
but i haven ' t done that . 
put them on the internet . 
put them on a web page . 
that ' s what i was wondering . 
uh yeah you could write write them write something on the board . 
well but 
i mean we could just make make numbers up . 
and 
i don ' t know . 
it ' s it ' s a different task . 
can ' t we ? 
yeah . 
it ' s a different task than read . 
yeah . 
you you do it differently if it ' s sitting in front of you and you ' re reading it than if it ' s not . 
okay . 
so 
right . 
i guess we could write them down and then read them . 
but 
uhhuh . 
okay . 
i i we can get digits . 
i 
i mean as you said we don ' t have to be in a meeting . 
and so if we ' re short on digits i can just you know capture people in the hallway . 
drag them in here . 
and have them read digits for me . 
that ' s right . 
oh can you bring them up from the 
no . 
okay . 
all right . 
i wanted to ask about also the air conditioning . 
are uh is there a plan to to turn the air conditioning off in some of these meetings or is it always going to be on ? 
yeah it ' s way too cold in here . 
we should do that . 
because you can turn it off on that that thing right there . 
right . 
well . 
and it makes a huge difference . 
you also gain noise from the projector as well isn ' t it ? 
the the hum we hear right now is actually the projector . 
yeah yeah . 
all right . 
but the projector . 
not the air conditioner . 
yeah . 
huh . 
the projector is much louder than the air conditioning . 
this is the first time we ' ve done it with a projector . 
yeah . 
but i was just thinking he was showing it on what he showed us on the web site . 
you could see the contribution of the air conditioning . 
yep . 
and i just wondered if that was going to be sometimes clear . 
but the projector ' s not part of your meeting . 
or or or is it ? 
do is this normally going to be on during collection ? 
um no . 
not normally . 
not for our meetings . 
i at least very few of the ones we ' ve done have we had to do anything on the computer . 
no . 
it 
for ours it will . 
but we have a rear projector . 
so it ' s in a separate room . 
huh . 
right . 
it actually gives you a way of calibrating microphone position in a way . 
doesn ' t it ? 
that ' s right . 
from volume . 
yeah . 
that ' s interesting . 
for volume it ' s a point source pretty much . 
huh . 
yeah . 
huh huh . 
so 
although unfortunately you know they ' re all pretty close . 
huh . 
right ? 
uh 
oh look ! 
digit strings . 
oh wow ! 
there you go . 
uhhuh . 
modern technology . 
oh i see . 
perfect . 
see you may want to call up your computer . 
computer . 
give us digit strings . 
digit strings . 
that ' s right . 
yeah . 
wow . 
but the but the recorder just crashed . 
i think i recognize those . 
oh no ! 
okay . 
do we have anything like an agenda ? 
what ' s going on ? 
um 
i guess 
um 
so 
sunil ' s here for the summer ? 
one thing 
sunil ' s here for the summer . 
right . 
um 
so one thing is to talk about a kick off meeting . 
maybe . 
uh 
and then just uh i guess uh progress reports individually and then uh plans for where we go between now and then pretty much . 
um 
i could say a few words about um some of the uh compute stuff that ' s happening around here . 
so that people in the group know . 
uhhuh . 
okay . 
why don ' t you start with that ? 
that ' s sort of 
okay . 
we um 
yeah . 
so we just put in an order for about twelve new machines uh to use as sort of a compute farm . 
and um 
uh we ordered uh sun blade one hundreds . 
and um 
i ' m not sure exactly how long it ' ll take for those to come in . 
but uh in addition we ' re running 
so the plan for using these is uh we ' re running p . make and customs here . 
and andreas has sort of gotten that all uh fixed up and up to speed . 
and he ' s got a number of little utilities that make it very easy to um run things using p . make and customs . 
you don ' t actually have to write p . make scripts and things like that . 
the simplest thing 
and i can send an email around . 
or maybe i should do an f . a . q . on the web site about it or something . 
um 
there ' s a 
how about an email that points to the f . a . q ? 
yeah yeah . 
you know what i ' m saying ? 
so that you can 
yeah . 
uh there ' s a command uh that you can use called run command . 
run dash command . 
run hyphen command . 
and if you say that and then some job that you want to execute uh it will find the fastest currently available machine and export your job to that machine . 
and uh and run it there . 
and it ' ll duplicate your environment . 
so 
you can try this as a simple test with uh the l . s . command . 
so you can say run dash command l . s . 
and um it ' ll actually export that l . s . command to some machine in the institute and um do an l . s . on your current directory . 
so substitute l . s . for whatever command you want to run . 
and um and that ' s a simple way to get started using using this . 
and so soon when we get all the new machines up um then we ' ll have lots more compute to use . 
now one of the nice things is that uh each machine that ' s part of the p . make and customs network has attributes associated with it . 
uh attributes like how much memory the machine has . 
what its speed is . 
what its operating system . 
and when you use something like run command you can specify those attributes for your program . 
for example if you only want your thing to run under linux you can give it the linux attribute . 
and then it will find the fastest available linux machine and run it on that . 
so 
you can control where your jobs go to a certain extent . 
all the way down to an individual machine . 
each machine has an attribute which is the name of itself . 
so you can give that as an attribute and it ' ll only run on that . 
if there ' s already a job running on some machine that you ' re trying to select your job will get queued up . 
and then when that resource that machine becomes available your job will get exported there . 
so 
there ' s a lot of nice features to it . 
and it kind of helps to balance the load of the machines . 
and uh 
right now andreas and i have been the main ones using it . 
and we ' re uh 
the s . r . i . recognizer has all this p . make customs stuff built into it . 
so 
so as i understand you know he ' s using all the machines and you ' re using all the machines . 
yeah . 
is the rough division of 
exactly . 
yeah you know i i sort of got started using the recognizer just recently . 
and uh 
uh i fired off a training job . 
and then i fired off a recognition job . 
and i get this email about midnight from andreas saying uh are you running two trainings simultaneously . 
my my jobs are not getting run . 
so i had to back off a little bit . 
but 
soon as we get some more machines then uh then we ' ll have more compute available . 
so 
um 
that ' s just a quick update about what we ' ve got . 
um i have i have a question about the uh parallelization . 
so 
uhhuh . 
so um let ' s say i have like a thousand little little jobs to do . 
uhhuh . 
um how do i do it with run command ? 
i mean do 
you could write a script uh which called run command on each sub job . 
uhhuh . 
a thousand times ? 
right ? 
okay . 
but you probably want to be careful with that . 
because um you don ' t want to saturate the network . 
uh 
so um 
you know you should you should probably not run more than say ten jobs yourself at any one time . 
uh just because then it would keep other people 
oh . 
too much file transfer and stuff . 
well it ' s not that so much as that you know with if everybody ran fifty jobs at once then it would just bring everything to a halt . 
and you know people ' s jobs would get delayed . 
so it ' s sort of a sharing thing . 
okay . 
um 
so you should try to limit it to some number around ten jobs at a time . 
um 
so if you had a script for example that had a thousand things it needed to run um you ' d somehow need to put some logic in there if you were going to use run command uh to only have ten of those going at a time . 
and uh then when one of those finished you ' d fire off another one . 
um 
i remember i i forget whether it was when the rutgers or or hopkins workshop . 
i remember one of the workshops i was at there were everybody was real excited because they got twenty five machines . 
and there was some kind of p . make like thing that sent things out . 
uhhuh . 
uhhuh . 
uhhuh . 
so all twenty five people were sending things to all twenty five machines . 
yeah . 
yeah . 
and and things were a lot less efficient than if you ' d just use your own machine . 
yep . 
yeah exactly . 
yeah you have to be a little bit careful . 
as i recall . 
but 
huh . 
yeah . 
um 
but uh you can also 
if you have that level of parallelization um and you don ' t want to have to worry about writing the logic in in a perl script to take care of that you can use um p . make . 
just do p . make . 
and and you basically write a make file that uh you know your final job depends on these one thousand things . 
uhhuh . 
and when you run p . make uh on your make file you can give it the dash capital j . and and then a number . 
uhhuh . 
and that number represents how many uh machines to use at once . 
right . 
and then it ' ll make sure that it never goes above that . 
right . 
okay . 
so 
i can get some documentation . 
so it it ' s it ' s not systematically queued . 
i mean all the jobs are running . 
if you launch twenty jobs they are all running . 
it depends . 
all right . 
if you run command that i mentioned before is doesn ' t know about other things that you might be running . 
uhhuh . 
so it would be possible to run a hundred run jobs at once . 
right . 
and they wouldn ' t know about each other . 
but if you use p . make then it knows about all the jobs that it has to run . 
uhhuh . 
and it can control uh how many it runs simultaneously . 
so run command doesn ' t use p . make or 
it uses export underlyingly . 
but if you 
it ' s meant to be run one job at a time . 
so you could fire off a thousand of those . 
and it doesn ' t know any one of those doesn ' t know about the other ones that are running . 
so why would one use that rather than p . make ? 
well if you have 
um 
like for example uh if you didn ' t want to write a p . make script . 
and you just had a uh an h . t . k . training job that you know is going to take uh six hours to run . 
and somebody ' s using uh the machine you typically use . 
you can say run command and your h . t . k . thing . 
and it ' ll find another machine . 
the fastest currently available machine . 
and and run your job there . 
now does it have the same sort of behavior as p . make ? 
which is that you know if you run something on somebody ' s machine and they come in and hit a key then it 
yes . 
yeah . 
there are um 
right . 
so some of the machines at the institute um have this attribute called no evict . 
and if you specify that in in one of your attribute lines then it ' ll go to a machine which your job won ' t be evicted from . 
uhhuh . 
but the machines that don ' t have that attribute if a job gets fired up on that which could be somebody ' s desktop machine and and they were at lunch . 
uhhuh . 
they come back from lunch and they start typing on the console then your machine will get evicted your job will get evicted from their machine and be restarted on another machine automatically . 
so which can cause you to lose time . 
right ? 
if you had a two hour job and it got halfway through . 
and then somebody came back to their machine and it got evicted . 
so if you don ' t want your job to run on a machine where it could be evicted then you give it the minus the attribute you know no evict . 
and it ' ll pick a machine that it can ' t be evicted from . 
so 
um what what about 
i remember always used to be an issue maybe it ' s not anymore that if you if something required if your machine required somebody hitting a key in order to evict things that are on it so you could work . 
uhhuh . 
but if you were logged into it from home ? 
and you weren ' t hitting any keys because you were home . 
yeah . 
i i ' m not sure how that works . 
uh it seems like andreas did something for that . 
yeah . 
huh . 
um 
okay . 
we can ask him sometime . 
but 
yeah . 
i don ' t know whether it monitors the keyboard or actually looks at the console t . t . y . 
so maybe if you echoed something to the you know dev dev console or something . 
you probably wouldn ' t ordinarily though . 
yeah right ? 
huh ? 
you probably wouldn ' t ordinarily . 
i mean you sort of 
you ' re at home and you ' re trying to log in . 
and it takes forever to even log you in . 
yeah yeah . 
and you probably go screw this . 
and you know . 
yeah . 
yeah . 
so um 
yeah . 
yeah . 
i i can i ' m not sure about that one . 
yeah . 
but uh 
okay . 
uh i need a little orientation about this environment and uh how to run some jobs here . 
because i never did anything so far with this x . emissions . 
okay . 
so 
i think maybe i ' ll ask you after the meeting . 
um 
yeah . 
yeah and and also uh stephane ' s a a really good resource for that if you can ' t find me . 
yeah yeah yeah . 
yep . 
okay . 
sure . 
huh . 
especially with regard to the aurora stuff . 
okay . 
he he knows that stuff better than i do . 
okay . 
well why don ' t we uh 
uh 
sunil since you ' re haven ' t haven ' t been at one of these yet why don ' t you tell us what ' s what ' s up with you ? 
what you ' ve been up to hopefully . 
um . 
yeah . 
so 
uh shall i start from 
well i don ' t know how may i how 
okay . 
uh i think i ' ll start from the post uh aurora submission maybe . 
yeah . 
uh yeah . 
after the submission the what i ' ve been working on mainly was to take take other submissions . 
and then 
over their system what they submitted . 
because we didn ' t have any speech enhancement system in in ours . 
so 
so i tried 
uh 
and first i tried just l . d . a . 
and then i found that 
uh 
i mean if if i combine it with l . d . a . it gives improvement over theirs . 
uh 
are are you saying l . d . a ? 
yeah . 
l . d . a . 
okay . 
yeah . 
so 
just just the l . d . a . filters . 
i just plug in i just take the cepstral coefficients coming from their system and then plug in l . d . a . on top of that . 
uhhuh . 
but the l . d . a . filter that i used was different from what we submitted in the proposal . 
what i did was i took the l . d . a . filter ' s design using clean speech . 
uh mainly because the speech is already cleaned up after the enhancement . 
so instead of using this uh narrow narrow band l . d . a . filter that we submitted uh i got new filters . 
so 
that seems to be giving uh improving over their uh system . 
slightly . 
but not very significantly . 
and uh that was 
uh showing any improvement over final by plugging in an l . d . a . 
and uh 
so then after after that i i added uh online normalization also on top of that . 
and that there there also i i found that i have to make some changes to their time constant that i used . 
because it has a a mean and variance update time constant . 
and which is not suitable for the enhanced speech and whatever we try it on with proposal one . 
but um 
i didn ' t i didn ' t play with that time constant a lot . 
i just 
i just found that i have to reduce the value . 
i mean i have to increase the time constant or reduce the value of the update value . 
that ' s all i found . 
so i have to 
uh 
yeah . 
and uh 
uh the other other thing what i tried was i just um uh took the baseline and then ran it with the endpoint uh information . 
just the aurora baseline . 
to see that how much the baseline itself improves . 
by just supplying the information of the i mean the speech and nonspeech . 
and uh 
i found that the baseline itself improves by twenty two percent by just giving the 
uh can you back up a second ? 
i i i missed something . 
uh 
i guess my mind wandered . 
when you added the online normalization and so forth uh uh things got better again ? 
yeah . 
or is it 
no . 
no . 
did it not ? 
no things didn ' t get better with the same time constant that we used . 
no no . 
with a different time constant . 
with the different time constant i found that 
i mean i didn ' t get an improvement over not using online normalization . 
oh . 
no you didn ' t . 
because i i found that i would have change the value of the update factor . 
okay . 
but i didn ' t play it with play play quite a bit to make it better than 
yeah . 
okay . 
so it ' s still not . 
i mean the online normalization didn ' t give me any improvement . 
okay . 
and uh 
okay . 
so 
oh yeah . 
so i just stopped there with the uh speech enhancement . 
the the other thing what i tried was the adding the uh endpoint information to the baseline . 
and that itself gives like twenty two percent . 
because the the second the new phase is going to be with the endpointed speech . 
and just to get a feel of how much the baseline itself is going to change by adding this endpoint information i just uh use 
huh . 
so people won ' t even have to worry about uh doing speech - nonspeech then . 
yeah . 
that ' s that ' s what the feeling is like . 
huh . 
they ' re going to give the endpoint information . 
i see . 
i guess the issue is that people do that anyway . 
everybody does that . 
and they wanted to see given that you ' re doing that what what are the best features that you should use . 
yeah . 
yeah . 
i see . 
so 
i mean clearly they ' re interact . 
so i don ' t know that i entirely agree with it . 
yeah . 
but but it might be uh in some ways it might be better to rather than giving the endpoints to have a standard that everybody uses and then interacts with . 
uhhuh . 
but you know it ' s it ' s still reasonable . 
so are people supposed to assume that there is uh 
are are people not supposed to use any speech outside of those endpoints ? 
uh 
or can you then use speech outside of it for estimating background noise and things ? 
no . 
no . 
that i 
yeah . 
yeah yeah . 
exactly . 
i guess that is that is where the consensus is . 
like you will you will you ' ll be given the information about the beginning and the end of speech . 
but the whole speech is available to you . 
okay . 
so 
so it should make the spectral subtraction style things work even better . 
because you don ' t have the mistakes in it . 
yeah . 
yeah ? 
okay . 
yeah . 
so 
so that that the baseline itself 
i mean it improves by twenty two percent . 
i found that in one of the speechdat - car cases that like the spanish one improves by just fifty percent by just putting the endpoint . 
wow . 
i mean you don ' t need any further speech enhancement with fifty . 
so uh 
so the baseline itself improves by fifty percent . 
yeah by fifty percent . 
yeah . 
so it ' s it ' s going to be harder to beat that actually . 
wow . 
yeah . 
yeah . 
but but 
so 
so that is when uh the the qualification criteria was reduced from fifty percent to something like twenty five percent for well matched . 
and i think they have they have actually changed their qualification criteria now . 
and uh 
yeah . 
i guess after that i just went home i just had a vacation for four weeks . 
okay . 
uh 
no that ' s that ' s that ' s a good good update . 
yeah . 
and i i came back and i started working on uh some other speech enhancement algorithm . 
i mean so i from the submission what i found that people have tried spectral subtraction and wiener filtering these are the main uh approaches where people have tried . 
yeah . 
so just to just to fill the space with some few more speech enhancement algorithms to see whether it improves a lot i i ' ve been working on this uh signal subspace approach for speech enhancement . 
where you take the noisy signal and then decomposing the signal and the noise subspace . 
and then try to estimate the clean speech from the signal plus noise subspace . 
uhhuh . 
and 
so i ' ve been actually running some 
so far i ' ve been trying it only on matlab . 
i have to to to test whether it works first or not . 
yeah . 
and then i ' ll port it to c . . 
and i ' ll update it with the repository once i find it giving any some positive result . 
so yeah . 
so you you so you said one thing i want to jump on for a second . 
so so now you ' re you ' re getting tuned into the repository thing that he has here . 
yeah . 
and so we ' ll have a single place where the stuff is . 
yep . 
yeah . 
cool . 
um 
so maybe uh just briefly you could remind us about the related experiments . 
because you did some stuff that you talked about last week . 
i guess ? 
uhhuh . 
um where you were also combining something 
both of you i guess were both combining something from the uh french telecom system with the uh 
right . 
i i don ' t know whether it was system one or system two . 
or 
uhhuh . 
it was system one . 
so 
okay . 
we 
the main thing that we did is just to take the spectral subtraction from the france telecom . 
which provide us some speech samples that are uh with noise removed . 
so i let me let me just stop you there . 
so then one distinction is that uh you were taking the actual france telecom features and then applying something to 
uh no . 
there is a slight different . 
uh 
i mean which are extracted at the handset . 
yeah . 
because they had another back end blind equalization . 
yeah . 
but that ' s what i mean . 
yeah . 
yeah . 
but 
sorry . 
yeah i ' m not being i ' m not being clear . 
yeah . 
yeah . 
what i meant was you had something like cepstra or something right ? 
yeah yeah yeah yeah . 
and so one difference is that i guess you were taking spectra . 
the speech . 
yeah . 
yeah . 
but i guess it ' s the exactly the same thing . 
because on the uh handset they just applied this wiener filter and then compute cepstral features . 
right ? 
yeah . 
or 
the cepstral the difference is like there may be a slight difference in the way . 
because they use exactly the baseline system for converting the cepstrum once you have the speech . 
right . 
i mean if we are using our own code for i mean that that could be the only difference . 
i mean there is no other difference . 
uhhuh . 
yeah . 
but you got some sort of different result . 
so i ' m trying to understand it . 
but uh 
yeah well i think we should uh have a table with all the result . 
i 
because i don ' t know i uh i don ' t exactly know what are your results . 
but 
okay . 
okay . 
huh . 
yeah but so we did this . 
and another difference i guess is that we just applied uh proposal one system after this . 
without well with our modification to reduce the delay of the the l . d . a . filters . 
and 
uhhuh . 
well there are slight modifications . 
and the filter 
but it was the full proposal one . 
in your case if you tried just putting l . d . a . then maybe online normalization . 
only l . d . a . 
yeah . 
i after that i added online normalization . 
yeah . 
uhhuh . 
so we just tried directly to to just keep the system as it was . 
and 
um 
when we plug the spectral subtraction it improves uh significantly . 
um 
but what seems clear also is that we have to retune the time constants of the online normalization . 
yeah yeah . 
yeah . 
because if we keep the value that was submitted uh it doesn ' t help at all . 
you can remove online normalization or put it it doesn ' t change anything . 
uh uh as long as you have the spectral subtraction . 
but you can still find some kind of optimum somewhere . 
and we don ' t know where exactly . 
but 
yeah . 
uh 
yeah i assume . 
so it sounds like you should look at some tables of results or something . 
right . 
and see where where the where they were different and what we can learn from it . 
yeah . 
yeah . 
uhhuh . 
uhhuh . 
without any change . 
yeah . 
but it ' s 
okay . 
well . 
it ' s the new . 
with with with changes . 
with 
the new . 
because we change it the system to have 
oh yeah . 
i mean the the new l . d . a . filters . 
the new . 
i mean 
yeah . 
okay . 
l . d . a . filters . 
there are other things that we finally were shown to improve also . 
like the sixty four hertz cutoff . 
uhhuh . 
uhhuh . 
uh it doesn ' t seem to hurt on t . i . digits finally . 
okay . 
maybe because of other changes . 
okay . 
um 
well there are some minor changes . 
yeah . 
uhhuh . 
and right now if we look at the results it ' s um always better than it seems always better than france telecom for mismatch and high mismatch . 
and it ' s still slightly worse for well matched . 
um 
but 
but this is not significant . 
but the problem is that it ' s not significant . 
but if you put this in the huh uh spreadsheet it ' s still worse . 
even with very minor 
uh 
even if it ' s only slightly worse for well matched . 
uhhuh . 
and significantly better for h . m . 
uh 
but well . 
i don ' t think it ' s important . 
because when they will change their metric 
uh 
uh mainly because of uh when you you plug the um frame dropping in the baseline system it will improve a lot h . m . and m . m . 
yeah . 
so 
um i guess what will happen 
i don ' t know what will happen . 
but the different contribution i think for the different test set will be more even . 
because the your improvement on h . m . and m . m . will also go down significantly in the spreadsheet . 
so 
but the the well matched may still 
uhhuh . 
i mean the well matched may be the one which is least affected by adding the endpoint information . 
right . 
yeah . 
so the 
the m . m . 
uhhuh . 
m . m . and h . m . are going to be hugely affected by it . 
yeah . 
so um 
yeah . 
yeah . 
yeah . 
but they the everything i mean is like 
but there 
that ' s how they reduce why they reduce the qualification to twenty five percent or some something on . 
uhhuh . 
but are they changing the weighting ? 
uh no . 
i guess they are going ahead with the same weighting . 
yeah . 
yeah . 
so there ' s nothing on 
i don ' t understand that . 
i guess i i haven ' t been part of the discussion . 
yeah . 
so um 
it seems to me that the well matched condition is going to be unusual . 
in this case . 
usual . 
unusual . 
uhhuh . 
because um you don ' t actually have good matches ordinarily for what any particular person ' s car is like . 
or 
huh . 
uh 
huh . 
it seems like something like the middle one is is more natural . 
huh . 
so i don ' t know why the well matched is 
right . 
uh 
uhhuh . 
yeah but actually the well well the well matched 
um 
uh 
i mean the the well matched condition is not like uh the one in t . i . digits . 
where uh you have all the training uh conditions exactly like replicated in the testing condition also . 
it ' s like this is not calibrated by s . n . r . or something . 
the well matched has also some some mismatch in that which is other than the 
the well matched has mismatch ? 
has has also some slight mismatches . 
unlike the t . i . digits where it ' s like perfectly matched . 
perfect to match . 
yeah . 
because it ' s artificially added noise . 
yeah . 
but this is natural recording . 
so remind me of what well matched meant . 
you ' ve told me many times . 
the the well matched is like 
the the well matched is defined like it ' s seventy percent of the whole database is used for training and thirty percent for testing . 
yeah . 
well so it means that if the database is large enough it ' s matched . 
it ' s it ' s 
because it 
okay . 
it ' s 
yeah . 
in each set you have a range of conditions . 
well 
right . 
so i mean 
yeah unless they deliberately chose it to be different which they didn ' t because they want it to be well matched . 
it is pretty much . 
you know so it ' s so it ' s sort of saying if you 
it ' s it ' s not guaranteed though . 
yeah . 
uh it ' s not guaranteed . 
yeah . 
right . 
uhhuh . 
right . 
yeah because the the main major reason for the 
the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually . 
again if you have enough if you have enough 
yeah yeah . 
yeah . 
so it ' s sort of it ' s sort of saying okay . 
so you much as you train your dictation machine for talking into your computer um you you have a car . 
and so you drive it around a bunch and and record noise conditions or something . 
and then i don ' t think that ' s very realistic . 
i mean i 
uhhuh . 
i i you know . 
so i 
i i you know . 
i guess they ' re saying that if you were a company that was selling the stuff commercially that you would have a bunch of people driving around in a bunch of cars . 
and and you would have something that was roughly similar . 
and maybe that ' s the argument . 
but i ' m not sure i buy it . 
so 
yeah yeah yeah . 
uh 
so 
what else is going on ? 
huh . 
yeah . 
we are playing we are also playing trying to put other spectral subtraction huh in the code . 
um 
it would be a very simple spectral subtraction on the um mel energies . 
which i already tested but without the um frame dropping actually . 
and i think it ' s important to have frame dropping if you use spectral subtraction . 
is it is spectral subtraction typically done on the after the mel uh scaling ? 
or is it done on the f . f . t . bins ? 
um 
does it matter ? 
or 
i 
i don ' t know . 
well it ' s both both uh cases can 
oh . 
yeah . 
some of the proposal uh we ' re doing this on the bin on the f . f . t . bins . 
huh . 
others on the um mel energies . 
you can do both . 
but i cannot tell you what ' s which one might be better . 
or 
huh . 
i 
i guess if you want to reconstruct the speech it may be a good idea to do it on f . f . t . bins . 
i don ' t know . 
huh . 
yeah . 
but 
but for speech recognition it may not . 
i mean it may not be very different if you do it on mel warped or whether you do it on f . f . t . 
i see . 
so you ' re going to do a linear weighting anyway after that . 
well . 
yeah . 
huh . 
so it may not be really a big different . 
well it gives something different . 
but i don ' t know what are the pros and cons of both . 
uhhuh . 
huh . 
okay . 
the other thing is like when you ' re putting in a speech enhancement technique . 
uh 
is it like one stage speech enhancement ? 
because everybody seems to have a two stages of speech enhancement in all the proposals . 
which is really giving them some improvement . 
yeah . 
uhhuh . 
uhhuh . 
i mean they just do the same thing again once more . 
uhhuh . 
and so there ' s something that is good about doing it . 
i mean to cleaning it up once more . 
yeah it might be . 
yeah . 
yeah . 
so we can 
so maybe in my implementation i should also try to inspire me from this kind of thing . 
yeah . 
that ' s what 
and yeah . 
well the other thing would be to combine what you ' re doing . 
i mean maybe one or one or the other of the things that you ' re doing would benefit from the other happening first . 
that ' s 
yeah . 
so 
right ? 
so he ' s doing a signal subspace thing . 
maybe it would work better if you ' d already done some simple spectral subtraction . 
or maybe maybe the other way around . 
yeah . 
uhhuh . 
yeah . 
you know ? 
uhhuh . 
so i ' ve been thinking about combining the wiener filtering with signal subspace . 
i mean just to see all some some such permutation combination to see whether it really helps or not . 
uhhuh . 
uhhuh . 
uhhuh . 
yeah . 
yeah . 
how is it 
i i guess i ' m ignorant about this . 
how does 
i mean since wiener filter also assumes that you ' re that you ' re adding together the two signals how is how is that differ from signal subspace ? 
the signal subspace ? 
yeah . 
the 
the signal subspace approach has actually an in built wiener filtering in it . 
oh okay . 
yeah . 
it is like a k . l . transform followed by a wiener filter . 
is the signal is is a signal substrate . 
oh oh okay . 
so the difference is the k . l . 
so the the different 
the the the advantage of combining two things is mainly coming from the signal subspace approach doesn ' t work very well if the s . n . r . is very bad . 
it ' s 
i see . 
it works very poorly with the poor s . n . r . conditions and in colored noise . 
so essentially you could do simple spectral subtraction followed by a k . l . transform followed by a 
wiener filtering . 
wiener filter . 
it ' s a it ' s a cascade of two 
yeah in general you don ' t 
that ' s right . 
you don ' t want to orthogonalize if the things are noisy . 
actually . 
um that was something that uh herve and i were talking about with um the multi band stuff . 
that if you ' re converting things to from uh bands groups of bands into cepstral you know local sort of local cepstral coefficients that it ' s not that great to do it if it ' s noisy . 
uhhuh . 
okay . 
yeah . 
uh 
so 
so 
so that that ' s one reason maybe we could combine . 
some something to improve s . n . r . a . little bit first stage . 
yeah . 
and then do a something in the second stage . 
which could take it further . 
what was your point about about colored noise there ? 
oh the colored noise 
yeah . 
uh 
the colored noise the the the signal subspace approach has i mean it it actually depends on inverting the matrices . 
so it it 
the covariance matrix of the noise . 
uhhuh . 
so if if it is not positive definite 
i mean it has a it ' s 
it doesn ' t behave very well if it is not positive definite . 
it works very well with white noise because we know for sure that it has a positive definite . 
so you should do spectral subtraction and then add noise . 
so the way they get around is like they do an inverse filtering . 
first of the colored noise . 
yeah . 
and then make the noise white . 
yeah . 
and then finally when you reconstruct the speech back you do this filtering again . 
yeah right . 
i was only half kidding . 
i mean if you sort of you do the spectral subtraction that also gets rid 
yeah . 
yeah . 
yeah . 
and then you then then add a little bit noise noise addition . 
i mean that sort of what j . j . rasta does in a way . 
if you look at what j . rasta doing essentially it ' s equivalent to sort of adding a little adding a little noise . 
yeah . 
huh . 
uhhuh . 
uhhuh . 
in order to get rid of the effects of noise . 
so 
yeah . 
okay . 
uh yeah . 
so there is this . 
and 
maybe we 
well we find some people so that uh agree to maybe work with us . 
and they have implementation of v . t . s . techniques . 
so it ' s um vector taylor series that are used to huh uh to model the transformation between clean cepstra and noisy cepstra . 
so well . 
if you take the standard model of channel plus noise uh it ' s it ' s a nonlinear uh transformation in the cepstral domain . 
uhhuh . 
yes . 
and 
uh there is a way to approximate this using uh first order or second order taylor series . 
and 
it can be used for uh getting rid of the noise and the channel effect . 
who is doing this ? 
uh working in the cepstral domain ? 
so there is one guy in grenada . 
yeah in grenada . 
and another in uh lucent that i met at i . cassp . 
one of my friend . 
uh 
who ' s the guy in grenada ? 
uh jose carlos segura . 
i don ' t know him . 
this v . t . s . has been proposed by c . m . u ? 
uhhuh . 
is it is it the c . m . u ? 
yeah yeah yeah . 
yeah yeah okay . 
originally the idea was from c . m . u . 
uhhuh . 
from c . 
yeah . 
uhhuh . 
well it ' s again a different thing that could be tried . 
um 
uhhuh . 
huh yeah . 
yeah so at any rate you ' re looking general uh standing back from it looking at ways to combine one form or another of uh noise removal uh with with these other things we have . 
uhhuh . 
uh looks like a worthy thing to to do here . 
uh yeah . 
but yeah . 
but for sure there ' s required to that requires to re check everything else and re - optimize the other things . 
oh yeah . 
and 
for sure the online normalization may be the l . d . a . filter . 
um 
well one of the seems like one of the things to go through next week when hari ' s here . 
i 
because hari will have his own ideas too . 
uhhuh . 
or i guess not next week . 
week and a half . 
uh will be sort of go through these alternatives . 
what we ' ve seen so far . 
and come up with some game plans . 
um 
you know . 
so i mean one way would 
here are some alternate visions . 
i mean one would be you look at a few things very quickly . 
you pick on something that looks like it ' s promising . 
and then everybody works really hard on the same different aspects of the same thing . 
another thing would be to have to to pick two two plausible things . 
and and you know have sort of two working things for a while until we figure out what ' s better . 
uhhuh . 
and then 
you know . 
uh 
but um 
uh he ' ll have some ideas on that too . 
the other thing is to uh most of the speech enhancement techniques have reported results on small vocabulary tasks . 
but we we going to address this wall street journal in our next stage . 
which is also going to be a noisy task . 
so very few people have reported something on using some continuous speech at all . 
so there are some 
i mean i was looking at some literature on speech enhancement applied to large vocabulary tasks . 
and 
spectral subtraction doesn ' t seems to be the thing to do for large vocabulary tasks . 
and it ' s 
always people have shown improvement with wiener filtering and maybe subspace approach over spectral subtraction everywhere . 
but if we if we have to use simple spectral subtraction we may have to do some optimization to make it work . 
so they ' re making 
there somebody ' s generating wall street journal with additive artificially added noise or something ? 
yeah yeah . 
sort of a sort of like what they did with t . i . digits and 
yeah . 
yeah okay . 
yeah . 
i i guess guenter hirsch is in charge of that . 
guenter hirsch and t . i . 
okay . 
maybe roger . 
roger maybe in charge of . 
and then they ' re they ' re uh uh generating h . t . k . scripts to 
yeah . 
yeah i don ' t know . 
there are they have there is no 
i don ' t know if they are converging on h . t . k . or are using some mississippi state . 
mississippi state maybe . 
yeah . 
yeah . 
i ' m not sure about that . 
yeah so that ' ll be a little little task in itself . 
yeah . 
um 
well we ' ve 
yeah it ' s true for the additive noise artificially added noise we ' ve always used small vocabulary too . 
but for there ' s been noisy speech this large vocabulary that we ' ve worked with in broadcast news . 
so we did the broadcast news evaluation . 
and some of the focus conditions were noisy . 
uhhuh . 
and and 
it had additive 
but we but we didn ' t do spectral subtraction . 
we were doing our funny stuff right ? 
we were doing uh multi stream and and so forth . 
yeah . 
but it you know we stuff we did helped . 
i mean it did something . 
so 
okay . 
um 
now we have this um meeting data . 
you know like the stuff we ' re recording right now . 
yeah . 
yeah . 
and 
and uh 
that we have uh for the uh the quote unquote noisy data there is just noisy and reverberant actually . 
it ' s the far field mike . 
and uh we have uh the digits that we do at the end of these things . 
and that ' s what most 
again most of our work has been done with that . 
with with uh connected digits . 
uhhuh . 
um 
but uh we have recognition now with some of the continuous speech . 
large vocabulary continuous speech using switchboard uh switchboard recognizer . 
yeah . 
okay . 
uh 
no training from this . 
just just plain using the switchboard . 
oh you just take the switchboard trained 
that ' s that ' s what we ' re doing . 
yeah . 
yeah . 
yeah . 
now there are some adaptation though . 
okay . 
that that uh andreas has been playing with . 
yeah . 
that ' s cool . 
okay . 
but we ' re 
uh actually uh dave and i were just talking earlier today about maybe at some point not that distant future trying some of the techniques that we ' ve talked about on uh some of the large vocabulary data . 
um 
i mean i guess no one had done yet done test one on the distant mike using uh the s . r . i . recognizer . 
and uh 
i don ' t 
not that i know of . 
yeah . 
because everybody ' s scared . 
yeah . 
you ' ll see a little smoke coming up from the the c . p . u . or something trying to trying to do it . 
that ' s right . 
but 
uh yeah . 
but you ' re right . 
that that that ' s a real good point that uh we we don ' t know yeah uh i mean what if any of these 
i guess that ' s why they ' re pushing that in the uh in the evaluation . 
yeah . 
uh 
but um 
good . 
okay . 
anything else going on ? 
at you guys ' end . 
or 
i don ' t have good result with the including the new parameters . 
i don ' t have good result . 
are similar or a little bit worse . 
with what what other new new parameter ? 
you ' re talking about your voicing ? 
yeah . 
so maybe you probably need to back up a bit . 
yeah . 
uhhuh . 
yeah . 
seeing as how sunil 
i tried to include another new parameter to the traditional parameter . 
yeah . 
the the cepstrum coefficient . 
uhhuh . 
that like the auto correlation the r . zero and r . one over r . zero . 
uhhuh . 
uhhuh . 
and another estimation of the the variance of the difference for of the uh spectrum of the signal . 
and and the spectrum of time after mel filter bank . 
i ' m so sorry . 
i didn ' t get it . 
nuh well . 
anyway . 
the first you have the the spectrum of the signal . 
uhhuh . 
and you have the on the other side you have the output of the mel filter bank . 
uhhuh . 
you can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal . 
huh . 
okay . 
i do the difference . 
okay . 
i found a difference at the variance of this different . 
uhhuh . 
because suppose we we think that if the variance is high maybe you have uh noise . 
yeah . 
and if the variance is small maybe you have uh speech . 
uhhuh . 
to to 
to 
the idea is to found another feature for discriminate between voice sound and unvoice sound . 
okay . 
and we try to use this new feature feature . 
and i did experiment . 
i need to change to obtain this new feature i need to change the size the window size size . 
of the of the analysis window size . 
to have more information . 
yeah . 
make it longer . 
uh sixty two point five milliseconds i think . 
okay . 
and 
i do i did two type of experiment to include this feature directly with the with the other feature . 
and to train a neural network to select it voice - unvoice - silence silence . 
unvoiced . 
well . 
and to to concat this new feature . 
but the result are 
with the neural network i have more or less the same result . 
as using just the cepstrum ? 
result . 
or 
yeah . 
yeah . 
okay . 
it ' s 
sometime it ' s worse . 
sometime it ' s a little bit better . 
but not significantly . 
and 
uh is it with t . i . digits or with 
no i work with uh italian and spanish basically . 
okay . 
okay . 
and if i don ' t use the neural network and use directly the feature the results are worse . 
uhhuh . 
but doesn ' t help . 
uhhuh . 
i i i really wonder though . 
i mean we ' ve had these discussions before . 
and and one of the things that struck me was that uh about this line of thought that was particularly interesting to me was that we um whenever you condense things uh in an irreversible way um you throw away some information . 
and that ' s mostly viewed on as a good thing in the way we use it . 
because we want to suppress things that will cause variability for uh particular uh phonetic units . 
um 
but you ' ll do throw something away . 
and so the question is uh can we figure out if there ' s something we ' ve thrown away that we shouldn ' t have . 
and um 
so 
when they were looking at the difference between the filter bank and the f . f . t . that was going into the filter bank i was thinking oh okay . 
so they ' re picking on something . 
they ' re looking on it to figure out noise or voice voiced property whatever . 
so that that ' s interesting . 
maybe that helps to drive the the thought process of coming up with the features . 
but for me sort of the interesting thing was well but is there just something in that difference which is useful . 
so another way of doing it maybe would be just to take the f . f . t . uh power spectrum and feed it into a neural network . 
and then use it you know in combination or alone or or whatever . 
to know 
with what targets ? 
voiced unvoiced is like 
uh no . 
oh . 
or anything . 
no . 
the just the same same way we ' re using i mean the same way that we ' re using the filter bank . 
phones . 
oh okay . 
uhhuh . 
exact way the same way we ' re using the filter bank . 
i mean the filter bank is good for all the reasons that we say it ' s good . 
but it ' s different . 
and you know maybe if it ' s used in combination it will get at something that we ' re missing . 
uhhuh . 
and maybe you know using you know k . l . t . or uh um adding probabilities i mean all all the different ways that we ' ve been playing with that we would let the essentially let the neural network determine what is it that ' s useful that we ' re missing here . 
uhhuh . 
yeah but there is so much variability in the power spectrum . 
uhhuh . 
well that ' s probably why it would be unlikely to work as well by itself . 
uhhuh . 
but it might help in combination . 
huh . 
but i i i have to tell you 
i can ' t remember the conference . 
but uh i think it ' s about ten years ago i remember going to one of the speech conferences . 
and and uh 
i saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front end or something . 
and a couple posters away it was somebody who compared one to uh just putting in the f . f . t . 
and the f . f . t . did slightly better . 
uhhuh . 
so i mean the it ' s true there ' s lots of variability . 
but again we have these wonderful statistical mechanisms for quantifying that that variability and you know doing something reasonable with it . 
uhhuh . 
so 
um 
uh 
it ' s same you know argument that ' s gone both ways about uh you know we have these data driven filters in l . d . a . 
and on the other hand if it ' s data driven it means it ' s driven by things that have lots of variability and that are necessarily not necessarily going to be the same in training and test . 
so in some ways it ' s good to have data driven things . 
and in some ways it ' s bad to have data driven things . 
so 
yeah 
part of what we ' re discovering is ways to combine things that are data driven than are not . 
yeah . 
uh so anyway it ' s just a thought that that if we if we had that maybe it ' s just a baseline . 
uh which would show us well what are we really getting out of the filters . 
or maybe 
probably not by itself . 
but in combination . 
uhhuh . 
uh 
you know maybe there ' s something to be gained from it . 
and let the 
but you know you ' ve only worked with us for a short time . 
maybe in a year or two you you will actually come up with the right set of things to extract from this information . 
but maybe the neural net and the h . m . m . ' s could figure it out quicker than you . 
maybe . 
so 
it ' s just a thought . 
yeah . 
i can i will try to do that . 
yeah . 
what one one um one thing is like what before we started using this v . a . d . in this aurora the what we did was like i i guess most of you know about this adding this additional speech silence bit to the cepstrum and training the h . m . m . on that . 
uhhuh . 
that is just a binary feature . 
and that seems to be improving a lot on the speechdat - car where there is a lot of noise . 
but not much on the t . i . digits . 
so adding an additional feature to to discriminate between speech and nonspeech was helping . 
that ' s it . 
wait i i ' m sorry ? 
yeah we actually added an additional binary feature to the cepstrum . 
just the baseline . 
yeah ? 
you did some experiment . 
yeah . 
yeah . 
well in in the case of t . i . digits it didn ' t actually give us anything . 
because there wasn ' t any anything to discriminate between speech . 
yeah . 
and it was very short . 
huh . 
but italian was like very it was a huge improvement on italian . 
well 
uhhuh . 
but anyway the question is even more is within speech can we get some features . 
are we dropping information that can might be useful within speech ? 
i mean to maybe to distinguish between voice sound and unvoiced sounds . 
okay . 
uhhuh . 
yeah yeah . 
yeah . 
and it ' s particularly more relevant now since we ' re going to be given the endpoints . 
yeah . 
uhhuh . 
so 
yeah yeah . 
uh 
huh . 
so 
um 
huh . 
there was a paper in i . cassp this i . cassp over the uh extracting some higher order uh information from the cepstral coefficients . 
and i forgot the name . 
some some harmonics 
i don ' t know . 
i can i can pull that paper out from i . cassp . 
yeah . 
talking cumulants or something ? 
it 
huh ? 
cumulants or something . 
uh i don ' t know . 
but no . 
i don ' t remember . 
it it was taking the um 
it was about finding the higher order moments of 
yeah . 
yeah . 
cumulants . 
and i ' m not sure about whether it is the higher order moments or 
yeah . 
maybe higher order cumulants . 
oh . 
and 
yeah . 
or 
it was it was 
yeah . 
i mean he was showing up uh some something on noisy speech . 
yeah . 
some improvement on the noisy speech . 
uhhuh . 
some small vocabulary tasks . 
uh 
so it was on p . l . p . derived cepstral coefficients . 
yeah but again you could argue that that ' s exactly what the neural network does . 
huh . 
so neural network uh is in some sense equivalent to computing you know higher order moments of what you 
trying to 
to 
moments . 
yeah . 
yeah . 
yeah . 
so 
i mean it doesn ' t do it very specifically . 
uhhuh . 
and 
pretty you know . 
but 
yep . 
uh 
anything on your end you want to talk about ? 
uh 
um nothing i want to really talk about . 
i can i can just uh um share a little bit . 
sunil hasn ' t hasn ' t heard about uh what i ' ve been doing . 
yeah . 
um 
so 
um i told you i was i was i was getting prepared to take this qualifier exam . 
so basically that ' s just um trying to propose um uh your next your your following years of of your p . h . d . work . 
trying trying to find a project to to define and and to work on . 
so i ' ve been uh looking into um doing something about uh speech recognition using acoustic events . 
so 
um the idea is you have all these these different events . 
for example voicing . 
nasality . 
r . coloring . 
you know burst . 
or noise uh frication . 
that kind of stuff . 
um building robust um primary detectors for these acoustic events . 
and using the outputs of these robust detectors to do speech recognition . 
um 
and um these these primary detectors um will be uh inspired by you know multi band techniques um doing things um similar to larry saul ' s work on uh graphical models to to detect these these uh acoustic events . 
and um so i i been i been thinking about that . 
and some of the issues that i ' ve been running into are um exactly what what kind of acoustic events i need . 
what um what acoustic events will provide a a good enough coverage to in order to do the later recognition steps . 
and also um once i decide a set of acoustic events um how do i how do i get labels . 
training data for for these acoustic events . 
and then later on down the line i can start playing with the the models themselves . 
the the primary detectors . 
um 
so 
um i kind of see like after after building the primary detectors i see um myself taking the outputs and feeding them in sort of tandem style into into a um gaussian mixtures h . m . m . back end um and doing recognition . 
um 
so that ' s that ' s just generally what i ' ve been looking at . 
yeah . 
um 
by by the way uh the voiced - unvoiced version of that for instance could tie right in to what carmen was looking at . 
yeah . 
so 
uhhuh . 
you know um if you if a multi band approach was helpful as as i think it is . 
it seems to be helpful for determining voiced - unvoiced . 
uhhuh . 
that one might be another thing . 
yeah . 
uhhuh . 
yeah . 
um 
were were you going to say something ? 
huh . 
oh . 
it looked 
okay . 
never mind . 
um yeah . 
and so this this past week um i ' ve been uh looking a little bit into uh traps um and doing doing traps on on these events too . 
just um seeing seeing if that ' s possible . 
uh 
and 
um other than that uh i was kicked out of i . house for living there for four years . 
oh no . 
so you live in a cardboard box in the street now ? 
yeah . 
or no ? 
uh well something like that . 
yeah . 
in albany . 
yeah . 
yeah . 
and uh 
yep . 
that ' s it . 
did you did uh did you find a place ? 
is that out of the way ? 
uh no . 
not yet . 
uh yesterday i called up a lady who who will have a vacant room from may thirtieth . 
and she said she ' s interviewing two more people . 
so 
and she would get back to me on monday . 
so that ' s that ' s only thing i have . 
and diane has a few more houses . 
she ' s going to take some pictures and send me after i go back . 
okay . 
so it ' s that ' s 
oh . 
so you ' re not down here permanently yet ? 
no . 
i ' m going back to o . g . i . today . 
uh . 
oh okay . 
oh . 
okay . 
and then you ' re coming back uh 
uh i mean i i i plan to be here on thirty first . 
thirty first . 
okay . 
thirty first . 
yeah . 
well if there ' s a house available or place to . 
well i mean if if 
yeah i hope . 
they ' re available . 
and they ' ll be able to get you something . 
so worst comes to worst we ' ll put you up in a hotel for for for a while . 
yeah . 
so in that case i ' m going to be here on thirty first definitely . 
until you 
okay . 
you know if you ' re in a desperate situation and you need a place to stay you could stay with me for a while . 
i ' ve got a spare bedroom right now . 
oh okay . 
thanks . 
that sure is nice of you . 
so it may be he needs more than me . 
oh 
oh . 
oh no no . 
my my cardboard box is actually a nice spacious two bedroom apartment . 
so a two bedroom cardboard box . 
that ' s great . 
yeah . 
yeah yeah yeah . 
thanks dave . 
yeah . 
um 
yeah . 
do want to say anything about 
you you actually been 
uh last week you were doing this stuff with pierre you were you were mentioning . 
is that that something worth talking about ? 
or 
um 
it ' s 
well um it i don ' t think it directly relates . 
um well so i was helping a speech researcher named pierre divenyi . 
and he ' s he wanted to um look at um how people respond to formant changes i think . 
um 
so he he created a lot of synthetic audio files of vowel to vowel transitions . 
and then he wanted a psycho acoustic um spectrum . 
and he wanted to look at um how the energy is moving over time in that spectrum . 
and compare that to the to the listener tests . 
and um 
so i gave him a p . l . p . spectrum . 
and to um he he wanted to track the peaks so he could look at how they ' re moving . 
so i took the um p . l . p . l . p . c . coefficients and um i found the roots . 
this was something that stephane suggested . 
i found the roots of the um l . p . c . polynomial to um track the peaks in the um p . l . p . l . p . c . spectra . 
well there is aligned spectral pairs is like the the 
is that the aligned 
it ' s a root l . p . c . uh of some sort . 
oh no . 
uhhuh . 
so you just 
yeah . 
instead of the log you took the root square i mean cubic root or something . 
what i didn ' t get that . 
no no . 
it ' s it ' s it ' s taking the finding the roots of the l . p . c . polynomial . 
polynomial . 
yeah . 
is that the line spectral 
so it ' s like line spectral pairs . 
oh it ' s like line 
except i think what they call line spectral pairs they push it towards the unit circle . 
don ' t they ? 
to sort of 
yeah yeah yeah yeah . 
but it 
but uh you know . 
but what we ' d used to do when i did synthesis at national semiconductor twenty years ago the technique we were playing with initially was was taking the l . p . c . polynomial and and uh finding the roots . 
it wasn ' t p . l . p . because hynek hadn ' t invented it yet . 
but it was just l . p . c . 
and uh we found the roots of the polynomial . 
and when you do that sometimes they ' re they ' re what most people call formants . 
sometimes they ' re not . 
huh . 
so it ' s it ' s it ' s a little 
huh . 
uh formant tracking with it can be a little tricky . 
because you get these funny values in in real speech . 
so you just you typically just get a few roots ? 
but 
you know ? 
two or three . 
something like that . 
well you get these complex pairs . 
and it depends on the order that you ' re doing . 
uhhuh . 
right . 
but 
so um 
if every root that ' s 
since it ' s a real signal the l . p . c . polynomial ' s going to have real coefficients . 
so i think that means that every root that is not a real root is going to be a complex pair . 
uhhuh . 
um of a complex value and its conjugate . 
um 
so for each 
and if you look at that on the unit circle um one of these one of the members of the pair will be a positive frequency one will be a negative frequency i think . 
so i just 
so um 
for the i ' m using an eighth order polynomial . 
and i ' ll get three or four of these pairs . 
yeah . 
which give me which gives me three or four peak positions . 
huh . 
this is from synthetic speech ? 
or 
it ' s right . 
yeah . 
yeah . 
so if it ' s from synthetic speech then maybe it ' ll be cleaner . 
i mean for real speech in real then what you end up having is like i say funny little things that are don ' t exactly fit your notion of formants all that well . 
how did 
but but mostly they are . 
yeah . 
mostly they do . 
huh . 
and and what i mean in in what we were doing which was not so much looking at things it was okay . 
i 
because it was just a question of quantization . 
uh we were just you know storing 
it was we were doing uh stored speech uh quantization . 
uhhuh . 
but but uh in your case 
um you know 
actually you have peaks that are not at the formant ' s positions . 
but they are lower in energy . 
but there ' s some of that . 
yes . 
and well they are much lower . 
if this is synthetic speech can ' t you just get the formants directly ? 
i mean how is the speech created ? 
it was created from a synthesizer . 
and um 
wasn ' t a formant synthesizer was it ? 
i bet it it might have may have been . 
i this 
but maybe he didn ' t have control over it or something ? 
in in fact we we could get um formant frequencies out of the synthesizer as well . 
and um 
one thing that the um l . p . c . approach will hopefully give me in addition um is that i i might be able to find the the bandwidths of these humps as well . 
um stephane suggested looking at each complex pair as a like a second order i . i . r . filter . 
yeah . 
um 
but i don ' t think there ' s a a really good reason not to um get the formant frequencies from the synthesizer instead . 
except that you don ' t have the psycho acoustic modeling in that . 
yeah . 
so the actual 
so you ' re not getting the actual formants per se . 
you ' re getting the again you ' re getting sort of the 
uh 
uhhuh . 
you ' re getting something that is is uh strongly affected by the p . l . p . model . 
and so it ' s more psycho acoustic . 
so it ' s a little it ' s it ' s it ' s sort of sort of a different thing . 
oh . 
i see . 
that ' s sort of the point . 
but yeah . 
ordinarily in a formant synthesizer the bandwidths as well as the uh formant centers are 
yeah . 
i mean that ' s somewhere in the synthesizer that was put in . 
as as what you 
uhhuh . 
but but yeah . 
you view each complex pair as essentially a second order section . 
which has uh band center and band width . 
and um 
um 
but 
yeah . 
okay . 
so uh 
yeah you ' re going back today . 
and then back in a week i guess . 
and 
yeah . 
yeah . 
great . 
well welcome . 
thanks . 
i guess we should do digits quickly ? 
huh . 
oh yeah digits . 
i almost forgot that . 
digits . 
i almost forgot our daily digits . 
you want to go ahead ? 
sure . 
all right we ' re on . 
ooh thursday . 
so 
there ' s two sheets of paper in front of us . 
yeah so 
what are these ? 
this is the arm wrestling ? 
uh yeah we formed a coalition actually . 
yeah almost . 
we already made it into one . 
oh good . 
yeah . 
yeah . 
excellent . 
that ' s the best thing . 
uhhuh . 
so tell me about it . 
so it ' s well it ' s spectral subtraction or wiener filtering . 
um 
depending on if we put if we square the transfer function or not . 
right . 
and then with over estimation of the noise depending on the uh the s n r with smoothing along time . 
um 
smoothing along frequency . 
uhhuh . 
it ' s very simple smoothing things . 
uhhuh . 
and um the best result is when we apply this procedure on f f t bins uh with a wiener filter . 
uhhuh . 
and there is no noise addition after after that . 
okay . 
so it ' s good . 
because it ' s difficult when we have to add noise to to to find the right level . 
okay . 
are you looking at one in in particular of these two ? 
yeah so the it ' s the sheet that gives fifty f three point sixty six . 
uhhuh . 
um the second sheet is uh about the same . 
and it ' s a spectral subtraction instead of wiener filter . 
and there is also a noise addition after uh cleaning up the mel bins . 
huh 
well the results are similar . 
yeah i mean it ' s it ' s actually uh very similar . 
uhhuh . 
i mean if you look at databases 
uh 
the uh one that has the smallest smaller overall number is actually better on the finnish and spanish . 
uh but it is uh worse on the uh aurora . 
it ' s worse on 
i mean on the uh t t i digits . 
on the multi condition in t i digits yeah . 
uh uh 
um 
huh 
so it probably doesn ' t matter that much either way . 
but um when you say uh unified do you mean uh it ' s one piece of software now ? 
or 
so now we are yeah setting up the software . 
uhhuh . 
um it should be ready uh very soon . 
um and 
so what ' s what ' s happened ? 
i think i ' ve missed something . 
so a week ago 
maybe you weren ' t around when when when hynek and guenther and i 
hynek was here . 
yeah i didn ' t . 
oh okay so yeah let ' s summarize . 
um and then if i summarize somebody can tell me if i ' m wrong . 
which will also be possibly helpful . 
what did i just press here ? 
i hope this is still working . 
we uh we looked at uh 
anyway we after coming back from qualcomm we had you know very strong feedback . 
and uh i think it was hynek and guenter ' s and my opinion also that um you know we sort of spread out to look at a number of different ways of doing noise suppression . 
but given the limited time uh it was sort of time to choose one . 
uhhuh . 
huh 
uh and so uh the vector taylor series hadn ' t really worked out that much . 
uh the subspace stuff uh had not been worked with so much . 
um so it sort of came down to spectral subtraction versus wiener filtering . 
huh 
uh we had a long discussion about how they were the same and how they were uh completely different . 
uhhuh . 
and uh i mean fundamentally they ' re the same sort of thing . 
but the math is a little different . 
so that there ' s a a there ' s an exponent difference in the index . 
you know what ' s the ideal filtering . 
and depending on how you construct the problem . 
uhhuh . 
and uh i guess it ' s sort you know after after that meeting it sort of made more sense to me . 
because um if you ' re dealing with power spectra then how are you going to choose your error . 
and typically you ' ll do choose something like a variance . 
and so that means it ' ll be something like the square of the power spectra . 
uhhuh . 
whereas when you ' re when you ' re doing the the uh um looking at it the other way you ' re going to be dealing with signals . 
and you ' re going to end up looking at power uh noise power that you ' re trying to reduce . 
and so uh so there should be a difference of you know conceptually of of uh a factor of two in the exponent . 
uhhuh . 
but there ' re so many different little factors that you adjust in terms of of uh uh over subtraction and and and and and so forth . 
um that arguably you ' re 
and and and the choice of do you do you operate on the mel bands or do you operate on the f f t beforehand . 
there ' re so many other choices to make that are are almost well if not independent certainly in addition to the choice of whether you uh do spectral subtraction or wiener filtering . 
that um again we sort of felt the gang should just sort of figure out which it is they want to do . 
and then let ' s pick it . 
go forward with it . 
so that ' s that was that was last week . 
and and uh we said uh take a week go arm wrestle . 
you know . 
oh . 
figure it out . 
i mean and the joke there was that each of them had specialized in one of them . 
and and so they 
oh okay . 
so instead they went to yosemite and bonded and and they came out with a single single piece of software . 
so it ' s another another victory for international collaboration . 
so 
uh 
so so you guys have combined or you ' re going to be combining the software ? 
oh boy ! 
well the piece of software has like plenty of options . 
like you can parse command line arguments . 
so depending on that it it becomes either spectral subtraction or wiener filtering . 
oh okay . 
so 
well that ' s fine . 
they ' re close enough . 
but the thing is the important thing is that there is a piece of software that you that we all will be using now . 
yeah yeah . 
yes . 
yeah . 
there ' s just one piece of software . 
yeah . 
i need to allow it to do everything and even more more than this . 
well if we want to like optimize different parameters of 
right . 
parameters yeah . 
sure . 
yeah we can do it later . 
but still so there will be a piece of software with uh will give this system the fifty three point sixty six by default . 
and 
uhhuh . 
how how is how good is that ? 
uhhuh . 
i i i don ' t have a sense of 
it ' s just one percent off of the best proposal . 
best system . 
it ' s between we are second actually if we take this system . 
right ? 
yeah . 
yeah . 
okay . 
compared to the last evaluation numbers yeah . 
but uh 
uhhuh yeah . 
yeah . 
which we sort of were before . 
but we were considerably far behind . 
and the thing is this doesn ' t have neural net in yet for instance . 
uhhuh . 
you know ? 
huh 
so it so um it ' s it ' s not using our full bag of tricks if you will . 
uhhuh . 
and uh and it it is uh very close in performance to the best thing that was there before . 
uh but you know looking at it another way maybe more importantly uh we didn ' t have any explicit noise uh handling . 
stationary dealing with 
we didn ' t explicitly have anything to deal with stationary noise . 
uhhuh . 
and now we do . 
so will the neural net operate on the output from either the wiener filtering or the spectral subtraction ? 
well so so so arguably i mean what we should do 
or will it operate on the original ? 
i mean i gather you have it sounds like you have a few more days of of nailing things down with the software and so on . 
but and then but um arguably what we should do is even though the software can do many things we should for now pick a set of things . 
these things i would guess . 
uhhuh . 
and not change that . 
and then focus on everything that ' s left . 
and i think you know that our goal should be by next week when hynek comes back uh to uh really just to have a firm path uh for the you know for the time he ' s gone . 
of of uh what things will be attacked . 
but i would i would i would thought think that what we would want to do is not futz with this stuff for a while . 
because what ' ll happen is we ' ll change many other things in the system . 
uhhuh . 
and then we ' ll probably want to come back to this and possibly make some other choices . 
but um 
but just conceptually where does the neural net go ? 
do do you want to run it on the output of the spectrally subtracted ? 
huh 
well depending on its size 
well one question is is it on the um server side or is it on the terminal side . 
uh if it ' s on the server side it you probably don ' t have to worry too much about size . 
uhhuh . 
so that ' s kind of an argument for that . 
we do still however have to consider its latency . 
so the issue is is um for instance could we have a neural net that only looked at the past . 
right . 
um what we ' ve done in uh in the past is to use the neural net uh to transform um all of the features that we use . 
so this is done early on . 
this is essentially um um i guess it ' s it ' s more or less like a a speech enhancement technique here . 
right ? 
uhhuh . 
where we ' re just kind of creating new if not new speech at least new new f f t ' s . 
that that have you know which could be turned into speech . 
uhhuh . 
uh that that have some of the noise removed . 
uhhuh . 
um after that we still do a mess of other things to to produce a bunch of features . 
right . 
and then those features are not now currently transformed by the neural net . 
and then the the way that we had it in our proposal two before we had the neural net transformed features and we had the untransformed features . 
which i guess you you actually did linearly transform with the k l t . 
yeah yeah right . 
but but but uh to orthogonalize them . 
but but they were not uh processed through a neural net . 
and stephane ' s idea with that as i recall was that you ' d have one part of the feature vector that was very discriminant and another part that wasn ' t . 
uhhuh . 
uh which would smooth things a bit for those occasions when uh the testing set was quite different than what you ' d trained your discriminant features for . 
so um all of that is is uh still seems like a good idea . 
the thing is now we know some other constraints . 
we can ' t have unlimited amounts of latency . 
uh you know that ' s still being debated by the by people in europe . 
but uh no matter how they end up there it ' s not going to be unlimited amounts . 
so we have to be a little conscious of that . 
yeah . 
um 
so there ' s the neural net issue . 
there ' s the v a d issue . 
and uh there ' s the second stream thing . 
and i think those that we last time we agreed that those are the three things that have to get uh focused on . 
what was the issue with the v a d ? 
well better ones are good . 
and so the the default uh boundaries that they provide are they ' re okay but they ' re not all that great ? 
i guess they still allow two hundred milliseconds on either side or 
uhhuh . 
is that what the deal is ? 
uh so um they keep two hundred milliseconds at the beginning and end of speech and they keep all the 
outside the beginnings and end . 
yeah . 
and all the speech pauses . 
uhhuh . 
which is sometimes on the speechdat car you have pauses that are more than one or two seconds . 
wow . 
more than one second for sure . 
um 
huh 
yeah . 
and yeah it seems to us that this way of just dropping the beginning and end is not 
we we can do better i think . 
uhhuh . 
because um with this way of dropping the frames they improve over the baseline by fourteen percent . 
and sunil already showed that with our current v a d we can improve by more than twenty percent . 
on top of the v a d that they provide ? 
no . 
just using either their v a d or our current v a d . 
our way . 
oh okay . 
so our current v a d is is more than twenty percent . 
while their is fourteen . 
theirs is fourteen ? 
yeah . 
i see . 
huh . 
so 
yeah . 
and another thing that we did also is that we have all this training data for let ' s say for speechdat car . 
we have channel zero which is clean . 
channel one which is far field microphone . 
and 
if we just take only the um v a d probabilities computed on the clean signal and apply them on the far field uh test utterances then results are much better . 
uhhuh . 
in some cases it divides the error rate by two . 
wow ! 
so it means that there are stim still 
if if we can have a good v a d well it would be great . 
how how much latency does the uh does our v a d add ? 
is it significant ? 
uh right now it ' s um a neural net with nine frames . 
or 
so it ' s forty milliseconds plus um the rank ordering . 
which uh should be 
like another ten frames . 
ten . 
yeah . 
so right now it ' s one hundred and forty milliseconds . 
rank . 
oh . 
with the rank ordering ? 
i ' m sorry . 
the the the smoothing the the the filtering of the probabilities . 
the the um 
on the r . 
yeah it ' s not a median filtering . 
it ' s just we don ' t take the median value we take something 
um so we have eleven um frames 
oh this is for the v a d ? 
and 
yeah . 
for the v a d yeah . 
and we take the third . 
yeah . 
oh okay . 
yeah . 
um 
yeah . 
um 
huh 
so yeah i was just noticing on this that it makes reference to delay . 
so what ' s the if you ignore 
um the v a d is sort of in in parallel . 
isn ' t isn ' t it ? 
with with the i mean it isn ' t additive with the the uh l d a and the wiener filtering and so forth . 
the l d a ? 
yeah so so what happened right now we removed the delay of the l d a . 
right ? 
uhhuh . 
yeah . 
so we i mean if so if we if so which is like if we reduce the delay of v a 
so the the final delay ' s now is determined by the delay of the v a d . 
because the l d a doesn ' t have any delay . 
so if we if we reduce the delay of the v a d i mean it ' s like effectively reducing the delay . 
how how much uh delay was there on the l d a ? 
so the l d a and the v a d both had a hundred millisecond delay . 
so and they were in parallel . 
so which means you pick either one of them . 
huh 
the the biggest whatever . 
uhhuh . 
i see . 
so right now the l d a delays are more . 
and there 
oh okay . 
and there didn ' t seem to be any uh penalty for that ? 
pardon ? 
there didn ' t seem to be any penalty for making it causal ? 
oh no it actually made it like point one percent better or something actually . 
okay . 
or something like that . 
well may as well then . 
and 
and he says wiener filter is is forty milliseconds delay . 
yeah so that ' s the one which stephane was discussing like 
huh 
so is it 
the smoothing . 
yeah the you smooth it and then delay the decision by 
so 
right . 
okay . 
so that ' s that ' s really not not bad . 
so we may in fact we ' ll see what they decide we may in fact have um the the uh latency time available for to have a neural net . 
i mean sounds like we probably will . 
uhhuh . 
so 
that ' d be good . 
because i because it certainly always helped us before . 
so 
uh . 
what amount of latency are you thinking about when you say that ? 
well they ' re you know they ' re disputing it . 
you know they ' re saying uh one group is saying a hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds . 
huh 
two hundred and fifty is what it was before actually . 
so 
oh . 
uh some people are lobbying lobbying to make it shorter . 
huh 
um 
and um 
were you thinking of the two fifty or the one thirty when you said we should have enough for the neural net ? 
well it just it when we find that out it might change exactly how we do it is all . 
i mean how much effort do we put into making it causal ? 
oh okay . 
i mean i think the neural net will probably do better if it looks at a little bit of the future . 
uhhuh . 
but um it will probably work to some extent to look only at the past . 
and we you know limited machine and human time and effort . 
and you know how how much time should we put into into that ? 
so it ' d be helpful if we find out from the the standards folks whether you know they ' re going to restrict that or not . 
uhhuh . 
um 
but i think you know at this point our major concern is making the performance better . 
and and um if uh something has to take a little longer in latency in order to do it that ' s you know a secondary issue . 
uhhuh . 
but if we get told otherwise then you know we may have to clamp down a bit more . 
huh 
so the one one one difference is that was there is like we tried computing the delta and then doing the frame dropping . 
uhhuh . 
the earlier system was do the frame dropping and then compute the delta on the 
uhhuh . 
so this 
which could be a kind of a funny delta . 
right ? 
yeah . 
oh . 
oh oh ! 
so that ' s fixed in this . 
yeah we talked about that . 
yeah . 
yeah uhhuh 
so we have no delta and then 
good . 
so the frame dropping is the last thing that we do . 
so yeah what we do is we compute the silence probability . 
convert it to that binary flag . 
uhhuh . 
and then in the end you upsample it to match the final features number of 
uhhuh . 
did that help then ? 
it seems to be helping on the well matched condition . 
so that ' s why this improvement i got from the last result . 
so and it actually reduced a little bit on the high mismatch . 
so in the final weightage it ' s better . 
because the well matched is still weighted more than . 
so i mean you were doing a lot of changes . 
did you happen to notice how much uh the change was due to just this frame dropping problem ? 
what about this ? 
uh you had something on it . 
right ? 
just the frame dropping problem . 
yeah but it ' s it ' s difficult . 
sometime we we change two two things together . 
and but it ' s around maybe it ' s less than one percent . 
uhhuh . 
yeah . 
it 
but like we ' re saying if there ' s four or five things like that then pretty soon you ' re talking real improvement . 
yeah . 
yeah and it 
yeah . 
and then we have to be careful with that also with the neural net . 
yeah . 
because in the proposal the neural net was also uh working on after frame dropping . 
uhhuh . 
um 
oh that ' s a real good point . 
so well we ' ll have to be 
to do the same kind of correction . 
it might be hard if it ' s at the server side . 
right ? 
huh well we can do the frame dropping on the server side . 
or we can just be careful at the terminal side to send a couple of more frames before and after . 
and so 
i think it ' s okay . 
okay . 
you have um 
so when you 
uh maybe i don ' t quite understand how this works . 
but um couldn ' t you just send all of the frames but mark the ones that are supposed to be dropped ? 
because you have a bunch more bandwidth . 
right ? 
well you could . 
yeah i mean it it always seemed to us that it would be kind of nice to in addition to uh reducing insertions actually use up less bandwidth . 
yeah yeah . 
but nobody seems to have cared about that in this evaluation . 
and that way the net could use 
so 
if the net ' s on the server side then it could use all of the frames . 
yes it could be . 
it ' s like you mean you just transferred everything . 
and then finally drop the frames after the neural net . 
right ? 
uhhuh . 
uhhuh . 
yeah that ' s that ' s one thing which 
but you could even mark them before they get to the server . 
yeah right now we are 
uh 
right now what what we did is like we just mark we just have this additional bit which goes around the features saying it ' s currently a it ' s a speech or a nonspeech . 
oh . 
oh okay . 
so there is no frame dropping till the final features like including the deltas are computed . 
i see . 
and after the deltas are computed you just pick up the ones that are marked silence and then drop them . 
uhhuh . 
i see . 
so it would be more or less the same thing with the neural net i guess actually . 
uhhuh . 
i see . 
so yeah that ' s what that ' s what that ' s what uh this is doing right now . 
i see . 
okay . 
yeah . 
uhhuh . 
um 
okay . 
so uh 
what ' s uh 
that ' s that ' s a good set of work that that uh 
just one more thing . 
like should we do something more for the noise estimation ? 
because we still 
yeah i was wondering about that . 
yeah . 
uhhuh . 
that was i i had written that down there . 
um 
so we uh actually i did the first experiment . 
this is with just fifteen frames . 
um 
we take the first fifteen frame of each utterance to it . 
yeah . 
and average their power spectra . 
um 
i tried just plugging the um uh guenter noise estimation on this system . 
and it uh it got worse . 
um 
but of course i didn ' t play with it . 
uhhuh . 
but uhhuh 
uh i didn ' t do much more for noise estimation i just tried this . 
and 
huh yeah well it ' s not surprising it ' d be worse the first time . 
uhhuh . 
but um 
it does seem like you know some compromise between always depending on the first fifteen frames and always depending on a a pause is is is a good idea . 
uh maybe you have to weight the estimate from the first fifteen frames more heavily than than was done in your first attempt . 
but 
uhhuh . 
but 
yeah i guess . 
yeah . 
um 
no i mean 
um 
do you have any way of assessing how well or how poorly the noise estimation is currently doing ? 
huh no we don ' t . 
yeah . 
we don ' t have nothing that 
is there was there any experiment with 
well i i did the only experiment where i tried was i used the channel zero vad for the noise estimation . 
and frame dropping . 
so i don ' t have a i don ' t have a split like which one helped more . 
yeah . 
so it it was the best result i could get . 
uhhuh . 
so that ' s the 
so that ' s something you could do with um this final system . 
right ? 
just do this everything that is in this final system except uh use the channel zero . 
uhhuh . 
for the noise estimation . 
yeah . 
yeah we can try something . 
and then see how much better it gets . 
uhhuh sure . 
if it ' s you know essentially not better then it ' s probably not worth 
yeah . 
any more . 
yeah but the guenter ' s argument is slightly different . 
it ' s like even even if i use a channel zero vad i ' m just averaging the the power spectrum . 
but the guenter ' s argument is like if it is a non stationary segment then he doesn ' t update the noise spectrum . 
so he ' s like he tries to capture only the stationary part in it . 
so the averaging is like different from updating the noise spectrum only during stationary segments . 
so the guenter was arguing that i mean even if you have a very good v a d averaging it like over the whole thing is not a good idea . 
because you ' re averaging the stationary and the non stationary and finally you end up getting something . 
i see . 
which is not really the because you anyway you can ' t remove the stationary part i mean non stationary part from the signal . 
so 
not using these methods anyway yeah . 
yeah so you just update only doing or update only the stationary components . 
yeah so that ' s so that ' s still a slight difference from what guenter is trying . 
and 
well yeah and and also there ' s just the fact that um 
uh although we ' re trying to do very well on this evaluation um we actually would like to have something that worked well in general . 
yeah yeah . 
and um relying on having fifteen frames at the front or something is is pretty 
i mean you might you might not . 
huh 
uhhuh . 
so um 
um it ' d certainly be more robust to different kinds of input if you had at least some updates . 
um 
uhhuh . 
but um 
well i don ' t know . 
what what do you uh what do you guys see as as being what you would be doing in the next week given what ' s happened ? 
cure the vad . 
yeah . 
what was that ? 
v a d . 
oh . 
and 
uh 
okay . 
so should we keep the same i think we might try to keep the same idea . 
of having a neural network . 
but training it on more data . 
and adding better features i think . 
but because the current network is just p l p features . 
well it ' s trained on noisy p l p . 
just the cepstra . 
yeah ? 
p l p features computed on noisy speech . 
but there is nothing particularly robust in these features . 
so uh 
no . 
there ' s no rasta no 
so uh i i don ' t remember what you said the answer to my uh question earlier . 
will you will you train the net on after you ' ve done the spectral subtraction or the wiener filtering ? 
this is a different net . 
oh . 
so we have a v a d which is like that ' s a neural net . 
oh yeah huh 
oh you ' re talking about the v a d net . 
yeah . 
okay . 
uhhuh . 
i see . 
so that that v a d was trained on the noisy features . 
uhhuh . 
so right now we have like uh we have the cleaned up features . 
so we can have a better v a d by training the net on the cleaned up speech . 
uhhuh . 
i see i see . 
yeah but we need a v a d for uh noise estimation also . 
so it ' s like where do we want to put the v a d ? 
uh it ' s like 
can you use the same net to do both ? 
or 
for 
can you use the same net that you that i was talking about to do the v a d ? 
uhhuh . 
uh it actually comes at at the very end . 
so the net the final net i mean which is the feature net 
uhhuh . 
so that actually comes after a chain of like l d a plus everything . 
so it ' s like it takes a long time to get a decision out of it . 
and and you can actually do it for final frame dropping . 
but not for the v noise estimation . 
uhhuh . 
you see the idea is that the um initial decision to that that you ' re in silence or speech happens pretty quickly . 
oh okay . 
huh 
and that 
because that ' s used by some of these other 
yeah and that ' s sort of fed forward and and you say well flush everything it ' s not speech anymore . 
oh okay . 
i see . 
yeah . 
i thought that was only used for doing frame dropping later on . 
um it is used uh 
yeah it ' s only used well it ' s used for frame dropping . 
um it ' s used for end of utterance . 
huh 
because you know there ' s if you have more than five hundred milliseconds of of of nonspeech then you figure it ' s end of utterance or something like that . 
uhhuh . 
so 
um 
and it seems important for like the on line normalization . 
um we don ' t want to update the mean and variance during long silence portions . 
um so it it has to be done before . 
oh . 
i see . 
this mean and variance normalization . 
um 
um 
yeah so probably the v a d and and maybe testing out the noise estimation a little bit . 
i mean keeping the same method . 
but but uh seeing if you but um noise estimation could be improved . 
uhhuh . 
those are sort of related issues . 
it probably makes sense to move from there . 
and then uh later on in the month i think we want to start including the neural net at the end . 
um 
okay anything else ? 
the half dome was great . 
good . 
yeah you didn ' t didn ' t fall . 
well yeah . 
that ' s good . 
our our effort would have been devastated . 
if you guys had run into problems . 
so hynek is coming back next week you said ? 
yeah that ' s the plan . 
huh 
i guess the week after he ' ll be uh going back to europe . 
and so we want to 
is he in europe right now or is he up at 
no no he ' s he ' s he ' s dropped into the u s yeah yeah . 
oh . 
huh 
so 
uh so uh 
uh the idea was that uh we ' d we ' d sort out where we were going next with this with this work before he uh left on this next trip . 
uh barry you just got through your quals so i don ' t know if you have much to say . 
but uh 
huh 
no just uh looking into some some of the things that um uh john ohala and hynek um gave as feedback . 
um as as a starting point for the project . 
um 
in in my proposal i i was thinking about starting from a set of uh phonological features or a subset of them . 
um but that might not be necessarily a good idea according to um john . 
uhhuh . 
he said uh um these these phonological features are are sort of figments of imagination also . 
uhhuh . 
um 
in conversational speech in particular . 
i think you can you can put them in pretty reliably in synthetic speech . 
but we don ' t have too much trouble recognizing synthetic speech since we create it in the first place . 
so it ' s 
right . 
yeah so um a better way would be something more more data driven . 
uhhuh . 
just looking at the data and seeing what ' s similar and what ' s not similar . 
uhhuh . 
so i ' m i ' m um taking a look at some of um sangita ' s work on on traps . 
she did something where um where the traps 
she clustered the the temporal patterns of um certain certain phonemes in in averaged over many many contexts . 
and uh some things tended to cluster . 
uhhuh . 
right you know like stop stop consonants clustered really well . 
huh 
um silence was by its own self . 
uhhuh . 
and uh um vocalic was clustered . 
uhhuh . 
and um so those are interesting things to 
so you ' re now you ' re sort of looking to try to gather a set of these types of features ? 
right . 
uhhuh . 
yeah . 
just to see where where i could start off from . 
uhhuh . 
uh you know ? 
a a a set of small features and continue to iterate and find uh a better set . 
uhhuh . 
yeah . 
okay well short meeting . 
that ' s okay . 
yeah . 
okay so next week hopefully we ' ll can get hynek here to to join us . 
and uh 
uh 
should we do digits ? 
digits digits . 
okay now . 
go ahead morgan . 
all right let me get my glasses on so i can see them . 
you can start . 
okay . 
okay . 
okay . 
so we we had a meeting with uh with hynek um in in which uh uh sunil and stephane uh summarized where they were and and uh talked about where we were going to go . 
so that that happened sort of mid week . 
did did you guys get your code pushed together ? 
uh . 
oh yeah . 
yeah . 
it ' s it ' s it ' s it was updated yesterday . 
cool . 
right ? 
yeah . 
yeah . 
oh right i saw i saw the note . 
you probably received the mail . 
yeah . 
uhhuh . 
what was the update ? 
what was the update ? 
yeah . 
so there is then the all the new features that go in . 
the um noise suppression the re synthesis of speech after suppression . 
is the um the c v s mechanism working well ? 
these are the 
yeah . 
are are people uh up at o g i grabbing code uh via that ? 
or 
uh i don ' t think i don ' t think 
i don ' t know if they use it . 
but 
uhhuh . 
yeah i don ' t think anybody up there is like working on it right now . 
huh . 
i think it more likely that what it means is that when sunil is up there he will grab it . 
yeah . 
yeah . 
yeah . 
so right now nobody ' s working on aurora there . 
i see . 
they ' re 
yeah they ' re working on a different task . 
i see . 
yeah . 
okay . 
but what ' ll happen is is he ' ll go back up there and uh pratibha will come back from from uh the east coast . 
uhhuh . 
uh 
and uh and and i guess actually uh after eurospeech for a little bit uh he ' ll go up there too . 
so actually everybody who ' s working on it will be up there for at least a little while . 
so they ' ll remotely access it from there . 
so has has anybody tried remotely accessing the c v s using uh uh s s h ? 
yeah . 
yeah . 
um i don ' t know if hari did that or you 
well i can actually do it too there . 
i mean i can just log into 
have you tried it yet ? 
no i didn ' t . 
okay . 
so i ' ll try it today . 
good idea . 
yeah . 
yeah . 
actually i i tried while when i installed the repository i tried from belgium . 
i logged in there and i tried to import . 
yeah ? 
it worked good ? 
yeah it works . 
oh good . 
great . 
oh yeah . 
but it ' s so right now it ' s the mechanism with s s h . 
i don ' t i didn ' t set up you can also set up a c v s server on a new port . 
it ' s like well uh a main server or you can do a c v s server . 
yeah . 
right . 
then that ' s using the c v s password mechanism and all that . 
but 
right ? 
yeah right . 
but i didn ' t do that because i was not sure about security problems . 
i i would have to 
so when you came in from belgian belgium using s s h uh was it asking you for your own password into icsi ? 
so if you can only do that if you have an account at icsi . 
right . 
yeah . 
okay . 
yeah . 
because there is an a way to set up anonymous c v s . 
right ? 
so that 
yeah you in this way you you have to set up a c v s server but then yeah you can access it . 
oh okay . 
so the anonymous mechanism 
you you can set up priorities . 
you can access them and mostly if you if the the server is set up like this . 
okay . 
because a lot of the open source stuff works with anonymous c v s . 
and i ' m just wondering uh i mean for our transcripts we may want to do that . 
uhhuh . 
yeah . 
uh 
yeah for this stuff i don ' t think we ' re quite up to that . 
uhhuh . 
i mean we ' re still so much in development . 
yeah . 
yeah yeah . 
we want to have just the insiders . 
oh i wasn ' t suggesting for this . 
i ' m thinking of the meeting recorder stuff . 
but 
yeah . 
yeah . 
okay . 
cool . 
yeah . 
so uh 
what ' s new ? 
well i mean i think maybe the thing to me might be i i ' m sure you ' ve just been working on on uh details of that since the meeting . 
right ? 
and so 
huh since the meeting 
that was that was tuesday . 
well i i ' ve been i ' ve been training a new v a d and a new feature net . 
okay . 
so they should be ready . 
um 
but i guess maybe the thing since you weren ' t you guys weren ' t at that that meeting might be just just to um sort of recap uh the the conclusions of the meeting . 
oh great . 
uhhuh . 
you ' re talking about the meeting with hynek ? 
so 
yeah . 
because that was sort of uh we we ' d sort of been working up to that that that uh he would come here this week and and we would sort of 
uhhuh . 
since he ' s going out of town like now and i ' m going out town in a couple weeks uh and time is marching sort of given all the many wonderful things we could be working on what what will we actually focus on . 
uhhuh . 
and uh and what do we freeze . 
and you know what do we 
so um 
i mean this software that these guys created was certainly a a key part . 
so then there ' s something central . 
and there aren ' t at least a bunch of different versions going off in in ways that differ trivially . 
yeah . 
uh um and um 
that ' s that ' s nice . 
and then within that i guess the idea was to freeze a certain set of options for now to run it uh a particular way and decide on what things are going to be experimented with as opposed to just experimenting with everything . 
so keep a certain set of things constant . 
so um 
uh maybe describe roughly what what we are keeping constant for now . 
or 
yeah . 
well so we ' ve been working like six weeks on on the noise compensation and we end up with something that seems reasonable . 
um 
are you going to use which of the two techniques ? 
so finally it ' s it ' s um wiener filtering on f f t bins . 
and it uses uh two steps smoothing of the transfer function . 
the first step that ' s along time which use recursion . 
and after this step there is a further smoothing along frequency which use a sliding window of twenty f f t bins . 
huh . 
and uh 
so this is on the uh before any mel scaling has been done ? 
yeah . 
this is 
yeah . 
this this smoothing is done on the estimate um of what you ' re going to subtract or on the thing that has already had something subtracted ? 
it was 
yeah . 
uh it ' s on the transfer function . 
so 
oh it ' s on the transfer function for the wiener filter . 
yeah . 
yeah okay . 
yeah so basically we tried different configuration within this idea . 
we tried applying this on mel bands having spectral subtraction instead of wiener filtering . 
um 
well finally we end up with this configuration that works uh quite well . 
so we are going to fix this for the moment and work on the other aspects of the whole system . 
uhhuh . 
so 
actually let me uh dave isn ' t here to talk about it but let me just interject . 
this module in principle i mean you would know whether it ' s true in fact is somewhat independent from the rest of it . 
i mean because you you re synthesize speech . 
right ? 
uhhuh . 
so um 
uh well you don ' t i guess you don ' t re synthesize speech but you could . 
we we do not 
uh but you could . 
well well we do but we don ' t don ' t re synthesize . 
in in the program we don ' t re synthesize and then re analyze once again . 
we just use the clean f f t bins . 
but you have a re synthesized thing that you that ' s an an option here . 
this is an option that then you can 
yeah . 
yeah i i guess my point is that um in some of the work he ' s doing in reverberation one of the things that we ' re finding is that uh it ' s it ' s for the for an artificial situation we can just deal with the reverberation and his techniques work really well . 
but for the real situation uh problem is is that you don ' t just have reverberation you have reverberation in noise . 
and if you don ' t include that in the model it doesn ' t work very well . 
so in fact it might be a very nice thing to do to just take the noise removal part of it and put that in front of what he ' s looking at and uh generate new files or whatever and and uh uh and then do the reverberation part . 
uhhuh . 
so it ' s 
huh . 
anyway . 
so dave hasn ' t tried that yet ? 
no no he ' s i mean 
i guess he ' s busy with 
yeah prelims right . 
prelim hell . 
yeah . 
yeah . 
so 
yeah . 
uh but but you know that ' ll 
uh it ' s clear that we uh we are not with the real case that we ' re looking at we can ' t just look at reverberation in isolation . 
because the interaction between that and noise is is considerable . 
and that ' s i mean in the past we ' ve looked at uh and this is hard enough the interaction between channel effects and and uh and additive noise uh so convolutional effects and and additive effects . 
and that ' s hard enough . 
i mean i don ' t think we really 
i mean we ' re trying to deal with that . 
in a sense that ' s what we ' re trying to deal with in this aurora task . 
and we have uh the uh uh l d a stuff that in principle is doing something about convolutional effects . 
and we have the noise suppression that ' s doing something about noise . 
uh even that ' s hard enough . 
and and the on line normalization as well in that category . 
there ' s all these interactions between these two and that ' s part of why these guys had to work so hard on on juggling everything around . 
but now when you throw in the reverberation it ' s even worse . 
because not only do you have these effects but you also have some long time effects . 
and um so dave has something which uh is doing some nice things under some conditions with with long time effects . 
but when it ' s when there ' s noise there too it ' s it ' s it ' s pretty hard . 
so we have to start 
since any almost any real situation is going to have uh where you have the microphone distant is going to have both things . 
we we actually have to think about both at the same time . 
huh . 
so 
um so there ' s this noise suppression thing which is sort of worked out . 
and then uh maybe you should just continue telling what what else is in the the form we have . 
yeah well the um the other parts of the system are the the blocks that were already present before and that we did not modify a lot . 
so that ' s again that that ' s the wiener filtering followed by uh uh that ' s done at the f f t level . 
then 
yeah then the mel filter bank . 
uhhuh . 
then the log operation . 
uhhuh . 
huh . 
the the the filtering is done in the frequency domain ? 
yeah . 
yeah . 
okay . 
and then the mel and then the log and then the 
then the l d a filter . 
l d a filter . 
huh then the downsampling . 
and then uh 
downsample . 
d c t . 
d c t . 
then um on line normalization . 
on line norm . 
followed by upsampling . 
then finally we compute delta and we put the neural network also . 
right and then in parallel with an a neural net and then following neural net some probably some orthogonalization . 
uh 
yeah . 
um 
and finally frame dropping which um would be a neural network also used for estimated silence probabilities . 
and the input of this neural network would be somewhere between log mel bands or one of the earlier stages of the processing . 
uhhuh . 
so that ' s sort of most of this stuff is yeah is operating parallel with this other stuff . 
uhhuh . 
yeah . 
so the things that we um uh 
i guess we sort of uh 
there ' s there ' s some uh neat ideas for v a ds . 
so i mean in 
i think there ' s sort of like there ' s a bunch of tuning things to improve stuff . 
there ' s questions about various places where there ' s an exponent if it ' s the right exponent or ways that we ' re estimating noise that we can improve estimating noise . 
and there ' s going to be a host of those . 
but structurally it seemed like the things the main things that that we brought up that uh are are going to need to get worked on seriously are uh uh a a significantly better v a d uh putting the neural net on um which you know we haven ' t been doing anything with the uh neural net at the end there and uh the uh opening up the second front . 
uh 
the other half of the channel ? 
that what you mean ? 
yeah yeah i mean because we we have we have uh uh half the the uh data rate that they allow . 
and uh so the initial thing which came from uh the meeting that we had down south was uh that um we ' ll initially just put in a mel spectrum as the second one . 
it ' s you know cheap easy . 
uh 
there ' s a question about exactly how we do it . 
we probably will go to something better later . 
uhhuh . 
but the initial thing is that cepstra and spectra behave differently . 
so 
um i think tony robinson used to do i was saying this before i think he used to do mel uh spectra and mel cepstra . 
he used them as alternate features . 
huh . 
put them together . 
uh 
so if you took the system the way it is now the way it ' s you ' re going to freeze it and it ran it on the last evaluation where it would it be ? 
uhhuh . 
it uh 
in terms of ranking . 
second . 
right now it ' s second . 
right ? 
um 
uhhuh . 
although you you know you haven ' t tested it actually on the german and danish . 
have you ? 
no we didn ' t . 
no . 
um 
yeah . 
so on the ones that you did test it on it would have been second ? 
yeah . 
would it i mean but 
when you ' re saying second you ' re comparing to the numbers that the uh that the best system before got on uh also without german and danish ? 
yeah yeah . 
yeah okay . 
and the ranking actually didn ' t change after the german and danish . 
so yeah . 
well ranking didn ' t before but i ' m just asking where this is to where theirs was without the german and danish . 
yeah . 
yeah . 
yeah . 
huh . 
yeah yeah . 
right ? 
so 
where where where were we actually on the last test ? 
oh we were also essentially second although there were there were i mean we had a couple systems and they had a couple systems . 
and so i guess by that we were third . 
but i mean there were two systems that were pretty close that came from the same place . 
uhhuh . 
i see . 
okay . 
uh so institutionally we were we were second with uh the third third system . 
we ' re so this second that you ' re saying now is system wide second ? 
see 
uh no i think it ' s also institutional . 
still institutionally second ? 
isn ' t it ? 
right . 
i mean i think both of their systems probably 
uh we are between their two systems . 
oh are we ? 
so 
i it is a triumph . 
yeah . 
their their first system is fifty four point something . 
is it ? 
and uh we are fifty three point something . 
and their second system is also fifty three point something . 
but everything is within the range of one one percent . 
yeah one percent . 
oh wow ! 
yeah so so basically they ' re all they ' re all pretty close . 
that ' s very close . 
so 
yeah . 
yeah . 
and and um you know in some sense we ' re all doing fairly similar things . 
uh i mean one could argue about the l d a and so forth . 
but i i think you know in a lot of ways we ' re doing very similar things . 
but what what 
so how did they fill up this all these these bits ? 
i mean if we ' re 
um why are we using half ? 
yeah . 
well so you could you 
or how are they using more than half i guess maybe is what i 
yeah so i i think uh you guys are closer to it than me so correct me if i ' m wrong but i i think that what ' s going on is that in in both cases some kind of normalization is done to deal with convolutional effects . 
uh they have some cepstral modification . 
right ? 
uhhuh . 
in our case we have a couple things . 
we have the on line normalization and then we have the l d a rasta . 
and they seem to complement each other enough and be different enough that they both seem to help help us . 
but in any event they ' re both doing the same sort of thing . 
but there ' s one difference . 
the l d a rasta uh throws away high modulation frequencies . 
and they ' re not doing that . 
so so 
so that if you throw away high modulation frequencies then you can downsample . 
get down . 
i see . 
i see . 
so 
so what if you didn ' t so do you explicitly downsample then ? 
do we explicitly downsample ? 
yeah . 
yeah . 
and what if we didn ' t do that ? 
would we get worse performance ? 
i think it doesn ' t affect it . 
um yeah not better not worse . 
does it ? 
i see . 
okay . 
yeah . 
so i think the thing is since we ' re not evidently throwing away useful information let ' s try to put in some useful information . 
yeah . 
yeah . 
and uh so i you know we we ' ve found in a lot of ways for quite a while that having a second stream uh helps a lot . 
so that ' s that ' s put in and you know it may even end up with mel spectrum even though i ' m saying i think we could do much better just because it ' s simple . 
uhhuh . 
um 
and you know in the long run having something everybody will look at and say oh yeah i understand is is very helpful . 
so you would you ' re you ' re thinking to put the uh mel spectrum in before any of the noise removal stuff or after ? 
well that ' s a question . 
i mean we were talking about that . 
it looks like it ' d be straightforward to to uh remove the noise . 
um and uh 
because that happens before the mel conversion . 
right ? 
yeah . 
so i mean to do it after the mel conversion uh after the noise removal after the mel conversion . 
there ' s even a question in my mind anyhow of whether you should take the log or not . 
uh 
i sort of think you should . 
but i don ' t know . 
what about normalizing also ? 
right . 
uh 
well but normalizing spectra instead of cepstra ? 
yeah . 
yeah probably . 
some kind would be good . 
you know ? 
i would think . 
well it it it it so it actually makes it dependent on the overall energy of the uh the frame . 
if you do or don ' t normalize ? 
if if you don ' t normalize and if if you don ' t normalize . 
right . 
yes so i mean one would think that you would want to normalize . 
but i i 
my thought is uh particularly if you take the log try it . 
and then if if normalization helps then you have something to compare against and say okay this much effect i mean you don ' t want to change six things and then see what happens . 
you want to change them one at a time . 
uhhuh . 
so adding this other stream in that ' s simple in some way . 
and then saying oh uh particularly because we ' ve found in the past there ' s all these these these different results you get with slight modifications of how you do normalization . 
normalization ' s a very tricky sensitive thing and you learn a lot . 
so i would think you would want to have some baseline that says okay we don ' t normalize this is what we get when we do this normalization when we do that normalization . 
but but the other question is 
so i think ultimately we ' ll wind up doing some normalization . 
i agree . 
so this second stream will it add latency to the system ? 
or 
no it ' s in parallel . 
we ' re not talking about computation time here . 
we ' re i think we ' re pretty far out . 
yeah . 
so it ' s just in terms of what data it ' s depending on . 
it ' s depending on the same data as the other . 
same data . 
okay . 
so it ' s in parallel . 
uhhuh . 
so with this uh new stream would you train up a v a d on both both features somehow ? 
no i guess the v a d has its own set of features . 
okay . 
i mean which could be this one of these streams or it can be something derived from these streams . 
then it ' s 
yeah . 
okay . 
and there is also the idea of using traps maybe for the v a d . 
which um 
yeah that ' s also . 
well pratibha apparently showed when she was at i b m that it ' s a good idea . 
so 
would would that fit on the handset ? 
or 
oh ! 
i have no idea . 
okay . 
well it has i mean the 
it would have to fit . 
but 
yeah if it has to fit the delays and all this stuff . 
yeah . 
well there ' s the delays and the storage . 
okay . 
yeah ? 
yeah . 
but i don ' t think the storage is so big for that . 
right . 
i think the biggest we ' ve run into for storage is the neural net . 
yeah . 
right ? 
yeah . 
um 
and so i guess the issue there is are we are we using neural net based traps . 
and and how big are they . 
oh right . 
so that ' ll that ' ll be you know an issue . 
yeah because 
maybe they can be little ones . 
right . 
because she also does the uh the correlation based uh traps without the neural net just looking at the correlation between 
mini traps . 
right . 
and maybe for v a d they would be okay . 
yeah . 
yeah . 
yeah . 
yeah . 
that ' s true . 
or a simple neural net . 
right ? 
i mean the thing is if you ' re doing correlation you ' re just doing a simple uh uh uh dot product you know with some weights which you happened to learn from this learn from the data . 
uhhuh . 
and so 
uh putting a nonlinearity on it is you know not that big a deal . 
uhhuh . 
it certainly doesn ' t take much space . 
right . 
so uh the question is how complex a function do you need . 
do you need to have an added layer or something . 
in which case uh potentially you know it could be big . 
so 
uhhuh . 
so uh 
uh so what ' s next ? 
maybe remind us . 
so the meeting with hynek that you guys just had was to decide exactly what you were going to freeze in this system ? 
is that 
or was there 
were you talking about what new stuff ? 
or 
what to freeze and then what to do after we froze . 
huh . 
yeah . 
and like i was saying i think the you know the basic directions are uh uh i mean there ' s lots of little things such as improve the noise estimator but the bigger things are adding on the neural net and uh the second stream and then uh improving the v a d . 
uh 
so i ' ll um i ' ll actually after the meeting i ' ll add the second stream to the vad and maybe i ' ll start with the feature net in that case . 
so 
it ' s like you ' re looking at the v a d . 
right ? 
uh yeah . 
i ' ll 
i ' ve a new feature net ready also . 
for the v a d ? 
no uh well two network one v a d and one feature net . 
oh you already have it ? 
uhhuh . 
okay so just figure how to take the features from the final . 
yeah . 
okay . 
um 
but yeah i think there are plenty of issues to work on for the feature net . 
what about the um uh the new part of the evaluation ? 
feature net . 
the uh wall street journal part . 
right . 
right . 
um 
have you ever 
very good question . 
have you ever worked with the mississippi state uh software ? 
sorry . 
no . 
not yet . 
oh . 
well you you may be called upon to help uh uh on account of uh all the work in this stuff here has been uh with small vocabulary . 
okay . 
uhhuh . 
so what how is the uh interaction supposed to happen ? 
uh i remember the last time we talked about this it was sort of up in the air whether they were going to be taking uh people ' s features and then running them or they were going to give the system out or 
yeah . 
yeah . 
oh so they ' re going to just deliver a system basically ? 
yeah yeah . 
do we already have it ? 
yeah i i guess it ' s almost ready . 
uhhuh . 
so 
that ' s what 
so they have released their uh document describing the system . 
i see . 
maybe you could uh point it at chuck . 
sure . 
because i mean 
so we ' ll have to grab this over c v s or something ? 
no it ' s just downloadable from their from their web site . 
is that how they do it ? 
okay . 
okay . 
because one of the things that might be helpful if you ' ve if you ' ve got time in all of this is is if if these guys are really focusing on improving uh all the digit stuff uh maybe and you got the front end from them maybe you could do the runs for the 
uhhuh . 
sure . 
and and you know iron out hassles that that you have to uh tweak joe about or whatever . 
because you ' re more experienced with running the large vocabulary stuff . 
okay . 
so i ' ll point you to the web site and the mails corresponding . 
so 
and it but it ' s not ready yet the system ? 
uh i i think they are still uh tuning something on that . 
so they ' re like they ' re varying different parameters like the insertion penalty and other stuff and then seeing what ' s the performance . 
are those going to be parameters that are frozen nobody can change ? 
or 
uh i guess there is uh time during which people are going to make suggestions . 
oh but everybody ' s going to have to use the same values . 
after that . 
oh ! 
interesting . 
okay . 
yeah i guess . 
so these these this uh period during which people are going to make suggestions is to know whether it is actually biased towards any set of features or 
yeah so i certainly the thing that i would want to know about is whether we get really hurt uh on insertion penalty language model scaling sorts of things . 
using our features . 
yeah . 
yeah . 
yeah . 
uh in which case um hari or hynek will need to you know push the case more about about this . 
uhhuh . 
um 
and we may be able to revisit this idea about you know somehow modifying our features to work with 
yes in this case 
that ' s right . 
yeah . 
that ' s right . 
um some of that may be uh a last minute rush thing because if the if our features are changing 
yeah . 
uh 
uh but um 
yeah the other thing is that even though it ' s months away uh it ' s starting to seem to me now like november fifteenth is right around the corner . 
and um if they haven ' t decided things like this like what the parameters are going to be for this uh when deciding is not just somebody deciding i mean in fact there should be some understanding behind the uh deciding which means some experiments and and so forth it it it seems pretty tight to me . 
so what ' s the significance of november fifteenth ? 
that ' s when the evaluation is . 
okay . 
yeah . 
so yeah so i have to 
but you know they may even decide in the end to push it off . 
it wouldn ' t you know entirely surprise me . 
but uh due to other reasons like some people are going away i ' m i ' m hoping it ' s not pushed off for a a long while . 
that would be uh put us in an awkward position . 
but 
anyway . 
okay . 
great . 
yeah i think that ' ll be helpful . 
there ' s there ' s not anybody o g i currently who ' s who ' s uh working with this . 
and and 
is is this part of the evaluation just a small part ? 
or how important is this to the overall ? 
i i think it ' s it ' s um it depends how badly you do . 
i mean i think that it it is uh 
this is one of those things that will be debated afterwards ? 
yeah . 
well i mean it ' s it ' s conceptually it my impression again you guys correct me if i ' m wrong but my impression is that um they want it as a double check . 
that you haven ' t come across you haven ' t invented features which are actually going to do badly for a a significantly different task particularly one with larger vocabulary . 
huh . 
and um but it ' s not the main emphasis . 
i mean the truth is most of the applications they ' re looking at are pretty small vocabulary . 
huh . 
so it ' s it ' s a double check . 
so they ' ll probably assign it some sort of low weight . 
seems to me that if it ' s a double check they should give you a one or a zero . 
you passed the threshold or you didn ' t pass the threshold . 
and they shouldn ' t even care about what the score is . 
yeah . 
but i mean we ' ll we ' ll we ' ll see what they come up with . 
yeah . 
uh but in in the current thing for instance where you have this well matched moderately matched and and highly mismatched uh the emphasis is somewhat on the on the well matched but it ' s only a a marginal . 
right ? 
it ' s like forty thirty five twenty five or something like that . 
yeah . 
so you still if you were way way off on the highly mismatched it would have a big effect . 
uhhuh . 
and um it wouldn ' t surprise me if they did something like that with this . 
so again if you ' re if you get if it doesn ' t help you much uh for noisy versions of this of large vocabulary data then uh you know it may not hurt you that much . 
oh . 
but if it if you don ' t if it doesn ' t help you much at all um or put it another way if it helps some people a lot more than it helps other people uh if their strategies do then 
uhhuh . 
so is this uh 
uh guenter was putting a bunch of wall street journal data on our disks . 
that ' s it . 
so that ' s the data that we ' ll be running on ? 
yeah . 
i see . 
okay . 
yeah . 
so we have the data just not the recognizer . 
okay . 
so this test may take quite a while to run then judging by the amount of data that he was putting on . 
uh well there ' s training and test . 
right ? 
i i guess i ' m not sure . 
i just 
no i mean if it ' s like the other things there ' s there ' s data for training the h m ms and and data for testing it . 
so i wouldn ' t 
so it it ' s 
okay . 
so there ' s 
so training the recognizer . 
but um 
um 
but i think it ' s trained on clean and 
is it trained on clean and and test on 
the wall street ? 
yeah . 
apparently no . 
it ' s training on a range between ten and twenty d b i think and testing between five and fifteen . 
huh . 
yeah . 
that ' s what i got on 
okay . 
it ' s uh it ' s like a medium medium mismatch condition sort of . 
i see . 
yeah . 
and so the noise is there is a range of different noises also um which are selected randomly and added randomly uh to the files . 
and there are noises that are different from the noises used on t i digits . 
yeah . 
yeah i mean i wouldn ' t imagine that the amount of testing data was that huge . 
they probably put training uh almost certain they put training data there too . 
maybe not . 
so 
that ' s that . 
anybody have anything else ? 
uh one one last question on that . 
when did they estimate that they would have that system available for download ? 
um i guess i guess one some preliminary version is already there . 
oh so there ' s something you can download to just learn ? 
yeah it ' s already there . 
okay . 
yeah . 
good . 
but they ' re actually parallel y doing some modifications also i think . 
okay . 
so i guess the final system will be frozen by middle of like one more week maybe . 
oh well that ' s pretty soon . 
yeah that ' s just one more . 
is this their um s v m recognizer ? 
no it ' s just a straightforward h m m . 
oh okay . 
you know their their they have a lot of options in their recognizer and and the s v m is one of the things they ' ve done with it but it ' s not their more standard thing . 
uhhuh . 
for the most part it ' s it ' s gaussian mixtures . 
oh okay . 
oh okay . 
yeah . 
it ' s just a h m m gaussian mixture model . 
gaussian mixture h m m . 
yeah . 
okay . 
yeah the s v m thing was an h m m also . 
it was just a it it it was like a hybrid like . 
yeah this is a 
uhhuh . 
yeah this 
yeah . 
what ? 
yeah . 
so just so that i understand they ' re providing scripts and everything so that basically uh you you push a button and it does training and then it does test and everything ? 
is that the idea ? 
i i i think yeah i i guess something like that . 
uhhuh . 
it ' s like as painless as possible . 
is what do they provide all the scripts everything and then just 
i see . 
huh . 
somehow there ' s hooks to put your features in and 
yeah i i think . 
huh . 
huh . 
yeah um 
in fact i mean if you look into it a little bit it might be reasonable 
you know joe . 
right ? 
uhhuh . 
yeah . 
just to sort of ask him about the issue of um different features having different kinds of uh scaling characteristics and so on . 
so that you know possibly having entirely different optimal values for for the usual twiddle factors . 
and what ' s what ' s the plan about that ? 
okay . 
so shall we like add chuck also to the mailing lists ? 
it may be better i mean in that case if he ' s going to 
yeah . 
because there ' s a mailing list for this . 
is that okay ? 
yeah . 
that ' d be great . 
yeah i guess maybe hari or hynek one of them has to send a mail to joe . 
or maybe if you 
i i could send him an e mail . 
well yeah to add or maybe 
i i know him really well . 
i mean i was just talking with him on e mail the other day actually . 
yeah so that ' s just fine . 
so 
so 
uh yeah and just um maybe see . 
about other things . 
but 
do you have hari ' s uh 
i have hari ' s . 
yeah so maybe just c c hari and say that you ' ve just been asked to handle the large vocabulary part here . 
okay . 
and uh you know and 
would it be better if i asked hari to ask joe ? 
uh 
why don ' t you just ask joe but c c hari and then in the note say hari hopefully this is okay with you ? 
okay . 
okay . 
and then if joe feels like he needs a confirmation hari can answer it . 
yeah . 
that way you can get started asking joe quickly while he ' s while he ' s maybe still you know putting in nails and screws and to it . 
so it ' s 
yeah . 
and there is an uh archive of all the mails that has been that has gone uh between these people among these people . 
so just you can see all this mails in the i s i p web site . 
okay . 
okay . 
mississippi web site . 
is that a password controlled 
yeah it ' s password protected . 
okay . 
so like like it ' s like 
have you thought about how long would be uh most useful for you to go up to o g i ? 
i don ' t know . 
uh 
we can for september we can set up a work schedule and we can maybe work independently . 
and then at some point it maybe be better to work together again . 
oh so you ' re you ' re imagining more that you would come back here first for a while and then and then go up there ? 
i 
i mean it ' s to you . 
maybe yeah . 
i you guys are 
well anyway you don ' t have to decide this second but think about it about what what you would think would be the the best way to work it i ' ll . 
but uh huh 
uhhuh . 
i ' ll support it either way so . 
uhhuh . 
right . 
okay ? 
uh 
got anything to tell us ? 
um 
well i ' ve been reading some literature about clustering of data . 
just um i guess let me put it in context . 
okay so we ' re talking about discovering intermediate categories to um to classify . 
and uh i was looking at some of the work that uh sangita was doing on these traps things . 
so she has um she has temporal patterns for um a certain set of phonemes from from timit . 
right ? 
the most common phonemes . 
and each one of them has has a a nice pattern over time a one one second window . 
and it has has these patterns . 
um so she has um a trap for each one of the phonemes um times fifteen for each of the fifteen critical bands . 
and um she does this agglomerative hierarchical clustering which which basically um is a clustering algorithm that uh starts with many many many different points many different clusters uh corresponding to the number of data uh patterns that you have in the data . 
and then you have this distance metric which uh measures how how closely related they are . 
and you start um by merging the patterns that are most closely related . 
and you create a tree . 
and you 
yeah yeah . 
a dendrogram tree . 
uhhuh . 
um 
and then you can pick uh values anywhere along that tree to fix your set of clusters ? 
right usually it ' s when um when the similarity measures um don ' t go down as much . 
uhhuh . 
and so uh so you stop at that point . 
and what she found was um was that there were five broad um broad categories uh corresponding to uh things like uh fricatives and uh vocalic um and uh stops . 
uhhuh . 
and uh one for silence and and another one for schwa schwa sounds . 
um and um i was thinking about ways to to generalize this . 
because you ' re it ' s sort of like a it ' s not a completely automatic way of clustering . 
because beforehand you have these these traps and you ' re saying that that these frames correspond to this particular phoneme . 
um and that ' s that ' s constraining your your clustering to to the set of phonemes that you already have . 
um whereas maybe we want to just take take a look at um arbitrary windows in time um of varying length um and cluster those . 
uhhuh . 
uhhuh . 
and i ' m thinking if we if we do that then we would probably um at some point in the clustering algorithm find that we ' ve clustered things like okay this is a transition um this is a relatively stable stable point . 
um and i ' m hoping to find other things of of similarity and maybe use these things as the intermediate um intermediate categories that uh um i ' ll later classify . 
are you looking at these in narrow bands ? 
uhhuh . 
um right . 
um i ' m 
because that ' s what you ' re going to be using . 
right ? 
yeah . 
yeah . 
i i haven ' t exactly figured out um the exact details for that . 
but uh the the representation of the data that i was thinking of was using um critical band um energies um over different lengths of time . 
so 
yeah . 
yeah i mean it seems somehow that needs uh there ' s a couple things that i wonder about with this . 
okay . 
i mean so one is is again looking at the same representation . 
i mean if you ' re going for this sort of thing where you have uh little detectors that are looking at narrow bands then what you ' re going to be looking for should be some category that you can find with the narrow bands . 
uhhuh . 
that that seems to be kind of fundamental to it . 
right . 
um and then the other thing uh is that i wonder about with it and and don ' t take this in the wrong way like i i know what i ' m doing or anything . 
but i mean um just wondering really . 
uhhuh . 
um the sort of standard answer about this sort of thing is that if you ' re trying to find the right system in some sense whether you ' re trying by categories or or parameters um and your goal is discrimination then having choices based on discrimination as opposed to um unsupervised nearness of things um is actually better . 
huh . 
um and i don ' t know if that i mean since you ' re dealing with issues of robustness you know maybe maybe this isn ' t right but it ' d be something i ' d be concerned about . 
because for instance you can imagine uh uh if you remember from from uh from your your quals john ohala saying that uh buh and puh differed uh not really because of voicing but because of aspiration ? 
uhhuh . 
i mean in as far as what ' s really there in the acoustics . 
so um if you looked if you were doing some coarse clustering you probably would put those two sounds together . 
and yet i would i would guess that many of your recognition errors were coming from uh um pfft screwing up on this distinction . 
uhhuh . 
so in fact it ' s a little hard because recognizers to first order sort of work . 
and the reasons we ' re doing the things we ' re doing is because they don ' t work as well as we ' d like . 
and since they sort of work uh it means that they are already doing 
if you go and take any recognizer that ' s already out there and you say how well is it distinguishing between schwas and stops . 
uhhuh . 
boy i bet they ' re all doing nearly perfectly on this . 
uhhuh . 
right ? 
so these these big categories that differ in huge obvious ways we already know how to do . 
so what are we bringing to the party ? 
i mean in fact what we want to do is have something that particularly in the presence of noise uh is better at distinguishing between uh categories that are actually close to one another and hence would probably be clustered together . 
huh . 
so that ' s that ' s the hard thing . 
i mean i understand that there ' s this other constraint that you ' re considering is that you want to have categories that uh that would be straightforward for say a human being to mark if you had manual annotation . 
and it ' s something that you really think you can pick up . 
but i think it ' s also essential that you want to look at what are the confusions that you ' re making and how can you come up with uh categories that uh can clarify these confusions . 
uhhuh . 
huh . 
so i mean the standard sort of way of doing that is take a look at the algorithms you ' re looking at but then throw in some discriminative aspect to it . 
this is more like you know how does l d a differ from p c a . 
i mean they ' re the same sort of thing . 
right . 
they ' re both orthogonalizing . 
but you know 
and and um this is a little harder because you ' re not just trying to find parameters you ' re actually trying to find the the the the categories themselves . 
uh so a little more like brain surgery i think . 
on yourself . 
uh 
yeah . 
so uh 
um 
anyway that ' s my thought . 
okay . 
you ' ve been thinking about this problem for a long time actually . 
i mean well actually you stopped thinking about it for a long time but you used to think about it a lot . 
yeah . 
and you ' ve been thinking about it more now . 
yeah . 
yeah . 
these categories . 
i guess 
uhhuh . 
i don ' t i don ' t um it ' s not clear to me how to reconcile you know what you ' re saying which i think is right with the way i ' ve been looking at it . 
that it ' s it ' s it ' s all not very clear to me . 
but it seems to me that the desire the desirable feature to have is something that um is bottom up . 
you know however we do that . 
uhhuh . 
and and so i guess what i don ' t understand is how to do that and still be discriminative . 
because to be discriminative you have to have categories and the only categories that we know of to use are sort of these human human significant categories that are significant to humans like phonemes things like that . 
right . 
but that ' s sort of what you want to avoid . 
and so that feels i don ' t know how to get out of this . 
well here ' s a here ' s a uh uh here ' s a generic and possibly useless thought which is um what do you really i mean in a sense the only systems that make sense uh are ones that that have something from top down in in them . 
right ? 
because if even the smallest organism that ' s trying to learn to do anything if it doesn ' t have any kind of reward for doing or penalty for doing anything then it ' s just going to behave randomly . 
uhhuh . 
so whether you ' re talking about something being learned through evolution or being learned through experience it ' s got to have something come down to it that gives its reward or you know at least some reinforcement learning . 
right . 
so the question is how far down . 
right ? 
and 
we could stop at words but we don ' t . 
right ? 
we go all the way down to phonemes . 
right but i i i think that maybe in some ways part of the difficulty is is trying to deal with the with these phonemes . 
uhhuh . 
you know and and and it ' s almost like you want categories if if our if our uh um metric of of goodness uh if our 
correction if our metric of badness is word error rate then um maybe we should be looking at words . 
uhhuh . 
i mean for for for very nice uh reasons we ' ve looked for a while at syllables and they have a lot of good properties . 
but if you go all the way to words i mean that ' s really i mean in many applications you want to go further . 
you want to go to concepts or something or have have have concepts actions this sort of thing . 
yeah . 
but words would be a nice 
but 
words aren ' t bad yeah . 
and and 
yeah so the common right the common wisdom is you can ' t do words because there ' s too many of them . 
right ? 
so you have to have some smaller set that you can use . 
uh and and so everybody goes to phonemes . 
but the problem is that we we build models of words in terms of phonemes and these models are are really cartoon - ish . 
right ? 
so when you look at conversational speech for example you don ' t see the phonemes that you that you have in your word models . 
yeah . 
but but but we ' re not trying for models of words here . 
see so here ' s maybe where 
if the issue is that we ' re trying to come up with um some sort of intermediate categories which will then be useful for later stuff uh then maybe it doesn ' t matter that we can ' t have enough 
uhhuh . 
uhhuh . 
i mean what you want to do is is build up these categories that are that are best for word recognition . 
right . 
right . 
and and somehow if that ' s built into the loop of what the categories 
i mean we do this every day in this very gross way of of running a thousand experiments . 
oh . 
right . 
because we have fast computers and picking the thing that has the best word error rate . 
yeah . 
in some way i mean we derive that all the time . 
in some ways it ' s really not a bad bad thing to do . 
because it tells you in fact how your adjustments at the very low level affect the the final goal . 
uhhuh . 
uhhuh . 
um so maybe there ' s a way to even put that in in a much more automatic way . 
right . 
where you take you know something about the error at the level of the word or some other it could be syllable but in some large unit . 
uhhuh . 
uh and uh yeah you may not have word models you have phone models whatever . 
but you sort of don ' t worry about that and just somehow feed it back through . 
uhhuh . 
you know so that ' s uh what i called a useless comments because i ' m not really telling you how to do it . 
but i mean it ' s a it ' s it ' s you know it 
no but i think the important part in there is that you know if you want to be discriminative you have to have uh you know categories . 
right . 
and i think this the important categories are the words and not the phones . 
yeah . 
yeah . 
maybe . 
and so 
right . 
if you can put the words in to the loop somehow for determining goodness of your sets of clusters uh 
now that being said i think that that if you have something that is um 
once you start dealing with spontaneous speech all the things you ' re saying are are really true . 
uhhuh . 
if you have read speech that ' s been manually annotated like timit then you know the phones are going to be right actually for the most part . 
yeah . 
yeah . 
yeah . 
so so uh it doesn ' t really hurt them to to do that to put in discrimination at that level . 
um if you go to spontaneous speech then it ' s it ' s trickier . 
and and and uh the phones are 
uh you know it ' s going to be based on bad pronunciation models that you have of 
right . 
huh . 
and um and it won ' t allow for the overlapping phenomenon . 
so it ' s almost like there ' s this mechanism that we have that you know when when we ' re hearing read speech and all the phonemes are there you know we we deal with that . 
but but when we go to conversational and then all of a sudden not all the phonemes are there it doesn ' t really matter that much to us as humans . 
because we have some kind of mechanism that allows for these word models whatever those models are to be munged you know . 
and and it doesn ' t really hurt . 
and 
i ' m not sure how how to build that in . 
uh 
yeah . 
i mean i guess the other thing is is to think of a little bit . 
i mean when when you start looking at these kind of results i think it usually is is pretty intuitive . 
but start looking at um what are the kinds of confusions that you do make uh you know between words if you want or or or uh even phones in in in in read speech say uh when there is noise . 
you know so is it more across place or more across manner . 
uhhuh . 
or is it you know is it 
i mean i know one thing that happens is that you you you uh you lose the um uh low energy phones . 
i mean if there ' s added noise then low energy phones sometimes don ' t get heard . 
and if that if that is if it uh if that turns it into another word or or different you know or another pair of words or something then it ' s more likely to happen . 
but um i don ' t know i i would i would guess that you ' d 
uhhuh . 
i don ' t know . 
anyway that ' s 
i think part of the difficulty is that a a lot of the robustness that we have is probably coming from a much higher level . 
you know we understand the context of the situation when we ' re having a conversation . 
uhhuh . 
and so if there ' s noise in there you know our brain fills in and imagines what what should be there . 
well that 
yeah we ' re we ' re doing some sort of prediction of what 
yeah exactly . 
oh sure that ' s really big . 
yeah . 
uh but i mean even if you do um uh diagnostic rhyme test kind of things you know where there really isn ' t any information like that uh people are still better in noise than they than they are in in uh uh than the machines are . 
huh . 
so i mean that ' s 
right we can ' t we can ' t get it at all without any language models . 
language models are there and important . 
but but uh 
uh 
if we ' re not working on that then we should work on something else and improve it . 
but especially if it looks like the potential is there . 
so 
should we do some digits ? 
yeah . 
since we ' re here . 
go ahead morgan . 
okay . 
uh 
let ' s get started . 
the uh 
should i go first with the uh um data ? 
can i have the remote control ? 
thank you . 
okay . 
so on friday we had our wizard test data test and um these are some of the results . 
this was the introduction . 
i actually uh even though liz was uh kind enough to offer to be the first subject i sort of felt that she knew too much . 
so i asked uh litonya just on the spur of the moment and she was uh kind enough to uh serve as the first subject . 
uhhuh . 
so this is what she saw as part of as uh for introduction . 
this is what she had to read aloud . 
uh that was really difficult for her . 
and uh 
because of all the names you mean ? 
the names and um 
this was the uh first three tasks she had to to master after she called the system . 
and um then of course the system broke down . 
and those were the uh uh 
i should say the system was supposed to break down and then um these were the remaining three tasks that she was going to solve with a human . 
um 
there are here are uh the results . 
huh . 
and i will not 
we will skip the reading now . 
um 
and um 
the reading was five minutes exactly . 
and now comes the 
this is the phone in phase of 
wait can i i have a question . 
so so there ' s no system . 
right ? 
like there was a wizard for both uh both parts . 
is this right ? 
yeah . 
it was it both times the same person . 
okay . 
one time pretending to be a system . 
one time to pretending to be a human which is actually not pretending . 
okay . 
and she didn ' t 
i should 
i mean 
well isn ' t this kind of obvious when it says okay now you ' re talking to a human and then the human has the same voice ? 
no no no . 
we wait . 
okay good question but uh 
you you just wait and see . 
it ' s you ' re going to learn . 
okay . 
and um the wizard sometimes will not be audible . 
because she was actually they there was some uh lapse in the um wireless . 
we have to move her closer . 
is she mispronouncing anlage ? 
is it anlaga or anlunga ? 
they ' re mispronouncing everything . 
but it ' s 
okay . 
this is the system breaking down actually . 
did i call europe ? 
so this is it . 
well if we we um 
so are are you trying to record this meeting ? 
there was a strange reflex . 
i have a headache . 
i ' m really sort of out of it . 
okay the uh lessons learned . 
the reading needs to be shorter . 
five minutes is just too long . 
um that was already anticipated by some people suggested that if we just have bullets here they ' re going to not they ' re subjects are probably not going to going to follow the order . 
and uh she did not . 
she 
really ? 
no . 
she she jumped around quite a bit . 
oh it ' s surprising . 
so if you just number them one two three it ' s 
yeah and make it sort of clear in the uh 
okay . 
right . 
um we need to so that ' s one thing . 
and we need a better introduction for the wizard . 
that is something that fey actually thought of a in the last second that the system should introduce itself when it ' s called . 
uhhuh . 
true . 
and um um another suggestion by liz was that we uh through subjects switch the tasks . 
so when when they have task one with the computer the next person should have task one with a human and so forth . 
uhhuh . 
so we get nice um data for that . 
um we have to refine the tasks more and more which of course we haven ' t done at all so far in order to avoid this rephrasing . 
so where even though we don ' t tell the person ask blah blah blah blah blah . 
they still try or at least litonya tried to um repeat as much of that text as possible . 
say exactly what ' s on there ? 
yeah . 
and uh my suggestion is of course we we keep the wizard because i think she did a wonderful job . 
great . 
in the sense that she responded quite nicely to things that were not asked for . 
how much is a a bus ticket and a transfer ? 
so this is going to happen all the time we you can never be sure . 
uhhuh . 
um johno pointed out that uh we have maybe a grammatical gender problem there with wizard . 
so um 
yes . 
i wasn ' t wasn ' t sure whether wizard was the correct term for uh not a man . 
but uh 
there ' s no female equivalent of 
are you sure ? 
no i don ' t know . 
not that i know of . 
right . 
well there is witch and warlock . 
and uh 
yeah that ' s what i was thinking but 
yeah that ' s so 
right . 
right . 
okay . 
uh 
and um 
so some some work needs to be done but i think we can uh 
and this and in case no you hadn ' t seen it this is what litonya looked at during the uh um while taking the while partaking in the data collection . 
uh . 
okay . 
great . 
so first of all i agree that um we should hire fey and start paying her . 
probably pay for the time she ' s put in as well . 
um do you know exactly how to do that ? 
or is uh lila 
i mean you know what exactly do we do to to put her on the payroll in some way ? 
i ' m completely clueless but i ' m willing to learn . 
okay . 
well you ' ll have to 
right . 
so anyway 
um 
so why don ' t you uh ask lila ? 
and see what she says about you know exactly what we do for someone in 
student type worker . 
or 
well yeah she ' s she ' s not a a student . 
she just graduated . 
but anyway 
huh . 
so if 
yeah i agree . 
she sounded fine . 
she actually was uh more uh present and stuff than than she was in conversation . 
so she did a better job than i would have guessed from just talking to her . 
yeah . 
so i think that ' s great . 
this is sort of what i gave her so this is for example how to get to the student prison . 
yeah . 
and i didn ' t even spell it out here . 
and in some cases i i spelled it out a little bit um more thoroughly . 
right . 
this is the information on on the low sunken castle and the amphitheater that never came up . 
and um so if we give her even more um instruments to work with i think the results are going to be even better . 
oh yeah . 
and then of course as she does it she ' ll she ' ll learn . 
so that ' s great . 
um and also if she ' s willing to take on the job of organizing all those subjects and stuff that would be wonderful . 
huh . 
and uh she ' s actually she ' s going to graduate school in a kind of an experimental paradigm . 
so i think this is all just fine in terms of her learning things she ' s going to need to know uh to do her career . 
huh . 
so i my guess is she ' ll be quite happy to take on that job . 
and so 
yep . 
yeah she she didn ' t explicitly state that . 
so 
great . 
and um i told her that we going to um figure out a meeting time in the near future to refine the tasks and look for the potential sources to find people . 
she also agrees that you know if it ' s all just going to be students the data is going to be less valuable because of that . 
so 
well as i say there is this set of people next door it ' s not hard to 
we ' re already 
yeah . 
uh 
however we may run into a problem with a reading task there . 
and um we ' ll see . 
yeah . 
we could talk to the people who run it and um see if they have a way that they could easily uh tell people that there ' s a task pays ten bucks or something . 
uhhuh . 
yeah . 
but um you have to be comfortable reading relatively complicated stuff . 
and and there ' ll probably be self selection to some extent . 
huh . 
yep . 
uh so that ' s good . 
um now i signed us up for the wednesday slot and part of what we should do is this . 
okay . 
so 
my idea on that was uh partly we ' ll talk about system stuff for the computer scientists . 
but partly i did want it to get the linguists involved in some of this issue about what the task is and all um you know what the dialogue is and what ' s going on linguistically . 
because to the extent that we can get them contributing . 
that will be good . 
yep . 
so this issue about you know re formulating things . 
maybe we can get some of the linguists sufficiently interested that they ' ll help us with it . 
uh other linguists if you ' re a linguist . 
but in any case . 
yep . 
um the linguistics students and stuff . 
so my idea on on wednesday is partly to uh 
you i mean what you did today would is just fine . 
you just uh do this is what we did and here ' s the thing and here ' s some of the dialogue and and so forth . 
but then the other thing of course is we should um give the computer scientists some idea of of what ' s going on with the system design . 
and where we think the belief nets fit in . 
and where the pieces are and stuff like that . 
yep . 
is is this make sense to everybody ? 
yeah . 
so i don ' t i don ' t think it ' s worth a lot of work particularly on your part to to to make a big presentation . 
i don ' t think you should 
you don ' t have to make any new uh powerpoint or anything . 
i think we got plenty of stuff to talk about . 
and then um just see how a discussion goes . 
uhhuh . 
sounds good . 
the uh other two things is um 
we ' ve can have johno tell us a little about this . 
great . 
and we also have a little bit on the interface . 
m three l enhancement . 
and then um that was it i think . 
so what i did for this this is uh a pedagogical belief net . 
because i was i i took i tried to conceptually do what you were talking about with the nodes that you could expand out . 
so what i did was i took 
i made these dummy nodes called trajector - in and trajector - out that would isolate the things related to the trajector . 
yep . 
and then there were the things with the source and the path and the goal . 
yep . 
and i separated them out . 
and then i um did similar things for our our net to uh with the context and the discourse and whatnot . 
um so we could sort of isolate them or whatever in terms of the the top layer . 
uhhuh . 
and then the bottom layer is just the mode . 
so 
so let ' s let ' s 
yeah i don ' t understand it . 
let ' s go 
slide all the way up so we see what the the very bottom looks like . 
or is that it ? 
yeah there ' s just one more node and it says mode which is the decision between the 
yeah . 
okay great . 
all right . 
so 
so basically all i did was i took the last belief net . 
uhhuh . 
and i grouped things according to what how i thought they would fit in to uh image schemas that would be related . 
and the two that i came up with were trajector - landmark and then source path goal as initial ones . 
yep . 
uhhuh . 
and then i said well uh the trajector would be the person in this case probably . 
right . 
yep . 
um you know we have we have the concept of what their intention was whether they were trying to tour or do business or whatever . 
right . 
or they were hurried . 
that ' s kind of related to that . 
and then um in terms of the source the things uh the only things that we had on there i believe were whether 
oh actually i kind of i might have added these because i don ' t think we talked too much about the source in the old one . 
but uh whether the where i ' m currently at is a landmark might have a bearing on whether 
uhhuh . 
or the landmark - iness of where i ' m currently at . 
and usefulness is basically means is that an institutional facility like a town hall or something like that that ' s not something that you ' d visit for tourist ' s tourism ' s sake or whatever . 
travel constraints would be something like you know maybe they said they can they only want to take a bus or something like that . 
right ? 
and then those are somewhat related to the path . 
uhhuh . 
so that would determine whether we ' d could take we would be telling them to go to the bus stop or versus walking there directly . 
um goal . 
similar things as the source except they also added whether the entity was closed . 
and whether they have somehow marked that is was the final destination . 
um and then if you go up 
robert . 
yeah so um in terms of context what we had currently said was whether they were a businessman or a tourist of some other person . 
um discourse was related to whether they had asked about open hours . 
or whether they asked about where the entrance was or the admission fee or something along those lines . 
uhhuh . 
uh prosody i don ' t really i ' m not really sure what prosody means in this context . 
so i just made up you know whether whether what they say is or how they say it is is that . 
right okay . 
um the parse would be what verb they chose . 
and then maybe how they modified it in the sense of whether they said i need to get there quickly or whatever . 
uhhuh . 
and um in terms of world knowledge this would just basically be like opening and closing times of things the time of day it is and whatnot . 
what ' s tourbook ? 
tourbook 
that would be i don ' t know the landmark - iness of things . 
uhhuh . 
whether it ' s in the tourbook or not . 
ch - ch - ch - ch 
now . 
all right so i understand what ' s what you got . 
i don ' t yet understand how you would use it . 
so let me see if i can ask . 
a 
well this is not a working bayes - net . 
right . 
no i understand that . 
but but um 
so what 
let ' s slide back up again . 
and see 
start at the at the bottom . 
and 
oop - bo - doop - boop - boop . 
yeah . 
so you could imagine 
uh go ahead you were about to go up there and point to something . 
well i okay i just 
say what you were going to say . 
good do it . 
no no . 
okay . 
go do it . 
uh i i ' d no i was going to wait until 
oh okay . 
so so if you if we made if we wanted to make it into a a real uh bayes - net . 
that is you know with fill 
you know actually uh fill it in then uh 
so we ' d have to get rid of this and connect these things directly to the mode . 
well i don ' t 
that ' s an issue . 
so um 
because i don ' t understand how it would work otherwise . 
well here ' s the problem . 
and and uh bhaskara and i was talking about this a little earlier today . 
is if we just do this we could wind up with a huge uh combinatoric input to the mode thing . 
and uh 
well i oh yeah i i understand that . 
i just uh it ' s hard for me to imagine how he could get around that . 
well but that ' s what we have to do . 
okay . 
okay so so 
uh 
there there are a variety of ways of doing it . 
uh let me just mention something that i don ' t want to pursue today . 
which is there are technical ways of doing it . 
uh i slipped a paper to bhaskara and about noisy - or ' s and noisy - maxes . 
and 
there ' re ways to uh sort of back off on the purity of your bayes - net - edness . 
huh . 
uh so if you you could and 
now i don ' t know that any of those actually apply in this case . 
but there is some technology you could try to apply . 
so it ' s possible that we could do something like a summary node of some sort that 
yeah . 
okay . 
yeah . 
and um 
so 
so in that case the we ' d have we 
i mean these wouldn ' t be the summary nodes . 
we ' d have the summary nodes like 
where the things were i guess maybe if if things were related to business or some other 
yeah . 
so what i was going to say is is maybe a good at this point is to try to informally 
yeah . 
i mean not necessarily in in this meeting but to try to informally think about what the decision variables are . 
so if you have some bottom line uh decision about which mode . 
you know what are the most relevant things . 
huh . 
and the other trick which is not a technical trick it ' s kind of a knowledge engineering trick is to make the each node sufficiently narrow that you don ' t get this combinatorics . 
so that if you decided that you could characterize the decision as a tradeoff between three factors whatever they may be . 
okay ? 
then you could say aha let ' s have these three factors . 
okay ? 
and maybe a binary version for each or some relatively compact decision node just above the final one . 
huh . 
and then the question would be if if those are the things that you care about uh can you make a relatively compact way of getting from the various inputs to the things you care about . 
so that so that you know you can sort of try to do a knowledge engineering thing . 
okay . 
given that we ' re not going to screw with the technology and just always use uh sort of orthodox bayes nets then we have a knowledge engineering little problem of how do we do that . 
um 
and 
so what i kind of need to do is to take this one and the old one and merge them together ? 
uh uh uh 
yeah . 
so that 
well huh something . 
i mean so uh robert has thought about this problem for a long time because he ' s had these examples kicking around . 
so he may have some good intuition about you know what are the crucial things . 
huh . 
and um i understand where this the uh 
this is a way of playing with this source path goal trajector uh uh abstraction and and sort of displaying it in a particular way . 
yeah . 
uh i don ' t think our friends uh on wednesday are going to be able to 
well maybe they will . 
well let me think about whether whether i think we can present this to them or not . 
um 
uh 
well i think this is still i mean ad hoc . 
this is sort of the second version and i i i look at this maybe just as a you know a a whatever u m l diagram or you know as just a uh screen shot not really as a bayes net as john johno said . 
we could actually yeah draw it in a different way in the sense that it would make it more abstract . 
yeah . 
but the uh the the nice thing is that you know it just is a is a visual aid for thinking about these things which has clearly have to be specified more carefully . 
and uh 
all right well let me think about this some more . 
and uh see if we can find a way to present this to this linguists group that that is helpful to them . 
i mean ultimately we we may 
we regard this as sort of an exercise in in thinking about the problem . 
and maybe a first version of uh a module if you want to call it that that you can ask 
that you can give input . 
and it ' ll uh throw the dice for you . 
uh throw the die for you . 
because um i integrated this into the existing smartkom system in in the same way as much the same way we can um sort of have this uh this thing . 
close this down . 
so if this is what m three l um will look like and what it ' ll give us . 
um 
and a very simple thing . 
we have an action that he wants to go from somewhere which is some type of object to someplace . 
uhhuh . 
and this these uh this changed now only um um 
it ' s doing it twice now because it already did it once . 
um we ' ll add some action type which in this case is approach and could be you know more refined uh in many ways . 
uhhuh . 
good . 
or we can uh have something where the uh goal is a public place . 
and it will give us then of course an action type of the type enter . 
so this is just based on this one um on this one feature . 
and that ' s that ' s about all you can do . 
and so in the 
if this if the object type um here is is a is a landmark of course it ' ll be um vista . 
and um this is about as much as we can do if we don ' t if we want to avoid uh uh a huge combinatorial explosion where we specify okay if it ' s this and this but that is not the case and so forth it just gets really really messy . 
okay i ' m sorry . 
you ' re you ' re 
huh ? 
it was much too quick for me . 
okay so let me see if i understand what you ' re saying . 
so i i do understand that uh you can take the m three l and add not and it 
and you need to do this for sure . 
we have to add you know not too much about um object types and stuff . 
and what i think you did is add some rules of the style that are already there that say if it ' s of type landmark then you take you ' re going to take a picture of it . 
exactly . 
full stop . 
i mean that ' s what you do . 
every landmark you take a picture of . 
every public place you enter and statue you want to go as near as possible . 
you enter . 
you approach . 
okay . 
uh and certainly you can add rules like that to the existing smartkom system . 
and you just did . 
right ? 
yeah . 
okay . 
and it it would do us no good . 
that . 
uh 
ultimately . 
well so well and let ' s think about this . 
um that ' s a that ' s another kind of baseline case . 
that ' s another sort of thing okay here ' s a another kind of minimal uh way of tackling this . 
add extra properties 
a deterministic rule for every property . 
you have an action pppt . 
you do that . 
um then the question would be 
uh now if that ' s all you ' re doing then you can get the types from the ontology . 
okay ? 
because that ' s all you ' re all you ' re using is this type the types in the ontology and you ' re done . 
huh ? 
right ? 
so we don ' t we don ' t use the discourse we don ' t use the context we don ' t do any of those things . 
no . 
all right but that ' s but that ' s okay and i mean it ' s again a kind of one minimal extension of the existing things . 
and that ' s something the uh smartkom people themselves would 
they ' d say sure that ' s no problem . 
you know no problem to add types to the 
right ? 
yeah . 
no . 
and 
this is just in order to exemplify what what we can do very very easily is um 
we have this this silly uh interface and we have the rules that are as banal as of we just saw and we have our content . 
now the content 
huh . 
i which is sort of what what we see here which is sort of the vista schema source path goal whatever . 
yeah . 
yeah . 
this will um be um a job to find ways of writing down image schema x schema constructions in some some form . 
and have this be in a in a in the content . 
loosely called constructicon . 
and the rules we want to throw away completely . 
and um and here is exactly where what ' s going to be replaced with our bayes net . 
which is exactly getting the input feeding into here . 
this decides whether it ' s whether action 
the the enter . 
the vista . 
or the whatever . 
uh approach you called it i think this time . 
uh approach um construction should be activated i e just pasted in . 
that ' s what you said . 
yeah that ' s fine . 
yeah but 
right . 
but it ' s not construction there it ' s action . 
construction is a is a different story . 
yeah . 
right . 
this is uh 
so what we ' d be generating would be a reference to a semantic uh like parameters for the for the x schema ? 
for for for 
yes . 
okay . 
yeah . 
so that that uh 
if you had the generalized go x schema . 
and you wanted to specialize it to these three ones then you would have to supply the parameters . 
right . 
and then uh although we haven ' t worried about this yet you might want to worry about something that would go to the g i s . 
and use that to actually get you know detailed route planning . 
so you know where do you do take a picture of it and stuff like that . 
uhhuh . 
but that ' s not it ' s not the immediate problem . 
right . 
but presumably that that that functionality ' s there when when we 
so the immediate problem is just deciding which 
aspects of the x schema to add . 
yeah so the the immediate problem is is back to what you were what you are doing with the belief net . 
yeah . 
you know uh what are we going to use to make this decision ? 
right and then once we ' ve made the decision how do we put that into the content ? 
yeah . 
right . 
right . 
well that that actually is relatively easy in this case . 
okay . 
the harder problem is we decide what we want to use how are we going to get it . 
and that the the that ' s the hardest problem . 
so the hardest problem is how are you going to get this information from some combination of the what the person says and the context and the ontology . 
the 
so i think that ' s the hardest problem at the moment is is 
okay . 
where are you going to 
how are you going to get this information . 
um 
and that ' s so getting back to here . 
uh we have a a technical problem with the belief nets that we we don ' t want all the 
there ' s just too many factors right now . 
too many factors if we if we allow them to just go combinatorially . 
right . 
so we want to think about which ones we really care about . 
and what they really most depend on . 
and can we you know clean this this up to the point where it 
so what we really want to do 
because this is really just the three layer net we want to make it expand it out into more layers basically ? 
right . 
we might . 
uh i mean that that ' s certainly one thing we can do . 
uh it ' s true that the way you have this a lot of the times you have 
what you ' re having is the values rather than the variable . 
so uh 
right . 
okay . 
so instead of instead it should really be just be intention as a node instead of intention business or intention tour . 
so you 
yeah . 
right . 
and then it would have values uh tour business or uh hurried . 
right . 
but then but it still some knowledge design to do about how do you want to break this up what really matters . 
right . 
i mean it ' s fine . 
you know we have to it ' s it ' s iterative . 
we ' re going to have to work with it some . 
i think what was going through my mind when i did it was someone could both have a business intention and a touring intention . 
and 
the probabilities of both of them happening at the same time 
well you you could do that . 
and it ' s perfectly okay to uh insist that that you know um they add up to one . 
but that there ' s uh that that it doesn ' t have to be one zero zero . 
huh . 
okay . 
okay ? 
so you could have the conditional 
so 
the each of these things is going to be a a a probability . 
so whenever there ' s a choice 
uh 
so like landmark ness and usefulness . 
well see i don ' t think those would be mutually 
okay ? 
it seems like something could both be 
absolutely right . 
okay . 
and so that you might want to then have those 
then they may have to be separate . 
they may not be able to be values of the same variable . 
object type . 
uhhuh . 
so that ' s 
but again this is this is the sort of knowledge design you have to go through . 
right . 
it ' s you know it ' s great is is you know as one step toward uh toward where we want to go . 
also it strikes me that we we may want to approach the point where we can sort of try to find a uh a specification for some interface here that um takes the normal m three l looks at it . 
then we discussed in our pre edu e d u meeting um how to ask the ontology what to ask the ontology . 
um the fact that we can pretend we have one make a dummy until we get the real one . 
and so um we we may want to decide we can do this from here . 
but we also could do it um you know if we have a a a belief net interface . 
so the belief net takes as input a vector . 
right ? 
of stuff . 
and it 
yeah . 
and um it output is whatever as well . 
but this information is just m three l . 
and then we want to look up some more stuff in the ontology . 
and we want to look up some more stuff in the 
maybe we want to ask the real world . 
maybe you want to look something up in the g r s . 
but also we definitely want to look up in the dialogue history um some some stuff . 
based on 
we we have uh 
i was just made some examples from the ontology . 
and so we have for example some information there that the town hall is both a a a building and it has doors and stuff like this . 
but it is also an institution so it has a mayor and so forth and so forth . 
and we get relations out of it and once we have them we can use that information to look in the dialogue history . 
were any of these things that that are part of the town hall as an institution mentioned ? 
uhhuh . 
were any of these that make the town hall a building mentioned ? 
right . 
and so forth . 
and maybe draw some inferences on that . 
so this may be a a sort of a process of two to three steps before we get our vector that we feed into the belief net . 
and then 
yeah . 
i think that ' s i think that ' s exactly right . 
there will be rules but they aren ' t rules that come to final decisions they ' re rules that gather information for a decision process . 
yeah . 
yeah . 
no i think that ' s that ' s just fine . 
uh yeah . 
so they ' ll they presumably there ' ll be a thread or process or something that 
agent yeah agent whatever you want to say yeah . 
that uh is rule driven and can can uh can do things like that . 
and um there ' s an issue about whether there will be that ' ll be the same agent and the one that then goes off and uh carries out the decision . 
so it probably will . 
my guess is it ' ll be the same basic agent that um can go off and get information run it through a a this belief net that 
turn a crank in the belief net . 
that ' ll come out with uh more another vector . 
okay . 
which can then be uh applied at what we would call the simulation or action end . 
so you now know what you ' re going to do . 
and that may actually involve getting more information . 
so once you pull that out it could be that that says uh . 
now that we know that we going to go ask the ontology something else . 
okay ? 
now that we know that it ' s a bus trip . 
okay ? 
we didn ' t we didn ' t need to know beforehand uh how long the bus trip takes or whatever but but now that we know that ' s the way it ' s coming out then we got to go find out more . 
uhhuh . 
so i think that ' s okay . 
uhhuh . 
so this is actually if if we were to build something that is um 
and uh i had one more thing . 
the it needs to do 
yeah 
i think we i i can come up with a a code for a module that we call the cognitive dispatcher which does nothing . 
okay . 
but it looks of complect object trees and decides how are there parts missing that need to be filled out . 
there ' s this is maybe something that this module can do something that this module can do . 
and then collect uh sub objects and then recombine them and put them together . 
so maybe this is actually some some useful tool that we can use to rewrite it and uh get this part . 
oh okay . 
uh 
then 
yeah . 
i confess i ' m still not completely comfortable with the overall story . 
um 
this this is not a complaint this is a promise to do more work . 
so i ' m going to have to think about it some more . 
um in particular 
see what we ' d like to do and and this has been implicit in the discussion is to do this in such a way that you get a lot of reuse . 
so what you ' re trying to get out of this deep cognitive linguistics is the fact that if you know about source source paths and goals and nnn all this sort of stuff that a lot of this is the same for different tasks . 
and that uh there ' s there ' s some some important generalities that you ' re getting . 
so that you don ' t take each and every one of these tasks and have to redo it . 
and i don ' t yet see how that goes . 
all right . 
there ' re no primitives upon which uh 
what are the primitives and how do you break this 
yeah . 
so i i ' m just just there saying eee well you i know how to do any individual case . 
right ? 
but i don ' t yet 
see what ' s the really interesting question is can you use uh deep uh cognitive linguistics to get powerful generalizations . 
and 
yep . 
um 
maybe we 
should we add then the what ' s this domain ? 
i mean we have to . 
how do i get to x . 
then we also have the what ' s this domain where we get some slightly different 
right . 
could uh 
um johno actually does not allow us to call them intentions anymore . 
yeah . 
so he he dislikes the term . 
well i i don ' t like the term either so i have 
uh 
it uh 
but um i ' m sure the what ' s this questions also create some interesting x schema aspects . 
could be . 
so 
i ' m not a i ' m not particularly opposed to adding that or any other task . 
i mean eventually we ' re going to want a whole range of them . 
uhhuh . 
that ' s right . 
uh 
i ' m just saying that i ' m going to have to do some sort of first principles thinking about this . 
i just at the moment don ' t know . 
uhhuh . 
no . 
well no the bayes the bayes nets 
the bayes nets will be specific for each decision . 
but what i ' d like to be able to do is to have the way that you extract properties that will go into different bayes nets be the uh general . 
so that if you have sources you have trajectors and stuff like that . 
and there ' s a language for talking about trajectors . 
you shouldn ' t have to do that differently . 
for uh uh going to something than for circling it . 
for uh telling someone else how to go there . 
getting out of 
whatever it is . 
so that that the the decision processes are going to be different . 
what you ' d really like of course is the same thing you ' d always like which is that you have um a kind of intermediate representation which looks the same over a bunch of inputs and a bunch of outputs . 
so all sorts of different tasks and all sorts of different ways of expressing them use a lot of the same mechanism for pulling out what are the fundamental things going on . 
and that ' s that would be the really pretty result . 
and pushing it one step further when you get to construction grammar and stuff what you ' d like to be able to do is say you have this parser which is much fancier than the parser that comes with uh smartkom . 
that that actually uses constructions and is able to tell from this construction that there ' s uh something about the intent . 
you know the actual what people want to do or what they ' re referring to and stuff . 
independent of whether it about what is this or where is it or something that you could tell from the construction you could pull out deep semantic information which you ' re going to use in a general way . 
so that ' s the 
you might . 
you might . 
you might be able to to uh 
say that this this is the kind of construction in which the 
there ' s let ' s say there ' s a uh 
there the the the construction implies the there ' s a this thing is being viewed as a container . 
okay ? 
so just from this local construction you know that you ' re going to have to treat it as a container you might as well go off and get that information . 
and that may effect the way you process everything else . 
so if you say how do i get into the castle . 
okay ? 
then um 
or you know what is there in the castle or 
so there ' s all sorts of things you might ask that involve the castle as a container . 
and you ' d like to have this orthogonal so that anytime the castle ' s referred to as a container you crank up the appropriate stuff . 
independent of what the goal is and independent of what the surrounding language is . 
uhhuh . 
all right so that ' s that ' s the that ' s the thesis level . 
uhhuh . 
uh 
it ' s unfortunate also that english has sort of got rid of most of its spatial adverbs . 
because they ' re really fancy then in in for these kinds of analysis . 
but uh 
well you have prepositional phrases that 
yeah but they ' re they ' re easier for parsers . 
right . 
parsers can pick those up but but the with the spatial adverbs they have a tough time . 
because the the semantics are very complex in that . 
right . 
okay yeah . 
i had one more thing . 
i don ' t remember . 
i just forgot it again . 
no . 
oh yeah ! 
but an architecture like this would also enable us maybe to to throw this away and and replace it with something else or whatever . 
so that we have so that this is sort of the representational formats we ' re we ' re we ' re talking about that are independent of the problem . 
that generalize over those problems and are oh of a higher quality than any actual whatever um belief net or x that we may use for the decision making ultimately . 
should be decoupled yeah . 
okay . 
right . 
so are we going to be meeting here from now on ? 
i ' m i ' m happy to do that . 
we we had talked about it because you have the display and everything that seems fine . 
yeah um liz also asks whether we ' re going to have presentations every time . 
i don ' t think we will need to do that but it ' s 
right . 
so far i think it was nice as a visual aid for some things and and 
oh yeah ! 
no i i think it ' s worth it to to meet here to bring this and assume that something may come up that we want to look at . 
yeah . 
i mean why not . 
and um 
yeah that was my 
she was good . 
litonya was good . 
yeah ? 
the uh um she she was definitely good in the sense that she she showed us some of the weaknesses . 
right . 
and um also the um the fact that she was a real subject you know is is 
right . 
yeah and and and yeah and and she took it seriously and stuff . 
no it was great . 
yeah . 
yeah . 
so i think that um i mean 
looking just looking at this data listening to it what can we get out of it in terms of our problem . 
for example is you know she actually said you know she never just spoke about entering she just wanted to get someplace and she said for buying stuff . 
nuh ? 
so this is definitely interesting and 
yeah right . 
um and in the other case where she wanted to look at the stuff at the graffiti . 
also of course not in the sentence how do you get there was pretty standard . 
nuh ? 
except that there was a nice anaphora you know for pointing at what she talked about before . 
and there she was talking about looking at pictures that are painted inside a wall on walls . 
so 
right . 
actually you ' d need a lot of world knowledge . 
this would have been a classical um uh tango actually . 
um because graffiti is usually found on the outside and not on the inside . 
yeah . 
but 
okay . 
so the mistake would have make a mistake the system would have made a mistake here . 
yep . 
click . 
all right . 
so uh so the uh the new procedural change that just got suggested which i think is a good idea is that um we do the digit recordings at the end . 
and that way if we ' re recording somebody else ' s uh meeting and a number of the participants have to run off to some other meeting and don ' t have the time uh then they can run off . 
it ' ll mean we ' ll get somewhat fewer uh sets of digits . 
but um i think that way we ' ll cut into people ' s time um if someone ' s on strict time uh less . 
so i i think i think we should start doing that . 
um so uh let ' s see we were having a discussion the other day maybe we should bring that up about uh the nature of the data that we are collecting . 
uh that uh we should have a fair amount of data that is um collected for the same meeting so that we can 
uh 
i don ' t know . 
what what were some of the points again about that ? 
is it 
uh well okay i ' ll back up . 
um at the previous at last week ' s meeting this meeting i was griping about wanting to get more data . 
yeah . 
and i i talked about this with jane and adam . 
um and was thinking of this mostly just so that we could do research on this data um since we ' ll have a new this new student does want to work with us . 
the guy that was at the last meeting . 
well great . 
great . 
and he ' s already funded part time . 
so we ' ll only be paying him for sort of for half of the normal part time . 
what a deal . 
uh yeah . 
and what ' s he interested in specifically ? 
so 
he ' s comes from a signal processing background . 
but i liked him a lot . 
because he ' s very interested in higher level things like language and disfluencies and all kinds of maybe prosody . 
uhhuh . 
so he ' s just getting his feet wet in that . 
great . 
anyway i thought okay maybe we should have enough data so that if he starts he ' d be starting in january next semester that we ' d have you know enough data to work with . 
right . 
but um jane and adam brought up a lot of good points that just posting a note to berkeley people to have them come down here has some problems in that you you need to make sure that the speakers are who you want and that the meeting type is what you want and so forth . 
so i thought about that and i think it ' s still possible . 
um but i ' d rather try to get more regular meetings of types that we know about and hear then sort of a mish mosh of a bunch of one onetime . 
one offs . 
yeah just because it would be very hard to process the data in all senses . 
both to get the um to figure out what type of meeting it is and to do any kind of higher level work on it like well i was talking to morgan about . 
things like summarization or what ' s this meeting about . 
i mean it ' s very different if you have a group that ' s just giving a report on what they did that week versus coming to a decision and so forth . 
so then i was um talking to morgan about some new proposed work in this area sort of a separate issue from what the student would be working on where i was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns . 
like in numbers of overlaps and amount of speech . 
sort of raw cues from the interaction that can be measured from the signals and from the different microphones that point to sort of hot spots in the meeting or things where stuff is going on that might be important for someone who didn ' t attend to listen to . 
and in that uh regard i thought we definitely will need it ' d it ' d be nice for us to have a bunch of data from a few different domains or a few different kinds of meetings . 
so this this meeting is one of them . 
although i ' m not sure i can participate if i 
you know i would feel very strange being part of a meeting that you were then analyzing later for things like summarization . 
uhhuh . 
um and then there are some others that that morgan mentioned . 
like the front end meeting and maybe a networking group meeting . 
right . 
yep . 
yeah we ' re we ' re hoping that they ' ll let us start recording regularly . 
so so if that were the case then i think we ' d have enough . 
so 
uhhuh . 
but basically for anything where you ' re trying to get a summarization of some kind of meeting meaning out of the meeting um it would be too hard to have fifty different kinds of meetings where we didn ' t really have a good grasp on what does it mean to summarize . 
yeah . 
but rather we should have different meetings by the same group but hopefully that have different summaries . 
and then we need a couple that of we don ' t want to just have one group . 
because that might be specific to that particular group but three or four different kinds . 
so 
yeah we have a lot of overlap between this meeting and the morning meeting . 
see i ' ve never listened to the data for the front end meeting . 
yeah . 
yeah . 
yeah we we ' ve only had three . 
so 
okay . 
but maybe that ' s enough . 
so in general i was thinking more data . 
but also data where we hold some parameters constant or fairly similar . 
like a meeting about of people doing a certain kind of work where at least half the participants each time are the same . 
uhhuh . 
um 
now let let me just give you the other side to that . 
because i because i i don ' t disagree with that . 
but i think there is a complimentary piece to it too . 
uh for other kinds of research particularly the acoustic oriented research i actually feel the opposite need . 
i ' d like to have lots of different people . 
right . 
right . 
as many people here and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . 
i ' d like to have many different speakers . 
so um i think i would also very much like us to have a fair amount of really random scattered meetings of somebody coming down from campus and and uh 
uhhuh . 
i mean sure if we can get more from them fine . 
uhhuh . 
right . 
but if we only get one or two from each group that still could be useful acoustically just because we ' d have close and distant microphones with different people . 
yeah i definitely agree with that . 
yeah . 
uhhuh . 
definitely . 
yeah . 
can i can i say about that that the the issues that i think adam and i raised were more a matter of advertising so that you get more native speakers . 
because i think if you just say 
and in particular my suggestion was to advertise to linguistics grad students because there you ' d have people who ' d have proficiency enough in english that that uh it would be useful for for purposes you know . 
uhhuh . 
but you know i think i ' ve been i ' ve i i ' ve gathered data from undergrads at on campus . 
and if you just post randomly to undergrads i think you ' d get such a mixed bag that it would be hard to know how much conversation you ' d have at all and and the english you ' d have the language models would be really hard to build . 
well you want to 
because it would not really be it would be an interlanguage rather than than a 
well okay uh first place i i i don ' t think we ' d just want to have random people come down and talk to one another . 
okay . 
i think there should be a meeting that has some goal and point because i i think that ' s what we ' re investigating . 
it has to be a a pre - existing meeting like a meeting that would otherwise happen anyway . 
so 
yeah yeah . 
right . 
okay . 
so i was i was thinking more in terms of talking to professors uh and and and uh senior uh uh and uh doctoral students who are leading projects and offering to them that they have their hold their meeting down here . 
yep . 
that ' s i think what we and i agree with . 
oh interesting ! 
yeah . 
oh i see . 
oh interesting ! 
uh that ' s the first point . 
the second point is 
um 
i think that for some time now going back through berp i think that we have had speakers that we ' ve worked with who had non native accents and i i think that 
oh oh i ' m not saying accents . 
the accent ' s not the problem . 
oh okay . 
no it ' s more a matter of uh proficiency . 
just simply fluency . 
i mean i deal with people on on campus who i think sometimes people undergraduates um in computer science uh have language skills that make you know that their their fluency and writing skills are not so strong . 
yeah . 
oh ! 
you ' re not talking about foreign language at all . 
yeah yeah just talking about . 
you ' re just talking about 
well i just think 
we all had the same thought . 
but you know it ' s like when you get into the graduate level uh no problem . 
i mean i ' m not saying accents . 
uhhuh . 
yeah then we ' re completely gone . 
i ' m i ' m saying fluency . 
it ' s the the habits are already burnt in . 
uhhuh . 
well yeah . 
i ' m just saying fluency . 
but 
well i think that um i think that the only thing we should say in the advertisement is that the meeting should be held in english . 
yeah . 
and and i think if it ' s a pre existing meeting and it ' s held in english i i think it ' s probably okay if a few of the people don ' t have uh particularly good english skills . 
okay now can i can i say the other aspect of this from my perspective . 
which is that um there ' s there ' s this this issue you have a corpus out there it should be used for for multiple things . 
because it ' s so expensive to put together . 
right . 
right . 
and if people want to approach 
um 
i so i know you know this 
the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group . 
uhhuh . 
but the idea of language models which are you know generally speaking uh you know terms of like the amount of benefit per dollar spent or an hour invested in preparing the data . 
uhhuh . 
uhhuh . 
if you have a choice between people who are more proficient in um more fluent more more close to being academic english then it would seem to me to be a good thing . 
i guess maybe 
huh . 
because otherwise you don ' t have the ability to have 
uh so if if you have a bunch of idiolects that ' s the worst possible case . 
if you have people who are using english as a as an interlanguage because they they don ' t uh they can ' t speak in their native languages and but their interlanguage isn ' t really a match to any existing uh language model . 
uhhuh . 
this is the worst case scenario . 
yeah . 
yeah . 
well that ' s pretty much what you ' re going to have in the networking group . 
and 
right . 
because because they most the network group is almost entirely germans and spaniards . 
well 
oh . 
but the thing is i think that these people are of high enough level in their in their language proficiency that 
i see . 
and i ' m not objecting to accents . 
i i ' m i ' m just thinking that we have to think at a at a higher level view could we have a language model a a grammar a grammar basically that um would be a a possibility . 
okay . 
uhhuh . 
so so if you wanted to bring in a model like dan jurafsky ' s model and do some top down stuff it to help the bottom up and merge the things or whatever uh it seems like um i don ' t see that there ' s an argument . 
uhhuh . 
i ' m i what i think is that why not have the corpus since it ' s so expensive to put together uh useful for the widest range of of central things that people generally use corpora for and which are you know used in computational linguistics . 
uhhuh . 
that ' s that ' s my point which which includes both top down and bottom up . 
okay . 
it ' s difficult . 
yeah . 
okay well let ' s let ' s see what we can get . 
i mean it it i think that if we ' re aiming at at uh groups of graduate students and professors and so forth who are talking about things together and it ' s from the berkeley campus probably most of it will be okay . 
yes that ' s fine . 
that ' s fine . 
exactly . 
and my point in in my note to liz was i think that undergrads are an iffy population . 
but 
okay . 
i definitely agree with that i mean for this purpose . 
okay . 
okay . 
grads and professors fine . 
yeah . 
well not to mention the fact that i would be hesitant certainly to take anyone under eighteen probably even anyone under twenty one . 
yeah . 
so 
oh you age - ist ! 
what ' s that ? 
age - ist . 
well age - ist the eighteen is because of the consent form . 
right yeah . 
yeah . 
we ' d have to get find their parent to sign for them . 
age - ist . 
yeah yeah . 
yes . 
yeah that ' s true . 
so 
i have a uh um question . 
well morgan you were mentioning that mari may not use the equipment from i b m if they found something else because there ' s a 
they ' re they ' re yeah they ' re they ' re uh assessing whether they should do that or do something else hopefully over the next few weeks . 
because i mean one remote possibility is that if we if we inherited that equipment if she weren ' t using it could we set up a room in the linguistics department ? 
and and i mean there there may be a lot more or or in psych or in wherever in another building where we could um record people there . 
i think we ' d have a better chance . 
i think we ' d need a real motivated partner to do that . 
right . 
we ' d need to find someone on campus who was interested in this . 
but 
right . 
but if there were such a 
i mean it ' s a remote possibility then um you know one of us could you know go up there and record the meeting or something rather than bring all of them down here . 
yep . 
so it ' s just a just a thought if they end up not using the the hardware . 
well the other thing yeah i mean the other thing that i was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around . 
right . 
uh . 
but um and 
well i know that space is really scarce on at least in c s . 
uh . 
you know to to actually find a room that we could use regularly might actually be very difficult . 
yeah . 
but you may not need a separate room you know . 
that ' s true . 
the idea is if they have a meeting room and they can guarantee that the equipment will be safe and so forth and if one of us is up there once a week to record the meeting or something . 
yeah . 
true . 
uhhuh . 
yep . 
well maybe john would let us put it into the phonology lab or something . 
huh . 
yep . 
you know . 
i i think it ' s not out of the question . 
yeah . 
yeah i think it would be interesting because then we could regularly get another meeting . 
um . 
so 
yeah . 
another type of meeting . 
right . 
right . 
but i i i think you need uh another portable thing another portable equipment to to do uh more easier the recording process uh out from icsi . 
huh . 
yeah . 
uh and probably i don ' t know . 
yeah . 
right . 
uh if you you want to to record uh a seminar or a class uh in the university you you need it it would be uh uh very difficult to to put uh a lot of uh head phones uh in different people when you have to to record only with uh this kind of uh device . 
yeah . 
yeah but 
i think if we if we want to just record with the tabletop microphones that ' s easy . 
yeah . 
yeah yeah . 
right ? 
that ' s very easy . 
but that ' s not the corpus that we ' re collecting . 
yeah . 
actually that ' s a that raises an interesting point that came up in our discussion that ' s maybe worth repeating . 
we realized that um when we were talking about this that okay there ' s these different things that we want to do with it . 
so um it ' s true that we want to be selective in some ways uh the way that you were speaking about with uh not having an interlingua and uh these other issues . 
but on the other hand it ' s not necessarily true that we need all of the corpus to satisfy all of it . 
so as per the example that we want to have a fair amount that ' s done with a small recorded with a small uh number of types of meetings . 
but we can also have another part that ' s uh just one or two meetings of each of a of a range of them . 
and that ' s okay too . 
uh we realized in discussion that the other thing is what about this business of distant and close microphones . 
i mean we really want to have a substantial amount recorded this way . 
that ' s why we did it . 
but what about for for these issues of summarization a lot of these higher level things you don ' t really need the distant microphone . 
right . 
i mean i i think there ' s 
you actually don ' t . 
and you don ' t really need the close microphone you mean . 
yeah . 
yeah yeah you actually don ' t really even need any fancy microphone . 
which one did you mean ? 
you you don ' t it doesn ' t you just need some microphone somewhere . 
you can use found data . 
yeah yep . 
yeah . 
tape recorder . 
oh . 
yeah . 
yeah . 
you you can . 
you need some microphone . 
you can . 
use um but i think that any data that we spend a lot of effort to collect 
but i mean 
uhhuh . 
yeah . 
you know each person who ' s interested in i mean we have a we have a bunch of different um slants and perspectives on what it ' s useful for um they need to be taking charge of making sure they ' re getting enough of the kind of data that they want . 
right . 
and so in my case um i think there there is enough data for some kinds of projects and not enough for others . 
not enough for others right . 
and so i ' m looking and thinking well i ' d be glad to walk over and record people and so forth if it ' s to help in my interest . 
uhhuh . 
and other people need to do that for themselves uh or at least discuss it so that we can find some optimal . 
right so that 
yeah . 
but i think that i ' m raising that because i think it ' s relevant exactly for this idea up there that if you think about well gee we have this really complicated setup to do well maybe you don ' t . 
maybe if if if really all you want is to have a a a recording that ' s good enough to get a uh a transcription from later you just need to grab a tape recorder and go up and make a recording . 
yeah . 
for some of it . 
right . 
yep . 
i mean we we could have a fairly we could just get a dat machine and 
well i agree with jane though on the other hand that 
yeah . 
so that might be true you may say for instance summarization or something that sounds very language oriented . 
you may say well oh yeah you just do that from transcripts of a radio show . 
i mean you don ' t even need the speech signal . 
right . 
but what you what i was thinking is long term what would be neat is to be able to pick up on um 
suppose you just had a distant microphone there and you really wanted to be able to determine this . 
there ' s lots of cues you ' re not going to have . 
so i do think that long term you should always try to satisfy the greatest number of of interests and have this parallel information which is really what makes this corpus powerful . 
right . 
yeah . 
yeah . 
special ? 
yep . 
i i i i i agree . 
otherwise you know lots of other sites can propose individual studies so 
uh but i i think that the uh we can ' t really underestimate the difficulty shouldn ' t really underestimate the difficulty of getting a setup like this up . 
yep . 
and so uh it took quite a while to get that together and to say oh we ' ll just do it up there . 
okay . 
if you ' re talking about something simple where you throw away a lot of these dimensions then you can do that right away . 
talking about something that has all of these different facets that we have here . 
it won ' t happen quickly it won ' t be easy and there ' s all sorts of issues about you know keeping the equipment safe or else hauling it around and all sorts of 
so then maybe we should try to bring people here . 
i think the first priority should be to pry to get try to get people to come here . 
here . 
i mean that ' s that ' s 
okay so . 
we ' re set up for it . 
uhhuh . 
okay . 
the room is is really uh underused . 
right . 
uh 
i thought the free lunch idea was a great idea . 
yeah i thought so too . 
yeah i and i think we can get people to come here that 
free lunch is good . 
yeah . 
but the issue is you definitely want to make sure that the kind of group you ' re getting is the right group . 
so that you don ' t waste a lot of your time and the overhead in bringing people down . 
uhhuh . 
no crunchy food . 
yeah . 
so well it would be lunch afterwards . 
yeah . 
well i was thinking lunch after . 
right . 
and they ' d have to do their digits or they don ' t get dessert . 
yeah they have to do their digits or they don ' t get they don ' t get their food . 
yep . 
yeah . 
yeah . 
um i had a i spoke with some people up at haas business school who volunteered . 
should i pursue that ? 
oh definitely yeah . 
yeah . 
yeah . 
so 
they they originally they ' ve decided not to do go into speech . 
so i ' m not sure whether they ' ll still be so willing to volunteer . 
but i ' ll send an email and ask . 
tell them about the free lunch . 
i ' ll tell them about the free lunch . 
yeah . 
yeah . 
and they ' ll say there ' s no such thing . 
so 
i ' d love to get people that are not linguists or engineers because these are both weird . 
right . 
yeah . 
yeah . 
the the the the other 
well i know i shouldn ' t say that . 
that ' s all right . 
no they they ' re very weird . 
we need a wider sampling . 
beep . 
uh 
yeah . 
beep . 
uh the the 
the problem with engineers is beep . 
they make funny sounds . 
the the the other the other thing is uh that we we talked about is give to them uh burn an extra c d rom . 
yep let them have their meeting . 
and give them so if they want a basically and audio record of their 
well i thought that was i thought he meant give them a music c d like they then he said a c d of the of their speech . 
oh . 
and i guess it depends of what kind of audience you ' re talking to . 
but you know i personally would not want a c d of my meeting . 
of the meeting . 
but maybe yeah maybe you ' re 
if you ' re having some planning meeting of some sort and uh you ' d like 
right right right . 
oh that ' s a good idea . 
it ' d be fun . 
yeah . 
i think it would just be fun you know if nothing else you know . 
right . 
yeah . 
but it it it it also i think builds up towards the goal . 
it ' s a novelty item . 
right . 
we ' re saying look you know you ' re going to get this . 
isn ' t that neat . 
then you ' re going to go home with it . 
it ' s actually it ' s probably going to be pretty useless to you . 
yep . 
but you ' ll appreciate you know where it ' s useful and where it ' s useless . 
right . 
and then we ' re going to move this technology so it ' ll become useful . 
no i think that ' s a great idea actually . 
so 
yeah . 
but we might need a little more to incentivize them that ' s all . 
what if you could tell them that you ' ll give them the the transcripts when they come back ? 
oh yeah . 
i mean anyone can have the transcripts so i thought we could point that out . 
oh yeah . 
yeah . 
well that ' s interesting . 
i i have to uh raise a little eensy weensy concern about doing giving them the c d immediately because of these issues of you know this kind of stuff where maybe you know . 
good point . 
so 
that ' s a very good point . 
we could burn it after it ' s been cleared with the transcript stage . 
so we can so we can 
right . 
and then they they get a c d but just not the same day . 
oh right . 
if it should be the same c d rom that we distribute publically . 
yeah that ' s right . 
that ' s a good point . 
right ? 
right it can ' t be the internal one . 
otherwise they ' re not allowed to play it for anyone . 
although it ' s 
there we go . 
oh i like that . 
that ' s right . 
well put well put . 
so after the transcript screening phase . 
yeah that ' s true . 
things have been weeded out . 
otherwise we ' d need two lawyer stages . 
yeah that ' s right say yeah well i got this c d and your honor i 
yeah . 
that ' s a good point . 
yeah so that ' s so let ' s start with haas and yeah . 
sorry to have to sorry i have to leave . 
i will be here full time next week . 
oh that ' s fine . 
okay see you . 
okay . 
no . 
bye . 
that ' s all right . 
see you . 
okay . 
see you . 
so uh let ' s see . 
so that was that topic . 
and then um i guess another topic would be where are we in the whole disk resources question . 
for 
we are slowly slowly getting to the point where we have uh enough room to record meetings . 
so i uh did a bunch of archiving and still doing a bunch of archiving . 
i i ' m in the midst of doing the p files from uh broadcast news . 
and it took eleven hours to do to uh copy it . 
eleven ? 
and it ' ll take another eleven to do the clone . 
where did you copy it to ? 
well it ' s abbott . 
it ' s abbott so it just but it ' s it ' s a lot of data . 
it ' s copying from one place on abbott to another place on abbott ? 
tape . 
tape ? 
i did an archive . 
oh ! 
i ' m sorry . 
oh on the tape . 
oh . 
uh . 
so i ' m archiving it and then i ' m going to delete the files . 
so that will give us ten gigabytes of free space . 
eleven hours ? 
wow ! 
oh . 
yeah the archiving program does take a long time . 
yeah . 
and and 
yep . 
and so that that will be done like in about two hours . 
and so uh at that point we ' ll be able to record five more meetings . 
so 
yeah . 
one thing the good news about that that is that once once it ' s archived it ' s pretty quick to get back . 
yeah . 
i mean it it it the other direction is fast but this direction is really slow . 
is it ? 
right . 
huh . 
yeah . 
well especially because i ' m generating a clone also . 
yeah okay . 
so and that takes a while . 
yeah . 
generating a clone ? 
yeah that ' s a good point . 
two copies . 
yeah . 
one offsite one onsite . 
oh . 
oh . 
huh . 
now what will uh is the plan to to so stuff will be saved it ' s just that you ' re relocating it ? 
i mean so we ' re going to get more disk space ? 
or did i 
no the the these are the p files from broadcast news which are regeneratable regeneratable . 
okay . 
oh good . 
i see . 
um if we really need to but we had a lot of them and for the full uh hundred forty hour sets . 
okay . 
and so they they were two gigabytes per file and we had six of them or something . 
wow ! 
yeah . 
wow ! 
we are getting more space . 
we are getting uh another disk rack and and four thirty six gigabyte disks . 
uh so uh but that ' s not going to happen instantaneously . 
wonderful . 
or maybe six . 
or maybe six ? 
the sun uh takes more disks than the andatico one did . 
how many ? 
the sun rack takes one took four and one took six or maybe it was eight and twelve whatever it was it was you know fifty per cent more . 
how much 
is there a difference in price or something ? 
well what happened is that we we bought all our racks and disks from andatico for years according to dave . 
and andatico got bought by another company and doubled their prices . 
oh ! 
oh . 
and so uh we ' re looking into other vendors . 
we by we of course i mean dave . 
wow . 
so 
uhhuh . 
huh i ' ve been looking at the uh aurora data and um first first look at it there were basically three directories on there that could be moved . 
one was called aurora one was spanish which was carmen ' s spanish stuff and the other one was um spine . 
spine . 
and so um i wrote to dan and he was very concerned that the spine stuff was moving to a non backed up disk . 
so um i realized that well probably not all of that should be moved just the c d rom type data the the static data . 
so i moved that and then um i asked him to check out and see if it was okay . 
before i actually deleted the old stuff um but i haven ' t heard back yet . 
i told him he could delete it if he wanted to i haven ' t checked today to see if he ' s deleted it or not . 
and then carmen ' s stuff i realized that when i had copied all of her stuff to x a i had copied stuff there that was dynamic data . 
and so i had to redo that one and just copy over the static data . 
and so i need to get with her now and delete the old stuff off the disk . 
and then i haven ' t done any of the aurora stuff . 
i have to meet with uh stephane to do that . 
so 
so but uh you ' re figuring you can record another five meetings or something with the space that you ' re clearing up from the broadcast news . 
but we have some other disks some of which you ' re using for aurora . 
but are we do we have some other other space now ? 
yep . 
so so uh we have space on the current disk right now where meeting recorder is . 
yeah . 
and that ' s probably enough for about four meetings . 
yeah . 
is that the one that has is that d c ? 
so 
yep . 
no no . 
well it ' s wherever the meeting recorder currently is . 
i think it ' s d i . 
okay . 
i but the stuff i ' m moving from aurora is on the d c disk that we 
i don ' t remember . 
i think it ' s d it ' s whatever that one is . 
okay d c . 
i just don ' t remember it might be d c . 
yeah . 
and that has enough for about four more meetings right now . 
uhhuh . 
yeah i mean we were at a hundred per cent and then we dropped down to eighty six for reasons i don ' t understand . 
um someone deleted something somewhere . 
and so we have some room again . 
and then with broadcast news that ' s five or six more meetings . 
so you know we have a couple weeks . 
uh so yeah i think i think we ' re okay until we get the new disk . 
okay . 
so should um one question i had for you was um we need we probably should move the aurora and all that other stuff off of the meeting recorder disk . 
is there another backed up disk that you know of that would 
we should put it onto the broadcast news one . 
that ' s probably the best thing to do and that way we consolidate meeting recorder onto one disk rather than spreading them out . 
okay . 
right . 
right . 
do you know what happen to know what disk that is off ? 
no . 
okay . 
i mean i can tell you i just don ' t know off the top of my head . 
yeah . 
okay . 
all right i ' ll find out from you . 
but so we could just do that at the end of today once the archive is complete and i ' ve verified it . 
okay . 
because that ' ll give us plenty of disk . 
uh okay so uh then i guess the last thing i ' d had on my my agenda was just to hear hear an update on what what jose has been doing . 
uhhuh . 
so 
okay . 
i have uh the result of my work during the last days . 
okay . 
thank you for your information because i i read uh and the the last uh days uh i work uh in my house uh in a lot of ways and thinking reading uh different things about the the meeting recording project . 
yeah . 
uhhuh . 
and i have uh some ideas . 
uh this information is very very useful . 
i ' m glad to hear it glad to hear it . 
you have the the the distribution now . 
but for me uh is interesting because uh uh here ' s is the demonstration of the overlap uh problem . 
i ' ve seen it already . 
it ' s a real problem a frequently problem uh because you have overlapping zones uh uh uh all the time . 
yeah . 
yeah . 
yep . 
yeah . 
throughout the meeting . 
uh by a moment i have uh nnn the uh i i did a mark of all the overlapped zones in the meeting recording . 
with uh a exact mark . 
uhhuh . 
oh you did that by hand ? 
that ' s uh yet yeah by by hand by hand because uh uh why . 
can i see that ? 
can i get a copy ? 
oh . 
my my idea is to work 
i i i i i don ' t i don ' t know uh if uh it will be possible because i i i haven ' t a lot uh enough time to to to work uh only just uh six months as you know . 
wow ! 
but uh my idea is uh is very interesting to to work in in the line of uh automatic segmenter . 
uhhuh . 
uh but uh uh in my opinion we need uh uh a reference uh session to to to evaluate the the the tool . 
yes absolutely . 
and so are you planning to do that or have you done that already ? 
and no no with 
sorry ? 
have you done that or are you planning to do that ? 
no i i plan to do that . 
okay . 
darn ! 
i plan i plan but uh uh the idea is the is the following . 
now uh i need um to detect uh all the overlapping zones exactly . 
i i will i will uh talk about uh in the in the blackboard about the my ideas . 
yeah . 
duration . 
uhhuh . 
uh um uh this information uh with uh exactly time marks uh for the overlapping zones uh overlapping zone and uh a speaker a a pure speech uh uh speaker zone . 
i mean uh zones uh of uh speech of uh one speaker without any any uh noise uh any any acoustic event uh that uh uh uh is not uh speech real speech . 
and i need true uh silence . 
for that because my my idea is to to study the nnn the the set of parameters uh what uh are more more discriminant to uh classify . 
right . 
the overlapping zones in cooperation with the speech uh zones . 
the idea is to uh to use uh i ' m not sure to uh yet but uh my idea is to use a a cluster uh algorithm or nnn a person strong in neural net algorithm to uh to uh study . 
what is the uh the property of the different uh feature uh to classify uh speech and overlapping uh speech . 
huh . 
and my idea is uh it would be interesting to to have uh a control set . 
and my control set uh will be the uh silence silence without uh any any noise . 
uhhuh . 
which means that we ' d still you ' d hear the 
yeah that ' s interesting . 
yeah acoustic with this with with yeah the background . 
yeah fans . 
this is like a ground level with it ' s it ' s not total silence . 
uh i i mean uh noise uh uh claps uh tape clips uh the difference uh 
uhhuh . 
uh uh event uh which uh uh has uh uh a hard effect of spectral distortion in the in the uh speech . 
uhhuh . 
uhhuh . 
so so you intend to hand mark those and exclude them ? 
yeah i have in in in in that not in all in all the the file . 
uhhuh . 
only uh uh nnn huh i have uh um i don ' t remind what is the the the the quantity . 
but uh i i have marked enough speech on and all the overlapping zones . 
i have uh two hundred and thirty more or less overlapping zones and is similar to to this information . 
whew ! 
great great . 
uhhuh . 
because with the program i cross the information of uh of jane with uh my my segmentation by hand . 
and is uh more similar . 
excellent . 
glad to hear it . 
good . 
but 
sorry sorry . 
go ahead . 
and the the idea is uh i i will use uh i want my idea is uh to uh to classify . 
i should ' ve got the digital camera . 
oh well . 
i i need uh the exact uh mark of the different uh uh zones . 
because i i want to put uh for uh each frame a label indicating it ' s a supervised and uh hierarchical clustering process . 
i i i put uh uh for each frame a label indicating what is the type what is the class uh which it belong . 
uhhuh . 
uh i mean the class you will overlapping speech overlapping is a class uh speech the class that ' s 
non speech . 
these will be assigned by hand ? 
i i i i i i put the mark by hand . 
based on the 
uhhuh . 
because uh my idea is uh in in the first session i need uh i i need uh to be sure that the information uh that uh i i will cluster is is right because uh uh if not uh i will i will uh return to the speech file to analyze uh what is the problems . 
well training and validation sure . 
uhhuh . 
uh and i i ' d prefer i would prefer to to have uh this labeled automatically . 
but uh uh i need truth . 
you need truth huh . 
yeah but this is what you ' re starting with . 
yeah . 
i ' ve got to ask you so uh the difference between the top two 
yeah yeah yeah . 
so so i start at the bottom so silence is clear . 
by speech do you mean speech by one by one person only ? 
speech 
so this is okay and then and then the top includes people speaking at the same time or or a speaker and a breath overlapping someone else ' s breath or or clicking overlapping with speech so that that ' s all those possibilities in the top one . 
yeah . 
yeah . 
yeah . 
is 
one two or more . 
one two three . 
but 
no by by the moment yeah yeah yeah . 
yeah . 
yeah . 
okay . 
uh in the first moment because uh uh i i have information uh of the overlapping zones uh information about if the uh overlapping zone is uh from a speech clear speech from a one to a two uh speaker or three speaker or is is the zone where the breath of a speaker uh overlaps uh onto uh a speech another especially speech . 
so it ' s it ' s basically speech with with something overlapping which could be speech but doesn ' t need to be . 
no no especially uh overlapping speech from uh different uh uh speaker . 
no but there ' s but i think she ' s saying where do you in these three categories where do you put the instances in which there is one person speaking and other sounds which are not speech ? 
uh . 
uh ! 
which category do you put that in ? 
yeah that ' s right that ' s my question . 
yeah . 
yeah here i i put uh speech from uh from uh one speaker without uh uh any any any events more . 
oh ! 
right so where do you put speech from one speaker that does have a non speech event at the same time ? 
which which category ? 
like a 
where where what is the class ? 
no by the moment no . 
oh . 
yeah yeah that ' s what he was saying before . 
so you don ' t it ' s not in that 
oh so you not not marked . 
for for the by the no because i i i i want to limit the the nnn the the study . 
okay . 
got it . 
fine so so 
yeah so that ' s what he was saying before is that he excluded those . 
so you ' re not using all of the data . 
the all i exactly . 
yeah . 
yeah . 
yeah you mean . 
so you ' re ignoring overlapping events unless they ' re speech with speech . 
yeah 
yeah that ' s fine . 
yeah . 
okay . 
why ? 
why ? 
what ' s the reason ? 
because it ' s the first study . 
oh no no it ' s a perfectly sensible way to go . 
the first 
we ' re 
we just wondered trying to understand what what you were doing . 
yeah . 
yeah . 
yeah because you ' ve talked about other overlapping events in the past . 
okay . 
yeah . 
so this is this is a subset . 
yeah . 
in the in the future the the idea is to to extend the class . 
is is 
to consider all the all the information you you mentioned before . 
yeah yeah i i don ' t think we were asking for that . 
okay 
we were just trying to understand . 
yeah . 
but uh the the first idea because uh i don ' t know what what will happen with the study . 
yeah we just wanted to know what the category was here . 
yeah . 
right . 
sure . 
yeah . 
is your silence category pure silence or 
what if there was a door slam or something ? 
it ' s pure 
no no it ' s pure silence . 
pure silence . 
it ' s the control set . 
okay . 
okay . 
it ' s the control set . 
what you 
it ' s pure pure silence with the with the machine on the on the roof . 
well 
i i think what you i think what you mean is that it ' s non speech segments that don ' t have impulsive noises . 
with the fan . 
yeah . 
right ? 
because you ' re calling what you ' re calling event is somebody coughing or clicking or rustling paper or hitting something which are impulsive noises . 
yeah . 
but steady state noises are part of the background . 
yeah . 
which are being included in that . 
right ? 
here yet yet i i i i i think i i think uh there are that some kind of noises that uh don ' t don ' t wanted to to be in that uh in that control set . 
yeah . 
so it ' s like a signal noise situation . 
yeah . 
well 
yeah . 
but i prefer i prefer at at the first uh the the silence with uh this uh this kind of the of uh of noise . 
well steady state . 
right it ' s i mean it ' s background might be might be a better word than silence . 
yeah . 
it ' s just sort of that the the background acoustic . 
yeah . 
yeah . 
yeah . 
right so fine go on . 
is is is only 
yeah . 
okay . 
well we needed to get the categories yeah . 
and um with this information the idea is uh uh nnn i have a label for for each uh frame and uh with a cluster uh algorithm i and 
sorry . 
and uh i am going to prepare a test bed uh well uh a a set of feature structure uh uh models . 
right . 
and my idea is 
tone whatever . 
so so on because i have a pitch extractor yet . 
right . 
uhhuh . 
i have to to test but uh i 
you have your own ? 
yeah yeah yeah . 
oh ! 
i i have prepare . 
is a modified version of of of a pitch tracker uh from uh uh stanford university . 
in stanford ? 
no . 
from uh them cambridge university . 
oh ! 
what ' s it written in ? 
uh them i i i don ' t remember what is the the name of the of the author . 
because i i have several i have uh uh them uh library tools from uh festival and of from edinburgh uh from cambridge uh and from our department . 
uh . 
uhhuh uhhuh . 
and and i have to because in general the pitch tracker doesn ' t work very well and 
bad . 
right . 
but you know as a feature it might be okay . 
yeah yeah . 
so we don ' t know . 
this this is and the idea is to to uh to obtain uh for example uh uh uh uh different well no a great number of uh f e c for example uh uh twenty five uh thirty thirty parameters uh for for each one . 
and in a first uh nnn step in the in the research uh my idea is try to uh to prove what is the performance of the difference parameter uh to classify the different uh what is the the the the front end approach to classify uh the different uh frames of each class uh and what is the the nnn nnn nnn uh what is the the error uh of the data . 
supervised clustering . 
uhhuh . 
this is the the uh first idea . 
uhhuh . 
and the second is try to uh to use some ideas uh similar to the linear discriminant analysis . 
uhhuh . 
uh 
uh similar because the idea is to to study what is the contribution of uh each parameter to the process of classify correctly the different the different parameters . 
uhhuh . 
what sort of classifier 
uh the the the classifier is nnn by the moment is uh is uh similar nnn that the classifier used uh in a quantifier vectorial quantifier is uh used to to uh some distance to to put uh a vector uh in in a class different . 
is yeah with a model is is only to cluster using a uh or a similarity . 
unimodal ? 
uhhuh . 
so is it just one cluster per 
another possibility it to use uh a a neural network . 
right . 
but uh what ' s the what is my idea ? 
what ' s the problem i i i i see in in in if you you use the the neural network ? 
if when this kind of uh huh cluster clustering algorithm to can test to can uh observe what happened you you can ' t you can ' t uh uh put up with your hand in the different parameter . 
right you can ' t analyze it . 
but uh if you use a neural net is is a good idea but uh you don ' t know what happened in the interior of the neural net . 
well actually you can do sensitivity analyses which show you what the importance of the different pieces of the input are . 
yeah . 
it ' s hard to what you it ' s hard to tell on a neural net is what ' s going on internally . 
yeah . 
but it ' s actually not that hard to analyze it and figure out the effects of different inputs especially if they ' re all normalized . 
yeah . 
yeah . 
um but 
well using something simpler first i think is probably fine . 
well this isn ' t if if if you really wonder what different if if 
yeah . 
but 
decision tree . 
yeah then a decision tree is really good . 
but the thing is here he ' s he ' s not he ' s not like he has one you know a bunch of very distinct variables like pitch and this he ' s talking about like all these cepstral coefficients and so forth . 
right . 
yeah . 
yeah . 
right . 
yeah . 
in which case any reasonable classifier is going to be a mess and it ' s going to be hard to figure out what what uh 
and 
right . 
i i i will include too the the the differential derivates too . 
yeah . 
deltas . 
yeah so . 
i i mean i think the other thing that one i mean this is i think a good thing to do to sort of look at these things at least 
see what i ' d i ' d let me tell you what i would do . 
i would take just a few features instead of taking all the m f c c ' s or all the p l p ' s or whatever i would just take a couple . 
yeah . 
okay . 
like like c one c two something like that so that you can visualize it . 
and look at these different examples and look at scatter plots . 
yeah . 
yeah . 
okay so before you do build up any kind of fancy classifiers just take a look in two dimensions at how these things are split apart . 
that i think will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier . 
yeah . 
yeah . 
and the second thing is once you actually get to the point of building these classifiers what this lacks so far is the temporal properties . 
so if you ' re just looking at a frame and a time you don ' t know anything about you know the structure of it over time and so you may want to build build a markov model of some sort uh or or else have features that really are based on um on on some bigger chunk of time . 
yeah . 
yeah . 
yeah . 
but i think this is a good place to start . 
but don ' t anyway this is my suggestion is don ' t just you know throw in twenty features at it the deltas and the delta and all that into some classifier even even if it ' s k nearest neighbors you still won ' t know what it ' s doing even you know it ' s not a neural net . 
yeah . 
yeah yeah . 
uh i think to know what it ' s to have a better feeling for what it ' s doing you want to look at it . 
so you want to look at at some picture that shows you here ' s these things uh uh are offer some separation . 
yep . 
and uh in l p c uh the thing to particularly look at is i think is something like uh the residual the energy in the residual . 
yeah . 
um so . 
yeah . 
can i ask ? 
it strikes me that there ' s another piece of information um that might be useful and that ' s simply the transition . 
so if you go from a transition of silence to overlap versus a transition from silence to speech there ' s going to be a a big informative area there it seems to me . 
yeah because 
yeah yeah . 
yeah . 
yeah i yeah but uh i i is my my own vision of the of the project . 
so some sort of 
uhhuh . 
i uh the the meeting recorder project for me has uh two uh has uh several parts several objective . 
uhhuh . 
uh because it ' s a a great project . 
but uh at the first in the acoustic uh uh parts of the project uh i think you uh we have uh two main uh objective . 
one one of these is to uh to detect the change the acoustic change . 
and for that if you don ' t use uh uh a speech recognizer uh broad class or not broad class to to try to to to label the different frames i think the ike criterion or bic criterion uh will be enough to detect the change . 
and probably i i i i would like to to prove . 
uh probably when you you have uh uh uh the transition of speech or or silence uh to overlap zone this criterion is enough with probably with uh this kind of uh uh the the the more uh use uh use uh used uh them normal regular uh parameter m m f c c . 
you you have to to to find you can find the the mark . 
you can find the nnn the the acoustic change . 
but uh uh i i understand that you your objective is to uh classify to know that uh that zone not is only a new zone in the in the file that uh you have uh but you have to to to know that this is overlap zone . 
because in the future you will uh try to to process that zone with a regular uh uh speech recognizer model i suppose . 
uhhuh . 
uhhuh . 
you you will pretend to to to process the overlapping uh zone with another kind of algorithm . 
because it ' s very difficult to to to obtain the transcription from uh using uh uh a regular normal speech recognizer . 
that you know i i i think is the idea . 
and so uh the nnn the the system uh will have two models . 
a model to detect more the most accurately possible that is uh will be possible the uh the mark the change . 
okay . 
and another another model will or several models to try but uh several uh robust models sample models to try to classify the difference class . 
i ' m i ' m i ' m sorry i didn ' t understand you what you said . 
what what model ? 
uh the the classifiers of of the to detect the different class to the different zones before try to to recognize uh with uh to transcribe with uh a speech recognizer . 
uhhuh . 
so 
and my idea is to use uh for example a neural net . 
with the information we obtain from this uh this uh study of the parameter with the selected parameter to try to uh to put the class of each frame uh for the difference zone . 
features . 
yeah . 
you you uh uh have obtained in the first uh step with the for example bic uh uh criterion compare model . 
uhhuh . 
and you 
okay but i i think in any event we ' re agreed that the first step is . 
i don ' t 
yeah . 
because what we had before for for uh speaker change detection did not include these overlaps . 
yeah . 
so the first thing is for you to to build up something that will detect the overlaps . 
yeah . 
right ? 
so again i think the first thing to do to detect the overlaps is to look at these uh in in in in 
yeah . 
features . 
well i again the things you ' ve written up there i think are way too way too big . 
yeah . 
okay if you ' re talking about say twelfth twelfth order uh m f c c ' s or something like that it ' s just way too much . 
you won ' t be able to look at it . 
yeah . 
all you ' ll be able to do is put it into a classifier and see how well it does . 
yeah . 
whereas i think if you have things if you pick one or two dimensional things or three of you have some very fancy display uh and look at how the the different classes separate themselves out you ' ll have much more insight about what ' s going on . 
it will be enough . 
well you ' ll you ' ll get a feeling for what ' s happening you know . 
so if you look at suppose you look at first and second order cepstral coefficients for some one of these kinds of things and you find that the first order is much more effective than the second and then you look at the third and there ' s not and not too much there you may just take first and second order cepstral coefficients . 
yeah . 
yeah . 
right ? 
yeah . 
and with l p c i think l p c per se isn ' t going to tell you much more than than than the other maybe . 
uh and uh on the other hand the l p c residual the energy in the l p c residual will say how well uh the low order l p c model ' s fitting it which should be pretty poorly for two or more people speaking at the same time and it should be pretty well for for for one . 
yeah . 
yeah . 
and so i again if you take a few of these things that are are um promising features and look at them in pairs uh i think you ' ll have much more of a sense of okay i now have uh doing a bunch of these analyses . 
yeah . 
i now have ten likely candidates . 
and then you can do decision trees or whatever to see how they combine . 
yeah . 
yeah . 
yeah . 
i ' ve got a question . 
interesting . 
huh . 
sorry . 
but uh uh uh uh uh i don ' t know it is the first uh way to to do that . 
and i would uh like to to know what uh your opinion . 
uh all this study in the in the first moment i i i i will pretend to do with uh uh equalizes speech the the equalizes speech the speech uh the mixes of speech . 
with 
with what ? 
with what ? 
right mixed . 
the the mix mixed speech . 
mixed thank you . 
uh why ? 
because uh the spectral distortion is more uh a lot uh clearer very much clearer if we compare with the p d a . 
right . 
p d a speech file is uh it will be uh difficult . 
i 
so it ' s messier . 
the the p d a is messier . 
yeah . 
because the the noise uh to the signal to noise relation is uh is is low . 
okay . 
yeah i think that that ' s a good way to start . 
and i don ' t know . 
but 
i don ' t know uh uh that uh the the result of the of the study uh with uh with uh this uh this speech the mix speech uh will work exactly with the uh p d a files . 
it would be interesting in itself to see . 
uh what i i mean what is the effect of the low signal to to to noise relation you know uh with 
well i think that would be an interesting result . 
well i think i think i think it ' s not a it ' s not at all unreasonable . 
it makes sense to start with the simpler signal . 
because if you have features which don ' t aren ' t even helpful in the high signal to noise ratio then there ' s no point in putting them into the low signal ratio one would think anyway . 
yeah . 
and so if you can get uh again my prescription would be that you would with a mixed signal you would take a collection of possible uh features look at them look at how these different classes that you ' ve marked separate themselves and then collect uh in pairs and then collect ten of them or something and then proceed with a bigger classifier . 
yeah . 
yeah . 
and then if you can get that to work well then you go to the other signal . 
and then and you and you know they won ' t work as well but how you know how much . 
yeah . 
right . 
yeah yeah . 
and then you can re optimize and so on . 
yeah but i think it would be interesting to try a couple with both . 
because it i think it would be interesting to see if some features work well with close mixed and and don ' t . 
huh . 
uh yeah yeah yeah yeah . 
that ' s well the it it ' s it ' s true that it also it could be useful to do this exploratory analysis where you ' re looking at scatter plots and so on in both cases sure . 
but 
uhhuh . 
i i i i think that the the uh parameter we found uh uh worked with both uh speech file . 
that ' s good . 
but uh what is the the the relation of uh of the performance when uh you use uh the uh uh speech the p d a speech files ? 
huh . 
yeah i don ' t know . 
right . 
but it i i i i think it will be important . 
because uh people uh uh different groups eh has uh experience with this uh kind of problem is uh is not easy uh to solve because if you 
i i i have seen the the the speech file from uh p d a and some parts is very difficult . 
because you you don ' t see the spectrum the spectrogram . 
right . 
is very difficult to apply uh uh a parameter to detect change when you don ' t see . 
yeah they ' re totally hidden . 
yeah . 
yeah . 
well that that that ' s another reason why very simple features things like energy and things things like harmonicity and residual energy are uh yeah are are better to use than very complex ones because they ' ll be more reliable . 
but i suppose 
are probably better yep . 
yeah yeah yeah . 
i i i will put uh the energy here . 
yeah yeah yeah . 
chuck was going to ask something i guess . 
you have a question ? 
yeah i maybe this is a dumb question . 
but i thought it would be i thought it would be easier if you used a p d a . 
nah . 
because can ' t you couldn ' t you like use beam forming or something detect speaker overlaps ? 
i mean 
well if you used the array rather than the signal from just one . 
uhhuh . 
yeah no you ' re you ' re right . 
but that ' s 
that in fact if we made use of the fact that there are two microphones you do have some location information which we don ' t have with the one . 
and and so that ' s 
is that not allowed with this project ? 
uh well no i mean we don ' t have any rules really . 
but i didn ' t mean i given given the goal . 
i think i i think i think it ' s it ' s it ' s a it ' s an additional interesting question . 
i mean is is that violation of the 
oh . 
no . 
yeah . 
i mean i think you want to know whether you can do it with one . 
because you know it ' s not necessarily true that every device that you ' re trying to do this with will have two . 
uhhuh . 
yeah . 
uh if on the other hand we show that there ' s a huge advantage with two well then that could be a real point . 
yeah . 
but we don ' t even know yet what the effect of detecting having the ability to detect overlaps is . 
you know maybe it doesn ' t matter too much . 
right . 
right . 
yeah . 
so this is all pretty early stages . 
okay . 
yeah . 
but no you ' re absolutely right . 
yeah . 
i see . 
yeah yeah yeah . 
that ' s a good thing to consider . 
okay . 
there there is a complication though and that is if a person turns their back to the to the p d a then some of the positional information goes away . 
well it it it does it it does but the the the issue is that that 
yeah . 
no it ' s not it ' s not that so much as 
and then and if they ' re on the access on the axis of it that was the other thing i was thinking . 
uhhuh . 
he you mentioned this last time that that if if you ' re straight down the midline then then the the left right ' s going to be different . 
yeah we need to put it on a little turntable . 
i i i i i 
and 
well 
yeah . 
and and and in his case i mean he ' s closer to it anyway . 
yeah . 
it seems to me that that it ' s not a uh you know it ' s this the the topology of it is is a little bit complicated . 
yeah . 
but it ' s another source of information . 
i i yeah . 
i don ' t i don ' t know 
i i i think 
sorry . 
i i i think because the distance between the two uh microphone uh in the p d a is very near . 
but it ' s uh from my opinion it ' s an interesting idea to to try to study the binaural uh problem uh with information because i i found difference between the the speech from from each uh in the p d a . 
i would guess 
yep . 
yeah it ' s timing difference . 
oh yeah oh i agree and we use it ourselves . 
it ' s not amplitude . 
right ? 
right . 
i mean i know i i know that ' s a very important cue . 
yep . 
yeah . 
but i ' m just i ' m just saying that the way we ' re seated around a table is not the same with respect to each to each person with respect to the p d a . 
no . 
no . 
no no no . 
so we ' re going to have a lot of differences with respect to the speaker . 
that ' s that ' s fine . 
but i don ' t think that matters though . 
but 
that ' s so so i think the issue is is there a clean signal coming from only one direction . 
right . 
if it ' s not coming from just one direction if it if if there ' s a broader pattern it means that it ' s more likely there ' s multiple people speaking . 
yeah . 
wherever they are . 
so it ' s sort of like how how confused is it about where the beam is . 
is it a is it 
yeah is there a narrow is there a narrow beam pattern or is it a a distributed beam pattern ? 
yeah . 
so if there ' s a distributed beam pattern then it looks more like it ' s it ' s uh multiple people . 
okay . 
wherever you are even if he moves around . 
yeah . 
okay it just it just seemed to me that uh that this isn ' t the ideal type of separation . 
i mean i i think it ' s i can see the value 
oh ideal would be to have the wall filled with them . 
but i mean but the thing is just having two mikes if you looked at that thing on on dan ' s page it was when when there were two people speaking and it looked really really different . 
yeah okay . 
yeah . 
yeah . 
yeah . 
yep . 
oh yeah yeah okay . 
yeah . 
what looked different ? 
yeah . 
uh well he was looking at correlation . 
cross cross correlation . 
just cross correlation between two sides . 
correlation yeah . 
so cross correlation is pretty sensitive . 
sorry uh i ' m not sure what dan ' s page is that you mean he was looking at the two 
uh his a web page . 
you take the signal from the two microphones and you and you cross correlate them with different lags . 
subtract them . 
okay . 
uhhuh . 
yeah . 
uhhuh . 
okay . 
so when one person is speaking then wherever they happen to be at the point when they ' re speaking then there ' s a pretty big maximum right around that point in the in in the lag . 
so if at whatever angle you are at some lag corresponding to the time difference between the two there you get this boost in the in in the cross correlation value function . 
okay okay . 
so so if there ' s two 
and if there are multiple people talking you ' ll see two peaks . 
it ' s spread out . 
well let me ask you if if both people were over there it would be less effective than if one was there and one was across catty corner . 
yeah . 
yeah . 
yeah . 
the oh i ' m sorry . 
no ? 
if they ' re right next to one another ? 
if i was if i was here and morgan was there and we were both talking it wouldn ' t work . 
next next one over over on this side of the p d a . 
there we go . 
right . 
yeah . 
good example the same one i ' m asking . 
yeah . 
yeah i see . 
yeah . 
versus you versus you know and we ' re catty corner across the table and i ' m farther away from this one and you ' re farther away from that one . 
yes . 
or or even if like if people were sitting right across from each other you couldn ' t tell the difference either . 
yeah . 
yeah . 
it seems like that would be pretty strong . 
yeah oh yeah . 
yeah . 
yeah . 
across the same axis you don ' t have as much to differentiate . 
and so my point was just that it ' s it ' s going to be differentially differentially valuable . 
yeah . 
well we yeah we don ' t have a third dimension there yeah so it ' s 
right . 
i mean it ' s not to say i mean i certainly think it ' s extremely and we we humans depend on you know these these binaural cues . 
yeah yeah . 
but it ' s almost but it ' s almost a i think what you ' re talking about there ' s two things . 
but . 
there ' s a sensitivity issue and then there ' s a pathological error uh issue . 
so the one where someone is just right directly in line is sort of a pathological error . 
yes yeah . 
if someone just happens to be sitting right there then we won ' t get good information from it . 
yeah . 
okay . 
and and if there so it and if it ' s the two of you guys on the same side 
uh if they ' re if they ' re close it ' s just a question of the sensitivity . 
yep . 
yeah . 
okay . 
so if the sensitivity is good enough and we just we just don ' t have enough uh experience with it to know how 
yeah yeah okay yeah . 
but 
yeah . 
oh i ' m not i ' m not trying to argue against using it by any means i just wanted to point out that that weakness that it ' s topologically impossible to get it perfect for everybody . 
yeah . 
uhhuh . 
and i think dan is still working on it . 
so he actually he wrote me about it a little bit . 
so 
great . 
no i don ' t mean to discourage that at all . 
i mean the other thing you can do uh if i mean we ' re assuming that it would be a big deal just to get somebody convince somebody to put two microphones in the p d a . 
but if you put a third in you could put in the other axis and then you know then you ' re sort of yeah then then you pretty much could cover 
once you got two . 
interesting . 
yeah . 
well what about just doing it from these mikes ? 
interesting . 
you know ? 
yeah . 
yep . 
it will be more interesting to study the p z m because the the separation i i think . 
uh but that ' s i mean we we ' ll be all of this is there for us to study . 
then they ' re much broader . 
yeah we can do whatever we want . 
yeah . 
but but but the thing is uh one of the at least one of the things i was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a p d a . 
whatever you ' re interested in . 
yeah . 
that ' s what i was asking about what are the constraints . 
yeah . 
yeah . 
right yeah . 
yeah . 
yeah . 
well that ' s that ' s the constraint of one question that i think both adam and i were were were interested in . 
well 
uhhuh . 
yep . 
uhhuh . 
uh 
yeah . 
but you know if you can instrument a room this is really minor league compared with what some people are doing right ? 
some people at at uh yeah at brown and and and and at uh um and at cape . 
big micro arrays . 
yeah . 
didn ' t they have something at cape ? 
they both have these you know big arrays on the wall . 
and you know if you could do that you ' ve got microphones all over the place . 
very finely . 
uh you know tens of microphones . 
and and uh 
oh i saw a demo ! 
oh right oh yeah . 
and if you do that then you can really get very nice uh kind of selectivity . 
yeah . 
oh i saw one that was like a hundred microphones a ten by ten array . 
yeah yeah . 
hundred . 
and you could in a noisy room they could have all kinds of noises and you can zoom right in on somebody . 
yeah . 
and they had very precision 
yeah . 
right . 
pretty much yeah . 
very complex uh yeah . 
it was all in software and they and you could pick out an individual beam and listen to it . 
yeah . 
that is cool . 
yeah . 
it was yeah it was interesting . 
but the reason why i haven ' t focused on that as the my first concern is because um i ' m interested in what happens for people random people out in some random place where they ' re having an impromptu discussion . 
and you can ' t just always go well let ' s go to this heavily instrumented room that we spent tens of thousands of dollars to to set up . 
yeah . 
yeah . 
no what you need to do is you ' d have a little fabric thing that you unroll and hang on a wall . 
it has all these mikes and it has a plug in jack to the p d a . 
interesting . 
the other thing actually that gets at this a little bit of something else i ' d like to do is what happens if you have two p d a ' s ? 
but i think 
yep . 
and they communicate with each other and then you know they ' re in random positions the likelihood that i mean basically there wouldn ' t be any likely to be any kind of nulls if you even had two if you had three or four it ' s yeah . 
yeah . 
ooo ! 
that ' s on my web pages . 
yeah . 
network . 
interesting . 
though 
all sorts of interesting things you can do with that . 
interesting . 
i mean not only can you do microphone arrays but you can do all sorts of um multi band as well . 
huh . 
yeah . 
yeah . 
uh ! 
so it ' s it would be neat . 
i still like my rug on the wall idea so if anybody patents that then 
but 
i think 
well you could have strips that you stick to your clothing . 
in terms of 
yeah . 
yeah ! 
hats . 
in terms of the research research it ' s really it ' s whatever the person who is doing the research wants to do . 
shirts . 
so if if jose is interested in that that ' s great . 
but if if he ' s not that ' s great too . 
yeah . 
yeah . 
yeah yeah . 
um i i i would actually kind of like us to wind it down see if we can still get to the end of the uh birthdays thing there . 
catch some tea ? 
um . 
so 
well i had a couple things that i did want to bring out . 
okay . 
one is do we need to sign new these again ? 
well it ' s slightly different so i i would say it would be a good idea . 
because it it ' s slightly different . 
are they new ? 
yep . 
oh . 
oh this morning we didn ' t sign anything because we said that if anybody had signed it already we didn ' t have to . 
yeah i i should ' ve checked with jane first but the the form has changed . 
it ' s slightly different . 
uhoh . 
so we may want to have everyone sign the new form . 
okay . 
i had to make one 
um i had some things i wanted to talk about with the thresholding stuff i ' m doing . 
but if we ' re in a hurry we can put that off . 
um and then also anonymity how we want to anonymize the data . 
well should i i mean i have some results to present but i mean i guess we won ' t have time to do that this time . 
uh 
but it seems like um the anonymization is uh is also something that we might want to discuss in greater length . 
um i mean what 
if if we ' re about to wind down i think what i would prefer is that we uh delay the anonymization thing till next week . 
and i would like to present the results that i have on the overlaps . 
we still have to do this too right ? 
right . 
digits ? 
right . 
well we don ' t have to do digits . 
well why don ' t we 
uh so okay it sounds like uh there were there were a couple technical things people would like to talk about . 
why don ' t we just take a couple minutes to to briefly do them and then and then and then and then and then we 
okay go ahead jane . 
i ' d i ' d prefer to have more time for my results . 
could i do that next week maybe ? 
okay . 
oh yeah sure . 
okay that ' s what i ' m asking . 
oh yeah yeah . 
and i think the anonymization if if you want to proceed with that now i just think that that ' s that ' s a discussion which also really deserves a a you know more that just a minute . 
we could 
i really do think that . 
uhhuh . 
because you raised a couple of possibilities yourself . 
you and i have discussed it previously . 
and there are different ways that people approach it and i think we should 
all right . 
we ' re we ' re we ' re getting enough data now that i ' d sort of like to do it now before i get overwhelmed with once we decide how to do it . 
well okay . 
going and dealing with it . 
it ' s just 
yeah okay i i ' ll give you the short version . 
but i do think it ' s an issue that we can ' t resolve in five minutes . 
uhhuh . 
okay so the the short thing is um we have uh tape recording uh uh sorry digitized recordings . 
those we won ' t be able to change . 
if someone says hey roger so - and - so . 
right . 
so that ' s going to stay that person ' s name . 
yep . 
now in terms of like the transcript . 
the question becomes what symbol are you going to put in there for everybody ' s name ? 
and whether you ' re going to put it in the text where he says hey roger or are we going to put that person ' s anonymized name in instead ? 
no because then that would give you a mapping and you don ' t want to have a mapping . 
okay so first decision is we ' re going to anonymize the same name for the speaker identifier and also in the text whenever the speaker ' s name is mentioned . 
no . 
i don ' t 
because that would give you a mapping between the speaker ' s real name and the tag we ' re using and we don ' t want 
i i don ' t think you understood what i what i said . 
okay . 
so uh so in within the context of an utterance someone says so roger what do you think . 
okay . 
then uh it seems to me that well maybe i uh it seems to me that if you change the name the transcript ' s going to disagree with the audio and you won ' t be able to use that . 
we don ' t we want to we we want the transcript to be roger . 
right you don ' t want to do that . 
because if we made the the transcript be the tag that we ' re using for roger someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name and we want to avoid that . 
yeah . 
okay well but then there ' s this issue of if we ' re going to use this for a discourse type of thing then and you know liz was mentioning stuff in a previous meeting about gaze direction and who ' s who ' s the addressee and all then to have roger be the thing in the utterance and then actually have the speaker identifier who was roger be frank that ' s going to be really confusing and make it pretty much useless for discourse analysis . 
oh . 
ugh . 
that ' s a good point . 
now if you want to you know i mean in some cases i i i know that susan ervin tripp in some of hers uh actually did do uh um a filter of the signal where the person ' s name was mentioned except . 
and and i and i so i mean the question then becomes one level back . 
um how important is it for a person to be identified by first name versus full name ? 
well on the one hand uh it ' s not a full identity . 
we ' re taking all these precautions um and they ' ll be taking precautions which are probably even the more important ones to they ' ll be reviewing the transcripts to see if there ' s something they don ' t like okay . 
so maybe uh maybe that ' s enough protection . 
on the other hand this is a small this is a small pool and people who say things about topic x who are researchers and well known in the field they ' ll be identifiable and simply from the from the first name . 
however taking one step further back they ' d be identifiable anyway even if we changed all the names . 
right . 
so is it really um you know 
huh . 
ugh ! 
now in terms of like so i i did some results which i ' ll report on next time which do mention individual speakers by name . 
uhhuh . 
now there the human subjects committee is very precise . 
you don ' t want to mention subjects by name in published reports . 
now it would be very possible for me to take those data put them in a in a study and just change everybody ' s name for the purpose of the publication . 
yeah once you get to the publication you can certainly do that . 
and someone who looked 
you can go you know uh z uh for instance . 
yeah exactly . 
doesn ' t matter if 
uh um yeah i mean it doesn ' t i mean i ' m not knowledgeable about this . 
that ' s the same thing you saw . 
but it certainly doesn ' t bother me to have someone ' s first name in in the in the transcript . 
okay . 
uh i think you don ' t want to have their full name to be uh listed . 
yeah and and in the form that they sign it does say your first name may arise in the course of the meetings . 
and so 
yeah . 
well 
yeah . 
so again the issue is if you ' re tracking discourse things you know if someone says uh uh frank said this and then you want to connect it to something later you ' ve got to have this part where that ' s frank colon . 
or your name . 
yeah shoot ! 
right ? 
yeah and and you know even more uh immediate than that just being able to uh well it just seems like to track track from one utterance to the next utterance who ' s speaking and who ' s speaking to whom because that can be important . 
uhhuh . 
you know you raised the point so - and - so it ' s be kind of nice to be able to know who you was . 
yeah . 
shoot ! 
i i ' m thinking too much . 
and and actually you remember furthermore you remember last time we had this discussion of how you know i was sort of avoiding mentioning people ' s names . 
yeah i was too yeah . 
and and it was and we made the decision that was kind of artificial . 
well i mean if we ' re going to step in after the fact and change people ' s names in the transcript we ' ve basically done something one step worse . 
yep . 
yeah . 
yeah . 
well i would i i don ' t want to change the names in the transcript . 
misleading . 
but that ' s because i ' m focused so much on the acoustics instead of on the discourse and so i think that ' s a really good point . 
yeah . 
you ' re right this is going to require more thought . 
yeah . 
let me just back up this to make a a brief comment about the uh what we ' re covering in the meeting . 
uh i realize when you ' re doing this that uh i mean i didn ' t realize that you had a bunch of things that you wanted to talk about . 
uh and so uh and so i was proceeding somewhat at random frankly . 
so i think what would be helpful would be uh and i ' ll i ' ll mention this to to liz and andreas too that um before the meeting if anybody could send me any any uh uh agenda items that they were interested in and i ' ll i ' ll take the role of organizing them uh into into the agenda . 
okay . 
sure . 
but i ' d be very pleased to have everyone else completely make up the agenda . 
i ' ve no desire to to make it up . 
but if if no one ' s told me things then i ' m just proceeding from my my guesses and and uh and yeah i i ' m sorry it ended up with your out your time to i mean i ' m just always asking jose what he ' s doing you know and and so it ' s there ' s uh there ' s obviously other things going on . 
uhhuh . 
oh it ' s not a problem not a problem yeah . 
i just i just couldn ' t do it in two minutes . 
how will we how would the person who ' s doing the transcript even know who they ' re talking about ? 
do you know what i ' m saying ? 
the person who ' s doing the transcript the i b m people ? 
yeah . 
i mean so how is that information going to get labeled anyway ? 
how do you mean who what they ' re who they ' re talking about ? 
how do you mean ? 
i mean so if i ' m saying in a meeting oh and bob by the way wanted wanted to do so - and - so 
they ' re just going to write bob on it or do 
if you ' re doing 
yeah they ' re just going to write bob . 
and so if you ' re if you ' re doing discourse analysis 
they won ' t be able to change it themselves . 
what how are they going to do any of this ? 
well i i ' m betting we ' re going to have huge chunks that are just totally untranscribable by them . 
yeah really . 
i mean they ' re going to say speaker one or speaker two or i mean i i 
well the current one they don ' t do speaker identity . 
yeah i think 
they can ' t do that . 
because in naturally speaking or excuse me in via voice it ' s only one person . 
and so in their current conventions there are no multiple speaker conventions . 
so it may just be one long transcript of a bunch of words . 
oh i think that my understanding from 
yep . 
is it yen ching ? 
is that how you pronounce her name ? 
uh yu ching yu ching yeah . 
oh uh yu ching ? 
yu ching ? 
yu - ching . 
was that um they will that they will adopt the part of the conventions that that we discussed where they put speaker identifier down . 
but you know they won ' t know these people . 
so i think it ' s well they ' ll they ' ll adopt some convention . 
but we haven ' t specified to them . 
so they ' ll do something like speaker one speaker two is what . 
i bet but i ' m betting there ' ll be huge variations in the accuracy of of their labeling the speakers . 
we ' ll have to review the transcripts in any case . 
and it and it may very well be i mean since they ' re not going to sit there and and and worry about uh it being the same speaker they may very well go the uh the the first the first time it changes to another speaker that ' ll be speaker two . 
yeah . 
and the next time it ' ll be speaker three even if it ' s actually speaker one . 
you know 
uhhuh . 
you know that would be a very practical solution on their part . 
yeah . 
and and but then we would need to label it . 
yeah . 
it ' s a good idea . 
and that ' s okay . 
yeah we we can probably regenerate it pretty easily from the close talking mikes . 
yeah yeah i think 
yes i was thinking the the time values of when it changes . 
yeah . 
yeah . 
so but i mean that doesn ' t this doesn ' t answer the the question . 
yeah . 
but that 
that ' d be very efficient . 
the it ' s a good point which what do you do for discourse tracking . 
because you don ' t know to know uh you don ' t need to know what what is the identification of the of the speakers you only uh want to know 
huh . 
for for acoustics you don ' t but for discourse you do . 
well you do . 
uh for discourse yeah yeah yeah . 
yeah . 
if if if if someone says uh what what is jose doing and then jose says something you need to know that that was jose responding . 
yeah yeah . 
yeah . 
yeah yeah yeah . 
yeah . 
yeah yeah . 
uhhuh . 
uh so . 
ugh that ' s a problem . 
yeah . 
unless we adopt a different set of norms which is to not to make a point of not identifying people by name which then leads you to be more contextually explicit . 
that would be hard . 
well people are very flexible you know i mean so when we did this last week i felt that you know now andreas may uh uh he he sometimes people think of something else at the same time and they miss a sentence or something and and because he missed something then he missed the the initial introduction of who we were talking about and was was unable to do the tracking . 
uhhuh . 
but i felt like most of us were doing the tracking and knew who we were talking about and we just weren ' t mentioning the name . 
so people are really flexible . 
yeah . 
but you know like at the beginning of this meeting or you i think said you know or liz said something about um uh is mari going to use the equipment . 
yeah . 
i mean how would you say that ? 
i mean you have to really think you know about what you ' re saying 
if you wanted to anonymize . 
is you know who up in you know where ? 
yeah yeah . 
uhhuh . 
right use the 
i think it would be really hard if we made a policy where we didn ' t say names plus we ' d have to tell everybody else . 
yeah darn ! 
i mean what i was going to say is that the other option is that we could bleep out the names . 
yeah is 
well 
yeah . 
but then again that kills your discourse analysis . 
right . 
uhhuh . 
yeah . 
yeah . 
yeah . 
yeah . 
that ' s that ' s the issue . 
i i think the i think i don ' t know my own two cents worth is that you don ' t do anything about what ' s in the recordings you only anonymize to the extent you can the speakers have signed the forms and all . 
well but that but that as i said that that that works great for the acoustics but it it hurts you a lot for trying to do discourse . 
well . 
uhhuh . 
yeah . 
why ? 
yeah . 
because you don ' t have a map of who ' s talking versus their name that they ' re being referred to . 
yeah . 
i thought we were going to get it labelled speaker one speaker two 
sure but then you have to know that jose is speaker one and 
why do you have to know his name ? 
okay so suppose someone says well i don ' t know if i really heard what uh what jose said . 
yeah . 
yeah . 
and then jose responds . 
yeah . 
and part of your learning about the dialogue is jose responding to it . 
but it doesn ' t say jose it says speaker five . 
okay . 
yeah . 
so uh 
yeah . 
oh i see you want to associated the word jose in the dialogue with the fact that then he responded . 
right . 
and so if we pass out the data to someone else and it says speaker five there we also have to pass them this little guide that says that speaker five is jose . 
someone who ' s doing discourse would want to do that . 
and if were going to do that we might as well give them jose say it was jose . 
and that violates our privacy . 
yeah . 
yeah . 
uhhuh . 
and that violates our privacy issue . 
yeah . 
yeah . 
yeah . 
now i i think that we have these two phases in the in the data which is the one which is our use university of washington ' s use i b m s r i . 
yeah . 
and within that it may be that it ' s sufficient to not uh change the to not incorporate anonymization yet but always always in the publications we have to . 
uhhuh . 
and i think also when we take it that next step and distribute it to the world we have to . 
but i but i that ' s that ' s a long way from now and and it ' s a matter of between now and then of of deciding how . 
making some decisions . 
it you know it may be that we ' ll need to do something like actually x out that part of the um the audio and just put in brackets speaker one . 
yeah . 
for the public one . 
you know ? 
yeah . 
you know what we could do also is have more than one version of release . 
one that ' s public and one one that requires licensing . 
and so the licensed one would we could it would be a sticky limitation . 
uhhuh . 
you know like 
i think that ' s risky i think that the public should be the same . 
well we can talk about that later . 
i think that when we do that world release it should be the same . 
i i agree . 
i i agree with jane . 
for a bunch of reasons legal . 
i i think that we we have a need to have a consistent licensing policy of some sort and 
but i also think a consistent licensing policy is important . 
yeah . 
well one thing to take into consideration is are there any um for example the people who are funding this work they want this work to get out and be useful for discourse . 
if we all of a sudden do this and then release it to the public and it ' s not longer useful for discourse . 
you know ? 
well depending on how much editing we do you might be able to still have it useful . 
because for discourse you don ' t need the audio . 
right ? 
so you could bleep out the names in the audio . 
uhhuh . 
and use the anonymized one through the transcript . 
excuse me we we do need audio for discourse . 
uh . 
but if you release both 
but excuse me but you could bleep out just the names . 
no but she ' s saying from the argument before she wants to be able to say if someone said jose in their in their thing and then connect to to what he said later then you need it . 
right . 
but in the transcript you could say everywhere they said jose that you could replace it with speaker seven . 
oh i see . 
yeah but i i also want to say that people 
i see . 
and then it wouldn ' t meet match the audio anymore . 
uhhuh . 
but it would be still useful for the 
but if both of those are publically available 
yeah that ' s good . 
but they 
right . 
and and the other thing is if if if liz were here what she might say is that she wants to look if things that cut across between the audio and the dialogue . 
well you see so it ' s complicated . 
and so uh 
uhhuh yeah . 
i think we have to think about how i think that this can ' t be decided today . 
yeah sorry . 
yeah okay good point . 
but it ' s but i think it was good to introduce the thing and we can do it next time . 
yeah . 
okay . 
i didn ' t think when i wrote you that email i wasn ' t thinking it was a big can of worms but i guess it is . 
okay . 
yeah a lot of these things are . 
discourse . 
well it discourse you know also i wanted to make the point that that discourse is going to be more than just looking at a transcript . 
yeah absolutely . 
it ' s going to be looking at a you know and prosodic stuff is involved . 
oh yeah sure . 
and that means you ' re going to be listening to the audio . 
and then you come directly into this confronting this problem . 
maybe we should just not allow anybody to do research on discourse . 
so 
and then we wouldn ' t have to worry about it . 
okay . 
yeah we should just market it to non english speaking countries . 
uh maybe we should only have meetings between people who don ' t know one another and who are also amnesiacs who don ' t know their own name . 
okay . 
did you read the paper on eurospeech ? 
we could have little labels . 
i i i want to introduce my reservoir dogs solution again which is everyone has like mister white mister pink mister blue . 
mister white . 
yeah . 
did you read the paper a few years ago where they were reversing the syllables ? 
they were they had the utterances . 
and they would extract out the syllables and they would play them backwards . 
but so the syllables were in the same order with respect to each other but the 
everything was in the same order but they were the individual syllables were played backwards . 
and you could listen to it and it would sound the same . 
what did it sound like ? 
people had no difficulty interpreting it . 
so what we need is something that ' s the reverse that a speech recognizer works exactly the same on it but people can ' t understand it . 
oh well that ' s there ' s an easy way to do that . 
just play it all backwards . 
oh right the speech recognizer ' s totally symmetric isn ' t it . 
what what does the speech recognizer care ? 
uh anyway . 
um 
oh do we do digits or 
what do we do ? 
let ' s do digits . 
uh okay we ' ll quickly do digits . 
or do we just quit ? 
yeah we we we already missed the party . 
so 
okay . 
yeah . 
we ' re recording . 
okay . 
so we are recording . 
uh . 
right ? 
yeah . 
oh . 
um everyone should have at least two forms possibly three in front of you depending on who you are . 
okay . 
um we we ' re doing a new speaker form and you only have to fill out the speaker form once . 
but everyone does need to do it . 
and so that ' s the name sex email et cetera . 
uhhuh . 
we we had a lot of discussion about the variety of english and so on . 
so if you don ' t know what to put just leave it blank . 
um i i designed the form and i don ' t know what to put for my own region . 
so 
huh . 
california . 
i think 
california . 
california . 
um may i make one suggestion ? 
instead of age put date of uh year of birth . 
sure . 
because age will change but the year of birth changes you know stays the same usually . 
oh . 
birth year ? 
actually wait a minute . 
although on 
yeah . 
shouldn ' t it be the other way around ? 
not for me . 
course on the other on the other hand you could you view it as the age at the time of the 
on the other side . 
yeah . 
well the thing is if ten years from now you look at this form knowing that 
yes but what we care about is the age at at the recording date rather than the 
but there ' s no other date on the form . 
yeah . 
we don ' t care how they old they really are . 
well well i don ' t know . 
yes unless we want to send them a card . 
well i guess it depends on how long the corpus is going to be collected for . 
yeah that ' s true . 
anyway . 
i still don ' t see the problem . 
either way 
yeah i think i think age is all right . 
and then um there will be attached to this a point or two these forms uh so that you ' ll be able to extract the date off that . 
okay . 
uhhuh . 
so anyway . 
and so then you also have a digits form which needs to be filled out every time the speaker form only once the digit form every time . 
even if you don ' t read the digits you have to fill out the digits form so that we know that you were at the meeting . 
okay ? 
and then also if you haven ' t filled one out already you do have to fill out a consent form . 
and that should just be one person whose name i don ' t know . 
okay ? 
do you want this adam ? 
uh sure . 
thank you . 
so uh 
okay so should we do agenda items ? 
uh oh that ' s a good idea . 
i shouldn ' t run the meeting . 
uh well i have i want to talk about new microphones and wireless stuff . 
huh . 
and i ' m sure liz and andreas want to talk about recognition results . 
anything else ? 
i guess what time do we have to leave ? 
three thirty ? 
yeah . 
yeah . 
why don ' t you go first then . 
so 
yeah . 
good idea . 
okay . 
um well i i sent out an email couple hours ago . 
so 
um with andreas ' help um andreas put together a sort of no frills recognizer . 
which is uh gender dependent but like no adaptation no crossword models no trigrams . 
a bigram recognizer . 
and that ' s trained on switchboard which is telephone conversations . 
um and thanks to don ' s help who 
don took the first meeting that jane had transcribed . 
and um you know separated used the individual channels we segmented it into the segments that jane had used . 
and uh don sampled that so so eight k . 
um and then we ran up to i guess the first twenty minutes . 
up to synch time of one two zero zero . 
so is that that ' s twenty minutes or so ? 
um yeah because i guess there ' s some 
or so . 
and don can talk to jane about this . 
there ' s some bug in the actual synch time file that uh uh 
i ' m we ' re not sure where it came from but stuff after that was a little messier . 
anyway so it ' s twenty minutes and i actually 
huh . 
um 
i 
was that did that did that recording have the glitch in the middle ? 
i ' m puzzled by that . 
i oh oh i see . 
there ' s there ' s a 
oh there was a glitch somewhere . 
yeah . 
so that actually 
um 
was it twenty minutes in ? 
i forgot about that . 
if it was twenty minutes in then i don ' t know . 
i thought 
well i mean they 
well it was interesting . 
but i was able to transcribe 
i don ' t remember when it is . 
suddenly the the overall error rate when we first ran it was like eighty percent . 
but looking at the first sentences looked much better than that . 
and then suddenly it turned very bad . 
and then we noticed that the reference was always one off with the 
yeah that might be that might be that might be my fault . 
it was actually recognized . 
oh no ! 
wow ! 
so 
i ' m not 
oh so that was just a parsing mismatch . 
okay . 
no actually it was 
yeah it was a complicated bug . 
because they were sometimes one off and then sometimes totally random . 
so 
oh . 
yeah i was pretty certain that it worked up until that time . 
that ' s not good . 
um 
yeah . 
so 
so that ' s what we have . 
okay . 
all right . 
yeah . 
but that that will be completely gone if this synch time problem . 
the the glitch . 
so so we have everything recognized but we scored only the first uh whatever up to that time to 
and the only glitch 
yeah . 
yeah . 
so you guys know . 
sorry i haven ' t seen the email . 
yeah . 
the 
the the well wait . 
so here ' s the actual copy of the email . 
what was the score ? 
we should say something about the glitch . 
he he can say something about the glitch . 
um oh okay . 
yeah . 
because it ' s it ' s it ' s it ' s it ' s very small . 
so does this glitch occur at other 
there there there ' s an acoustic glitch that occurs where um the channels get slightly asynchronized . 
very small . 
yep . 
oh . 
right . 
so the that that problem has gone away in the original driver believe it or not when the s s h key gen ran the driver paused for a fraction of a second . 
huh . 
huh . 
huh . 
and so the channels get a little asynchronous . 
and so if you listen to it in the middle there ' s a little part where it starts doing doing click sounds . 
so 
and is it only once that that happens ? 
but 
yeah . 
it 
okay . 
right once in the middle . 
there ' s the previous page has some more information about sort of what was wrong . 
so 
but 
um but that shouldn ' t affect anything . 
so unsurprisingly adam is the golden voice . 
okay . 
so that ' s actually 
and it 
you see this here ? 
yeah yeah . 
it it ' s 
bah . 
okay . 
no 
oh and 
what happens is it actually affects the script that don 
huh . 
i mean if we know about it then i guess it could always be checked for it . 
well the acoustic one shouldn ' t do anything . 
but they 
yeah i don ' t know exactly what affected it . 
i agree . 
i agree . 
but i ' ll i ' ll talk to you about it . 
i i have 
but i i do remember 
yeah . 
i ' ll show you the point . 
yeah . 
it it had no effect on my transcription . 
yeah . 
you know i mean i i had no trouble hearing it and and having time bins . 
huh . 
but there was a 
i do remember seeing once the transcriber produce an incorrect x m l file where one of the synch numbers was incorrect . 
oh . 
that ' s what happened . 
well the the synch time the synch numbers have more significant digits than they should . 
oh . 
yeah . 
there was 
where where they weren ' t monotonic . 
yeah i mean 
right ? 
there ' s things that are in smaller increments than a frame . 
yeah . 
oh interesting . 
oh okay . 
so that ' s 
huh . 
and so then i mean you look at that and it ' s got you know more than three significant digits in a synch time then that can ' t be right . 
oh . 
yeah sounds like a bug . 
yeah . 
huh . 
so anyway it ' s it ' s just 
that ' s why we only have twenty minutes . 
but there ' s a significant amount of 
non zero ? 
um there are like more because there ' s a lot of zeros i tacked on just because of the way the script ran . 
the other one i saw was that it 
i mean but there there was a point . 
yeah . 
yeah that was fine . 
the other one i saw was non monotonic synch times . 
that that was okay . 
okay . 
and that definitely indicates a bug . 
uh 
well that would really be a problem . 
yeah . 
so anyway these are just the ones that are the prebug for one meeting . 
yeah . 
um and what ' s which 
so that ' s very encouraging . 
this is really encouraging because this is free recognition . 
yeah . 
huh . 
cool . 
there ' s no i mean the language model for switchboard is totally different . 
huh . 
so you can see some like this trent lott which 
trent lott . 
um i mean 
these are sort of funny ones . 
it ' ll get those though . 
there ' s a lot of perfect ones and good ones and all the references . 
i mean you can read them and when we get more results you can look through and see . 
i and as i said i would like to look at the lattices . 
uhhuh . 
but 
um it ' s pretty good . 
because it sounded like even the ones it got wrong it sort of got it right . 
well so i guess we can generate 
sounds likes 
uhhuh . 
there are a fair number of errors that are you know where got the plural s wrong or the inflection on the verb wrong . 
um 
yeah . 
and who cares ? 
and and there were lots of of course the uh uh in on of uh . 
huh so if 
there ' s 
no those are actually 
yeah . 
a lot of the errors i think are out of vocabulary . 
so is it like p z m is three words . 
uhhuh . 
it ' s p z m . 
uhhuh . 
i mean there ' s nothing 
right . 
there ' s no language model for p z m or 
right . 
um 
did you say there ' s no language for p z m ? 
no language model i mean those 
do you mean so every time someone says p z m it ' s an error ? 
maybe we shouldn ' t say p z m in these meetings . 
well well there ' s all kinds of other stuff like jimlet . 
and i mean um anyway there 
yeah that ' s right jimlet . 
well we don ' t even know what that means . 
so but this is really encouraging because 
yeah that ' s right . 
so i 
so i mean the bottom line is even though it ' s not a huge amount of data um it should be uh reasonable to actually run recognition and be like within the scope of of reasonable you know switchboard . 
this is like about how well we do on switchboard two data with the switchboard one trained mostly trained recognizer . 
right . 
and switchboard two is got sort of a different population of speakers and a different topic . 
excellent . 
and they ' re talking about things in the news that happened after switchboard one . 
so there was so that ' s great . 
yeah . 
yeah so we ' re in better shape than we were say when we did had the ninety three workshop . 
um 
and we were all getting like seventy percent error on switchboard . 
uhhuh . 
oh yeah . 
i mean this is really 
you know 
huh . 
and thanks to andreas who i mean this is a 
huh . 
well especially for the very first run i mean you 
yeah . 
uh um 
oh it ' s the 
yeah . 
the first run i ran of switchboard i got a hundred twenty percent word error . 
yeah . 
but 
so and what also this means is that 
right . 
not switchboard . 
um 
uh broadcast news . 
well it ' s 
i mean there ' s a bunch of things in this note to various people . 
especially i guess um with jane that that would help for 
since we have this new data now uh in order to go from the transcripts more easily to um just the words that the recognizer would use for scoring . 
i had to deal with some of it by hand but i think a lot of it can be automated by 
oh one thing i guess i didn ' t get 
so you know the language model was straight from from bigram from switchboard . 
the acoustic models were also from switchboard or or 
yeah . 
yeah . 
that ' s amazing . 
so they didn ' t have anything from this acoustic data in yet ? 
yeah so that ' s great . 
no . 
and actually we actually um used switchboard telephone bandwidth models . 
that ' s amazing . 
okay . 
yeah . 
which i guess 
i was just going to say . 
well that ' s those are the only ones there are . 
yeah . 
so that ' s the that ' s the only acoustic training data that we have a lot of . 
yeah . 
i mean 
right . 
and i guess ramana 
so a guy at s r i said that um there ' s not a huge amount of difference going from 
it ' s it ' s not like we probably lose a huge amount . 
right . 
but we won ' t know . 
because we don ' t have any full band models for conversational speech . 
it ' s probably not as bad as going using full band models on telephone band speech . 
so 
oh yeah . 
right ? 
right . 
right so it ' s so 
yeah . 
yeah . 
but for broadcast news when we we played around between the two there wasn ' t a huge loss . 
right it was not a big deal . 
yeah . 
so i 
i should i should say that the language model is not just switchboard . 
so that ' s good . 
although combining them worked well . 
it ' s also 
i mean there ' s uh actually more data is from broadcast news . 
but with a little less weight . 
yeah . 
uhhuh . 
like trent lott must have been from . 
uh because 
i guess switchboard was before . 
uhhuh . 
right . 
um by the way just for fun we also ran 
uh 
good point . 
i mean our complete system starts by doing a gender detection . 
uhhuh . 
so just for the heck of it i ran that . 
and it said a hundred percent male ? 
um and it might be reassuring for everybody to know that it got all the genders right . 
the 
oh it did ? 
yeah so 
oh that ' s i ' m glad . 
it got all two genders ? 
yeah . 
but you know jane and adam have you about equal performance . 
yeah . 
yes . 
and uh and that ' s interesting . 
because i think the their language models are quite different . 
so 
and i i ' m pretty sure from listening to eric that you know given the words he was saying and given his pronunciation that the reason that he ' s so much worse is the lapel . 
right . 
that makes a lot of sense . 
yeah . 
so it ' s nice now if we can just sort of eliminate the lapel one when when we get new microphones . 
yeah . 
very possible . 
yeah . 
i i i would bet on that too . 
that would be worth it . 
um 
because he certainly in that when as a as a burp user he was he was a pretty uh strong one . 
sheep . 
yeah . 
he he he sounded to me just from he sounded like a 
yeah . 
what ' s it a sheep or a goat ? 
a sheep . 
baah . 
sheep . 
sheep . 
right . 
yeah . 
sheep is good . 
sounded good . 
yeah . 
right so um so i guess the good news is that 
uhhuh . 
and and again this is without a lot of the sort of bells and whistles that we can do with the s r i system . 
and we ' ll have more data and we can also start to maybe adapt the language models once we have enough meetings . 
so this is only twenty minutes of one meeting with no no tailoring at all . 
i mean clearly there are um with just a small amount of uh actual meeting transcriptions uh thrown into the language model you can probably do quite a bit better . 
yeah . 
because the 
or just dictionary . 
the the vocabulary especially . 
yeah . 
yeah so 
not that much the vocabulary actually . 
i think um well we have to see . 
but it ' s uh 
yeah . 
it ' s pretty good . 
um so then 
have to add p z m and so on . 
and i have to try it on the far field mike . 
but 
yeah . 
p z m . 
and then there ' s things like for the transcription i got when someone has a digit in the transcript i don ' t know if they said you know one one or eleven . 
and i don ' t know if they said tcl or t c l . 
there ' s things like that where you know the um we ' ll probably have to ask the transcribers to indicate some of those kinds of things . 
but in general it was really good . 
and i ' m hoping 
and this is this is good news . 
because that means the force alignments should be good . 
and if the force alignments 
i mean it ' s good news anyway . 
but if the force alignments are good we can get all kinds of information . 
for example about you know prosodic information . 
and speaker overlaps and so forth directly from the aligned times . 
um so that ' ll be something that 
actually in order to assess the forced alignment um we need some linguists or some people to look at it and say are these boundaries in about the right place . 
because it ' s just going to give us time marks . 
well we ' ve done that for one meeting . 
but you know 
so 
for forced alignment . 
uh oh oh . 
not for words . 
right . 
i ' m sorry just for overlaps is we did it for not not for words . 
right . 
so this would be like if you take the words um you know and force align them on all the individual close talk uh close talking mikes then how good are these sort of in reality ? 
right . 
and then i was thinking it 
so we might want to take twenty minutes and do a closer word level transcription . 
maybe actually mark the word boundaries . 
oh . 
or have someone look at the alignments . 
uh maybe a linguist who can say um you know roughly if these are okay and how far away they are . 
yeah . 
um but i think it ' s got to be pretty good . 
because otherwise the word recognition would be really crummy . 
right right . 
it wouldn ' t necessarily be the other way around . 
if the word recognition was crummy the alignment might be okay . 
but if the word recognition is this good the alignment should be pretty good . 
so that ' s about it . 
i wonder if this is a good thing or a bad thing though . 
i 
i mean if we ' re 
that we ' re starting so well ? 
yeah if we ' re producing a data base that everybody ' s going to do well on 
oh 
don ' t worry about it . 
that ' s that ' s the close talking mikes . 
try it on the p z m ' s and and 
yeah . 
which i would which well 
yeah yeah yeah yeah . 
so the real value of the data base is these ? 
yeah 
well no but 
i mean there ' s still just the the percentages . 
and i mean they ' re not 
this 
as we ' ve talked about before there ' s probably overlaps . 
yeah . 
this is not that good . 
there ' s probably overlaps in in uh in fair number in switchboard as well . 
so 
but but there ' s other phenomena . 
it ' s a meeting . 
it ' s a different thing and there ' s lots of stuff to learn with the close talking mikes . 
but uh 
yeah certainly i ' d like to see as soon as we could . 
i mean maybe get some of the glitches out of the way . 
but soon as we could how well it does with say with the p z ms or maybe even one of the 
right . 
and uh see if it ' s you know 
is it a hundred twenty percent ? 
or maybe it ' s not . 
maybe if with some adaptation you get this down to fifty percent or forty five percent or something . 
and and then if for the p z m it ' s seventy or something like that . 
that ' s actually something we could sort of work with a little bit . 
yeah . 
no i think it ' s really 
so 
i mean this way we least have a baseline . 
we know that for instance the transcripts are very good . 
so once you can get to the words that the recognizer which is a total subset of the things you need to understand the the text . 
um yeah they ' re pretty good . 
so and and it ' s converting automatically from the x m l to the chopping up the wave forms and so forth . 
it ' s not the case that the end of one utterance is in the next segment and things like that which we had more problems with in switchboard . 
so that ' s good . 
and um let ' s see . 
there was one more thing i wanted to to mention . 
i can ' t remember . 
um 
sorry can ' t remember . 
anyway it ' s 
congratulations . 
is really great . 
well it was i mean i really didn ' t do this myself . 
yeah . 
yeah it ' s really good . 
so andreas set up this recognizer and 
by the way the recognizer all the files i ' m moving to s r i and running everything there . 
so i brought back just these result files . 
and people can look at them . 
um so 
we we talked about setting up the s r i recognizer here . 
that ' s you know if if there are more machines um uh here . 
plus people can could run their own uh you know variants of of of the recognition runs . 
um 
certainly doable . 
um 
yeah and 
well certainly if the recognition as opposed to training . 
yeah . 
seems reasonable . 
i need huh i need to ask one question . 
yeah . 
yeah . 
which is um so this issue of the uh legalistic aspects of the present you know pre adapted 
yeah well so what i mean is 
um 
the uh the data that you take into s r i first first question . 
you ' re maintaining it in in a place that wouldn ' t be publicly readable that that kind of stuff . 
right ? 
um 
from the outside world or 
by uh people uh who are not associated with this project . 
it ' s human subjects issues . 
oh . 
i told you about that . 
exactly . 
um oh . 
well okay . 
we have no names . 
although i um 
that that ' s not the issue . 
it ' s just the audio data itself . 
audio data itself ? 
until people have a chance to edit it . 
uhhuh exactly . 
uh so well i can i can protect my directories through there . 
yeah . 
great . 
right now they ' re not they ' re in the speech group directories which so i will 
i didn ' t know that actually . 
yeah so we just have to go through this process of having people approve the transcriptions . 
yeah okay . 
say it ' s okay . 
yeah we had to get them to approve them . 
right okay . 
and then because because the other question i was going to ask is if we ' re having um you know it ' s 
but this this meeting that you have no problem . 
because i i well i mean i i speak for myself . 
it ' s us . 
but but i think that we didn ' t do anything that but 
well anyway so uh i wouldn ' t be too concerned about it with respect to that . 
although we should clear it with eric and dan of course . 
but these results are based on data which haven ' t had the uh haven ' t had the chance to be reviewed by the subjects . 
that ' s true . 
and i don ' t know how that stands . 
i mean if you if you get fantastic results and it ' s involving data which which later end up being lessened by you know certain elisions then i don ' t know . 
but i wanted to raise that issue . 
that ' s all . 
well we 
i mean once we get all this streamlined it may be it 
hopefully it will be fairly quick . 
but we get the transcriptions people approve them and so on . 
all right . 
it ' s just that we ' re 
we need to work at a system for doing that approval so that we can send people the transcripts . 
great . 
huh . 
yeah . 
and get back any bleeps that they want . 
yeah actually the bleeps are also an issue i thought . 
it ' s going to be a rare thing that there ' s a bleep for the most part . 
uh actually i had a question about the down sampling . 
um i don ' t know who i mean how this was done . 
but is is there are there any um issues with down sampling ? 
don did this . 
because i know that the recognizer um that we use can do it sort of on the fly . 
um 
so we wouldn ' t have to have it uh you know do it uh explicitly beforehand . 
and is there any um 
are there other uh is there more than one way to do the down sampling where one might be better than another ? 
there are lots of there are lots of ways to do the down sampling um different filters to put on . 
okay . 
right . 
like anti aliasing stuff . 
okay . 
so so the 
i don ' t think we even know which one . 
i assume you ' re using syn cat to do it ? 
no i ' m using uh s n s n d uh are resample . 
or sound resample ? 
resample . 
yeah . 
yeah and dan ' s archaic acronyms . 
r s m p . 
yeah i don ' t really . 
missing all the vowels . 
i just yeah i found it . 
not all of them . 
some of the vowels . 
almost all the vowels . 
that ' s the hard part . 
so so the other thing we should try is to just take the original wave forms . 
and a few of the consonants . 
i mean segment them but not down sample them . 
yeah we could we could try that and and compare . 
yeah that ' s 
and and feed them to feed them to the s r i recognizer and see if if the s r i front end does something . 
yeah . 
i suspect that ' s sort of premature optimization . 
but 
sure . 
we can try it . 
i i only down sampled them first because i was 
i mean that ' s just one line that ' s one line of code to comment at . 
well 
yeah . 
right and and it doesn ' t is no more work for um you know for us . 
so 
uhhuh . 
yeah . 
well they ' re just bigger to transfer . 
that ' s why i down sampled them before but 
well but they ' re only twice as big . 
so 
well i mean that was if it ' s the same then we can down sample here . 
i mean it ' s it ' s just a 
but if it ' s 
although those eighty meg files take a while to copy into my directories . 
so 
yeah . 
but 
no . 
i mean it ' s not it wouldn ' t be a problem if you ' re interested in it . 
we could try that . 
it would 
yeah i mean it would be uh you know it would probably take uh about um you know 
minus the transfer time it would it would take uh you know ten minutes to try and and and 
yeah . 
it ' s about a fifty minute drive ? 
right ? 
well it takes more disk space too . 
and and if for some reason we see that it works better then we might investigate why . 
so i was just 
and you know what 
huh . 
yeah . 
in the front end we could do that . 
yeah . 
so you just train just different filters ? 
yeah i 
and so you ' re just wondering whether the filter is 
yeah i can imagine it would be . 
right . 
right . 
i mean i guess there ' s some 
so we could try that with this particular twenty minutes of speech and sort of see if there ' s any differences . 
you know at some point someone might have optimized whatever filtering is done for the actual recognition um performance . 
huh . 
so in other words 
right . 
right . 
it just seems to me that you know small changes to the language model and the vocabulary will so swamp that that it may be premature to worry about that . 
so 
i mean so one is a half a percent better than the other . 
i don ' t think that gives you any information . 
well it ' s just as easy to to give you the sixteen k individual . 
yep . 
it was just more disk space you know for storing them . 
are you are you using uh uh mel cepstrum or p l p over there ? 
so 
mel cepstrum . 
so probably doesn ' t matter . 
well we could try . 
there ' s there ' s your answer . 
but but it wouldn ' t hurt to try . 
could easily try . 
that ' s what i would assume but you never know . 
yeah . 
so 
you know ? 
sure . 
just uhhuh . 
no the reason i say this 
p l p uses uh auto regressive filtering and uh modeling and so it can be sensitive to the kind of filtering that you ' re doing . 
uhhuh . 
but uh uh mel cepstrum uh might not you wouldn ' t expect to be so much . 
but 
well we can try it if you generate like the same set of files just up to that point where we stopped anyway . 
and just stick them somewhere . 
yeah it ' s it ' s really not a problem . 
and i ' ll rerun it with 
actually no . 
don ' t stop . 
keep going . 
don ' t stop at that part because we ' re actually using the entire conversation to estimate the speaker parameters . 
yeah . 
so shouldn ' t use you should you know get 
yeah i mean i ' ll i have to do is uh the reference file would stay the same . 
okay . 
yeah . 
right . 
it ' s just the individual segments would be approximately twice as long . 
huh . 
right . 
right . 
and i could just replace them with the bigger ones in the directory . 
that ' s not a problem . 
yeah . 
right . 
i mean i corrected all 
i mean i hand edited the whole the whole meeting . 
so that can be run . 
it ' s just 
once we get the the bug out . 
huh . 
one one question which is i i had the impression from this from this meeting that that i transcribed that um that there was already automatic down sampling occurring . 
yeah . 
uhhuh . 
is that 
i thought that in order to 
yep . 
so it was so it ' s like there ' s already down 
there ' s one level that ' s already happening right here . 
okay . 
this is being recorded at forty eight kilohertz which is more that anybody needs . 
oh . 
right . 
and it gets down sampled to sixteen . 
okay . 
and that ' s actually said in your meeting . 
so 
huh . 
oh okay . 
that ' s how i know that . 
that ' s exactly and that ' s how i know it . 
yeah . 
i i it ' s like are we down sampling to sixteen ? 
it ' s a digital audio orientation for the board . 
right . 
it ' s in the monitor so it ' s 
huh . 
thank god it ' s not more than that ! 
so 
is eight kilohertz is is eighty kilohertz generally accepted as like standard for voice ? 
yeah . 
and i have no idea what filter it ' s using . 
so 
telephone . 
for telephone stuff . 
telephone . 
yeah that ' s what i was going to say . 
i mean like 
so 
so it ' s it ' s it ' s just that they were operating from switchboard which was a completely telephone data base . 
oh i see . 
so 
okay . 
and so that was a standard for that sixteen 
so sixteen seems to be pretty typical for with this sort of thing . 
right . 
sixteen is more common for for uh broadband stuff that isn ' t 
that isn ' t music . 
that isn ' t music and isn ' t telephone . 
and i guess if you ' re comparing like uh if you want to run recognition on the p z m stuff you would want you don ' t want to down sample the that . 
yeah . 
why is that ? 
right ? 
i don ' t know . 
well i i mean if it ' s any better . 
no actually i would think that you would you would get better you ' d get better high frequencies in the local mike . 
all the way around i ' d think . 
uh but who knows ? 
yeah . 
yeah . 
i mean we we we we we we want to find all this stuff out . 
well we could try it . 
we don ' t know . 
we ' re going to have plenty of low frequency on the p z m ' s with the fans . 
okay . 
yeah . 
uh yeah . 
yeah . 
oh yeah . 
there was just one more thing i wanted to say which is totally unrelated to the recognition except that 
um 
well well it ' s sort of related . 
but um 
good news also . 
uh i got 
well chuck fillmore agreed to record meetings but he had too many people in his meetings . 
and that ' s too bad because they ' re very animated . 
and but uh jerry also agreed so uh we ' re starting on on 
they ' re less animated . 
well but he has fewer 
he he won ' t have more than eight . 
and it ' s a meeting on even deeper understanding e d u . 
so that sounds interesting . 
dot e d u ? 
as a compliment to our front end meeting . 
and um so that ' s going to start monday . 
and one of the things that i was realizing is um it would be really great if anyone has any ideas on some kind of time synchronous way that people in the meeting can make a comment to the person whose going to transcribe it . 
or or put a push a button or something when they want to make a note about oh boy you should probably erase those last few . 
or uh wait i want this not to be recorded now . 
or uh something like that 
weren ' t we going to do something with a pad at one point ? 
the cross pads ? 
yeah we could do it with the cross pads . 
because i was thinking you know if if the person who sets up the meeting isn ' t there and it ' s a group that we don ' t know 
um and this came up talking to to jerry also . 
that you know is there any way for them to indicate to make sure that the request that they have that they make explicitly get addressed somehow ? 
yeah . 
so i don ' t know if anyone has ideas . 
or you could even write down oh it ' s about three twenty five and 
well what i was just suggesting is is we have these this cross pad just for this purpose . 
yeah and use that . 
not a bad idea . 
and just use that . 
that would be great . 
and if we sink it in 
the other thing is uh 
that be great . 
i don ' t know if you know this or if it ' s a question for the mail to dan . 
but is this thing of two eight channel boards a maximum for this setup or could we go to a third board ? 
i don ' t know . 
i don ' t know . 
i ' ll send mail to dan and ask . 
i i think that it ' s the maximum we can do without a lot of effort . 
because it ' s one board with two digital channels . 
oh it is one board . 
eight each . 
so it it takes two fibers in to the one board . 
and so i think if we want to do that more than that we ' d have to have two boards . 
and then you have the synchronization issue . 
but that ' s a question because that would 
if it was possible because it is 
you know already we have a a a group of people in this room that cannot all be miked . 
right . 
and it ' s not just because we haven ' t been to the store . 
right ? 
it ' s 
what is the limit on each of those fiber channels ? 
is it the 
eight . 
it just it ' s eight channels come in ? 
it ' s eight . 
does it have do with the sampling rate ? 
i have no idea . 
but each each fiber channel has eight eight channels . 
and there are two two fibers that go in to the card . 
it might be a hard limitation . 
so 
i mean one thing is it the whole thing as i said is is all structured in terms of forty eight kilohertz sampling . 
so that pushes requirements up a bit . 
yeah . 
i was just wondering if if that could change . 
but 
i mean then we ' d also have to get another a d d and another mixer and all that sort of stuff . 
if we could drop that . 
yeah . 
so i i ' ll send a mail to dan and ask him . 
yeah . 
okay on the uh 
are we done with that ? 
so the topic is uh getting more mikes and different mikes . 
so i got a quote . 
um 
we can fit we have room for one more wireless . 
and the wireless 
this unit here is three fifty three hundred fifty dollars . 
it i didn ' t realize but we also have to get a tuner the receiver the other end . 
that ' s uh four thirty . 
um and then also 
wow ! 
for for each ? 
i mean the tuner is four thirty for each ? 
yep . 
wow ! 
and we just need one more so so 
yeah at least we got the good ones . 
yeah . 
so that ' s you know something like seven hundred eighty bucks for one more of these . 
yeah . 
okay . 
um and then also um it turns out that the connector that this thing uses is proprietary of sony . 
oh ! 
believe it or not . 
and sony only sells this headset . 
huh . 
so if we want to use a different set headset the solution that the guy suggested and they apparently lots of people have done is sony will sell you the jack with just wires coming out the end . 
and then you can buy a headset that has pigtail and solder it yourself . 
and that ' s the other solution . 
and so the jacks are forty bucks apiece . 
and the he recommended um a crown c m three eleven a e headset for two hundred bucks apiece . 
there isn ' t this some sort of thing that plugs in ? 
you actually have to go and do the soldering yourself ? 
the reason is the only only thing you can get that will plug into this is this mike or just the connector . 
no i understand . 
the reason i ask is these sort of handmade uh wiring jobs fall apart in use . 
so the other thing is to see if we can uh get them to do a custom job and put it together for this . 
oh i ' m sure they would they would just charge us . 
well and they ' d probably want quantity too . 
so 
they ' d 
well . 
no they ' ll just charge us more . 
so it ' s this 
huh . 
so so my question is should we go ahead and get nine identical head mounted crown mikes ? 
not before having one come here and have some people try it out . 
okay . 
because there ' s no point in doing that if it ' s not going to be any better . 
so why don ' t we get one of these with the crown with a different headset ? 
yeah . 
and and see if that works . 
and see if it ' s preferable and if it is then we ' ll get more . 
comfort . 
yeah . 
yeah . 
because i mean i think the microphones are okay . 
it ' s just the the 
right . 
it ' s just they ' re not comfortable to wear . 
right . 
could make our own handbands and 
um and he said they don ' t have any of these in stock but they have them in l a . 
and so it will take about a week to get here . 
yeah well it ' s 
um so okay to just go order ? 
we ' re in this for the long term . 
yeah . 
just order it . 
it ' s a lot of money for a handband . 
okay . 
and who is the contact if i want to do an invoice ? 
yeah . 
because i think that ' s how we did it before . 
uh we ' ll do this off line yeah . 
it ' s a long time to get from l a . 
okay . 
and then nine channels is the maximum we can do . 
so 
uh right . 
without getting more stuff . 
because 
so one is for the daisy chain so that ' s fifteen instead of sixteen . 
and there ' s six on the table . 
right . 
so that ' s nine . 
can i ask a really dumb question ? 
yeah . 
probably . 
is is there any way we can have you know like a a wireless microphone that you pass around to the people who you know the extra people for the times they want to talk that 
i mean 
that ' s a good idea . 
that ' s not a dumb question . 
it ' s a good idea . 
well i mean 
like uh like you know jerry springer thing . 
i ' m just not sure how we would handle that in the 
yeah . 
that ' s like the conch . 
well but 
like at conferences ? 
well but there might be a way to say that there are going to be these different people . 
you know 
see look . 
so nail the chairs down . 
um and i don ' t know identifying somehow ? 
yeah . 
yeah somehow . 
you know i was just thinking of jerry springer . 
it ' s not a bad idea . 
no that no no . 
that ' s a very 
if we can ' t get another board and even if we can i have a feeling they ' ll be some work . 
i mean for the few times that you might want to have that . 
the springer mike . 
let ' s figure that we have eight which are set up . 
and then there ' s a ninth which is passed around to 
a handheld . 
yeah . 
that ' s a good idea . 
infinite expansion . 
right . 
kind of rules out overlap . 
but but uh 
well or also for you know if people are not 
yeah . 
well we could just hand around the lapel . 
uh no . 
rather than get a 
no that ' s 
do you want a handset ? 
no not the lapel . 
no . 
well i mean is the is the handheld really any better ? 
liz hates the lapel . 
yes . 
okay . 
i don ' t know . 
but i i know the lapel is really suboptimal . 
no it 
is awful ? 
no it depends on the handheld . 
but hand many hand helds are built with sort of uh anti shock sort of things so that it it is less uh susceptible to hand noises . 
uhhuh . 
if you hold the lapel mike you just get all sorts of junk . 
right . 
okay . 
i mean the ones they really pass around must be sort of okay . 
so 
so i wonder if they have one that will hook up . 
yeah . 
they have 
what ? 
i wonder if they have one that will hook up to this or whether again we ' ll have to wire it ourselves . 
well you wouldn ' t want it to hook there . 
you ' d just want it to hook into the receiver in the other room . 
right ? 
no that ' s uh 
you need a transmitter . 
what ? 
is isn ' t that built into the mike ? 
oh i see . 
get a get a different radio . 
yeah . 
yeah just these ones that they pass around with no you know wireless . 
yeah . 
but you need a but it has to correspond to the receiver . 
have a little antenna coming out the bottom . 
it ' s going to be much easier to get one of these and just plug in a mike . 
isn ' t it ? 
but then the mike has to 
do you have to hand it around ? 
and if you have two pieces of 
yeah . 
no no . 
right . 
so right . 
so this is a good point . 
so yeah you have these these mikes with a little antenna on the end . 
okay . 
right ? 
and do you think you would be able to use the same receiver ? 
i don ' t know . 
okay i ' ll i ' ll ask . 
you ' ll have to check with them . 
yeah . 
yeah . 
it ' s just a frequency . 
but that ' s that ' s a great idea . 
and then just sort of have that as the and then you can have groups of twenty people or whatever . 
and and uh 
yeah because there ' s only i mean as andreas pointed out actually i think in the large the larger the group the less interaction the less people are talking um over each other . 
pretty soon . 
huh yeah . 
it just there might be a lot of people that speak once or twice . 
and 
right . 
um got to go . 
off you go . 
yeah . 
okay . 
so i guess people who have to leave can leave . 
and do we have anything else to discuss or should we just do digits ? 
i i thought of some extra a couple of extra things i ' d like to mention . 
okay . 
one of them is to give you a status in terms of the transcriptions so far . 
so um as of last night um i ' d assigned twelve hours and they ' d finished nine . 
uh yep . 
and my goal was to have eleven done by the end of the month . 
i think that by tomorrow we ' ll have ten . 
uh it ' s great . 
so they ' re still working . 
pretty close . 
wow ! 
i and this i got this email from jane at like two in the morning or something . 
that ' s good . 
that ' s good . 
so it ' s really great . 
it ' s working out thanks . 
it ' s really great . 
thanks . 
and then um also an idea for another meeting which would be to have the transcribers talk about the data . 
it ' s sort of a a little bit a little bit 
that ' s a great idea . 
yep . 
super idea . 
that ' d be very interesting . 
yeah . 
that ' s a great idea because i ' d like to have it recorded so that we can remember all the little things . 
i ' d love to hear what they have to say . 
yeah . 
so if we got them to talk about this meeting it would be a meta meta meeting . 
that ' s a great idea . 
yeah . 
yeah exactly . 
i guess nested several layers . 
now you have eight transcribers and there ' s ten of us . 
but 
so how do we do this is the only thing ? 
or just have them talk amongst themselves . 
have them have their own meeting . 
well that ' s what i ' m thinking . 
and have 
yeah . 
oh . 
have them talk about the data and they and they ' ve made observations to me . 
that would be great . 
like they say uh you know this meeting that we think has so much overlap in fact it does . 
but there are other groups of similar size that have very little . 
you know it ' s part of it ' s it ' s the norm of the group and all that . 
and they have various observations that would be fun i think . 
that ' s a great idea . 
yeah i ' d like to hear what they say . 
yeah . 
be great . 
okay . 
so maybe we could they could have a meeting more or less without us that to do this and we should record it . 
and then maybe one or two of them could come to one of these meetings and and could you know could tell us about it . 
yeah . 
give us a status . 
yeah . 
oh good . 
okay . 
yeah . 
what what 
that would be weird . 
it ' s they will get to transcribe their own meeting but they also get paid for having a break . 
yeah that ' s right . 
and i think that ' s a good idea . 
yeah exactly . 
yeah . 
get them involved . 
yeah . 
great . 
um that ' s a great idea . 
great . 
super . 
i ' m really sorry i have to 
no i have to go as well . 
okay . 
and then i wanted to also um say something about the fiscus uh uh john john fiscus visit tomorrow . 
and which is to say that it ' ll be from nine to one . 
that i ' m going to uh uh offer the organization allow him to uh adjust it if he wishes . 
but to be basically in three parts . 
the acoustic part coming first which would be basically the room engineering aspects . 
um other things . 
and he ' ll be also presenting what nist is doing . 
and and uh then uh 
number two would be sort of a the the transcription process . 
so this would be a focus on like presegmentation and the modifications to the the multitrans interface . 
which allows more refined encoding of the beginnings and ends of the overlapping segments . 
which uh dave gelbart ' s been doing . 
and then um uh and of course the presegmentation thilo ' s been doing . 
and then um the third part would 
and again he has some stuff that ' s relevant with respect to nist . 
and then the third one would be focus on transcription standards . 
so at nist he ' s interested in this establishment of a global encoding standard i guess i would say . 
and i want it . 
you know 
yeah . 
see what they ' re doing and also present what what we ' ve chosen as ours and and discuss that kind of thing . 
and so but he ' s only here until until one . 
and actually we ' re thinking of noon being uh lunch time . 
so basically hoping that we can get as much of this done as possible before noon . 
okay . 
and everybody who wants to attend is welcome . 
so 
yeah . 
oh where you ' re going to meet ? 
here mostly . 
but i ' ve also reserved the barco room um uh to figure out how that works in terms of like maybe having a live demonstration . 
okay . 
but the nine nine o ' clock will be be in here ? 
yeah . 
uhhuh . 
yeah okay . 
i assume we ' re not going to try to record it ? 
oh i think that would be hard yeah . 
yeah i think just adds 
all right . 
yeah . 
um good . 
thank you though . 
uhhuh . 
so maybe do digits and recess ? 
yeah . 
unless there ' s anything else ? 
yeah . 
do digital ones ? 
uh okay . 
yeah . 
uh should we make him wear andreas ' mike or would that just be too confusing ? 
yeah . 
no i don ' t think it ' s confusing . 
well it doesn ' t confuse me . 
when we do this in the key in the key in the key it has to indicate that channel change . 
does it mess up the forms ? 
right ? 
uh yeah i just don ' t know how we would do that . 
so 
well have a time mark . 
i mean other than free free form . 
the on switch is here on the on the top there . 
yeah . 
okay . 
and just clip it to your collar . 
that ' s fine . 
okay my name is uh espen eriksen . 
i ' m a norwegian . 
um uh this is my second semester at berkeley . 
currently i ' m taking uh my first graduate level courses in d s p . 
and um when i come back to norway i ' m going to continue with the more of a research project work kind of work . 
so this semester i ' m starting up with a with a small project through uh dave gelbart which i ' m taking a course with . 
i got in touch with him and he told me about this project . 
so with the help of uh dan ellis i ' m going to do small project associated to this . 
what i ' m going to try to do is uh use use echo cancellation to uh to handle the periods where you have overlapping talk . 
to try to do something about that . 
so currently i ' m um i ' m just reading up on echo cancellation . 
looking into the theory behind that . 
and then uh hopefully i get some results . 
so it it ' s a it ' s a project goes over the course of one semester . 
great . 
so i ' m just here today to introduce myself . 
tell about 
i ' ll be i ' ll be working on this . 
and are you staying at berkeley ? 
or is are you just here a semester ? 
this is my second semester and last . 
uh second and last . 
so i leave 
okay . 
yeah . 
he ' s in the he ' s in the two two five d course . 
yeah i ' m in morgan ' s course . 
so 
yeah . 
yeah . 
good . 
welcome . 
then you then you go back to norway ? 
that ' s 
yeah . 
okay . 
we were just talking about something like this yesterday . 
or 
yeah yesterday with liz . 
about doing some of the echo cancellation stuff or possibly the spectroanalysis over the overlaps . 
so 
cool . 
yeah . 
okay . 
digits ? 
let ' s do digits . 
headphones that aren ' t so uncomfortable . 
huh . 
i think well this should be off the record . 
but i think 
uh okay . 
we ' re not recording yet are we ? 
well i don ' t think 
no . 
no uh that that wasn ' t recorded . 
um i don ' t think they ' re designed to be over your ears . 
yeah i know . 
it just it really hurts . 
it gives you a headache . 
like if you 
temple squeezers . 
on your temple 
yep . 
yeah . 
yeah . 
uhhuh . 
but i definitely haven ' t figured it out . 
um meeting recorder meeting . 
i guess i have to stop doing this sigh of contentment you know after sipping cappuccino or something . 
yeah with the we i know . 
sip sigh . 
i was just noticing a big 
we know exactly how much you have left in your cup . 
so are we recording now ? 
is this 
yeah . 
oh we ' re we ' re we ' re live . 
okay . 
yeah . 
so uh what were we going to talk about again ? 
so we said we said data collection which we ' re doing . 
were we going to do digits ? 
okay do we do do you go around the room and do names or anything ? 
i think that 
it ' s a good idea . 
usually we ' ve done that . 
and also we ' ve done digits as well . 
but i forgot to print any out . 
so 
besides with this big a group . 
it would take too much time . 
no it ' d be even better with this big 
you can write them on the board if you want . 
which way is 
yeah but it takes too much time . 
mari . 
what 
what ? 
i think your your your thing may be pointing in a funny direction . 
it ' s not that long . 
sort of it ' s it helps if it points sort of upwards . 
whoops ! 
sort of it 
you know . 
yeah . 
would it 
so that thing the little that part should be pointing upwards . 
so 
oh this thing . 
that ' s it . 
yeah . 
otherwise you just get a heartbeats . 
yeah . 
it ' s kind of 
oh yeah the element . 
yeah should be as close to you your mouth as possible . 
yeah . 
that ' s good . 
okay . 
that kind of thing is good . 
it ' s a 
this 
all right . 
yeah . 
oh yeah . 
yeah . 
how ' s that working ? 
it ' s a 
it ' s working . 
okay . 
all right . 
so what we had was that we were going to talk about data collection . 
and um uh you you put up there data format . 
um 
and other tasks during data collection . 
so i think the goal the goal was what can we do how can you do the data collection differently to get 
and 
what can you add to it to get um some information that would be helpful for the user interface design ? 
like 
uh especially for querying . 
especially for querying . 
so getting people to do queries afterwards . 
getting people to do summaries afterwards . 
um 
well one thing that came up in the morning in the morning was the um 
uh if he i um 
if he has 
i i don ' t remember . 
mister doctor landry ? 
landay . 
landay james . 
so he has um these uh um tsk note - taking things . 
then that would sort of be a summary which you wouldn ' t have to solicit . 
uhhuh . 
if if we were able to to do that . 
well if if you actually take notes as a summary as opposed to take notes in the sense of taking advantage of the time stamps . 
so action item or uh reminder to send this to so - and - so blah blah blah . 
uhhuh . 
so that wouldn ' t be a summary . 
that would just be that would relate to the query side . 
uhhuh . 
but if we had the crosspads we could ask people you know if if something comes up write it down and mark it somehow . 
you know . 
right i mean we because you ' d have several people with these pads you could collect different things . 
i mean because i tend to take notes which are summaries . 
right . 
and so you know 
i mean the downside to that is that he sort of indicated that the uh quality of the handwriting recognition was quite poor . 
well 
but that ' s all right . 
i don ' t think there ' d be so many that you couldn ' t have someone clean it up . 
so 
pretty easily . 
yeah we also could come up with some code for things that people want to do so that for frequent things . 
yeah . 
and the other things people can write whatever they want . 
i mean it ' s to some extent uh for his benefit . 
so 
if that you know if if we just keep it simple then maybe it ' s still useful . 
right . 
yeah . 
i just realized we skipped the part that we were saying we were going to do at the front where we each said who we were . 
the roll call . 
right . 
roll call . 
i thought you did that on purpose . 
but anyway shall we do the roll call ? 
no not 
no i just my mind went elsewhere . 
so 
uh yeah i ' m morgan . 
and 
where am i ? 
i ' m on channel three . 
and i ' m adam janin on channel a . . 
i ' m jane edwards i think on channel b . . 
i ' m dan ellis . 
eric on channel nine . 
liz on channel one . 
mari on channel zero . 
katrin on channel two . 
should we have used pseudo names ? 
should we do it a second time with pseudo 
no no . 
i ' m rocky raccoon on channel 
and uh do you want to do the p . d . a . ' s and the p . z . m . ' s ? 
let me uh turn that off . 
oh p . z . m . nearest nearest next nearest . 
next one . 
next nearest . 
far . 
furthest . 
p . d . m . right . 
p . z . a . right . 
p . d . a . right . 
p . d . a . left . 
okay . 
thanks . 
yeah and eventually once this room gets a little more organized the jimlets will be mounted under the table . 
and these guys will be permanently mounted somehow . 
you know probably with double sided tape . 
but so 
you so we won ' t have to go through that . 
huh . 
i have a question on protocol in these meetings . 
which is when you say jimlet and the person listening won ' t know what that is how how do we get is that important information ? 
you know the jimlet 
i mean the box that contains the 
well i mean suppose we broaden out and go to a range of meetings besides just these internal ones . 
there ' s going to be lots of things that any group of people who know each other have in column common that we will not know . 
uhhuh . 
right . 
okay . 
right . 
so there will be jargon that we there ' ll be transcription errors . 
good . 
yeah . 
okay . 
i mean we we were originally going to do this with v . l . s . i . design . 
and and and the reason we didn ' t go straight to that was because immediately ninety percent of what we heard would be jargon to to us . 
so 
well that was just one of the reasons . 
but yeah definitely . 
yeah . 
okay good . 
that that ' s right . 
there were others of course . 
yeah . 
okay so we were on the data collection and the summary issue . 
right . 
we can go back . 
so 
uh 
so actually there ' s kind of three issues . 
there ' s the crosspad issue . 
should we do it and if so what ' ll we have them do ? 
um do we have people write summaries ? 
everybody or one person ? 
and then do we ask people for how they would query things ? 
there ' s there ' re sub problems in that . 
is that 
in that where or when do you actually ask them about that ? 
i mean that was one thing i was thinking about was is that dan said earlier that you know maybe two weeks later which is when you would want to query these things you might ask them then . 
right . 
right . 
but there ' s a problem with that in that if you ' re not 
if you don ' t have an interactive system it ' s going to be hard to go beyond sort of the first level of question . 
right . 
right ? 
and explore the data further . 
right . 
so 
and 
there ' s there ' s another problem . 
which is um we certainly do want to branch out beyond uh uh recording meetings about meeting recorder . 
and uh once we get out beyond our little group the people ' s motivation factor uh reduces enormously . 
and if we start giving them a bunch of other things to do 
how you know we we did you know another meeting here for another group . 
and and uh they were fine with it . 
but if we ' d said okay now all eight of you have to have to come up with uh the 
well i asked them to . 
and none of them did . 
see ? 
uhhuh . 
so i i asked them to send me ideas for queries after the meeting . 
there we go . 
they 
and no one ever did . 
uhhuh . 
i didn ' t follow up either . 
so i didn ' t track them down and say please do do it now . 
yeah . 
but uh no one spontaneously provided anything . 
i ' m worried that if you did even if you did push them into it it it it might be semi random . 
right . 
uh as opposed to what you ' d really want to know if you were going to use this thing . 
right . 
i just don ' t know how else to generate the queries other than getting an expert to actually listen to the meeting and say that ' s important . 
okay . 
that might be a query . 
tsk . 
well there is this other thing which which you were alluding to earlier which is um there are certain key words like you know action item and things like that . 
which could be used in uh to some degree finding the structure . 
although 
yeah . 
and and i also um was thinking with reference to the uh note - taking . 
the advantage there is that you get structure without the person having to do something artificial later . 
and the third thing i wanted to say is the summaries afterwards . 
um i think they should be recorded instead of written . 
because i think that um it would take so long for people to write that i think you wouldn ' t get as good a summary . 
how about this idea ? 
that normally at most meetings somebody is delegated to be a note taker . 
yeah good . 
good point . 
yeah . 
and so why don ' t we just use the notes that somebody takes ? 
i mean that gives you a summary . 
but it doesn ' t really 
how do you generate queries from that ? 
well but i mean maybe a summary is one of the things we ' d want from the output of the system . 
yeah . 
right ? 
right . 
i mean they ' re something . 
it ' s a a kind of output you ' d like . 
actually 
uh james and i were talking about this during one of the breaks . 
and so 
and the problem with that is i ' m definitely going to do something with information retrieval . 
even if it ' s sort of not full bore what i ' m going to do for my thesis . 
right . 
i ' m going to do something . 
i ' m not going to do anything with summarization . 
and so if someone wants to do that that ' s fine . 
but it ' s not going to be me . 
well i think that we i mean the the the core thing is that you know once we get some of these issues nailed down we need to do a bunch of recordings . 
well 
and send them off to i . b . m . 
and get a bunch of transcriptions . 
even if they ' re slightly flawed . 
yep . 
or need some other 
and then we ' ll have some data there . 
and then we can start looking and thinking what do we want to know about these things . 
yeah . 
and at the very least . 
uhhuh . 
i actually want to say something about the note pad . 
yeah . 
so if you could sense just when people are writing and you tell them not to doodle or try not to be using that for other purposes and each person has a note pad they just get it when they come in the room then you you can just have a fff plot of you know who ' s writing when . 
huh . 
activity . 
that ' s all you 
yeah . 
and you can also have notes of the meeting . 
but i bet that ' s that will allow you to go into the sort of the hot places where people are writing things down . 
uhhuh . 
oh i see . 
i mean you can tell when you ' re in a meeting when everybody stops to write something down that something was just said . 
uhhuh . 
it may not be kept in the later summary . 
but at that point in time is was something that was important . 
uhhuh . 
and that wouldn ' t take any extra 
that ' s a nice idea . 
or someone could just you could just put your hand on the pad . 
it 
uhhuh . 
uhhuh . 
and go like that if you want to . 
that ' s a good idea . 
it ' s 
but that doesn ' t 
maybe i ' m missing something . 
but that doesn ' t get to the question of how we come up with queries right ? 
well then you can go to the points where the you could actually go to those points in time . 
well what it does 
and find out what they were talking about . 
and you 
yeah . 
well what it does is provide a different 
and 
uh 
i i think it ' s an interesting thing . 
i don ' t think it gets at the the queries per se . 
but it does give us an information fusion sort of thing that you know you want to say what were the hot points of the meeting . 
yeah . 
that that ' s what i mean is that i think it gets at something interesting . 
but if we were asking the question which i thought we were of of of um how do we figure out what ' s the nature of the queries that people are going to want to ask of such a system knowing what ' s important doesn ' t tell you what people are going to be asking . 
but i bet it ' s a good superset of it . 
does it ? 
well see there are 
well yeah . 
i think you could say they ' re going to ask about uh when uh when did so - and - so talk about blah . 
and at least that gives you the word that they might run a query on . 
at least you can find the locations where there are maybe keywords . 
i mean this would tell you what the hit is . 
maybe . 
and 
not what the query is . 
what 
right right . 
right . 
it ' ll tell you the hit but not the query . 
but i think i think thinking about queries is a little bit dangerous right now . 
and so you could you can generate a query from the hits . 
but 
right . 
we don ' t even know what 
i mean if you want to find out what any user will use that might be true for one domain and one user . 
uhhuh . 
but i mean a different domain and a different user 
uhhuh . 
yeah but we ' re just looking for a place to start with that . 
um 
because you know what what what james is going to be doing is looking at the user interface . 
and he ' s looking at the query in in 
we we have five hours of pilot data of the other stuff . 
but we have zero hours of of of queries . 
so he ' s just sort of going where where do i where do i start . 
well you could do 
i think the summaries actually may help get us there . 
okay . 
for a couple reasons . 
one if you have a summary if you have a bunch of summaries you can do a word frequency count and see what words come up in different types of meetings . 
uhhuh . 
so action item is going to come up whether it ' s a v . l . s . i . meeting or speech meeting or whatever . 
so words that come up in different types of meetings may be something that you would want to query about . 
uhhuh . 
um the second thing you could possibly do with it is just run a little pilot experiment with somebody saying here ' s a summary of a meeting what questions might you want to ask about it to go back . 
yeah i think that ' s difficult . 
because then they ' re not going to ask the questions that are in the summary . 
well 
but i think it would give 
that ' s one one possible scenario though is you have the summary . 
uhhuh . 
and you want to ask questions to get more detail . 
yeah i think it has to be a participant . 
well it doesn ' t have to be . 
okay so that that is another use of meeting recorder that we haven ' t really talked about . 
which is for someone else . 
as opposed to as a remembrance agent . 
which is what had been my primary thought in the information retrieval part of it would be . 
but uh 
i guess if you had a meeting participant they could use the summary to refresh themselves about the meeting and then make up queries . 
but it ' s not 
uhhuh . 
i don ' t know how to do it if until you have a system . 
the summary is actually going to drive the queries then . 
yeah . 
huh . 
i mean your research is going to be very circular . 
yeah that that ' s what i was saying . 
yeah . 
but there is this um there is this class of queries which are the things that you didn ' t realize were important at the time . 
but in retrospect you think oh hang on didn ' t we talk about that . 
and it ' s something that didn ' t appear in the summary but you 
uhhuh . 
and that ' s kind of what this kind of uh complete data capture is kind of nicest for . 
right . 
right . 
because it ' s the things that you wouldn ' t have bothered to make an effort to record but they get recorded . 
right . 
so i mean and there ' s no way of generating those until we just until they actually occur . 
you know it ' s like 
but you could always post hoc label them . 
right right exactly . 
yeah . 
but i mean it ' s difficult to sort of say and if i was going to ask four questions about this what would they be . 
yeah . 
those aren ' t the kind of things that come up . 
but at least it would get us started . 
oh yeah . 
yeah sure . 
i also think that if if you can use the summaries as an indication of the important points of the of the meeting then you might get something like 
so if if the obscure item you want to know more about was some form of data collection . 
you know maybe the summary would say you know we discussed types of data collection . 
and you know and and maybe you could get to it by that . 
if you if you had the the larger structure of the of the discourse then if you can categorize what it is that you ' re looking for with reference to those those larger headings then you can find it . 
even if you don ' t have a direct route to that . 
huh . 
i think that 
although it seems like that ' s um a high burden on the note taker . 
that ' s a pretty fine grain that the note taker will have to take . 
maybe landay can put a student in to be a note taker . 
i 
no . 
i think you got to have somebody who knows the knows the topic or you know whose job it is delegated to be the note taker . 
no ? 
uhhuh . 
somebody who ' s part of the meeting . 
no i mean but someone who can come sit in on the meetings and then takes the notes with them that the real note taker 
but they 
and that way that one student has you know a rough idea of what was going on . 
and they can use it for their research . 
i mean this isn ' t really necessarily what you would do in a real system . 
uhhuh . 
because that ' s a lot of trouble . 
uhhuh . 
and maybe it ' s not the best way to do it . 
uhhuh . 
but if he has some students that want to study that then they should sort of get to know the people and attend those meetings . 
and get the notes from the note taker or something . 
right . 
huh . 
well i think that ' s a little bit of a problem . 
their sort of note - taking application stuff . 
they ' ve been doing for the last couple of years . 
and i don ' t think anyone is still working on it . 
i think they ' re done . 
yeah . 
um so i ' m not sure that they have anyone currently working on notes . 
so what we ' d have to interest someone in is the combination of note and speech . 
uhhuh . 
and so the question is is there such a person ? 
and i think right now the answer is no . 
i ' ve been thinking . 
we ' ll just have to see . 
i ' ve been thinking about it a little bit here about the uh this um 
i think that the 
now i ' m thinking that the summary a summary uh is actually a reasonable uh bootstrap into this into what we ' d like to get at . 
it ' s it ' s not ideal . 
but we you know we we have to get started someplace . 
so i was i was just thinking about um suppose we wanted to get 
we have this collection of meeting . 
we have five hours of stuff . 
uh we get that transcribed . 
so now we have five hours of meetings . 
and uh you ask me uh uh morgan what you know what kind of questions do you want to ask . 
uh i wouldn ' t have any idea what kind of questions i want to ask . 
i ' d have to get started someplace . 
so in fact if i looked at summary of it i ' d go oh yeah i was in that meeting . 
i remember that . 
um what was the part that 
and and i think that might then help me to think of things even things that aren ' t listed in the summary but just as a as a as a refresh of what the general thing was going on in the meeting . 
uhhuh . 
i think it serves two purposes . 
one as sort of a refresh to help bootstrap queries . 
uhhuh . 
yeah . 
but also i mean maybe we do want to generate summaries . 
well yeah that ' s true too . 
and then it ' s you know it ' s kind of a key . 
huh . 
yeah absolutely then you want to have it . 
so how does the summary get generated ? 
uh 
i ' m not against the idea of a summary . 
well 
by hand . 
but i wanted to think carefully about who ' s generating it . 
or 
and how 
because the summary will drive the queries . 
so 
what i i think you know in most meetings . 
this one being different . 
but in most meetings that i attend there ' s somebody explicitly taking notes frequently on a laptop . 
um you can just make it be on a laptop . 
uhhuh . 
so then you ' re dealing with ascii . 
and not somebody 
you don ' t have to go through handwriting recognition . 
um and then they post edit it into uh a summary . 
and they email it out for minutes . 
i mean that happens in most meetings . 
i i think that um there ' s we ' re using summary in two different ways . 
so what you just described i would describe as minutes . 
minutes . 
yeah . 
right . 
and what i originally thought was um if you asked someone what was the meeting about 
yeah . 
okay . 
and then they would say well we talked about this . 
huh . 
and then we talked about that . 
and so - and - so talked about . 
and then you ' d have like 
i my thought was to have multiple people summarize it on recording rather than writing . 
because writing takes time . 
and you get irrelevant other things that take time that 
uhhuh . 
whereas if you just say it immediately after the meeting 
you know a two minute summary of what the meeting was about i think you would get . 
uh with 
see i i also worry about having a single note taker . 
because that ' s just one person ' s perception . 
and um 
you know it it ' s it ' s relative to what you ' re focus was on that meeting . 
uhhuh . 
and and people have different major topics that they ' re interested in . 
so my proposal would be that it may be worth considering both of those types you know the note - taking and a spontaneous oral summary afterwards . 
okay . 
yeah . 
no longer than two minutes . 
adam you can 
from multiple people . 
yeah . 
you can correct me on this . 
but but uh my impression was that uh pretty much uh true that the meetings here nobody sits with a uh with a laptop . 
never . 
and 
never i ' ve never seen it at icsi . 
does anyone 
i mean dan is the one who who most frequently would take notes . 
dan . 
yeah . 
and 
i ' ve when we when we have other meetings . 
when i have meetings on the european projects we have someone taking notes . 
oh really ? 
in fact i often do it . 
yeah but those are bigger deal things . 
right ? 
yeah . 
where you ' ve got fifteen 
i mean most 
this is one of the larger meetings . 
most of the meetings we have are four or five people . 
that ' s true are four or five people . 
and you ' re not you don ' t have somebody sitting and taking minutes for it . 
yeah . 
you just get together and talk about where you are . 
right . 
so i think it depends on whether it ' s a business meeting or a technical discussion . 
culture . 
yeah . 
yeah . 
and i agree . 
technical discussions you don ' t usually have somebody taking notes . 
yeah . 
the i . ram meeting they they take notes every 
yeah . 
do they ? 
there ' s uh a person with a laptop at each meeting . 
how many people are those meetings ? 
there are more . 
i mean there are ten - ish . 
yeah . 
yeah . 
you should also have a record of what ' s on the board . 
they ' re very sparse . 
i mean i find it very hard to reconstruct what ' s going on . 
i i don ' t know how . 
yeah this is something early in the project we talked a lot about . 
i don ' t know how . 
but for instance i mean the outline is sort of up here . 
and that ' s what people are seeing . 
and if you have a 
or you could tell people not to to use the boards . 
but there ' s sort of this missing information otherwise . 
i agree . 
we we should 
i agree but but you you just you end up with video . 
well i don ' t know . 
and and instrumented rooms . 
and that ' s a different project i think . 
i think for this data capture it would be nice to have a digital camera . 
yeah different 
uh 
just to take pictures of who ' s there . 
where the microphones are . 
and then we could also put in what ' s on the board . 
you know like three or four snaps for every 
right . 
i agree . 
yeah . 
that ' s wonderful . 
for every meeting . 
people who were never at the meeting will have a very hard time understanding it otherwise . 
uhhuh . 
but don ' t you think that ' s 
i agree . 
don ' t you think that but 
uhhuh . 
well no i mean i i just think i mean i think that right now we don ' t make a record of where people are sitting on the tables . 
even people who were at the meeting . 
right . 
huh . 
right . 
and that the at some point that might be awfully useful . 
but i think adding photographs adds a whole nother level of problems . 
uhhuh . 
huh . 
yeah . 
it ' s just a digital record . 
uh 
not not as part of the not as a part of the data that you have to recover . 
i don ' t mean that you model it . 
just just in terms of 
we should just 
like archiving it or storing it . 
yeah . 
yes i agree . 
i agree . 
it ' s because discourse is about things . 
uhhuh . 
because someone 
and then you have the things that are about and it ' s recoverable . 
someone later might be able to take these and say okay they you know at least these are the people who were there . 
so 
and here ' s sort of what they started talking about . 
and 
and just 
yes . 
and it ' s so simple . 
like you said three snapshots . 
uh 
and 
liz you 
just to archive . 
uh liz you you sat in on the uh subcommittee meeting or whatever 
actually 
uh on you on the subcommittee meeting for for at the uh that workshop we were at that uh uh mark liberman was was having . 
so i i wasn ' t there . 
they they they they must have had some discussion about video and the visual aspect and all that . 
big big interest . 
yeah . 
huge . 
i mean it personally i don ' t i would never want to deal with it . 
but i ' m just saying first of all there ' s a whole bunch of fusion issues that darpa ' s interested in . 
yeah . 
yeah . 
you know fusing gesture and face recognition . 
yeah . 
even lip movement and things like that . 
for this kind of task . 
and there ' s also i think a personal interest on the part of mark liberman in this kind of in storing these images in any data we collect . 
uhhuh . 
so that later we can do other things with it . 
yeah . 
so so to address what what adam ' s saying 
huh . 
uhhuh . 
i mean i think you uh that 
and 
the key thing there is that this is a description of database collection effort that they ' re talking about doing . 
uhhuh . 
and if the database exists and includes some visual information that doesn ' t mean that an individual researcher is going to make any use of it . 
right ? 
uhhuh . 
so uh 
but that it ' s going to be a lot of effort on our part to create it and store it . 
and get all the standards and to do anything with it . 
right . 
so we ' re going to 
so we ' re going to do what we ' re going to do . 
whatever ' s reasonable for us . 
yeah . 
i think even doing something very crude 
but having 
like i know with atis we just had a tape recorder running all the time . 
uhhuh . 
and later on it turned out it was really good that you had a tape recorder of what was happening . 
even though you you just got the speech from the machine . 
so if you can find some really you know low uh perplexity 
low fidelity . 
yeah . 
yeah way of of doing that i think it would be worthwhile . 
i agree . 
and if it ' s simple as i mean as simple as just the digital 
otherwise you ' d you lose it . 
yeah . 
well minimally i mean what what dan is referring to at least having some representation of the the spatial position of the people . 
because we are interested in some spatial processing . 
uhhuh . 
and so 
right . 
uhhuh . 
so um 
well once the room is a little more fixed that ' s a little easier . 
yeah . 
because you ' ll 
well the wireless . 
yeah . 
yeah . 
but 
also c . m . u . has been doing this . 
and they were the most vocal at this meeting . 
alex waibel ' s group . 
and they have said i talked to the student who had done this that with two fairly inexpensive cameras they they just recorded all the time . 
uhhuh . 
and were able to get all the information from or maybe it was three from all the parts of the room . 
so i think we would be we might lose the chance to use this data for somebody later who wants to do some kind of processing on it if we don ' t collect it at all . 
yeah . 
i i i don ' t disagree . 
the problem with it is you ' ll have more people who don ' t want to be filmed than who don ' t want to be recorded . 
well she ' s not making 
so that there ' s going to be another group of people who are going to say i won ' t participate . 
huh . 
that ' s true . 
uhhuh . 
or you could put a paper bag over everybody ' s head . 
um 
and not look at each other . 
and not look at boards . 
and just all be sitting talking . 
uhhuh . 
well 
that would be an 
well there ' s that ' d be the the parallel yeah . 
great idea . 
but i think she ' s we ' re just proposing a minimal preservation of things on boards 
yeah i definitely won ' t participate if there ' s a camera . 
spatial organization . 
and you could anonymize the faces for that matter . 
you know i mean this is 
we can talk about the 
but you know that ' s a lot of infrastructure and work . 
it ' s just one snapshot . 
to set it up and then anonymize it . 
no it not um 
we ' re not talking about a movie . 
no no no no . 
we ' re talking about a snapshot . 
not for not for c . m . u . 
so 
uhhuh . 
they have a pretty crude set - up . 
yeah . 
uhhuh . 
and they had 
they just turn on these cameras . 
they were they were not moving or anything . 
couldn ' t find it ? 
and stored it on analog media . 
huh ? 
huh . 
and they they didn ' t actually align it or anything . 
they just they have it though . 
yeah . 
well it ' s worth considering . 
maybe we don ' t want to spend that much more time discussing it . 
did they store it digitally ? 
but 
or 
huh huh . 
i think they just 
or just put it on videotape ? 
i think they just had the videotapes with a you know a counter or something . 
um 
uhhuh . 
well i think for i mean for our purposes we probably will 
i ' m not sure . 
we we might try that some . 
and and we certainly already have some recordings that don ' t have that . 
uh which you know we ' ll we ' ll get other value out of i think . 
yeah . 
yeah . 
the thing is if it ' s easy to collect it it then i think it ' s a wise thing to do . 
because once it ' s gone it ' s gone . 
and 
i ' m just the community 
if l . d . c . collects this data i mean and l . if mark liberman is a strong proponent of how they collect it and what they collect there will probably be some video data in there . 
there you go . 
and so that could argue for us not doing it . 
or it could argue for us doing it . 
the only place where it sort of overlaps is when some of the summarization issues are actually could be um easier made easier if you had the video . 
uhhuh . 
i think at the moment we should be determining this on the basis of our own uh interests and needs rather than hypothetical ones from a community thing . 
as you say if they if they decide it ' s really critical then they will collect a lot more data than we can afford to . 
uh and and will include all that . 
huh . 
um 
i i i ' m not worried about the cost of setting it up . 
i ' m worried about the cost of people looking at it . 
in other words it ' s it it ' d be kind of silly to collect it all and not look at it at all . 
and so i i i think that we do have to do some picking and choosing of the stuff that we ' re doing . 
but i i am i do think that we minimally want something we might want to look at at some some uh subsets of that . 
like for a meeting like this at least uh take a polaroid of the of the of the boards . 
of the board . 
yeah . 
or at least make sure that the note taker takes a you know a snapshot of the board . 
exactly . 
and 
and know the position of the people . 
that ' ll make it a lot easier for meetings that are structured . 
exactly . 
uhhuh . 
i mean otherwise later on if nobody wrote this stuff on the board down we ' d have a harder time summarizing it or agreeing on a summary . 
we and it 
especially since this is common knowledge . 
i mean this is shared knowledge among all the participants . 
and it ' s a shame to keep it off the recording . 
uh except in 
uh if we weren ' t recording this this this would get lost right ? 
well i don ' t understand that point . 
yeah . 
i mean i just think that the 
the point is that we ' re not saving it anyway . 
right ? 
well 
in in our real life setting . 
what do you mean we ' re not saving it anyway ? 
i ' ve written all of this down and it ' s getting emailed to you . 
and you ' re going to send it out by email too . 
well uh in that case we don ' t need to take pictures of it . 
right that would be the other alternative to make sure that anything that was on the board um is in the record . 
yeah . 
yeah . 
well 
well that ' s why that ' s why i ' m saying that i think the note - taking would be . 
i think in many for many meetings there will be some sort of note - taking . 
in which case that ' s a useful thing to have . 
uh i mean we uh we don ' t need to require it . 
uhhuh . 
just like the 
i mean i think it would be great if we try to get a picture with every meeting . 
um 
i agree . 
so so we won ' t worry about requiring these things . 
but the more things that we can get it for the more useful it will be for various applications . 
so 
so 
so i mean departing for the moment from the data collection question but actually talking about you know this group and what we actually want to do . 
uh so i guess that ' s the way what you were figuring on doing was was was uh putting together some notes and sending them to to everybody . 
from from today . 
okay . 
so 
um 
that ' s great . 
so so the question that that we started with was whether there was anything else we should do during during during the collection . 
ow . 
and i guess the crosspads was certainly one idea . 
uh and we ' ll get them from him and we ' ll just do that . 
right ? 
and then the next thing we talked about was the was the summaries . 
and are we going to do anything about that ? 
well before we leave the crosspads and and call it done . 
oh okay . 
so if i ' m collecting data then there is this question of do i use crosspads . 
yeah . 
so i think that if we really seriously have me collect data and i can ' t use crosspads it ' s probably less useful for you guys to go to the trouble of using it . 
um unless you think that the crosspads are going to 
i ' m not i ' m not sure what they ' re going to do . 
but but having a small percentage of the data with it 
i ' m not sure whether that ' s useful or not . 
what 
maybe maybe it ' s no big deal . 
maybe we just do it and see what happens . 
i guess the point was to try again to try to collect more information that could be useful later for for the u . i . stuff . 
uhhuh . 
so it ' s sort of landay supplying it . 
so that landay ' s stuff can be easier to do . 
right . 
so it it right now he ' s operating from zero . 
nothing . 
and so even if we didn ' t get it done from u . w . it seems like that would could still you 
okay . 
i mean at least try it . 
i think it ' d be useful to have a small amount of it just as a proof of concept . 
yeah . 
it will 
right . 
and and they seem to not be able to give enough of them away . 
you know what you can do with things . 
okay . 
so we could probably get more as well . 
yeah but not not to rely on them for basic modeling . 
that ' s true . 
so if it if it seems to be really useful to you guys we could probably get a donation to me . 
yeah i ' m not sure . 
i think it it will again depend on landay . 
and if he has a student who ' s interested . 
and how much infrastructure we ' ll need . 
i mean if it ' s easy we can just do it . 
yeah . 
um but if it requires a lot of our time we probably won ' t do it . 
right . 
i guess a lot of the stuff we ' re doing now really is pilot . 
in one sense or another . 
yeah yeah we have to sort of figure out what we ' re going to do . 
and so we try it out and see how it works . 
right ? 
yeah . 
i just wouldn ' t base any of the modeling on having those . 
right i i think i agree with that . 
right . 
yeah . 
it ' s just 
right . 
okay . 
i think though the importance marking is a good idea though . 
that if if people have something in front of them . 
i ' d be sort of cool . 
i mean it would 
yeah . 
that shouldn ' t be hard for 
yeah . 
do it on pilots or laptops or something . 
okay if something ' s important everyone clap . 
okay so crosspads we ' re just going to try it and see what happens . 
okay . 
yeah um i think that ' s right . 
okay . 
okay . 
the note - taking 
so i i think that this is going to be useful . 
so if we record data i will definitely ask for it . 
so i i think we should just say this is not we don ' t want to put any extra burden on people but if they happen to generate minutes could could they send it to us . 
yeah . 
oh okay that ' s fine . 
absolutely . 
uhhuh . 
uhhuh . 
and then 
yeah what i was going to say is that i don ' t want to ask people to do something they wouldn ' t normally do in a meeting . 
it ' s i just want to keep away from the artificiality . 
but i think it definitely 
uhhuh . 
if they exist . 
and then jane ' s idea of summarization afterward i think is not a bad one . 
um 
picking out basically to let you pick out keywords . 
um and uh construct queries . 
so who who does this summarization ? 
yeah i ' m thinking that 
people in the meeting . 
yeah . 
you know just at at the end of the meeting before you go . 
uhhuh . 
without hearing each other though probably . 
go around the table . 
yeah . 
yeah . 
yeah . 
or even just have one or two people stay behind . 
ugh . 
yeah . 
yeah . 
people with radio mikes can go into separate rooms and continue recording without hearing each other . 
that ' s the nice thing . 
well then you should try them a few weeks later . 
how fascinating . 
and 
and see score them . 
they have all these memory experiments about how little you actually retain . 
that ' s right . 
well that ' s the interesting thing though . 
and wasn ' t 
if we do if we collect four different summaries you know we ' re going to get all this weird data about how people perceive things differently . 
oh . 
huh . 
it ' s like this is not what we meant to research . 
right right . 
oh . 
that could be very interesting . 
yeah . 
uhhuh . 
huh . 
yeah . 
but but again like the crosspads i don ' t think i would base a lot of stuff on it . 
i 
yeah i don ' t know how you would do it though . 
uhhuh . 
because i think i know when i see the the clock coming near the end of the meeting i ' m like inching towards the door . 
running to 
yeah . 
fff . 
so 
huh . 
you ' re probably not going to get a lot of people wanting to do this . 
well i think if 
maybe is email easier ? 
i mean i when you first said do do it um spoken what i was thinking is oh then people have to come up . 
uhhuh . 
and you have to hook them up to the recorder . 
so if they ' re already here i think that ' s good . 
but if they ' re not already here for i ' d rather do email . 
right . 
yeah i ' d just try well however the least intrusive and and quickest way is . 
i ' m much faster typing than anything else . 
and and closest to the meeting time too . 
because people will start to forget it as soon as they leave . 
yeah . 
yeah i think that i think doing it orally at the end of the meeting is the best time . 
i don ' t know . 
at 
uhhuh . 
i just don ' t 
because they ' re kind of a captive audience . 
uhhuh . 
once they leave . 
you know forget it . 
but but 
yeah read the digits . 
do the summary . 
right . 
but uh i don ' t think that they ' ll necessarily you ' ll you ' ll get many people willing to stay . 
huh . 
but you know if you get even one 
i would 
well i think it ' s like the note - taking thing . 
yeah . 
that that that you can ' t certainly can ' t require it . 
or people aren ' t going to want to do this . 
but but if there ' s some cases where they will then it would be helpful . 
and i ' m also wondering couldn ' t that be included in the data sample ? 
huh . 
so that you could increase the you know the words that are uh recognized by a particular individual . 
if you could include the person ' s meeting stuff and also the person ' s summary stuff maybe that would be uh 
yeah . 
an addition to their database . 
it ' s kind of nice . 
yeah . 
huh . 
under the same acoustic circumstance . 
because if they just walk next door with their set - up nothing ' s changed . 
right . 
just 
so i have a question about queries . 
god that ' s bugging me . 
which is um 
you turn 
can we turn that light off ? 
uh 
if can we turn that just that that let 
uh let the record show the light is flickering . 
the the fluorescent light is flickering . 
i don ' t know . 
yeah . 
yeah there ' s a 
yeah . 
oh it is it is like okay . 
very annoying . 
yeah . 
there you go . 
oh much better . 
okay . 
oh yeah . 
yeah . 
good . 
for a little while i thought it was just that i was really tired . 
that ' s better . 
too much caffeine . 
that and too much caffeine and really tired . 
but then i thought no maybe that ' s real . 
okay . 
so 
i thought it was the projector for a moment . 
it was like what ' s going on . 
yeah . 
the question i had about queries was um so what we ' re planning to do is have people look at the summaries and then generate queries ? 
we we ' ve just been talking how do we generate queries . 
are are we going to try and 
yeah . 
and so that was one suggestion . 
well i mean 
so the question i had is is have we given any thought to how we would generate queries automatically given a summary ? 
i mean i think that ' s a whole research topic unto itself . 
huh . 
so that it may not be a feasible thing . 
but 
hello . 
dan here . 
yeah . 
shouldn ' t landay and his group be in charge of figuring out how to do this ? 
i mean this is an issue that goes a little bit beyond where we are right now . 
okay . 
they ' re the 
mari . 
yeah ? 
someone wants to know when you ' re getting picked up . 
is someone picking you up ? 
um what ' s our schedule ? 
well you still wanted to talk with liz . 
let ' s see . 
you and i need uh 
and you and i need 
no we did the liz talk . 
oh oh you already did the liz talk . 
yeah . 
okay . 
so so that was the prosody thing . 
i don ' t remember it . 
um we need to finish the 
oh okay . 
it ' s already four fifteen . 
i have like no recall memory . 
yeah . 
uh after . 
we need to finish this discussion and you . 
and i need a little time for wrap up and quad chart . 
so 
and what ? 
i ' m at your disposal . 
um 
so up to you . 
um what what ' s the plan for this discussion ? 
we should 
um i think we should be able to wind up in another half - hour or something . 
at least yeah . 
you think ? 
even if that much . 
uh less . 
less . 
yeah . 
less ? 
so i think 
it ' s interesting that he ' s got like this discussion free . 
well i mean we still haven ' t talked about the action items from here and so on . 
action 
yeah . 
yeah . 
so 
yet it ' s separate . 
and 
why don ' t you say five - thirty ? 
okay five - thirty . 
i don ' t 
is that okay ? 
we ' ll probably hit horrible traffic . 
sounds 
okay . 
thanks bye . 
that ' s not a lot of time . 
that ' s that . 
but 
yeah . 
well in answer to is it landay ' s problem . 
um he doesn ' t have a student who ' s interested right now in doing anything . 
so he has very little manpower . 
um there ' s very little allocated for him . 
and also he ' s pretty focused on user interface . 
so i don ' t think he wants to do information retrieval . 
that sort of stuff . 
yeah well there ' s going to be these student projects that can do some things . 
but it can ' t be yeah very deep . 
i i actually think that that uh again just as a bootstrap if we do have something like summaries then having the people who are involved in the meetings themselves who are cooperative and willing to do yet more come up with with with queries uh could at least give give landay an idea of the kind of things that people might want to know . 
i mean 
right ? 
if he doesn ' t know anything about the area and the people are talking about and and uh 
but the people will just look at the summaries or the minutes and and sort of back generate the queries . 
that ' s what i ' m worried about . 
so you might as well just give him the summaries . 
uhhuh . 
and 
maybe . 
well i ' m not sure i ' m not sure that ' s a solved problem . 
well but i think 
right ? 
oh okay . 
of how to how to generate queries from a 
how to do this 
i uh 
yeah . 
from the summary . 
that was sort of what my question was aimed towards . 
so what you want to to do is people who were there who later see uh minutes and put in summary form which is not going to be at the same time as the meeting there ' s no way that can happen are we going to later go over it 
huh . 
right . 
right . 
and like make up some stuff to which these notes would be an answer . 
or or a deeper . 
yeah . 
or or just a memory refresher . 
i mean 
but that ' s done off they have to do that off line . 
yep i agree . 
i ' m also wondering if we could ask the the people a a question . 
which would be what was the most interesting thing you got out of this meeting . 
in terms of like informativeness . 
that ' s a good one . 
it might be you know that the summary would would not even include what the person thought was the most interesting fact . 
i would think that would be the most likely thing . 
dan doesn ' t know what sex he is . 
yeah really . 
but actually i would say that ' s a better thing to ask than have them summarize the meeting . 
i think you get two different types of information . 
you get two 
yeah that ' s true . 
yeah . 
because you get like the general structure of important points and what the what the meeting was about . 
hey . 
yeah . 
we ' re still here . 
so you get the general structure the important points of what the meeting was about with the summary . 
but with the what ' s the most interesting thing you learned ? 
uh so the fact that uh i know that transcriber uses snack is something that i thought was interesting . 
going to see the kids . 
you you can keep it on . 
and that and that dan worked on on that . 
so i thought that was really 
you know . 
so i mean you could pick up some of the micro items that wouldn ' t even occur as major headings . 
uhhuh . 
but could be very informative . 
yeah that ' s actually a really good idea . 
i think it wouldn ' t be too uh uh cost intensive either . 
you know i mean it ' s like something someone can do pretty easily on the spur of the moment . 
are you thinking about just asking one participant or all of them ? 
as many are willing to do it . 
make it a voluntary thing . 
yeah . 
because you ' ll get because you ' ll get very different answers from everybody right ? 
and then 
yeah that ' s why i was wondering . 
so 
well maybe one thing we could do is for the meetings we ' ve already done 
i mean i we didn ' t take minutes and we don ' t have summaries . 
but uh people could like listen to them a little bit and generate some queries . 
yeah . 
of course jane doesn ' t need to . 
i ' m sure you have that meeting memorized by now . 
yeah . 
but actually it would be an easy thing to just go around the room and say what was the most interesting thing you learned . 
huh . 
yeah . 
yeah . 
for those people willing to stay . 
and that i think it would pick up the micro structure the 
some some of the little things that would be hidden . 
and and that might be something people are willing to stay for . 
boy i i don ' t know how we get at this 
that would be interesting . 
or want to get up and leave . 
yeah but when you go around the room you might just get the effect that somebody says something . 
and then you go around the room and they say yeah me too i agree . 
me too me too me too . 
yeah . 
on the other hand people might try and come up with different ones right ? 
that ' s fine . 
so 
well 
they might say oh i was going to say that one . 
well 
but now i have to think of something else . 
you have the other thing that that they know why we ' re doing it . 
we ' ll i mean we ' ll we ' ll be telling them that the reason we ' re trying to do this is is to generate queries in the future . 
so try to pick things that other people didn ' t say . 
it ' s going to take some thought . 
i mean 
it seemed the kind of uh interest that i had in this thing initially was uh that basically the form that you ' re doing something else later . 
uhhuh . 
and you want to pick up something from this meeting related to the something else . 
so it ' s really the the the list of what ' s important ' s in the something else . 
huh . 
right . 
rather than the 
and it might be something minor of minor importance to the meeting . 
right . 
uhhuh . 
uh in fact if if it was really major if it ' s the thing that really stuck in your head then you might not need to go back and and and check on it even . 
so it ' s it ' s that you ' re trying to find you ' re you ' ve now 
you weren ' t interested 
say i i said well i wasn ' t that much interested in dialogue . 
i ' m more of an acoustics person . 
right . 
but but three months from now if for some reason i get really interested in dialogue and i ' m well what is what was that part that that that uh mari was saying . 
yeah like jim bass says add a few lines on dialogue in your next 
uh 
yeah . 
yeah . 
yeah . 
didn ' t really stick in my head the first time around . 
and but for some new reason i ' m i ' m i ' m interested in in in the old stuff . 
but that that ' s going to be very hard to generate . 
so i don ' t i don ' t know . 
well i that ' s hard to generate . 
do we 
uhhuh . 
and and i think that ' s half of what i would use it for . 
but i also a lot of times um make you know think to myself this is interesting . 
uhhuh . 
i ' ve got to come back and follow up on it . 
uhhuh . 
uhhuh . 
so things that i think are interesting um i would be uh wanting to do a query about . 
and also i like the idea of going around the room . 
because if somebody else thought something was interesting i ' d kind of want to know about it . 
and then i ' d want to follow up on it . 
huh . 
yeah that that might get at some of what i was 
i was concerned about uh being interested in something later that uh i didn ' t consider to be important the first time . 
which for me is actually the dominant thing . 
because if i thought it was really important it tends to stick more than if i didn ' t . 
but some new task comes along that makes me want to look up . 
but 
but what ' s interesting to me may not have been interesting to you . 
yeah so having multiple people might get at some of that . 
by so by going around 
yeah . 
yeah . 
yeah i i think you can ' t get at all of it . 
right ? 
yeah . 
we just need to start somewhere . 
yeah and this is a starting point . 
the question the question then is how much bias do we introduce by you know introduce by saying you know this was important now ? 
uhhuh . 
and you know maybe something else is important later . 
uhhuh . 
i mean does it does the bias matter ? 
i i don ' t know . 
i mean uh that ' s i guess a question for you guys . 
but 
well and and one thing we we ' re saying important and we ' re saying interesting . 
and and those those can be two different things . 
uh yeah yeah . 
sure sure . 
uhhuh . 
but i i i guess that ' s the question really is that i mean 
uhhuh . 
does building queries based on what ' s important now introduce an irreversible bias on being able to do what morgan wants to do later ? 
okay good . 
well irreversible . 
that ' s that ' s 
yeah . 
i i i mean i guess what what i i keep coming back to in my own mind is that um the soonest we can do it we need to get up some kind of system . 
right . 
so that people who ' ve been involved in the meeting can go back later . 
even if it ' s a poor system in some ways . 
and uh and ask the questions that they actually want to know . 
if you know if uh as soon as we can get that going at any kind of level then i think we ' ll have a much better handle on what kind of questions people want to ask than in any anything we do before that . 
but obviously we have to bootstrap somehow . 
sure . 
right . 
and 
uhhuh . 
i agree . 
right . 
i will say that that i i chose interesting . 
because i think it includes also important . 
in some cases . 
but um i i i feel like the summary gets at a different type of information . 
i think important can often be uninteresting . 
huh . 
huh . 
well and and also 
huh . 
and interesting is more interesting than important . 
it puts a lot of burden on the person to to evaluate . 
you know i think interesting is is non threatening in 
okay . 
yeah . 
in the interest of um 
yeah . 
importance ? 
generating an interesting summary um 
uhhuh . 
yeah . 
no in the interest of generating some minutes here 
uh and also moving on to action items and other things . 
let me just go through the things that i wrote down as being important . 
um that we at least decided on . 
crosspads we were going to try . 
um if landay can get the uh get them to to you guys . 
um and see if they ' re interesting . 
and if they are then we ' ll try to get do it more . 
um 
getting electronic summary from a note - taking person if they happen to do it anyway . 
uhhuh . 
um 
getting just uh digital pictures . 
a couple digital pictures of the the table and boards to set the context of the meeting . 
uh and then going around the room at the end to just say ask people to mention something interesting that they learned . 
so rather than say the most interesting thing something interesting . 
sure . 
and that way you ' ll get more variety . 
uhhuh . 
that ' s good . 
i wouldn ' t even say that that they learned . 
i like that . 
i like that . 
okay . 
yeah . 
uh you might want to mention something that that you brought up . 
thing that was discussed . 
and then the last thing would be for those people who are willing to stay afterwards and give an oral summary . 
uhhuh . 
okay ? 
does that pretty much cover everything we talked about ? 
uhhuh . 
that well that we want to do . 
and one and one qualification on on the oral summaries . 
they ' d be they ' d be separate . 
they wouldn ' t be hearing each other ' s summaries . 
okay . 
yeah that ' s like 
i think that ' s going to predominantly end up being whoever takes down the equipment then . 
and and that would also be that the data would be included in the database . 
yeah that would be let ' s see me . 
uhhuh . 
uhhuh . 
i mean there is still this hope that people might actually think of real queries they really want to ask at some point . 
okay . 
and that if if that ever should happen then we should try and write them down . 
uhhuh . 
right . 
give them a reward . 
uhhuh . 
a dollar a query ? 
yeah really . 
yeah . 
if they ' re real queries . 
yeah . 
okay so 
well and again if we can figure out a way to jimmy a a a a very rough system say in a year then uh so that in the second and third years we we actually have something to . 
yeah . 
play with and generate real queries from . 
ask queries . 
yeah . 
right . 
yeah . 
okay . 
uh 
so yeah 
i think i just wanted to say one thing about queries . 
i mean the level of the query could be you know very low level or very high - level . 
and it gets fuzzier and fuzzier as you go up right ? 
well we ' re going to 
so you need to have some sort of 
if you start working with queries some way of identifying what the 
you know if this is something that requires a a one word answer or it ' s one place in the recording versus was there general agreement on this issue of all the people who 
huh . 
you know you can you can ask queries that are meaningful for people . 
yep . 
in fact they ' re very meaningful . 
because they ' re very high - level . 
but they won ' t exist anywhere in the you know 
absolutely so i think we ' re going to have to start with keywords . 
uhhuh . 
and and if someone becomes more interested we could work our way up . 
i ' m 
i ' m not so sure i agree with that . 
but 
it but it may well 
really ? 
because uh because it depends on uh what our goal is . 
if our goal is wizard of oz - ish 
oh that ' s true . 
we might want to know what is it that people would really like to know about this data . 
yeah . 
and if it ' s if if it ' s something that we don ' t know how to do yet great . 
yeah . 
right . 
that ' s you know research project for year four or something . 
research yeah . 
uhhuh . 
you know . 
uhhuh . 
yeah i was thinking about wizard of oz . 
but it requires the wizard to know all about the meetings . 
we ' d have to listen to all the data . 
um 
well not maybe not true wizard of oz . 
so 
oh yeah i i understand . 
because people are too 
well just imagine if 
uh aware of what ' s going on . 
but but just 
get people to ask questions that they the machine definitely can ' t answer at the moment . 
yep . 
but 
yeah . 
just what would you like to know . 
yeah . 
but that neither could anyone else though is what uh my point is . 
yes . 
i was wondering if if there might be one more source of queries . 
which is indicator phrases like action item . 
okay . 
which could be obtained from the text from the transcript . 
right since we have the transcript . 
yeah . 
dates maybe . 
i don ' t know . 
that ' s something i always forget . 
yeah that ' s something to be determined something to be specified . 
well probably if you have to sit there at the end of a meeting and say one thing you remember it ' s probably whatever action item was assigned to you . 
but text oriented . 
i mean in that ' s all i remember from most meetings . 
i think you ' d remember that yeah . 
that that ' s all i wrote down . 
so in general i mean that could be something you could say right ? 
i ' m supposed to do this . 
yeah that ' s true . 
it it doesn ' t 
well but then you could you could prompt them to say you know other than your action item 
you know whatever . 
but but the action item would be a way to get uh maybe an additional query . 
well 
i mean that ' s realistically what people might well be remembering . 
so 
so 
huh . 
yeah . 
well but you know but you could get again . 
well we ' re piloting . 
we ' ll just do it and see what happens . 
yeah . 
yeah . 
yeah . 
yeah . 
i usually don ' t remember my action items . 
but i ' d i 
okay speaking of action items can we move on to action items ? 
yeah . 
uhhuh . 
yeah yeah . 
sure can you hand me my note pad ? 
um 
or maybe we should wait until the summary of this until this meeting is transcribed . 
and then we will 
yeah then we ' ll know . 
we we had i mean 
thanks . 
somewhere up there we had milestones . 
but i guess did did you get enough milestone uh from the description things ? 
i got 
yeah in fact why don ' t you hand me those transparencies so that i remember to take them ? 
eee 
okay . 
okay . 
and you know there ' s obviously detail behind each of those as much as is needed . 
so you just have to let us know . 
okay . 
what i have down for action items is we ' re supposed to find out about our human subject um requirements . 
good . 
yep . 
uh 
people are supposed to send me u . r . l . ' s . 
for their for web pages . 
to and i ' ll put together an overall cover . 
and you ' re 
right we 
huh ? 
we need to look at our web page . 
and make one that ' s 
and and you also need to look at your web page . 
that ' s 
right . 
and clean it up by mid july . 
p . d . a . free . 
yeah . 
um 
right . 
let ' s see . 
choo choo choo . 
mailing lists . 
we 
mailing list . 
uh you need to put together a mailing list . 
three of them . 
well i mean 
uh i think 
yeah . 
uh 
um 
mostly together . 
uh i need to email adam or jane . 
um about getting the data . 
who should i email ? 
uh how quickly do you want it ? 
um 
my july is really very crowded . 
and so uh 
how about if i just 
uh right now all i want 
i personally only want text data . 
i think the only thing jeff would do anything with right now 
but i ' m just speaking based on a conversation with him two weeks ago i had in turkey . 
but i think all he would want is the digits . 
um but i ' ll just speak for myself . 
i ' m interested in getting the language model data . 
uh so i ' m just interested in getting transcriptions . 
uhhuh . 
okay . 
so then just email you ? 
so 
sure sure sure . 
okay . 
you could email to both of us uh just i mean if you wanted to . 
uhhuh . 
i mean i don ' t think either of us would mind 
okay . 
but but in any case i ' d be happy to send you the 
that ' s right . 
and your email is ? 
edwards at 
icsi . 
okay . 
dot berkeley dot e . d . u . of course . 
in in our phone call uh before we we uh it turns out the way we ' re going to send the data is by uh c . d . roms . 
and then 
and uh 
and then what they ' re going to do is take the c . d . rom and transfer it to analog tape . 
and give it to a transcription service uh that will 
oh is this i . b . m ? 
yeah . 
yeah using foot pedals . 
and 
yeah foot foot pedals . 
and 
uh so do they how are they going to do the multi channel ? 
see that ' s a good question . 
yeah they they don ' t have a way . 
i thought so . 
but they have a verification . 
no i mean it ' ll be 
mix ? 
probably about like you did . 
and then there will be some things you know many things that don ' t work out well . 
and that ' ll go back to i . b . m . 
and they ' ll they ' ll uh they run their aligner on it . 
and it kicks out things that don ' t work well . 
which you know the overlaps will certainly be examples of that . 
and uh 
i mean what we will give them all of it right ? 
we ' ll give them all the the multi channel stuff . 
okay that ' s uh my question . 
so we ' ll give them all sixteen channels . 
and 
and they ' ll do whatever they want with it . 
yeah . 
but you also should probably give them the mixed you know equal sound level . 
yeah good idea . 
uhhuh . 
i mean they ' re not going to easily be able to do that probably . 
it ' s not hard . 
well 
uh yeah . 
so 
it ' s also won ' t be adding much to the data to give them the mixed . 
but 
uhhuh . 
it ' s not 
yep absolutely . 
right it doesn ' t it isn ' t difficult for us to do . 
right . 
you should 
so we might as well just do it . 
absolutely . 
yeah . 
you should that may be all that they want to send off to their transcribers . 
so sure . 
okay related to to the conversation with picheny . 
i need to email him uh my shipping address . 
and you need to email them something which you already did . 
i did . 
i i emailed them the transcriber u . r . l . 
um the online uh data that adam set up . 
the u . r . l . 
so they can click on an utterance and hear it . 
and i emailed them the streamlined conventions . 
which you got a copy of today . 
right and i was going to email them the which i haven ' t yet a pointer to to the web pages that we that we currently have . 
because in particular they want to see the one with the the way the recording room is set up . 
good . 
and so on your your page on that . 
oh excellent good . 
and then possibly 
i c . i c . c . ' ed morgan . 
i should have sent i should have c . c . ' ed you as well . 
okay . 
not an immediate action item but something we do have to worry about is data formats for for higher level information . 
okay . 
oh yeah . 
well or or not even higher level . 
we were going to 
different level prosody and all that sort of stuff . 
we ' re going to have to figure out how we ' re going to annotate that . 
yeah we 
yeah we never had our data format discussion . 
oh i thought we did . 
right . 
we discussed uh musical score notation . 
but that ' s not that ' s display . 
and 
oh okay . 
and its x . m . l . 
that ' s different than format . 
that ' s 
well um 
my my feeling right now on format is you guys have been doing all the work . 
well 
uh yeah . 
yeah . 
and whatever you want we ' re happy to live with . 
okay excellent . 
um 
okay . 
other people may not agree with that . 
so what 
important thing 
well it 
but because i ' m not actually touching the data . 
right . 
so i shouldn ' t be the one to talk . 
but 
no i think that ' s fine . 
so a key thing will be that you we tell you . 
great . 
yeah . 
what it is . 
here ' s a mysterious file . 
uh we also had 
and 
yeah . 
we also had the uh uh that we were uh that you were going to get us the eight hundred number . 
and we ' re all going to 
oh yeah . 
we ' re going to call up your communicator thing . 
and and we ' re going to be good slash bad . 
depending on how you define it uh users . 
now something that i mentioned earlier to mari and liz is that it ' s probably important to get as many non technical and non speech people as possible . 
in order to get some realistic users . 
so if you could ask other people to call and use our system that ' d be good . 
because we don ' t want people who already know how to deal with dialogue systems . 
yeah . 
who know that 
or like if you have a 
you shouldn ' t hyper articulate for instance and things like that . 
or like if you have somebody who makes your your plane reservations for you . 
so 
yeah . 
um which is 
yeah we can do that . 
the 
get my parents to do it . 
yeah for instance . 
yeah yeah seriously . 
yeah . 
your grandmother . 
huh . 
yeah . 
you know it could result in some good bloopers . 
which is always good for presentations . 
so 
yeah . 
um anyway 
i think my father would last through the second prompt before he hang hung up . 
my mother would have a very interesting conversation with it . 
huh . 
he would never use it . 
but it wouldn ' t have anything to do with the travel . 
okay . 
okay . 
um other 
let ' s see . 
other action items . 
so i have the 
we talked about that we ' re getting the recording equipment running at u . w . 
and so it depends 
they ' re you know they ' re 
if that comes together within the next month there at least will be uh uh major communications between dan and u . w . folks . 
yeah . 
i mean 
i ' m i ' m shooting to try to get it done get it put together by the beginning of august . 
as to 
we should talk about it . 
but 
huh . 
so um 
but we have it it ' s it ' s pretty 
you know 
we don ' t know . 
i mean he he uh he said that it was sitting in some room collecting dust . 
we don ' t know . 
and and so we don ' t know 
it ' s probably unlikely that we ' ll pull this off . 
but at least it ' s worth trying . 
uhhuh . 
what is it ? 
we don ' t know . 
oh okay . 
recording equipment . 
yeah . 
it ' s a tape recorder . 
we know it ' s eight channels . 
uh we know it ' s digital . 
it ' s eight tape recorders . 
we don ' t even know if there ' re microphones . 
so 
we ' ll find out . 
okay . 
um and i will email these notes . 
um i ' m not sure what to do about action items for the data stuff . 
although then somebody i guess somebody needs to tell landay that you want the pads . 
yeah okay . 
i ' ll do that . 
okay . 
um and he also said something about outside there that came up about the outside text sources that he he may have . 
uhhuh . 
oh . 
some text sources that are close enough to the sort of thing that we can play with them for a language model . 
huh . 
yeah that was uh that was what he was saying was this he this thing that uh jason had been working on finds web pages that are thematically related to what you ' re talking about . 
well that ' s the idea . 
so that that that would be a source of text which is supposedly got the right vocabulary . 
uhhuh . 
right . 
but it ' s obviously very different material . 
it ' s not spoken material for instance . 
yeah . 
so 
but it ' s it might be 
but but that ' s actually what i want to do . 
okay . 
that ' s that ' s what i want to work with . 
is is things that the wrong material but the right the right source . 
yeah . 
yeah . 
yeah . 
unfortunately landay told me that jason is not going to be working on that anymore . 
yeah . 
he ' s switching to other stuff again . 
yeah he seemed when i asked him if he could actually supply data he seemed a little bit more reluctant . 
so i ' ll i ' ll send him email . 
i ' ll put it in an action item that i send him email about it . 
and if i get something great . 
if i don ' t get something 
who ? 
landay or jason ? 
landay . 
okay . 
okay . 
and uh um 
you know otherwise if you guys have any papers 
or 
i could i could use uh i could use your web pages . 
that ' s what we could do . 
you ' ve got all the web pages on the meeting 
yeah why search for them ? 
true . 
they ' re we know where they are . 
yeah ! 
absolutely . 
yeah that ' s true . 
sure . 
oh forget this . 
well but that ' s not very much . 
i one less action item . 
i can use what web pages there are out there on meeting recorders . 
yep . 
right . 
i mean that that ' s 
yeah basically what his software does is it picks out keywords and does a google - like search . 
yeah . 
yeah . 
yeah . 
yeah . 
so we can we can we can do better than that . 
we can do that yeah . 
so you could 
yeah . 
yeah . 
uhhuh . 
there ' s there ' s some uh carnegie mellon stuff right ? 
on on meeting recording . 
yep . 
and xerox . 
and 
so there ' s there ' s icsi xerox . 
and xerox . 
and there ' s you should look under like intelligent environments . 
yeah . 
smart rooms . 
um the georgia tech classroom two thousand is a good one . 
um 
c . m . u . 
right and then 
right . 
there ' s 
that ' s where i thought you would want to eventually be able to have a board or a camera . 
because of all these classroom 
uhhuh . 
well georgia tech did a very elaborate instrumented room . 
and i want to try to stay away from that . 
yeah . 
uhhuh . 
so 
okay . 
great that solves that problem . 
one less action item . 
um 
okay i think that ' s good that ' s that ' s pretty much all i can think of . 
can i ask uh one thing ? 
it relates to data data collection . 
and i and i ' d and we mentioned earlier today this question of 
um so 
um i i know that from with the near field mikes some of the problems that come with overlapping speech uh are lessened . 
but i wonder if uh is that sufficient or should we consider maybe getting some data gathered in such a way that um we would uh have a meeting with less overlap than would otherwise be the case ? 
so either by rules of participation or whatever . 
oh yeah . 
now i mean you know it ' s true . 
i mean we were discussing this earlier . 
that depending on the task 
so if you ' ve got someone giving a report you ' re not going to have as much overlap . 
adam . 
but um 
uh so we ' re going to have you know non overlapping samples anyway . 
but um in a meeting which would otherwise be highly overlapping is the near field mike enough or should we have some rules of participation for some of our samples to lessen the overlap ? 
huh . 
turn off . 
i don ' t think we should have rules of participation . 
but i think we should try to get a variety of meetings . 
that ' s something that if we get the the meeting stuff going at u . w . that i probably can do more than you guys . 
okay . 
because you guys are probably mostly going to get icsi people here . 
uhhuh . 
but we can get anybody in e . e . uh over . 
and and possibly also some c . s . people uh over at u . w . 
so i think that that there ' s a good chance we could get more variety . 
okay . 
just want to be sure there ' s enough data to 
okay good . 
they ' re still going to overlap . 
um 
but mark and others have said that there ' s quite a lot of found data from the discourse community that has this characteristic . 
and also the political 
you know anything that was televised for a third party has the characteristic of not very much overlap . 
uhhuh . 
but i think we were saying before also that the natural language group here had less overlap . 
uhhuh . 
uhhuh . 
so 
so it also depends on the style of the group of people . 
like the um dominance relations of the people in the meeting . 
right . 
uhhuh . 
on the task and the task . 
it ' s just 
i just wanted to uh 
uhhuh . 
yeah . 
because you know it is true people can modify the amount of overlap that they do if if they ' re asked to . 
yeah . 
not not entirely modify it . 
but lessen it if if it ' s desired . 
but if if that ' s sufficient data 
i just wanted to be sure that we will not be having a lot of data which can ' t be processed . 
okay . 
so i ' m just writing here we ' re not going to try to specify rules of interaction . 
but we ' re going to try to get more variety by using different groups of people . 
time . 
and different sizes . 
fine and i you know i i know that the near near field mikes will take care of also the problems to to a certain degree . 
yeah . 
i just wanted to be sure . 
and then the other thing might be um uh technical versus administrative . 
because if i recorded some administrative meetings then that may have less overlap . 
because you might have more overlap when you ' re doing something technical and disagreeing or whatever . 
uhhuh . 
uhhuh . 
well i just as as as a contributary 
uh so i i know that in in legal depositions people are are prevented from overlapping . 
they ' ll just say you know you know wait till each person is finished before you say something . 
so it is possible to lessen if we wanted to . 
but but these other factors are fine . 
i just wanted to raise the issue . 
well the reason why i didn ' t want to is why i personally didn ' t want to is because i wanted it to be as uh unintrusive as 
uhhuh . 
uhhuh . 
as you could be with these things hanging on you . 
oh yeah . 
yeah i think that ' s always desired . 
i just want to be sure we don ' t that we ' re able to process uh you know as much data as we can . 
yeah . 
yeah . 
did they discuss any of that in the the meeting they had with liberman ? 
what 
uhhuh . 
what what do they 
and there was a big division . 
so liberman and others were interested in a lot of found data . 
yeah . 
so there ' s lots of recordings that 
yeah . 
they ' re not close talk mike . 
but 
and and there ' s lots of television you know stuff on um political debates and things like that . 
congressional hearings . 
boring stuff like that . 
um 
and then the c . m . u . folks and i were sort of on the other side in 
because they had collected a lot of meetings that were sort of like this . 
and said that those are nothing like these meetings . 
um so there ' re really two different kinds of data . 
and i guess we just left it as that if there ' s found data that can be transformed for use in speech recognition easily then of course we would do it . 
uhhuh . 
but newly collected data would would be natural meetings . 
actually the c . m . u . folk have collected a lot of data . 
so 
is that is that going to be publicly available ? 
as far as i know they have not . 
or 
okay . 
um but 
it ' s also it ' s not it ' s not near far right ? 
i ' m not sure . 
um 
if people were interested they could talk to them . 
but i i got the feeling there was some politics involved . 
i think going to add that to one of my action items . 
no 
just to check . 
yeah we should know what ' s out there certainly . 
i i don ' t know . 
yeah . 
i mean the 
yeah . 
because i had thought they ' d only done far field . 
i think you need to talk to waibel . 
and 
intelligent room sorts of things . 
oh really ? 
it ' s those guys . 
i hadn ' t known that then they ' d done any more than that . 
oh they only did the far field . 
yeah . 
i see . 
but they had multiple mikes . 
and they did do recognition . 
and they did do real conversations . 
but as far as i know they didn ' t offer that data to the community at this meeting . 
uhhuh . 
but that could change . 
because mark you know mark ' s really into this . 
we should keep in touch with him . 
yeah . 
yeah i think 
well once we send out 
i mean we still haven ' t sent out the first note saying hey this list exists . 
but but uh once we do that 
is that an action item ? 
yeah it ' s on i already added that one on my board to do that . 
so uh 
uh 
hopefully everybody here is on that list . 
we should at least check that everybody here 
i think everyone here is on the list . 
yeah . 
i ' m not . 
i think you are . 
we haven ' t sent anything to the list yet . 
oh . 
yeah . 
okay . 
we ' re just compiling the list . 
i see . 
i i added a few people who didn ' t who i knew had to be on it even though they didn ' t tell me . 
who specifically ask not to be . 
like jane for example . 
uhhuh . 
yeah . 
you are on it aren ' t you ? 
yeah i am . 
yeah . 
so i uh just just for clarification . 
so found data . 
they mean like established corpora of linguistics and and other fields right ? 
what they mean is stuff they don ' t have to fund to collect . 
it sounds like such a 
and especially good 
yeah okay . 
well i mean found has uh also the meaning that ' s it very natural . 
it ' s things occur without any 
you know the these people weren ' t wearing close talking mikes . 
but they were recorded anyway like the congressional hearings and you know for legal purposes or whatever . 
okay . 
but it includes like standard corpora that have been used for years in linguistics and other fields . 
mark ' s aware of those too . 
hey look what we found . 
okay . 
that would be found data . 
huh . 
exactly . 
because they found it and it exists . 
i found this great corpora . 
yeah . 
they didn ' t have to collect it . 
psst want to buy a corpora . 
of course it ' s not found in the sense that at the time it was collected for the purpose . 
yeah okay okay . 
but what he means is that you know mark was really a fan of getting as much data as possible from you know reams and reams of stuff of broadcast stuff . 
that ' s interesting . 
web stuff . 
uhhuh . 
t . v . stuff . 
radio stuff . 
but he well understands that that ' s very different than these this type of meeting . 
it ' s not the same . 
but so what ? 
it ' s still it ' s interesting for other reasons . 
okay . 
yeah . 
just wanted to know . 
so seems like we ' re winding down . 
right ? 
uhhuh . 
many ways . 
so we should go go around and 
you can tell by the prosody . 
yeah . 
we should go around and say something interesting that happened at the meeting ? 
oh . 
yes we should do that . 
rrrh ! 
now i was already thinking about it . 
so 
oh good man ! 
this is painful task . 
huh . 
so um 
i 
i really liked the idea of 
what i thought was interesting was the combination of the crosspad and the speech . 
especially um the interaction of them rather than just note - taking . 
so can you determine the interesting points by who ' s writing ? 
can you do special gestures and so on that that have uh special meaning to the corpora ? 
i really liked that . 
well i i just realized there ' s another category of interesting things . 
which is that um 
i i found this discussion very uh this this question of how you get at queries really interesting . 
and and the and i and the fact that it ' s sort of uh nebulous what what that what kind of query it would be . 
because it depends on what your purpose is . 
so i actually found that whole process of of trying to think of what that would involve to be interesting . 
but that ' s not really a specific fact . 
i just sort of thought we we went around a nice discussion of the factors involved there . 
which i thought was worthwhile . 
i had a real revelation about taking pictures . 
i don ' t know why . 
i didn ' t do this before and i regret it . 
so that was very interesting for me . 
uhhuh . 
did you take pictures of the boards ? 
yeah . 
not that i 
the boards aren ' t really related to this meeting . 
i mean i will take pictures of them . 
but 
that ' s a good point . 
they ' re related to this morning ' s meeting . 
but 
yeah . 
to the previous meeting that ' s right . 
okay . 
well that ' s why i ' ll take pictures of them then . 
i ' m going to pass . 
because i can ' t 
i mean of the jane took my answer . 
uh . 
oh . 
so 
um 
so i ' m going to pass for the moment . 
but come come back to me . 
for the moment . 
pass . 
i think i think pass is socially acceptable . 
but i will say uh i will actually 
uh a spin on different slightly different spin on what you said . 
this issue of uh realizing that we could take minutes 
and that actually may be a goal . 
so that that may be kind of the test in a sense test data . 
uh the the template of what we want to test against generating a summary . 
so that ' s an interesting new twist on what we can do with this data . 
i agree with jane and eric . 
i think the question of how to generate queries automatically was the most interesting question that came up . 
and it ' s something that as you said is a whole research topic in itself . 
so i don ' t think we ' ll be able to do anything on it . 
because we don ' t have funding on it uh in this project . 
but um it ' s definitely something i would want to do something on . 
i wonder if work ' s already been done on it . 
like expert systems and stuff ? 
or 
huh . 
uhhuh . 
well being more management lately than than research i think the thing that impressed me most was the people dynamics . 
and not any of the facts . 
that is i i really enjoyed hanging out with this group of people today . 
so that ' s what really impressed me . 
how are we going to find that in the data ? 
well if we had people wearing the wireless mikes all the time 
oh yeah . 
yeah i think 
well i mean one thing you could search for is were people laughing a lot . 
right ? 
right . 
so 
how happy were they ? 
yeah . 
i ' d probably search for something like that . 
that actually has come up a couple times in queries . 
i was talking to landay . 
and that was one of his examples . 
yeah . 
yeah . 
when when did people laugh . 
that ' s great . 
find me a funny thing that jeff said . 
so we need a laugh detector . 
yeah . 
yeah . 
uhhuh . 
yeah . 
perfect . 
because that seems to be pretty common . 
not in the congressional hearings . 
no . 
quiet sobbing . 
so i think we ' re done . 
okay . 
okay . 
i think we ' re done . 
okay . 
great . 
great . 
great . 
do we need do i need to turn something off here or i do unplug this or 
now these we turn off . 
right ? 
and uh shall i go ahead and do some digits ? 
uh we were going to do that at the end . 
remember ? 
okay whatever you want . 
yeah . 
just just to be consistent from here on in at least that that we ' ll do it at the end . 
the new consent form . 
it ' s uh yeah it doesn ' t matter . 
okay . 
okay . 
um well it i mean it might be that someone here has to go . 
and 
right ? 
that was that was sort of the point . 
so uh i had asked actually anybody who had any ideas for an agenda to send it to me and no one did . 
so 
so we all forgot . 
uh 
from last time i wanted to uh the an uh one topic from last time . 
right . 
okay so one item for an agenda is uh jane has some uh uh some research to talk about research issues . 
um and uh adam has some short research issues . 
and i have some short research issues . 
um i have a list of things that i think were done over the last three months . 
i was supposed to send off uh and um i i sent a note about it to uh to adam and jane . 
but i think i ' ll just run through it also and see if someone thinks it ' s inaccurate or uh insufficient . 
a list that you have to send off to who ? 
uh to uh uh i b m . 
oh . 
okay . 
they ' re you know 
so 
um so uh so i ' ll go through that . 
um and anything else anyone wants to talk about ? 
no . 
okay . 
what about the um your trip yesterday ? 
um . 
sort of off topic i guess . 
because that ' s because that was all all about the uh 
oh okay . 
i i i can chat with you about that off line . 
that ' s another thing . 
um and anything else ? 
nothing else ? 
uh there ' s a i mean there is a a um uh telephone call tomorrow which will be a conference call that some of us are involved in for uh a possible proposal . 
um we ' ll talk we ' ll talk about it next week if if something 
do you want me to be there for that ? 
i noticed you c c ' ed me but i wasn ' t actually a recipient . 
i didn ' t quite know what to make of that . 
uh well we ' ll talk talk about that after our meeting . 
okay . 
okay . 
uh okay . 
so it sounds like the the three main things that we have to talk about are uh this list uh jane and jane and adam have some research items and other than that anything as usual anything goes beyond that . 
okay uh jane since since you were sort of cut off last time why don ' t we start with yours ? 
make sure we get to it . 
okay it ' s it ' s very uh it ' s very brief i mean just let me just hand these out . 
oops ! 
is this the same as the e mail or different ? 
it ' s slightly different . 
thanks . 
i basically the same . 
okay . 
same idea ? 
but same idea . 
so if you ' ve looked at this you ' ve seen it before . 
so basically um as you know uh part of the encoding includes a mark that indicates an overlap . 
it ' s not indicated with um uh tight precision it ' s just indicated that okay so it ' s indicated to to so the people know what parts of which which stretches of speech were in the clear versus being overlapped by others . 
so i used this mark and um and uh uh divided the 
i wrote a script which divides things into individual minutes of which we ended up with forty five and a little bit . 
and uh you know minute zero of course is the first minute up to sixty seconds . 
okay . 
and um what you can see is the number of overlaps and then to the right whether they involve two speakers three speakers or more than three speakers . 
and um and what i was looking for specifically was the question of whether they ' re distributed evenly throughout or whether they ' re bursts of them . 
um . 
and it looked to me as though 
uh you know this is just uh uh this would this is not statistically verified but it did look to me as though there are bursts throughout rather than being localized to a particular region . 
the part down there where there ' s the maximum number of of um overlaps is an area where we were discussing whether or not it would be useful to to to code stress uh sentence stress as possible indication of uh information retrieval . 
so it ' s like you know rather lively discussion there . 
what was what ' s the the parenthesized stuff that says like the first one that says six overlaps and then two point eight ? 
oh . 
that ' s the per cent . 
huh . 
so six is uh two point eight per cent of the total number of overlaps in the session . 
uhhuh . 
uh . 
uhhuh . 
at the very end this is when people were you know packing up to go basically . 
there ' s this final stuff . 
i think we i don ' t remember where the digits fell . 
i ' d have to look at that . 
but the final three there are no overlaps at all . 
and couple times there are not . 
so it seems like it goes through bursts but um that ' s kind of it . 
uhhuh . 
uhhuh . 
now another question is is there are there individual differences in whether you ' re likely to be overlapped with or to overlap with others . 
and again i want to emphasize this is just one particular um one particular meeting and also there ' s been no statistical testing of it all but i um i took the coding of the 
i you know my i had this script figure out um who was the first speaker who was the second speaker involved in a two person overlap i didn ' t look at the ones involving three or more . 
and um this is how it breaks down in the individual cells of who tended to be overlapping most often with who who else . 
and if you look at the marginal totals which is the ones on the right side and across the bottom you get the totals for an individual . 
so um if you look at the bottom those are the um numbers of overlaps in which um adam was involved as the person doing the overlapping and if you look 
i ' m sorry but you ' re alphabetical that ' s why i ' m choosing you . 
and then if you look across the right then that ' s where he was the person who was the first speaker in the pair and got overlap overlapped with by somebody . 
huh ! 
uhhuh . 
and then if you look down in the summary table then you see that um they ' re differences in whether a person got overlapped with or overlapped by . 
is this uh just raw counts or is it 
raw counts . 
so it would be interesting to see how much each person spoke . 
uhhuh . 
yes very true very true . 
yeah yeah . 
yeah . 
normalized to how much 
it would be good to normalize with respect to that . 
now on the table i did take one step toward uh away from the raw frequencies by putting uh percentages . 
so that the percentage of time of the of the times that a person spoke what percentage uh 
so of the times a person spoke and furthermore was involved in a two two person overlap what percentage of the time were they the overlapper and what percent of the time were they the overlappee ? 
and there it looks like you see some differences . 
um that some people tend to be overlapped with more often than they ' re overlapped . 
but of course uh this is just one meeting uh there ' s no statistical testing involved and that would be required for a for a finding of any kind of scientific reliability . 
so it would be statistically incorrect to conclude from this that adam talked too much or something . 
no no actually that would be actually statistically correct . 
no no no . 
yeah yeah . 
yeah yeah . 
but 
yeah yeah . 
yeah that ' s right . 
that ' s right . 
yeah . 
and i ' m you know i ' m i don ' t see a point of singling people out . 
excuse me . 
now this is a case where obviously 
i i i rather enjoyed it but but this 
but the numbers speak for themselves . 
he ' s yeah yeah yeah . 
yes that ' s right so you don ' t okay . 
well you know it ' s like i ' m not i ' m not saying on the tape who did better or worse . 
because i don ' t think that it ' s 
sure . 
i you know 
and and here ' s a case where of course human subjects people would say be sure that you anonymize the results and and so might as well do this . 
yeah when this is what this is actually when jane sent this e mail first is what caused me to start thinking about anonymizing the data . 
yeah . 
well fair enough . 
fair enough . 
and actually you know the point is not about an individual it ' s the point about tendencies toward you know different styles different speaker styles . 
yeah . 
oh sure . 
and it would be you know of course there ' s also the question of what type of overlap was this and what were they . 
and and i and i know that i can distinguish at least three types and probably more . 
i mean the general cultural idea which uh the conversation analysts originally started with in the seventies was that we have this strict model where politeness involves that you let the person finish before you start talking . 
and and you know i mean we know that and they ' ve loosened up on that too in the intervening time that that that ' s that ' s viewed as being a culturally relative thing . 
i mean that you have the high involvement style from the east coast where people will overlap often as an indication of interest in what the other person is saying . 
uhhuh . 
and 
yeah exactly ! 
exactly ! 
well there you go . 
yeah . 
fine that ' s all right that ' s okay . 
and and you know in contrast so deborah and also deborah tannen ' s thesis . 
she talked about differences of these types that they ' re just different styles . 
and it ' s um you you can ' t impose a model of there of the ideal being no overlaps . 
and you know conversational analysts also agree with that . 
so it ' s now universally agreed with . 
and and 
i mean i can ' t say universally . 
but anyway the people who used to say it was strict um now uh don ' t . 
i mean they they also you know uh uh acknowledge the influence of of subcultural norms and cross cultural norms and things . 
so um then it though so just just superficially to give um a couple ideas of the types of overlaps involved i have at the bottom several that i noticed . 
so uh there are backchannels like what adam just did now . 
and um um anticipating the end of a question and simply answering it earlier . 
and there are several of those in this in these data where 
uhhuh . 
because we ' re people who ' ve talked to each other . 
um we know basically what the topic is what the possibilities are and and we ' ve spoken with each other . 
so we know basically what the other person ' s style is likely to be . 
and so and there are a number of places where someone just answered early . 
no problem . 
and places also which i thought were interesting where two or more people gave exactly the same answer in unison different words of course . 
but you know the basically you know everyone ' s saying yes or you know or even more specific than that . 
so uh the point is that um overlap ' s not necessarily a bad thing and that it would be useful to subdivide these further and see if there are individual differences in styles with respect to the types involved . 
and that ' s all i wanted to say on that unless people have questions . 
well of course the biggest um result here which is one we ' ve we ' ve talked about many times and isn ' t new to us but which i think would be interesting to show someone who isn ' t familiar with this is just the sheer number of overlaps . 
yep . 
yes yes ! 
oh okay interesting . 
that that right that that um 
yeah . 
here ' s a relatively short meeting . 
it ' s a forty forty plus minute meeting . 
and not only were there two hundred and fifteen overlaps but uh i think there ' s one one minute there where there where where there wasn ' t any overlap . 
hundred ninety seven . 
i mean it ' s uh throughout this thing . 
well at the bottom you have the bottom three . 
it ' s you have 
are 
it ' d be interesting 
yeah . 
so four four minutes all together with none none . 
oh so the bottom three did have stuff going on ? 
but it 
yes uhhuh . 
there was speech . 
yeah . 
but just no overlaps . 
okay so if the this 
it ' d be interesting to see what the total amount of time is in the overlaps versus 
yes exactly and that ' s that ' s where jose ' s project comes in . 
i was about to ask 
yeah yeah i i have that i have that information now . 
yeah . 
yeah . 
huh . 
oh about how much is it ? 
the the duration of uh of each of the overlaps . 
oh what ' s what ' s the what ' s the average length ? 
i i haven ' t averaged it now . 
but uh i i will uh i will do the the study of the with the with the program with the uh the different uh the nnn distribution of the duration of the overlaps . 
you don ' t know ? 
okay you you you don ' t have a feeling for roughly how much it is ? 
huh because the the uh budget is horrid . 
yeah . 
the duration is uh the variation the variation of the duration is uh very big on the 
yeah . 
uhhuh . 
i suspect that it will also differ depending on the type of overlap involved . 
but uh 
yeah . 
so backchannels will be very brief . 
oh i ' m sure . 
because on your surface uh a bit of zone of overlapping with the duration uh overlapped and another very very short . 
and 
yeah . 
yeah . 
uh probably it ' s very difficult to to because the the overlap is uh is only the in the final s of the of the the the the end the end word of the um previous speaker with the the next word of the the new speaker . 
uhhuh . 
um i considered that ' s an overlap but it ' s very short it ' s an x with a and the idea is probably uh when uh when uh we studied that zone uh uh we we have uh uh confusion with uh uh noise . 
uhhuh . 
with uh that fricative sounds but uh i have new information but i have to to study . 
yeah . 
yeah but i i ' d 
can i 
go ahead . 
yeah . 
you split this by minute um so if an overlap straddles the boundary between two minutes that counts towards both of those minutes . 
yes . 
uhhuh . 
actually um um actually not . 
uh so let ' s think about the case where a starts speaking and then b overlaps with a and then the minute boundary happens . 
and let ' s say that after that minute boundary um b is still speaking and a overlaps with b . 
that would be a new overlap . 
but otherwise um let ' s say b comes to the conclusion of of that turn without anyone overlapping with him or her . 
in which case there would be no overlap counted in that second minute . 
no but suppose they both talk simultaneously both a a portion of it is in minute one and another portion of minute two . 
okay . 
in that case um my the coding that i was using since we haven ' t uh incorporated adam ' s uh coding of overlap yets the coding of 
yeah yets is not a word . 
uh since we haven ' t incorporated adam ' s method of handling overlaps yet um then that would have fallen through the cracks . 
it would be an underestimate of the number of overlaps because um i i wouldn ' t be able to pick it up from the way it was encoded so far . 
we just haven ' t done the precise second to you know second to second coding of when they occur . 
i ' m i ' m i ' m confused now . 
so let me restate what i thought andreas was saying and and see . 
uhhuh . 
let ' s say that in in second fifty seven of one minute you start talking and i start talking and we ignore each other and keep on talking for six seconds . 
yep . 
okay . 
uhhuh . 
so we go over so we were we were talking over one another and it ' s just in each case it ' s just sort of one interval . 
uhhuh . 
right ? 
so um we talked over the minute boundary . 
is this considered as one overlap in each of the minutes the way you have done this ? 
no it wouldn ' t . 
it would be considered as an overlap in the first one . 
okay so that ' s good i think in the sense that i think andreas meant the question . 
that ' s that ' s good yeah because the overall rate is 
yeah . 
hmph . 
statistical . 
yeah . 
yep . 
uhhuh . 
otherwise you ' d get double counts here and there . 
right ? 
yeah . 
they ' re not double counted . 
yeah . 
uh but yeah . 
and then it would be harder . 
yeah . 
yeah . 
i should also say i did a simplifying uh count in that if a was speaking b overlapped with a and then a came back again and overlapped with b again . 
i i didn ' t count that as a three person overlap i counted that as a two person overlap and it was a being overlapped with by d . 
uhhuh . 
because the idea was the first speaker had the floor and the second person started speaking and then the the first person reasserted the floor kind of thing . 
these are simplifying assumptions . 
yeah . 
didn ' t happen very often . 
there may be like three overlaps affected that way in the whole thing . 
i want to go back and listen to minute forty one . 
yeah yeah . 
because i find it interesting that there were a large number of overlaps and they were all two speaker . 
yeah . 
i mean what i thought what i would have thought in is that when there were a large number of overlaps it was because everyone was talking at once but uh apparently not . 
that ' s interesting . 
that ' s interesting . 
yeah . 
yeah . 
huh . 
that ' s really neat . 
yeah there ' s a lot of backchannel a lot a lot of 
yeah . 
this is really interesting data . 
yeah it is . 
i think so too i think . 
i think what ' s really interesting though it is before saying yes meetings have a lot of overlaps is to actually find out how many more we have than two party . 
because in two party conversations like switchboard there ' s an awful lot too if you just look at backchannels if you consider those overlaps . 
it ' s also it ' s huge . 
it ' s just that people haven ' t been looking at that because they ' ve been doing single channel processing for speech recognition . 
uhhuh . 
uhhuh . 
so the question is you know how many more overlaps do you have of say the two person type by adding more people to a meeting . 
and it may be a lot more but it may it may not be . 
well but see i find it interesting even if it wasn ' t any more . 
so 
because since we were dealing with this full duplex sort of thing in switchboard where it was just all separated out we just everything was just nice . 
uhhuh . 
so that so the issue is in in a situation where that ' s 
well it ' s not really nice . 
it depends what you ' re doing . 
so if you were actually having 
uh 
depends what you ' re doing . 
if right now we ' re we have individual mikes on the people in this meeting . 
uhhuh . 
so the question is you know are there really more overlaps happening than there would be in a two person party . 
let let let me rephrase what i ' m saying because i don ' t think i ' m getting it across . 
and and there well may be but 
what what i what i shouldn ' t use words like nice because maybe that ' s too too imprecise . 
but what i mean is that um in switchboard despite the many many other problems that we have one problem that we ' re not considering is overlap . 
and what we ' re doing now is aside from the many other differences in the task we are considering overlap . 
and one of the reasons that we ' re considering it you know one of them not all of them one of them is that uh at least you know i ' m very interested in the scenario in which uh both people talking are pretty much equally audible and from a single microphone . 
and so in that case it does get mixed in and it ' s pretty hard to to just ignore it to just do processing on one and not on the other . 
i i agree that it ' s an issue here but it ' s also an issue for switchboard . 
and if you think of meetings being recorded over the telephone which i think you know this whole point of studying meetings isn ' t just to have people in a room but to also have meetings over different phone lines . 
uhhuh . 
maybe far field mike people wouldn ' t be interested in that but all the dialogue issues still apply . 
uhhuh . 
so if each of us was calling and having a meeting that way you you know like a conference call . 
and just the question is you know in switchboard you would think that ' s the simplest case of a meeting of more than one person . 
uhhuh . 
and i ' m wondering how much more overlap of the types that that jane described happen with more people present . 
so it may be that having three people is very different from having two people or it may not be . 
that ' s an important question to ask . 
i think what i ' m all i ' m really saying is that i don ' t think we were considering that in switchboard . 
so 
not you me . 
were you 
though it wasn ' t in the design . 
but uh but but 
were you were you were you were you measuring it ? 
i mean were 
there there ' s 
actually to tell you the truth the reason why it ' s hard to measure is because of 
so from the point of view of studying dialogue i mean which dan jurafsky and andreas and i had some projects on you want to know the sequence of turns . 
yeah . 
so what happens is if you ' re talking and i have a backchannel in the middle of your turn and then you keep going what it looks like in a dialogue model is your turn and then my backchannel . 
yeah . 
even though my backchannel occurred completely inside your turn . 
yeah . 
so for things like language modeling or dialogue modeling it ' s we know that that ' s wrong in real time . 
yeah . 
but because of the acoustic segmentations that were done and the fact that some of the acoustic data in switchboard were missing people couldn ' t study it . 
but that doesn ' t mean in the real world that people don ' t talk that way . 
yeah i wasn ' t saying that . 
so it ' s um 
right ? 
i was just saying that now we ' re looking at it . 
well we ' ve 
and and and you you maybe wanted to look at it before but for these various technical reasons in terms of how the data was you weren ' t . 
right . 
we ' re looking at it here . 
so that ' s why it ' s coming to us as new . 
even though it may well be you know if your if your the hypothesis you were offering uh 
um . 
right if it ' s the null hypothesis and if actually you have as much overlap in a two person we don ' t know the answer to that . 
the reason we don ' t know the answer to is because it wasn ' t studied and it wasn ' t studied because it wasn ' t set up right . 
yeah all i meant is that if you ' re asking the question from the point of view of what ' s different about a meeting studying meetings of say more than two people versus what kinds of questions you could ask with a two person meeting . 
uhhuh . 
it ' s important to distinguish that you know this project is getting a lot of overlap but other projects were too but we just couldn ' t study them . 
may have been . 
and and so uh 
may have been . 
right ? 
we do we don ' t know the numbers . 
well there is a high rate . 
so 
it ' s but i don ' t know how high in fact . 
well i have a question . 
that would be interesting to know . 
see i mean let me 
i mean my point was just if you wanted to say to somebody what have we learned about overlaps here . 
just never mind comparison with something else . 
uhhuh . 
what we ' ve learned about is overlaps in this situation is that the first the first order thing i would say is that there ' s a lot of them . 
yeah . 
right ? 
in in the sense that if you said if 
yeah i i don ' t i agree with that . 
in a way i guess what i ' m comparing to is more the common sense notion of how how much people overlap . 
uh you know the fact that when when when uh adam was looking for a stretch of of speech before that didn ' t have any overlaps and he he was having such a hard time . 
and now i look at this and i go well i can see why he was having such a hard time . 
right . 
that ' s also true of switchboard . 
it ' s happening a lot . 
i wasn ' t saying it wasn ' t . 
it may not be 
right . 
so it ' s just um 
right ? 
i was commenting about this . 
okay . 
i ' m saying if i i ' m saying if i have this complicated thing in front of me and we which you know we ' re going to get much more sophisticated about when we get lots more data . 
all i ' m saying is that from the 
but then if i was going to describe to somebody what did you learn right here about you know the the modest amount of data that was analyzed i ' d say well the first order thing was there was a lot of overlaps . 
in fact and it ' s not just an overlap bunch of overlaps second order thing is it ' s not just a bunch of overlaps in one particular point but that there ' s overlaps uh throughout the thing . 
right . 
and that ' s interesting . 
right . 
no i i agree with that . 
that ' s all . 
i ' m just saying that it may the reason you get overlaps may or may not be due to sort of the number of people in the meeting . 
oh yeah . 
yeah . 
and that ' s all . 
yeah i wasn ' t making any statement about that . 
and and it would actually be interesting to find out . 
yeah . 
because some of the data say switchboard which isn ' t exactly the same kind of context . 
i mean these are two people who don ' t know each other and so forth . 
but we should still be able to somehow say what what is the added contribution to sort of overlap time of each additional person or something like that . 
yep . 
i could certainly see it going either way . 
yeah that would be good to know . 
okay now . 
what 
but we 
yeah i i agree i agree with adam . 
but yeah . 
yeah . 
and the reason is because i think there ' s a limit there ' s an upper bound on how many you can have simply from the standpoint of audibility . 
when we speak we we do make a judgment of can you know as adults . 
uhhuh . 
right . 
i mean children don ' t adjust so well . 
i mean if a truck goes rolling past adults will well depending but mostly adults will will will hold off to what to finish the end of the sentence till the till the noise is past . 
uhhuh . 
and i think we generally do monitor things like that about whether we whether our utterance will be in the clear or not . 
right . 
and partly it ' s related to rhythmic structure in conversation . 
so you know you you yeah this is also um people tend to time their their their um when they come into the conversation based on the overall rhythmic uh uh ambient thing . 
well 
right . 
so you don ' t want to be cross cutting . 
and and just to finish this that um that i think that there may be an upper bound on how many overlaps you can have simply from the standpoint of audibility and how loud the other people are who are already in the fray . 
but i you know of certain types . 
now if it ' s just backchannels people may be doing that with less intention of being heard just sort of spontaneously doing backchannels . 
in which case that those might there may be no upper bound on those . 
i i have a feeling that backchannels which are the vast majority of overlaps in switchboard uh don ' t play as big a role here because it ' s very unnatural i think to backchannel if in a multi audience you know in a multi person audience . 
if you can see them actually . 
it ' s interesting . 
so if you watch people are going like right right like this here . 
right . 
yeah . 
but that may not be the case if you couldn ' t see them . 
but but it ' s sort of odd if one person ' s speaking and everybody ' s listening . 
and it ' s unusual to have everybody going uhhuh uhhuh . 
actually i think i ' ve done it a fair number of times today . 
but . 
yeah . 
there ' s a lot of head nodding in this . 
um . 
yeah . 
yep we need to put trackers on it . 
in in the two person 
yeah yeah yeah . 
he could he could . 
plus plus plus the 
yeah . 
so so actually um that ' s in part because the nodding if you have visual contact the nodding has the same function . 
but on the phone in switchboard you you that wouldn ' t work . 
yeah you don ' t have it . 
so so you need to use the backchannel . 
your mike is 
so in the two person conversations when there ' s backchannel is there a great deal of overlap in the speech ? 
that is an earphone so if you just put it so it ' s on your ear . 
or 
because my impression is sometimes it happens when there ' s a pause . 
yes . 
there you go . 
yeah . 
thank you . 
for example . 
you know like you you get a lot of backchannel when somebody ' s pausing . 
yes . 
right . 
she ' s doing that . 
sorry what were you saying ? 
it ' s hard to do both . 
huh ? 
um no when when when there ' s backchannel i mean just i was just listening and and when there ' s two people talking and there ' s backchannel it seems like um the backchannel happens when you know the pitch drops and the first person 
oh . 
and a lot of times the first person actually stops talking and then there ' s a backchannel and then they start up again . 
and so i ' m wondering about i just wonder how much overlap there is . 
is there a lot ? 
i think there ' s a lot of the kind that jose was talking about where i mean this is called precision timing in conversation analysis where they come in overlapping but at a point where the information is mostly complete . 
so all you ' re missing is some last syllables or something or the last word or some highly predictable words . 
huh . 
uhhuh . 
so technically it ' s an overlap . 
but you know from information flow point of view it ' s not an overlap in the predictable information . 
but maybe a just a small overlap ? 
more yeah . 
it ' d be interesting if we could do prediction . 
i was just thinking more in terms of alignment alignment overlap . 
yeah . 
language model prediction of overlap that would be really interesting . 
so so 
yeah . 
well that ' s exactly exactly why we wanted to study the precise timing of overlaps in uh switchboard . 
right . 
right . 
so so here ' s a here ' s a first interesting labeling task . 
say because there ' s a lot of that . 
uh to distinguish between say backchannels precision timing sort of you know benevolent overlaps and and and and and sort of um i don ' t know hostile overlaps where someone is trying to grab the floor from someone else . 
uhhuh . 
let ' s pick a different word . 
yeah . 
uh that that might be an interesting um problem to look at . 
yeah . 
hostile takeovers . 
yeah . 
yeah . 
well i mean you could do that . 
yeah . 
i i i think that in this meeting i really had the feeling that wasn ' t happening that the hostile hostile type . 
these were these were benevolent types as people finishing each other ' s sentences and stuff . 
okay . 
uhhuh . 
um i could imagine that as there ' s a fair number of um cases where and this is sort of not really hostile but sort of competitive where one person is finishing something and you have like two or three people jumping trying to trying to trying to uh grab the next turn . 
trying to get the floor . 
yeah . 
and so it ' s not against the person who talks first because actually we ' re all waiting for that person to finish . 
but they all want to be next . 
i have a feeling most of these things are that that are not a benevolent kind are are are uh um are are competitive as opposed to really really hostile . 
right . 
yeah i agree . 
but . 
i wonder what determines who gets the floor ? 
i agree . 
well there are various things you you have the 
i mean 
uh a vote vote in florida . 
it ' s been studied a lot . 
yeah . 
voting for 
um one thing i i wanted to or you can tell a good joke and then everybody ' s laughing and you get a chance to break in . 
seniority . 
but . 
but . 
um . 
you know the other thing i was thinking was that um these all these interesting questions are of course pretty hard to answer with uh you know a small amount of data . 
ach . 
so um i wonder if what you ' re saying suggests that we should make a conscious attempt to have um a a fair number of meetings with uh a smaller number of people . 
right ? 
i mean we most of our meetings are uh meetings currently with say five six seven eight people . 
should we really try to have some two person meetings or some three person meetings and record them just to to to beef up the the statistics on that ? 
that ' s a control . 
well it seems like there are two possibilities there . 
i mean it seems like if you have just two people it ' s not really like a meeting is not as similar as the rest of the of the sample . 
it depends on what you ' re after of course . 
but it seems like that would be more a case of the control condition compared to uh an experimental condition with more than two . 
uhhuh . 
well liz was raising the question of of whether it ' s the number there ' s a relationship between the number of people and the number of overlaps or type of overlaps there . 
uhhuh . 
and um if you had two people meeting in this kind of circumstance then you ' d still have the visuals . 
you wouldn ' t have that difference also that you have in the say in switchboard data . 
uhhuh . 
uh . 
yeah i ' m just thinking that ' d be more like a control condition . 
yeah . 
uhhuh . 
well but from the acoustic point of view it ' s all good . 
yeah . 
is the same . 
yeah acoustic is fine . 
if if the goal were to just look at overlap you would you could serve yourself save yourself a lot of time but not even transcribe the words . 
but 
yep . 
well i was thinking you should be able to do this from the acoustics on the close talking mikes . 
well that ' s the that was my my status report . 
yeah . 
you ' ve been working on that . 
right ? 
right i mean adam was 
yeah . 
yeah . 
so once we ' re done with this stuff discussing . 
right . 
yeah . 
i mean not as well as what i mean you wouldn ' t be able to have any kind of typology obviously . 
uhhuh . 
but you ' d get some rough statistics . 
but what what do you think about that ? 
so 
do you think that would be useful ? 
i ' m just thinking that as an action item of whether we should try to record some two person meetings or something . 
i guess my my first comment was um only that um we should not attribute overlaps only to meetings . 
but maybe that ' s obvious . 
maybe everybody knew that . 
yeah . 
but that in normal conversation with two people there ' s an awful lot of the same kinds of overlap . 
uhhuh . 
and that it would be interesting to look at whether there are these kinds of constraints that jane mentioned that what maybe the additional people add to this competition that happens right after a turn . 
you know because now you can have five people trying to grab the turn . 
but pretty quickly there ' re they back off . 
and you go back to this sort of only one person at a time with one person interrupting at a time . 
uhhuh . 
so i don ' t know . 
to answer your question i it i don ' t think it ' s crucial to have controls . 
but i think it ' s worth recording all the meetings we can . 
can . 
well okay . 
yeah . 
so um you know . 
i i have an idea . 
i wouldn ' t not record a two person meeting just because it only has two people . 
right . 
could we could we um 
we have have in the past and i think continue will continue to have a fair number of uh phone conference calls . 
uhhuh . 
yeah we talked about this repeatedly . 
and uh and as a to um as another comparison condition we could um see what what what happens in terms of overlap when you don ' t have visual contact . 
so um 
can we actually record ? 
it just seems like that ' s a very different thing than what we ' re doing . 
uh well we ' ll have to set up for it . 
i mean physically can we record the the other 
yeah . 
well we ' re not really set up for it to do that . 
but 
or this is getting a little extravagant we could put up some kind of blinds or something to to remove uh visual contact . 
yeah . 
barriers ! 
yeah . 
that ' s what they did on map task you know this map task corpus . 
they ran exactly the same pairs of people with and without visual cues . 
and it ' s quite interesting . 
well we we record this meeting so regularly it wouldn ' t be that i mean a little strange . 
okay we can record but no one can look at each other . 
well we could just put blindfolds on . 
yeah . 
close your eyes . 
well no you 
yeah yeah . 
turn off the lights . 
and we ' d take a picture of everybody sitting here with blindfolds . 
that would 
oh that was the other thing . 
weren ' t we going to take a picture at the beginning of each of these meetings ? 
um what i had thought we were going to do is just take pictures of the whiteboards rather than take pictures of the meeting . 
well linguistic 
and uh 
yeah . 
yes . 
linguistic anthropologists would would suggest it would be useful to also take a picture of the meeting . 
there ' s a head nodding here vigorously yeah . 
why why do we want to have a picture of the meeting ? 
the because you get then the spatial relationship of the speakers . 
you mean no 
well you could do that by just noting on the enrollment sheet the the seat number . 
and that could be 
yeah yeah . 
yeah . 
seat number that ' s a good idea . 
i ' ll do that . 
yeah . 
i ' ll do that on the next set of forms . 
so you ' d number them somehow . 
yeah . 
is possible to get information from the rhythmic from the uh uh files . 
i finally remembered to put uh put native language on the newer forms . 
we can can ' t you figure it out from the mike number ? 
no . 
okay . 
the wireless ones . 
and even the jacks i mean i ' m sitting here and the jack is over in front of you . 
oh . 
but probably from these you could ' ve infer it . 
yeah but it ' s it would be trivial 
it would be another task . 
it would be a research task . 
having having ground truth would be nice so seat number would be good . 
you know where you could get it ? 
yeah yeah . 
yeah . 
beam forming during the digit uh stuff . 
so i ' m going to put little labels on all the chairs with the seat number . 
uhhuh . 
that ' s a good idea . 
not the chairs . 
but you have to keep the chairs in the same like here . 
but uh 
the chairs are chairs are movable . 
put them like put them on the table where they 
the yeah . 
yep . 
yeah . 
yep . 
but you know they the the linguistic anthropologists would say it would be good to have a digital picture anyway . 
just remembered a joke . 
because you get a sense also of posture . 
what people were wearing . 
yeah . 
posture and we could like you know block out the person ' s face or whatever . 
the fashion statement . 
but but you know these are important cues . 
oh andreas was 
how big their heads are . 
i mean the the how a person is sitting is 
but if you just 
yeah . 
but from one picture i don ' t know that you really get that . 
andreas was wearing that same old sweater again . 
right ? 
you ' d want a video for that i think . 
it ' d be better than nothing is is just from a single picture i think you can tell some aspects . 
a video yeah . 
think so ? 
i mean i i could tell you i mean if if i ' m in certain meetings i notice that there are certain people who really do uh the body language is very uh is very interesting in terms of the dominance aspect . 
and and 
huh . 
yeah . 
and and morgan had that funny hair again . 
yeah well i mean you black out the that part . 
huh . 
but it ' s just you know the the body . 
he agreed . 
you know ? 
of course the where we sit at the table i find is very interesting that we do tend to to gravitate to the same place each time . 
yeah . 
and it ' s somewhat coincidental . 
i ' m sitting here so that i can run into the room if the hardware starts you know catching fire or something . 
oh no you you just like to be in charge that ' s why you ' re sitting 
i just want to be at the head of the table . 
yeah . 
take control . 
speaking of taking control you said you had some research to talk about . 
yeah . 
yeah i ' ve been playing with um uh using the close talking mike to do to try to figure out who ' s speaking . 
yeah . 
so my first attempt was just using thresholding and filtering that we talked about about two weeks ago . 
and so i played with that a little bit and it works okay except that it ' s very sensitive to your choice of your filter width and your threshold . 
so if you fiddle around with it a little bit and you get good numbers you can actually do a pretty good job of segmenting when someone ' s talking and when they ' re not . 
but if you try to use the same parameters on another speaker it doesn ' t work anymore . 
even if you normalize it based on the absolute loudness . 
but does it work for that one speaker throughout the whole meeting ? 
it does work for the one speaker throughout the whole meeting . 
um pretty well . 
pretty well . 
how did you do it adam ? 
how did i do it ? 
what do you mean ? 
yeah . 
i mean what was the 
the algorithm was uh take every frame that ' s over the threshold and then median filter it and then look for runs . 
yeah . 
uhhuh . 
so there was a minimum run length . 
every frame that ' s over what threshold ? 
so that 
a threshold that you pick . 
in terms of energy ? 
yeah . 
uh . 
okay . 
say that again . 
frame over threshold . 
so you take a each frame and you compute the energy . 
and if it ' s over the threshold you set it to one and if it ' s under the threshold you set it to zero so now you have a bit stream of zeros and ones . 
huh . 
okay . 
and then i median filtered that using um a fairly long filter length . 
uh well actually i guess depends on what you mean by long you know tenth of a second sorts of numbers . 
um and that ' s to average out you know pitch you know the pitch contours and things like that . 
and then uh looked for long runs . 
okay . 
and that works okay if you if you tune the filter parameters if you tune how long your median filter is and how high you ' re looking for your thresholds . 
did you ever try running the filter before you pick a threshold ? 
no . 
i certainly could though . 
but this was just i had the program mostly written already so it was easy to do . 
okay and then the other thing i did was i took javier ' s speaker change detector acoustic change detector and i implemented that with the close talking mikes . 
and unfortunately that ' s not working real well and it looks like it ' s 
the problem is he does it in two passes . 
the first pass is to find candidate places to do a break . 
and he does that using a neural net doing broad phone classification and he has the the uh one of the phone classes is silence . 
and so the possible breaks are where silence starts and ends . 
and then he has a second pass which is a modeling a gaussian mixture model . 
um looking for uh whether it improves or or degrades to split at one of those particular places . 
and what looks like it ' s happening is that the even on the close talking mike the broad phone class classifier ' s doing a really bad job . 
who was it trained on ? 
uh i have no idea . 
i don ' t remember . 
huh . 
does do you remember morgan ? 
was it broadcast news ? 
i think so yeah . 
um so at any rate my next attempt which i ' m in the midst of and haven ' t quite finished yet was actually using the uh thresholding as the way of generating the candidates . 
because one of the things that definitely happens is if you put the threshold low you get lots of breaks . 
all of which are definitely acoustic events . 
they ' re definitely someone talking . 
but like it could be someone who isn ' t the person here but the person over there or it can be the person breathing . 
and then feeding that into the acoustic change detector . 
and so i think that might work . 
but i haven ' t gotten very far on that . 
but all of this is close talking mike . 
so 
it ' s uh just just trying to get some ground truth . 
only with uh uh 
but uh i i i think uh when when i i saw the the the the speech from p d a and uh close talker . 
i i think the there is a a great difference in the in the signal . 
oh absolutely . 
so my intention for this is is as an aide for ground truth . 
um but uh i but uh i i i mean that uh uh in the in the mixed file you can find uh zone with uh great different uh level of energy . 
not 
um i i think for uh algorithm based on energy uh that um huh more or less uh like uh uh huh first sound energy detector . 
say it again ? 
uh nnn . 
when you the detect the the the first at at the end of of the detector of um um . 
what is the the name in english ? 
the the huh the detector of um of a word in the in the in an isolated word in in the background that uh 
i ' m i ' m not sure what you ' re saying . 
can you try 
i mean that when when you use uh uh any 
i think he ' s saying the onset detector . 
yeah . 
onset detector okay . 
i i think it ' s probably to work well uh because uh you have uh in the mixed files a great level of energy . 
uh and great difference between the speaker . 
and probably is not so easy when you use the the p d a uh that because the signal is uh the in the energy level . 
right . 
in in that uh uh speech file is uh more similar . 
right . 
between the different uh speaker um i i think is uh it will is my opinion . 
but different speakers . 
it will be uh more difficult to to detect bass tone energy . 
the the change . 
i think that um 
uh in the in the p d a you mean ? 
in the p d a . 
absolutely . 
yeah no question . 
yeah . 
yeah . 
it ' ll be much harder . 
much harder . 
yeah . 
and the the another question that when i review the the the work of javier . 
i think the nnn the nnn that the idea of using a neural network to to get a broad class of phonetic uh from uh uh a candidate from the the the speech signal . 
if you have uh uh i ' m considering only because javier uh only consider uh like candidate the nnn uh the silence because it is the the only model uh uh he used that uh uh nnn to detect the the possibility of a a change between the between the speaker . 
right . 
um another another research thing different groups uh working uh on broadcast news prefer to uh to consider hypothesis uh between each phoneme . 
uhhuh . 
yeah when a phone changes . 
because i i i think it ' s more realistic that uh only consider the the the the silence between the speaker . 
uh there there exists uh silence between between uh a speaker . 
is is uh uh acoustic uh event important to to consider . 
uhhuh . 
uhhuh . 
i i found that the uh silence in in many occasions in the in the speech file . 
but uh when you have uh uh two speakers together without enough silence between between them uh i think uh is better to use the acoustic change detector basically and i i i i x or huh bic criterion for consider all the frames in my opinion . 
uhhuh . 
yeah the you know the reason that he uh just used silence was not because he thought it was better it was it was it was the place he was starting . 
yeah . 
yep . 
yeah . 
so he was trying to get something going . 
yeah yeah yeah yeah . 
and uh you know as as as is in your case if you ' re here for only a modest number of months you try to pick a realistic goal . 
yeah . 
do something . 
yeah yeah yeah yeah . 
but his his goal was always to proceed from there to then allow broad category change also . 
uhhuh . 
but uh do do you think that if you consider all the frames to apply the the uh the bic criterion to detect the the the different acoustic change uh between speaker ? 
without uh with uh silence or with overlapping . 
uh 
i think like like uh uh a general uh uh way of process the the acoustic change . 
uhhuh . 
in a first step i mean . 
uhhuh . 
and then uh uh without considering the you you you um you can consider the energy like another parameter in the in the feature vector . 
right . 
absolutely . 
uh 
uhhuh . 
this this is the idea . 
and if if you do that uh uh with a bic uh criterion for example or with another kind of uh of distance in a first step and then you uh you get the uh the hypothesis to the this change acoustic uh to process . 
right . 
because uh uh probably you you can find the the uh a small gap of silence between speaker with uh uh a huh small duration less than uh two hundred milliseconds for example . 
uhhuh . 
and apply another another algorithm another approach like uh uh detector of uh detector of bass tone energy to to consider that uh that uh zone of a small silence between speaker . 
or another algorithm to to process uh the the segment between marks uh founded by the the the bic criterion and applied for for each frame . 
uhhuh . 
i think is uh nnn it will be an an a more general approach the if we compare with use uh a neural net or another uh speech recognizer with a broad class or or narrow class . 
uhhuh . 
because in my opinion uh it ' s in my opinion uh if you if you change the condition of the speech i mean if you adjust to your algorithm with a mixed speech file and to uh to uh adapt the neural net uh used by javier with a mixed file . 
uhhuh . 
uhhuh . 
with the what file ? 
uh with a mixed file . 
with a the mix mix . 
mixed . 
mixed . 
mixed ? 
uhhuh . 
sorry . 
and and then you you uh you try to to apply that uh uh uh speech recognizer to that signal to the p d a uh speech file i i think you will have problems because the the the the condition you you will need i i suppose that you will need to to to retrain it . 
oh absolutely . 
well i i 
this is this is not what i was suggesting to do . 
look i i think this is a 
really ? 
one once it ' s a i used to work like on voiced on voice silence detection you know and this is this kind of thing . 
yeah . 
um if you have somebody who has some experience with this sort of thing and they work on it for a couple months they can come up with something that gets most of the cases fairly easily . 
then you say okay i don ' t just want to get most of the cases i want it to be really accurate . 
then it gets really hard no matter what you do . 
so the the problem is is that if you say well i i have these other data over here that i learn things from either explicit training of neural nets or of gaussian mixture models or whatever . 
yeah . 
uh suppose you don ' t use any of those things . 
you say you have looked for acoustic change . 
well what does that mean ? 
that that means you set some thresholds somewhere or something . 
yeah . 
right ? 
yeah . 
and and so where do you get your thresholds from ? 
from something that you looked at . 
so you always have this problem you ' re going to new data . 
um how are you going to adapt whatever you can very quickly learn about the new data uh if it ' s going to be different from old data that you have ? 
and i think that ' s a problem with this . 
well also what i ' m doing right now is not intended to be an acoustic change detector for far field mikes . 
what i ' m doing is trying to use the close talking mike and just use and just generate candidate and just try to get a first pass at something that sort of works . 
yeah . 
actually actually actually 
you have candidates . 
the candidate . 
i 
to make marking easier . 
or 
yeah . 
and i haven ' t spent a lot of time on it and i ' m not intending to spend a lot of time on it . 
okay . 
i um i unfortunately have to run . 
so 
but um i can imagine uh building a um model of speaker change detection that takes into account both the far field and the uh actually not just the close talking mike for that speaker but actually for all of for all of the speakers . 
yep . 
everyone else . 
yeah . 
um if you model the the effect that me speaking has on your microphone and everybody else ' s microphone as well as on that and you build um 
basically i think you ' d you would build a an h m m that has as a state space all of the possible speaker combinations . 
all the yep . 
yeah . 
and um you can control 
it ' s a little big . 
it ' s not that big actually . 
um . 
two to the n . 
two to the number of people in the meeting . 
but actually andreas maybe maybe just something simpler but but along the lines of what you ' re saying . 
anyway . 
yeah . 
i was just realizing i used to know this guy who used to build uh um mike mixers automatic mike mixers where you know in order to able to turn up the gain you know uh as much as you can you you you lower the gain on on the mikes of people who aren ' t talking . 
huh . 
yeah yeah . 
huh . 
uhhuh . 
right ? 
uhhuh . 
and then he had some sort of reasonable way of doing that . 
but uh what if you were just looking at very simple measures like energy measures but you don ' t just compare it to some threshold overall but you compare it to the energy in the other microphones ? 
i was thinking about doing that originally to find out who ' s the loudest . 
and that person is certainly talking . 
yeah . 
but i also wanted to find threshold uh excuse me overlap . 
yeah . 
so not just just the loudest . 
uhhuh . 
but uh 
i i sorry . 
i i have found that when when i i analyzed the the speech files from the uh mike uh from the uh close uh microphone uh i found zones with a a different level of energy . 
sorry i have to go . 
okay . 
could you fill that out anyway ? 
just put your name in . 
are you want me to do it ? 
i ' ll do it . 
but he ' s not going to even read that . 
i know . 
oh . 
including overlap zone . 
including . 
because uh uh depend on the position of the of the of the each speaker to uh to get more or less energy in the mixed in the signal . 
and then if you consider energy to to detect overlapping in in uh and you process the the in the the the speech file from the the the mixed signals . 
the mixed signals uh . 
i i think it ' s it ' s difficult um only to with energy to to consider that in that zone we have uh uh overlapping zone uh if you process only the the energy of the of each frame . 
well it ' s probably harder . 
but i i think what i was nnn noting just when he when andreas raised that was that there ' s other information to be gained from looking at all of the microphones and you may not need to look at very sophisticated things . 
yeah . 
because if there ' s if most of the overlaps you know this doesn ' t cover say three but if most of the overlaps say are two if the distribution looks like there ' s a couple high ones and and the rest of them are low . 
yeah . 
yeah . 
yeah . 
and everyone else is low yeah . 
yeah . 
you know what i mean ? 
yeah . 
there ' s some information there about their distribution even with very simple measures . 
yeah . 
yeah . 
uh by the way i had an idea with while i was watching chuck nodding at a lot of these things is that we can all wear little bells on our heads so that then you ' d know that . 
yeah . 
ding ding ding ding . 
ding . 
yeah . 
that ' s cute . 
i think that ' d be really interesting too with blindfolds . 
nodding with blindfolds . 
then 
yeah . 
what are you nodding about ? 
the question is like whether 
well trying with and with and without yeah . 
sorry i ' m just i ' m just going to sleep . 
but then there ' s just one like . 
yeah . 
actually i saw a uh a woman at the bus stop the other day who um was talking on her cell phone speaking japanese and was bowing . 
yeah yeah . 
you know profusely . 
oh yeah that ' s really common . 
yeah . 
uh . 
just kept 
yeah . 
wow . 
it ' s very difficult if you try while you ' re trying say to convince somebody on the phone it ' s difficult not to move your hands . 
not you know if you watch people they ' ll actually do these things . 
uhhuh . 
so 
i still think we should try a a meeting or two with the blindfolds . 
at least of this meeting that we have lots of recordings of . 
uhhuh . 
yeah i think 
um maybe for part of the meeting we don ' t have to do it the whole meeting . 
i think it ' s a great idea . 
that could be fun . 
it ' ll be too hard to make barriers i was thinking because they have to go all the way . 
yeah . 
you know i can see chuck even if you put a barrier here . 
well we could just turn out the lights . 
actually well also i i can say i made barriers for so that the stuff i was doing with collin which just used um this kind of foam board . 
yeah ? 
really inexpensive . 
you can you can masking tape it together . 
these are you know pretty large partitions . 
yeah . 
but then we also have these mikes is the other thing i was thinking . 
so we need a barrier that doesn ' t disturb the sound . 
the acoustics . 
it ' s true it would disturb the um the the long range . 
um 
blindfolds would be good . 
i think blindfolds . 
it would 
i mean it sounds weird but but you know it ' s it ' s cheap and uh be interesting to have the camera going . 
probably we should wait until after adam ' s set up the mikes . 
but 
okay . 
i think we ' re going to have to work on the uh on the human subjects form . 
i ' ll be peeking . 
yeah that ' s right we didn ' t tell them we would be blindfolding . 
that ' s 
do you mind being blindfolded while you ' re interviewed ? 
that ' s that ' s that ' s the one that we videotape . 
so 
um i i want to move this along . 
uh i did have this other agenda item which is uh it ' s uh a list which i sent to uh a couple folks but um i wanted to get broader input on it . 
so this is the things that i think we did in the last three months . 
obviously not everything we did but but sort of highlights that i can can tell some outside person you know what what were you actually working on . 
um in no particular order uh one uh ten more hours of meeting meetings recorded something like that you know from from uh three months ago . 
uh x m l formats and other transcription aspects sorted out and uh sent to i b m . 
um pilot data put together and sent to i b m for transcription . 
uh next batch of recorded data put together on the c d roms for shipment to i b m . 
hasn ' t been sent yet but it ' s getting ready . 
but yeah that ' s why i phrased it that way yeah okay . 
um human subjects approval on campus uh and release forms worked out . 
so the meeting participants have a chance to request audio pixelization of selected parts of the their speech . 
um audio pixelization software written and tested . 
um preliminary analysis of overlaps in the pilot data we have transcribed . 
and exploratory analysis of long distance inferences for topic coherence that was i was wasn ' t sure if those were the right way that was the right way to describe that because of that little exercise that that you and and lokendra did . 
what was that called ? 
the uh say again . 
i well i ' m probably saying this wrong but what i said was exploratory analysis of long distance inferences for topic coherence . 
something like that . 
um so uh i a lot of that was from you know what what what you two were doing . 
so i i sent it to you . 
and you know please mail me you know the corrections or suggestions for changing . 
uhhuh . 
i i don ' t want to make this twice it ' s length but but you know just improve it . 
um is there anything anybody 
i i did a bunch of stuff for supporting of digits . 
bunch of stuff for 
okay maybe maybe send me a sentence that ' s a little thought through about that . 
so okay i ' ll send you a sentence that doesn ' t just say a bunch of ? 
bunch of stuff yeah stuff is probably bad too . 
yep . 
stuff is not very technical . 
yeah well . 
i ' ll try to phrase it in passive voice . 
yeah . 
yeah yeah . 
technical stuff . 
range of things yeah . 
um and and you know i sort of threw in what you did with what jane did on in under the uh uh preliminary analysis of overlaps . 
uh uh thilo can you tell us about all the work you ' ve done on this project in the last uh last three months ? 
yeah . 
so what is what um 
that ' s 
not really . 
it ' s too complicated . 
um i didn ' t get it . 
what is audio pixelization ? 
uh audio he did it . 
so why don ' t you explain it quickly ? 
it ' s just uh beeping out parts that you don ' t want included in the meeting . 
so you know you can say things like well this should probably not be on the record but beep . 
okay okay . 
i got that . 
yeah . 
we we we spent a a a fair amount of time early on just dealing with this issue about op we realized well people are speaking in an impromptu way and they might say something that would embarrass them or others later and how do you get around that . 
okay . 
so in the consent form it says well you we will look at the transcripts later and if there ' s something that you ' re unhappy with yeah . 
okay and you can say 
okay . 
but you don ' t want to just totally excise it . 
because 
um 
uh well you have to be careful about excising it how how you excise it . 
keeping the timing right and so forth . 
so that at the moment the idea we ' re running with is is putting the beep over it . 
yeah you can either beep or it can be silence . 
okay . 
i i couldn ' t decide which was the right way to do it . 
uh yeah . 
beep is good auditorily . 
if someone is listening to it there ' s no mistake that it ' s been beeped out . 
yeah . 
yeah . 
but for software it ' s probably better for it to be silence . 
no no . 
you can you know you could make a as long as you keep using the same beep people could make a model of that beep . 
huh . 
yep . 
and 
i like that idea . 
and i use it ' s it ' s uh it ' s an a below middle c beep . 
i think the beep is a really good idea . 
it ' s very clear . 
yeah . 
then you don ' t think it ' s a long pause . 
also 
so 
yeah it ' s more obvious that there was something there than if there ' s just silence . 
yeah that i mean he ' s he ' s removing the old thing . 
yeah . 
yeah . 
yeah . 
yep . 
and and and 
right . 
right . 
yeah it ' s not 
but i mean if you just replaced it with silence it ' s not clear whether that ' s really silence or 
yeah . 
yeah . 
yeah i agree . 
yep . 
yeah . 
yeah . 
one one question . 
do you do it on all channels ? 
of course . 
interesting . 
i like that . 
yeah you have to do it on all channels because it ' s uh audible . 
yeah . 
yeah i like that . 
very clear . 
very clear . 
uh it ' s it ' s potentially audible you could potentially recover it . 
keep a back door . 
well the other thing that you know i mean the the alternative might be to 
yeah . 
well i i haven ' t thrown away any of the meetings that i beeped . 
actually yours is the only one that i beeped and then uh the darpa meeting . 
notice how quiet i am . 
sorry . 
and then the darpa meeting i just excised completely . 
yeah . 
so it ' s in a private directory . 
that ' s great . 
you have some people who only have beeps as their speech in these meetings . 
yeah . 
okay . 
they ' re easy to find then . 
all right so uh i think we should uh uh go on to the digits . 
okay . 
i have one concept i i want to say which is that i think it ' s nice that you ' re preserving the time relations . 
so you ' re you ' re not just cutting you ' re not doing scissor snips . 
right . 
you ' re you ' re keeping the uh the time duration of a deleted deleted part . 
yeah definitely . 
yeah . 
okay good digits . 
yeah since we want to possibly synchronize these things as well . 
oh i should have done that . 
shoot ! 
it ' s great . 
oh well . 
yeah . 
oh 
so i guess if there ' s an overlap like if i ' m saying something that ' s bleepable and somebody else overlaps during it they also get bleeped too ? 
you ' ll lose it . 
there ' s no way around that . 
yeah . 
um i i did before we do the digits i did also want to remind people uh please do send me you know uh thoughts for an agenda . 
agenda ? 
yeah . 
that that would be that ' d be good . 
good . 
uh so that uh people ' s ideas don ' t get 
thursday crept up on me this week . 
yeah well it does creep up . 
doesn ' t it ? 
okay . 
and i wanted to say i think this is really interesting analysis . 
it ' s cool stuff definitely . 
thank you . 
thank you . 
i meant to say that before i started off on the switchboard stuff . 
i was going to say can you do that for the other meetings . 
it ' s neat . 
can you do it for them ? 
and no actually you can ' t . 
yeah . 
does it take 
actually actually i i thought that ' s what you were giving us was another meeting and i was like oh okay . 
thank you . 
ooo cool ! 
yeah . 
aw thanks . 
how long does it take just briefly like to okay to label the 
no . 
i have the script now . 
so i mean it can work off the uh other thing . 
it ' s as soon as we get labels yep . 
okay . 
but it has to be hand labeled first ? 
but 
uh well yeah . 
because uh well i mean once his his algorithm is up and running then we can do it that way . 
if it works well enough . 
right now it ' s not not quite to the point where it works . 
okay . 
but i i just worked off of my 
okay go ahead 
it ' s really neat . 
thanks . 
appreciate that . 
i think what i what this has uh caused me so this discussion caused me to want to subdivide these further . 
i ' m going to take a look at the uh backchannels . 
how much we have i hope to have that for next time . 
yeah my my algorithm worked great actually on these . 
that ' d be interesting . 
but when you wear it like that or with the uh lapel or if you have it very far from your face that ' s when it starts failing . 
uhhuh . 
well i can wear it i mean if you 
oh . 
it doesn ' t matter . 
okay . 
i mean we want it to work . 
right ? 
it ' s too late now . 
i i don ' t want to change the way we do the meeting . 
i feel like this troublemaker . 
it ' s uh so it was just a comment on the software not a comment on prescriptions on how you wear microphones . 
okay . 
okay that ' s let ' s let ' s let ' s do digits . 
get the bolts whh whh . 
let ' s do it . 
okay . 
okay . 
yeah i think i got my mike on . 
okay . 
let ' s see . 
okay ami do yours . 
then we ' ll open it . 
and i think it ' ll be enough . 
huh doesn ' t uh it should be the other way . 
yeah now it ' s on . 
right okay . 
okay . 
so we all switched on ? 
we are all switched on yeah . 
all right . 
we are all switched on . 
anyway so uh before we get started with the uh technical part i just want to review what i think is happening with the our data collection . 
so uh probably after today that shouldn ' t come up in this meeting . 
this this is should be it isn ' t there ' s another thing going on of gathering data . 
and that ' s pretty much independent of this . 
but uh i just want to make sure we ' re all together on this . 
what we think is going to happen is that uh in parallel starting about now we ' re going to get fey to where you ' re working with me and robert draft a note that we ' re going to send out to various cogsci and other classes saying here ' s an opportunity to be a subject . 
contact fey . 
and then there ' ll be a certain number of um hours during the week which she will be available . 
and we ' ll bring in people . 
uh roughly how many robert ? 
we do we know ? 
um fifty was our sort of our first 
okay so we ' re looking for a total of fifty people . 
not necessarily by any means all students . 
but we ' ll we ' ll start with with that . 
in parallel with that we ' re going to need to actually do the script . 
and so i guess there ' s a plan to have a meeting friday afternoon uh with uh jane and maybe liz and whoever on actually getting the script worked out . 
but what i ' d like to do if it ' s okay is to to as i say start the recruiting in parallel and possibly start running subjects next week . 
the week after that ' s spring break . 
and maybe we ' ll look for them some subjects next door . 
yeah . 
or 
yeah also fey will not be here during spring break . 
oh okay then we won ' t do it . 
so 
okay . 
so that ' s easy . 
um 
so is is that make sense to everybody ? 
yeah . 
also um both fey and i will um do something of which i may uh kindly ask you to to do the same thing . 
which is we going to check out our social infrastructures for possible subjects . 
meaning um kid children ' s gymnastic classes . 
preschool parents and so forth . 
they also sometimes have flexible schedules . 
so if you happen to be sort of in a non student social setting 
and you know people who may be interested in being subjects 
we also considered using the berkeley high school and their teachers maybe . 
and get them interested in stuff . 
that ' s a good idea . 
and um 
so that ' s as far as our brainstorming was concerned . 
oh yeah the high school ' s a great idea . 
so 
but i i will just make a first draft of the uh note . 
the write up note . 
send it to you and fey . 
and then 
and why don ' t you also copy jane on it ? 
and um 
are we have we concurred that uh these these forms are sufficient for us and necessary ? 
uh i think they ' re necessary . 
this the permission form . 
huh . 
nuh . 
uh there has to be one . 
and i think we ' re just going to use it as it is . 
and um 
n . . 
you happy with that ? 
well yeah . 
there ' s one tricky part about 
um 
they have the right 
um 
the last paragraph if you agree to participate you have the opportunity to have anything excised which you would prefer not to have included in the data set . 
okay . 
now that had to be included for this other one . 
which might have uh meetings you know about something . 
uhhuh . 
in this case it doesn ' t really make sense . 
um so what i ' d like to do is also have our subjects sign a waiver saying i don ' t want to see the final transcript . 
uhhuh . 
and if they don ' t if they say no i ' m not willing to sign that then we ' ll show them the final transcript . 
but um 
yep makes sense . 
that uh 
yeah so we might actually 
um 
jane may say that you know you can ' t do this . 
uh on the same form we need a separate form . 
but anyway i ' d i ' d i ' d like to um add a little uh a thing for them to initial saying nah i don ' t want to see the final transcript . 
uhhuh . 
but other than that that ' s one ' s been approved . 
this really is the same project . 
uh 
you know 
and so forth . 
so i think we just go with it . 
yeah . 
yeah . 
okay . 
so much for the data . 
except that with munich everything is fine now . 
they ' re going to transcribe . 
they ' re also going to translate the uh german data from the t . v . and cinema stuff for andreas . 
so 
they ' re they all seem to be happy now with that . 
so 
should we move on to the technical sides ? 
yep . 
well i guess the good good news of last week was the parser . 
so um 
bhaskara and i started working on the the parser . 
then bhaskara went to class and once he came back um it was finished . 
so 
it uh i didn ' t measure it . 
but it was about an hour and ten minutes . 
yep . 
something like that . 
and um and now it ' s we have a complete english parser that does everything the german parser does . 
which is not a lot . 
that ' s the uh point . 
but 
the uh that ' s not a lot . 
yes . 
okay . 
right . 
and um 
what did you end up having to do ? 
i mean was there anything interesting about it at all ? 
well if you uh 
we ' ll show you . 
yeah we can show us . 
or are we going to see that ? 
right ? 
well we the first we did is we we tried to to do change the the laufen into run or running or runs . 
yep . 
uhhuh . 
and we noticed that whatever we tried to do it no effect . 
okay . 
and we were puzzled . 
uhhuh . 
and uh the reason was that the parser completely ignores the verb . 
huh . 
so this sentence sentence is parses the the same output . 
interesting parser property . 
um even if you leave out um all all of this . 
i see . 
yeah . 
so it ' s basically feature film and t . v . 
today . 
that ' s what you need . 
okay . 
and the and the time right ? 
if if you ' d add add today and evening it ' ll add time or not . 
so it it does look at that . 
okay . 
but all the rest is simply frosting on the cake . 
and it ' s optional for that parser . 
true . 
so you can you you are are you going to show us the little templates ? 
and 
yeah we we can uh i can show you the templates . 
the former end 
i i also have it running here . 
oh i see . 
uhhuh . 
so if i do this now um you can see that it parsed the wonderful english sentence which films are on the cinema today evening . 
but um 
well that sounds 
uh don ' t worry about it . 
it could be this evening which which films are on the cinema . 
no 
or running in the cinema . 
which 
okay . 
uh today evening uh is anything happening in the cinema this evening . 
okay key words basically . 
well 
elaborate or more or less uh 
actually it ' s a little tricky in that there ' s some allowable german orders which aren ' t allowable english orders and so forth . 
and it is order based . 
so it it 
isn ' t it ? 
no . 
no . 
oh so it it it these these optional elements 
it is not 
it ' s it ' s actually a set ? 
not a sequence . 
yeah we were i was afraid that um 
oh . 
so it really is key word matching basically . 
really a 
yeah . 
um 
uhhuh . 
oh wow ! 
um i mean these sentences are just silly . 
huh . 
i mean uh these were not the ones we we actually did it . 
um 
what ' s an idiomatic of phrasing this ? 
which films are showing . 
are playing at the cinema . 
playing . 
yeah . 
tonight . 
i changed that file actually where it ' s on my account . 
this this evening . 
actually you would say which films are on tonight . 
you want to get it ? 
or is was it easy to get it ? 
um i have no net here . 
oh okay . 
do i ? 
okay so wonderful parse . 
same thing . 
um 
right . 
except that we we don ' t have this uh time information here now . 
which is 
um 
oh this are the reserve . 
anyways so 
um these are the sort of the ten different sentence types that the uh the parser was able to do . 
and it still is now in english . 
yeah . 
uhhuh . 
and um 
sorry . 
and um 
you have already to make it a little bit more elaborate right ? 
yeah i mean i changed those sentences to make it uh more uh idiomatic . 
and of course you can have many variations in those sentences they will still parse fine . 
so in a sense it ' s pretty broad . 
okay . 
okay . 
so if you want to look at the templates they ' re conveniently located in a file template . 
um 
and this is what i had to do . 
i had to change spielfilm to film . 
uh film to movie . 
kino to cinema . 
today heute to today . 
huh . 
evening abend to evening . 
capitalized as well . 
huh . 
and um 
one thing i was wondering was those functions there are those things that modify the m . three l . basically ? 
yep . 
okay . 
and that ' s that ' s the next step . 
but we ' ll get to that in a second . 
and so this means um 
oh . 
this and see are not optional . 
want i like is all maybe in there . 
but may also not be in there . 
so so the point is if it says this and see it also will work in see and this . 
in the other order . 
yeah . 
with those two key words . 
should we try it ? 
this is the one i want to see . 
or whatever . 
okay . 
action watch . 
huh . 
whatever . 
nothing was specified . 
except that it has some references to audio visual media here . 
a . v . medium . 
yeah . 
where it gets that from 
it ' s correct . 
but i don ' t know where it gets it from . 
see . 
oh see . 
yeah . 
i mean it ' s sort of 
yeah yep okay . 
and see this is exactly the same thing . 
okay so it is set based . 
all right . 
one thing i was wondering was those percentage signs right . 
so i mean why do we even have them ? 
because if you didn ' t have them 
yep . 
uh i ' ll tell you why . 
because it gives a you a score . 
uhhuh . 
oh . 
and the value of the score is i assume i guess the more of these optional things that are actually in there the higher the score it is . 
okay . 
right . 
it ' s a match . 
so that ' s the main purpose all right . 
uhhuh . 
okay . 
so we we shouldn ' t belittle it too much . 
it ' s doing something . 
some things . 
and it ' s very flexible . 
i ' ve just tried to 
uhhuh . 
right . 
be nice . 
no no . 
right yeah . 
fine . 
yeah yeah yeah flexible it is . 
but 
okay um let ' s hope that the generation will not be more difficult . 
even though the generator is a little bit more complex . 
uh but we ' ll 
huh 
that means we may need two hours and twenty minutes rather than an hour ten minutes . 
right . 
i hope . 
all right . 
and the next thing i would like to be able to do and it seems like this would not be too difficult either is to say okay let ' s now pretend we actually wanted to not only change the the mapping of of uh words to the m . three l . but we also wanted to change add a new sentence type . 
and and make up some some new m . threel . 
yep . 
that ' d be great . 
it would be a good exercise to just see whether one can get that to run . 
see 
uhhuh yep . 
and um 
so that ' s 
fine yeah . 
that ' s shouldn ' t be too tough . 
yeah so where are those 
those functions action goodbye and so on right . 
are they actually um are they going to be called ? 
um are they present in the code for the parser ? 
yeah i think what it does it it does something sort of fancy . 
it loads 
um 
it has these style sheets and also the um schemata . 
so what it probably does is it takes the 
uh um 
is this where it is ? 
this is already the x . m . l . stuff . 
this is where it takes its own um syntax . 
and converts it somehow . 
um 
where is the uh 
what are you looking for ? 
um where it actually produces the the x . m . l . out of the uh parsed stuff . 
oh okay . 
no this is not it . 
uh i can ' t find it now . 
you mean where the where the how the action goodbye maps into something 
yeah . 
yeah where are those constructors defined ? 
oh . 
nope . 
no that ' s not it . 
yeah . 
this is sort of what happens . 
this is what you would need to to change to get the uh x . m . l . changed . 
so when it encounters day it will uh 
activate those classes in the in the x . m . l . stuff . 
but um 
i saw those actions uh the goodbye stuff somewhere . 
huh huh huh huh huh . 
grep for it ? 
yeah let ' s do that . 
oh . 
huh . 
m . three l . dot d . t . d . 
yep . 
that ' s just a specification for the x . m . l . format . 
yep . 
well we ' ll find that out . 
so whatever this does 
i mean this is basically looks to me like a function call right ? 
huh ? 
oh yeah . 
and um 
so whenever it it encounters goodbye 
which we can make it do in a second here . 
that function automatically generates an initialized x . m . l . structure . 
i think each of those functions act on the current x . m . l . structure and change it in some way for example by adding a a a field to it or something . 
yeah they also seem to affect state . 
uhhuh . 
cause some of them 
there were other actions uh that that seemed to step state variables somewhere . 
right . 
like the discourse status confirm . 
yep . 
okay so that ' s going to be a call on the discourse . 
and confirm that it ' s 
uhhuh 
oh you mean that ' s not going to actually modify the tree . 
but it ' s going to change the event . 
i think that ' s right . 
i think it ' s actually that looks like it ' s state modification . 
oh oh . 
huh 
um well 
there is a feature called discourse status . 
when there ' s a feature . 
yeah . 
and so whenever i just say write it will it will put this in here . 
oh so it always just 
is it so it 
well go back then . 
because it may be that all those things while they look like function calls are just a way of adding exactly that to the x . m . l . 
yep . 
uhhuh . 
i ' m not i ' m not sure . 
so this 
i ' m not sure that 
um well we we ' ll see when we say 
let ' s test something . 
goodbye causes it to to create basically an action goodbye end action . 
which is a means of telling the system to shut down . 
right . 
right . 
now if we know that write produces a feature discourse status confirm discourse status . 
so if i now say write goodbye it should do that . 
it it creates this . 
uhhuh . 
right . 
confirm goodbye . 
right there . 
yep . 
but there is some kind of function call . 
because how does it know to put goodbye in content but uh confirm in features ? 
oh . 
it it that ' s because 
so it ' s not just that it ' s adding that field . 
it ' s 
right . 
absolutely . 
okay . 
good point . 
it ' s it ' s the it ' s under what subtype you ' re doing it . 
uhhuh . 
yeah . 
yeah . 
it ' s mystery functions . 
well they ' re defined somewhere presumably . 
well sometimes it sometimes 
yeah each is 
when it 
so that ' s funny . 
you bury the the state in the function . 
all right . 
uh 
well it just automatically initializes things that are common right ? 
it 
so it ' s just a shorthand . 
yeah . 
for example 
oh this is german . 
sorry . 
so now this it cannot do anymore . 
nothing comes out of here . 
a not a number is a value awesome . 
so it doesn ' t speak german anymore . 
but it does speak english . 
and there is here a reference . 
so this tells us that whatever is has the i . d . zero is referenced here by the restriction seed . 
and this is i want 
what was the sentence ? 
i want two seats here . 
need two seats here nuh . 
and where is it playing there should also be a reference to something maybe . 
our this is um 
huh . 
here we change and so we here we add something to the discourse status that the user wants to change something that was sort of done before . 
and uh 
and that whatever is being changed has something to do with the cinema . 
so then whatever takes this m . three l . is what actually changes the state . 
not the 
yeah okay . 
no right the discourse maintainer . 
yeah . 
yeah . 
i see . 
and it and it runs around looking for discourse status tags . 
and doing whatever it does with them . 
and other people ignore those tags . 
all right . 
so yeah i definitely think it ' s it ' s worth the exercise of trying to actually add something that isn ' t there . 
huh . 
uh 
sort of get a complete understanding of the whole thing . 
yeah a kid understanding what ' s going on . 
then the next thing we talked about is actually um figuring out how to add our own tags and stuff like that . 
okay . 
point number two . 
i got the uh m . three l . for the routes today . 
uh so i got some more . 
this is sort of the 
uh um 
huh . 
interesting . 
it ' s just going up . 
it ' s not going back down . 
so this is um what i got today is the the new um m . three l . for um the maps . 
yep . 
uh and with some examples . 
so this is the x . m . l . and this is sort of what it will look like later on . 
even though it you can ' t see it on on this resolution . 
and this is what it sort of is the the structure of map requests . 
um 
also not very interesting . 
and here is the more interesting stuff for us is the routes . 
route elements . 
and again as we thought it ' s really simple . 
this is sort of the uh um parameters . 
we have simple from objects and to objects and so forth . 
points of interest along the way . 
and um 
i asked them whether or not we could um 
first of all i was little bit 
it seemed to me that this way of doing it is sort of a a step backwards from the way we ' ve done it before . 
it seems to me that some notions were missing . 
so these are these are 
so these are these are your friends back at e . m . l . 
yep . 
who are doing this . 
so this is not a complicated negotiation . 
no . 
there ' s there ' s not seven committees or anything right ? 
no this is very straightforward . 
great . 
so this is just trying to 
it ' s a design thing not a political thing . 
yeah . 
once we ' ve uh we can just sort of agree on what ought to be done . 
exactly . 
good . 
and um 
and uh 
however the uh so that you understand it is really simple . 
uh you you have a route . 
and you cut it up in different pieces . 
and every every element of that of that every segment we call a route element . 
and so from a . to b . we cut up in three different steps . 
and every step has a from object where you start a to object . 
where where you sort of end and some points of interest along the way . 
what i was sort of missing here and uh maybe it was just me being too stupid is i didn ' t sort of get the the notion of the global goal of the whole route . 
really was not straightforward visibly for me . 
and some other stuff . 
and i suggested that they should be uh kind enough to do two things for us . 
is one um also allocating uh some tags for our action schema enter vista approach . 
and 
and also um since you had suggested that that um we figure out if we ever for a demo reason wanted to shortcut directly to the g . i . s . and the planner 
of how we can do it . 
now what ' s the state of the art of getting to entrances . 
um what ' s the syntax for that ? 
how getting to vista points and calculating those on the spot ? 
and the approach mode anyhow is the default . 
that ' s all they do it these days . 
wherever you ' ll find a route planner it does nothing but get to the closest point where the street network is at minimal distance to the geometric center . 
uhhuh . 
so 
so well let now this is important . 
let uh i want again outside of almost managerial point 
um 
you ' re in the midst of this . 
so you know better . 
but it seems to me it ' s probably a good idea to uh minimize the number of uh change requests we make of them . 
so it seemed to me what we ought to do is get our story together . 
okay ? 
and think about it some internally before asking them to make changes . 
uhhuh . 
oh 
does this does this make sense to you guys ? 
it i mean you ' re you ' re doing the the interaction . 
but it seemed to me that what we ought to do is come up with a uh something where you um 
and i i don ' t know who ' s working most closely on it . 
probably johno . 
okay . 
uh take what they have . 
send it to everybody saying this is what they have . 
this is what we think we should add . 
okay ? 
and then have a a an iteration within our group saying huh well 
okay ? 
and get our best idea of what we should add . 
uhhuh . 
and then go back to them . 
is 
or i don ' t know . 
does this make sense to you ? 
or 
yeah especially if we want 
sort of what i my feeling was we we sort of reserved something that has a an okay label . 
that ' s that was my first sort of step . 
uhhuh . 
no matter how we want to call it this is sort of our playground . 
and if we get something in there that is a structure elaborate and and and and and complex enough to to to maybe enable a whole simulation one of these days that would be the the perfect goal . 
right . 
right . 
that ' s right . 
so 
so yeah . 
the problem isn ' t the short range optimization . 
it ' s the sort of one or two year kind of thing . 
okay what are the class of things we think we might try to do in a year or two ? 
how how would we try to characterize those ? 
and what do we want to request now that ' s leave enough space to do all that stuff ? 
uhhuh . 
yep . 
right . 
and that that requires some thought . 
yep . 
and so that sounds like a great thing to do as the priority item . 
um as soon as we can do it . 
yep . 
so so you guys will send to the rest of us um a version of um this . 
and the uh description . 
with yeah suggested improvements . 
and 
well 
yeah . 
so the the uh not everyone uh reads german . 
so if you ' d 
um 
huh . 
uh change the description to uh english . 
okay . 
and um 
then then 
yeah then with some suggestions about where where do we go from here ? 
uh this and this of course was just the action end . 
okay . 
uh at some point we ' re going to have to worry about the language end . 
but for the moment just uh for this class of of things we might want to try to encompass . 
and 
then the scope of this is beyond approach and or vista . 
oh yeah yeah yeah yeah . 
yeah yeah . 
this is this is everything that that um you know um we might want to do in the next couple years . 
yeah yeah . 
so what would 
huh . 
okay . 
we don ' t i mean that ' s an issue . 
we don ' t know what entirely . 
uh yeah . 
but i ' m just 
but the 
yeah okay . 
so i just 
this x . m . l . stuff here just has to do with source path goal type stuff . 
in terms of traveling through heidelberg . 
huh . 
right . 
or travel specifically . 
so but this is the domain greater than that ? 
no . 
i think i think the the idea is that 
okay . 
oh it ' s beyond source path goal . 
but i think we don ' t need to get beyond it tourists in heidelberg . 
okay . 
it seems to me we can get all the complexity we want in actions and in language without going outside of tourists in heidelberg . 
okay ? 
but you know depending on what people are interested in one could have uh tours . 
one could have um explanations of why something is is you know why why was this done . 
or 
i mean no there ' s no end . 
to the complexity you can build into the uh what a tourist in heidelberg might ask . 
huh . 
so at least unless somebody else wants to suggest otherwise i think the general domain we don ' t have to uh broaden . 
that is tourists in heidelberg . 
and if there ' s something somebody comes up with that can ' t be done that way then sure . 
we ' ll we ' ll look at that . 
but uh 
i ' d be i ' d be surprised at 
if there ' s any important issue that that 
and um 
i mean if if you want to uh push us into reference problems that would be great . 
okay . 
okay so this is his specialty is reference . 
uhhuh . 
and you know what what are these things referring to ? 
not only anaphora . 
but uh more generally the uh this whole issue of uh referring expressions . 
and what is it that they ' re actually dealing with in the world ? 
uhhuh . 
and again this is in the this is also pretty well formed . 
because there is an ontology . 
and the database and stuff . 
so it isn ' t like um you know the evening star or stuff like that . 
right . 
it 
all the entities do have concrete reference . 
right . 
although the to get at them from a language may not be trivial . 
right . 
there aren ' t really deep mysteries about um what what things the system knows about . 
right . 
and you have both proper names and descriptions . 
and and you can ask for it . 
all those things . 
yeah . 
uhhuh . 
you have proper names and descriptions . 
right . 
okay . 
and a and a lot and and anaphora and pronouns . 
nuh . 
right . 
and all those things . 
right . 
now we the the whole unfortunately the whole database is uh in german . 
we have just commissioned someone to translate some bits of it . 
i . e . the the shortest the the more general descriptions of all the objects and um persons and events . 
so it ' s a relational database with persons events and um objects . 
and it ' s it ' s quite um there . 
but did i uh i think there will be great . 
because the reference problem really is not trivial even if you have such a well defined world . 
he knows . 
you are not uh throwing uh uh carrying owls to athens . 
could you give me an example of a reference problem ? 
so so i can make it more concrete . 
well how do i get to the powder tower . 
we sort of think that our bit in this problem is interesting . 
but just to get from powder tower to an object i . d . in a database is also not really trivial . 
or or if you take something even more scary um how do i get to the third building after the tower . 
the powder tower . 
huh . 
uh you need some mechanism for 
yeah . 
or you know the church across from city hall . 
or 
or the the restaurant where they wear lederhosen . 
or 
right . 
or is that 
yeah that would be fine . 
right . 
okay . 
yeah . 
right . 
or or tower or this tower or that building or 
uniquely . 
huh . 
okay . 
or you can say how you know how do i get back . 
trying to 
yeah yeah . 
okay . 
and again it ' s just a question of which of these things uh people want to dive into . 
what uh i think i ' m going to try to do 
and i guess pwww . 
let ' s say that by the end of spring break i ' ll try to come up with some general story about um construction grammar . 
and what constructions we ' d use . 
and how all this might fit together . 
there ' s this whole framework problem that i ' m feeling really uncomfortable about . 
and i haven ' t had a chance to think about it seriously . 
but i i want to i want to do that early rather than late . 
and you and i will probably have to talk about this some . 
that ' s what strikes me that we sort of . 
the uh small 
something uh maybe we should address one of these days is to that most of the work people actually always do is look at some statements . 
and and analyze those . 
whether it ' s abstracts or newspapers and stuff like this . 
huh . 
but the whole is it is it really relevant that we are dealing mostly with sort of questions ? 
uh you know 
oh yeah . 
well i mean 
yeah 
and this is it seems to me that we should maybe at least spend a session or or brainstorm a little bit about whether that this is special case in that sense . 
uhhuh . 
um 
i don ' t know . 
you know did we ever find metaphorical use in in questions in in that sense really ? 
yeah . 
you will . 
and how soon ? 
i don ' t know . 
oh yeah . 
i mean uh we could take all the standard metaphor examples and make question versions of them . 
okay . 
who got kicked out of france . 
nuh . 
yeah or you know why is he why is he pushing for promotion . 
right . 
or who ' s pushing 
nuh . 
uh just pick pick any of them . 
and just do the uh 
uhhuh . 
so i don ' t i don ' t think uh it ' s at all difficult uh to convert them to question forms that really exist and people say all the time . 
um 
and sort of we don ' t know how to handle them too . 
right ? 
i mean it ' s 
i it 
we don ' t know how to handle the declarative forms really . 
and then the interrogative forms uhoh . 
uh 
ooo . 
yeah . 
nancy it looked like you were 
oh it ' s just that that the goals are very different to cases . 
so we had this problem last year when we first thought about this domain actually . 
was that most of the things we talked about are our story understanding . 
uh we ' re going to have a short discourse . 
right . 
and the person talking is trying to i don ' t know give you a statement and tell you something . 
and here it ' s 
help you create a mental model blah blah blah . 
yeah . 
uh yeah i guess so . 
yes . 
and then here you are uh the person is getting information . 
and they or may not be following some larger plan you know that we have to recognize or you know infer . 
and the their discourse patterns probably don ' t follow quite as many logical 
right no i think that ' s one of things that ' s interesting . 
yeah . 
is is in this sort of over - arching story we we worked it out for as you say this the storytelling scenario . 
uhhuh . 
uhhuh . 
and i think it ' s really worth thinking through what it looks like . 
uhhuh . 
what is the simspec mean et cetera ? 
right because for a while we were thinking well how can we change the um data to sort of illicit illicit um actions that are more like what we are used to . 
but obviously we would rather you know try to figure out what ' s what ' s you know 
well i don ' t know . 
i mean maybe maybe that ' s what we ' ll do is is 
we can do anything we want with it . 
yep . 
i mean once we have fulfilled these requirements 
huh uhhuh . 
uhhuh . 
okay and the one for next uh summer is just half done . 
and then the other half is this um generation thing which we think isn ' t much different . 
uhhuh . 
so once that ' s done then all the rest of it is uh sort of you know what we want to do for the research . 
and we can we can do all sorts of things that don ' t fit into their framework at all . 
there ' s no reason why we ' re we ' re constrained to do that . 
uhhuh . 
if we can use all the uh execution engines then we can you know really try things that would be too too much pain to do ourselves . 
uhhuh . 
but there ' s no obligation on any of this . 
so if we want to turn it into standing stories about heidelberg we can do that . 
i mean that would just be a um 
or as a matter of fact we need and if we if uh take a ten year perspective we need to do that . 
because 
assuming we have this um in that case we actually do have these wonderful stories and historical anecdotes . 
yeah . 
and knights jumping out of windows . 
huh . 
and and and tons of stuff . 
so the database is huge . 
and if we want to answer a question on that we actually have to go one step before that and understand that . 
uhhuh . 
in order to do sensible information extraction . 
yeah . 
uhhuh . 
and so 
you might yeah . 
um this has been a a a deep map research issue that was is is part of the unresolved and to - do ' s and something for the future is how can we sort of run our our text our content through a machine that will enable us later to retrieve or answer questions more sensibly ? 
uhhuh . 
uhhuh . 
huh . 
right . 
anyway . 
who ' s going ? 
so uh so uh i was just going to ask . 
um so 
what is the the basic thing that that you are um obligated to do um uh by the summer before uh we can move 
uh . 
okay . 
so uh yeah 
so what happened is 
there ' s this uh uh 
robert was describing 
the there ' s two packages . 
there ' s a uh quote parser . 
there ' s a particular piece of this big system . 
which in german uh takes these sentence templates and produces x . m . l . structures . 
right . 
and one of our jobs was to make the english equivalent of that . 
that these guys did in a in a day . 
right . 
right . 
the other thing is at the other end roughly at the same level there ' s something that takes uh x . m . l . structures produces an output x . m . l . structure . 
which is instructions for the generator . 
right . 
okay . 
and then there ' s a language generator . 
and then after that a a synthesizer that goes from an x . m . l . structure to uh language generation to actual specifications for a synthesizer . 
uh but again there ' s one module in which there ' s one piece that we have to convert to english . 
right . 
right . 
got it . 
is that 
okay . 
and that but as i say this is all along was viewed as a kind of a a minor thing . 
necessary but but not 
right . 
okay ? 
right . 
and much more interesting is the fact that as part of doing this we we are you know inheriting this system that does all of these other things . 
that ' s great . 
right . 
not precisely what we want . 
and that ' s that ' s where it it gets difficult . 
and i i don ' t pretend to understand yet what i think we really ought to do . 
okay . 
so enough of that . 
but i uh um 
huh . 
the sort of johno and i will take up that responsibility . 
and um get a first draft of that . 
now we have um just i think two more short things . 
okay . 
um you guys sort of started fighting uh on the bayes - net noisy or front ? 
huh . 
yeah i thought i should um talk a little bit about that . 
because that might be a good uh sort of architecture to have in general for uh problems with you know multiple inputs to a node . 
good okay . 
good . 
and what ' s the other one ? 
so that just we know what the agenda is . 
um the wu paper . 
i think maybe 
oh yeah . 
i ' ve got a couple new wu papers as well . 
uh so i i ' ve been in contact with wu . 
so probably let ' s put that off till i i till i understand better uh what he ' s doing . 
it ' s just a little embarrassing . 
cause all this was in his thesis . 
and i was on his thesis committee . 
and so i really knew this at one time . 
ugh . 
but i i it ' s not only uh is part of what i haven ' t figured out yet is is how all this goes together . 
so i ' ll dig up some more stuff from dekai . 
and so why don ' t we just do the uh 
okay . 
so 
should i is there a white board here that i can use ? 
yeah you could 
uh 
yeah . 
or shall i just use this ? 
squealing sound . 
it ' s probably just as easy . 
yeah . 
yeah . 
you can put the microphone in your pocket . 
hey . 
i was envying you and your pocket . 
cause i don ' t have one . 
it was a quick one huh ? 
that ' s why they invented pocket t . ' s . 
they have clips . 
exactly . 
huh . 
yeah . 
so um recall that uh we want to have this kind of structure in our bayes - nets . 
namely that um you have these nodes that have several bands right ? 
so 
does i mean they sort of 
the typical example is that um these are all a bunch of cues for something . 
and this is a certain effect that we ' d like to conclude . 
so uh 
like let ' s just look at the case when um this is actually the the final action right ? 
so this is like uh you know touch . 
or 
sorry . 
e . eva . 
uh 
yeah . 
e . e . v . a . right ? 
yeah . 
enter view approach right ? 
what was this ? 
it uh uh 
so this is 
write it out for 
yeah . 
i mean 
enter . 
view . 
approach . 
okay right . 
right ? 
so i mean we ' d like to take all these various cues right ? 
like the army . 
so this one might be say uh 
yeah . 
new terminology . 
well let me pick a random one . 
huh ? 
i haven ' t heard that before . 
and say uh 
i don ' t know . 
it could be like this isn ' t the way it really is . 
but let me say that suppose someone mentioned uh admission fees 
uh it takes too long . 
try let me just say landmark . 
if the thing is a landmark you know um then there ' s another thing that says if um 
if it ' s closed or not at the moment 
all right so you have nodes . 
right ? 
and the uh problem that we were having was that you know given n . nodes there ' s two to the n 
given n . nodes and furthermore the fact that there ' s three things here we need to specify three times uh two to the n probabilities . 
right ? 
that ' s assuming these are all binary which they may not be . 
for example they could be time of day . 
in which case we could uh say you know morning afternoon evening night . 
so this could be more . 
so it ' s a lot anyway . 
and that ' s a lot of probabilities to put here which is kind of a pain . 
so noisy - ors are a way to uh sort of deal with this . 
um 
where should i put this ? 
so the idea is that um let ' s call these uh c . one c . two c . three and c . four and e . for cause and effect i guess . 
the idea is to have these intermediate nodes . 
right . 
well actually the idea first of all is that each of these things has a quote unquote distinguished state . 
which means that this is the state in which we don ' t really know anything about it . 
so 
right ? 
so for example if we don ' t really know if the thing is a landmark or not or if that just doesn ' t seem relevant then that would be sort of the the distinguish state . 
it ' s a really you know if there is something for the person talking about the admission fee 
you know if they didn ' t talk about it that would be the distinguish state . 
so 
so this is a fanciful way of saying default ? 
yeah yeah . 
okay . 
that ' s just what they the word they used in that paper . 
uhhuh . 
so the idea is that um you have these intermediate nodes right ? 
e . one e . two e . three and e . four . 
so this is the heckerman paper you ' re working with . 
yeah . 
good . 
so the idea is that each of these e . i . is represents what this would be if all the other ones were in the distinguish state right ? 
so for example suppose that the person i mean suppose the thing that they talked about is a landmark . 
but none of the other sort of cues really apply . 
then this would be 
the this would just represent the probability distribution of this 
assuming that this cue is turned on and the other ones just didn ' t apply . 
so you know if it is a landmark and none of the other things really applicable then this would represent the probability distribution . 
so maybe in this case maybe we just maybe we decide that if the thing ' s a landmark and we don ' t know anything else then we ' re going to conclude that um they want to view it with probability you know point four . 
they want to enter it with probability uh with probability point five . 
and they want to approach it probability point one say . 
right ? 
so we come up with these little tables for each of those . 
okay ? 
and the final thing is that um this is a deterministic function of these . 
so we don ' t need to specify any probabilities . 
we just have to um say what function this is right ? 
so we can let this be um g . of e . one comma e . two e . three e . four right . 
and our example g . would be um a majority vote . 
right ? 
well okay so so the important point is not what the g . function is . 
the important point is that um there is a a a general kind of idea of shortcutting the full c . p . t . 
the full conditional probability table with some function . 
okay . 
which you choose appropriately for each case . 
so depending on what your situation is there are different functions which are most appropriate . 
and 
so i gave uh bhaskara a copy of this uh sort of ninety two paper . 
uhhuh . 
and you got one robert . 
i don ' t know who else has seen it . 
there ' s i mean 
yeah . 
it ' s heckerman and breese . 
it ' s short . 
it ' s short . 
yeah . 
so um uh you have you read it yet ? 
uh you can yeah you should take a look at it i guess . 
okay so you should take a look . 
okay . 
nancy i ' m sure you read it at some point in life . 
i 
yeah . 
i i think so yeah . 
okay . 
and so you other guys can decide how interested 
yeah . 
anyway so the paper isn ' t isn ' t real hard . 
okay . 
and uh 
one of the questions just come at bhaskara is how much of this does javabayes support ? 
yeah it ' s a good question . 
um the so what we want is basically javabayes to support deterministic uh functions . 
right . 
and um in a sense it we can make it supported by um manually uh entering you know probabilities that are one and zeros right ? 
right so the little handout that the little thing that i sent 
i sent a message saying uh here is a way to take 
one thing you could do which is kind of in a way stupid is take this deterministic function and use it to build the c . p . t . 
so if javabayes won ' t do it for you . 
huh . 
that you can convert all that into what the c . p . t . would be . 
um and what i sent out about a week ago was an idea of how to do that for um evidence combination . 
so one of one function that you could use as your g . function is an evidence combining . 
so you just take the uh if each of if each of the ones has its own little table like that then you could take the uh strength of each of those times its little table . 
and you ' d add up the total evidence for v . e . and a . . 
huh . 
i don ' t think you can do this . 
uhhuh . 
because g . is a function from that to that . 
yep . 
right . 
right ? 
so there ' s no numbers . 
there ' s just quadruplets of well n . duplets of uh e . v . ' s . 
no no but i ' m saying is there there is a 
i mean if if if you decide what ' s what is appropriate is probablistic evidence combination you can write a function that does it . 
it ' s a it ' s actually one of the examples he ' s got in there . 
but anyway skipping skipping the question of exactly which functions . 
now is it clear that you might like to be able to shortcut the whole conditional probability table ? 
i mean in some it seems very plausible in some sense where we will be likely to not be observe some of the stuff . 
because we don ' t have the access to the information . 
oops sorry . 
right . 
that ' s one of the problems is is is where would where would it all come from ? 
yeah . 
so 
is 
huh . 
oh right . 
would not be able to observe 
what ? 
if it ' s a a a discourse initial phrase we will have nothing in the discourse history . 
so if if we ever want to wonder what was 
oh . 
oh are you saying that we ' ll not be able to observe certain nodes ? 
that ' s fine . 
that is sort of orthogonal thing . 
yeah so there ' s there ' s two separate things robert . 
the the the the bayes - nets in general are quite good at saying if you have no current information about this variable just take the prior for that . 
okay that ' s what they ' re real good at . 
so if you don ' t have any information about the discourse you just use your priors of of whatever the discourse 
uh 
uh basically whatever it ' s probabilistically whatever it would be . 
and it ' s it ' s sort of not a great estimate . 
uhhuh . 
but it ' s the best one you have . 
and so forth . 
so that they ' re good at . 
but the other problem is how do you fill in all these numbers ? 
and i think that ' s the one he was getting at . 
uhhuh . 
yeah . 
yeah . 
so specifically in this case you have to have this many numbers . 
whereas in this case you just have to have three for this three for this three for this right ? 
so you have to have just three n . . 
uhhuh . 
so this is much smaller than that . 
asymptotically . 
uhhuh . 
yeah . 
well pretty quickly . 
right . 
yeah yeah . 
so you don ' t need data enough to cover uh nearly as much stuff . 
i mean 
i don ' t know . 
so really what a a noisy or seems to kind of neural - net - acize these bayes - nets . 
uh 
no no . 
so noisy or is a funny way of referring to this . 
because the noisy or is only one instance . 
yeah this isn ' t a noisy or anymore . 
that one actually isn ' t a noisy or . 
so we ' ll have to think of of a way 
yeah . 
it ' s a noisy - arg - max or a noisy whatever . 
yeah whatever . 
yeah . 
so uh um 
well my point was more that we just uh 
with the neural net right uh things come in you have a function that combines them . 
and 
yeah it it that ' s true . 
it is is also more neural net like although uh it isn ' t necessarily sum uh you know sum of weights or anything like that . 
right . 
i mean you could have 
uh like the noisy or function really is one that ' s essentially says uh take the max . 
well the or . 
same . 
right i guess you ' re right . 
yeah . 
uh 
but anyway 
so 
and i i think that ' s the standard way people get around the uh 
there are a couple other ones . 
there are ways of breaking this up into to to subnets and stuff like that . 
but um 
the 
i think we definitely i think it ' s a great idea to to pursue that . 
yep . 
so 
still sort of leaves one question . 
it i mean you you can always uh see easily that that i ' m not grasping everything correctly . 
but what seemed attractive to me in uh in the last discussion we had was that we find out a means of of getting these point four point five point one of c . four . 
not because you know a . is a landmark or not but we we we label this whatever object type . 
and if it ' s a garden it ' s point three point four point two . 
if it ' s a castle it ' s point eight point one point one . 
if it ' s uh a town hall it ' s point two point three point five . 
right . 
and so forth . 
and we don ' t want to write this down necessarily every time for something . 
but uh 
it ' ll be students 
let ' s see . 
where else would it be stored ? 
that ' s the question . 
well in the beginning we ' ll write up a flat file . 
we know we have twenty object types . 
oh . 
yeah 
and we ' ll write it down in a flat file . 
no 
so 
well let me say something guys . 
because there ' s not there ' s a pretty point about this we might as well get in right now . 
uhhuh . 
which is the hierarchy that comes with the ontology is just what you want for this . 
so that uh if you know about it let ' s say a particular town hall that it ' s one that is a monument then that would be stored there . 
if you don ' t you look up the hierarchy 
uh so you you you may or so then you ' d have this little vector of um you know approach mode or e . v . a . mode . 
let ' s okay so we have the e . v . a . vector for for various kinds of landmarks . 
if you know it for a specific landmark you put it there . 
if you don ' t you just go up the hierarchy to the first place you find one . 
okay . 
so is the idea to put it in the ontology ? 
absolutely . 
okay . 
uh or link to . 
or 
but but in any case view it logically as being in the ontology . 
it ' s part of what you know about a an object is its e . v . a . vector . 
okay . 
uhhuh . 
and if as i say if you know about a specific object you put it there . 
this is part of what dekai was doing . 
so when we get to wu we ' ll see what he says about that . 
right . 
and then if you if it isn ' t there it ' s higher . 
and if you don ' t know anything except that it ' s a it ' s it ' s a building then up at the highest thing you have the what amounts to a prior . 
if you don ' t know anything else about a building uh you just take whatever your crude approximation is up at that level . 
right . 
which might be equal or whatever it is . 
yeah . 
so that ' s a very pretty relationship between these local vectors and the ontology . 
and it seems to me the obvious thing to do unless we find a reason to do something different . 
yeah . 
does this make sense to you ? 
so 
yeah . 
so we are but we we ' re not doing the ontology . 
so we have to get to whoever is doing the ultimately 
indeed . 
we have to get them to 
so that ' s another thing we ' re going to need to do is is to either 
we ' re going to need some way to either get a tag in the ontology or add fields . 
or some way to associate 
or it may be that all we can do is um some of our own hash tables that it 
the you know there ' s always a way to do that . 
it ' s a just a question of 
yeah hash on object name to you know uh the probabilities or whatever . 
yeah . 
right . 
and so 
uh 
but it ' s uh well it strikes me as a what 
if we get the mechanism that will be sort of the wonderful part . 
and then how to make it work is is the second part . 
in the sense that i mean the guy who was doing the ontology uh uh apologized that it will take him another through two to three days . 
because they ' re having really trouble getting the upper level straight . 
and 
right now . 
the reason is given the craw bet uh the the the projects that all carry their own taxonomy and on all history they ' re really trying to build one top level ontology that covers all the e . m . l . projects . 
and that ' s uh uh sort of a tough cookie . 
a little bit tougher than they figured . 
i could have told them so . 
right . 
uh 
yeah . 
but nevertheless it ' s going to be there by by uh next monday . 
and i will show you what ' s what some examples from that for towers and stuff . 
and um 
what i don ' t think is ever going to be in the ontology is sort of you know the likelihood of uh people entering town halls and looking at town halls and approaching town halls . 
especially since we are dealing with a case based . 
not an instance based ontology . 
so there will be nothing on on that town hall or on the berkeley town hall or on the heidelberg town hall . 
it ' ll just be information on town halls . 
well they they they how what are they going to do with instances ? 
but what 
i mean you 
well that ' s 
hhh . 
that ' s that ' s different question . 
i mean the first they had to make a design question do we take ontologies that have instances ? 
or just one that does not that just has the types ? 
okay . 
and so since the decision was on types on a simply type based we now have to hook it up to instances . 
i mean this is 
one 
but what what is smartkom going to do about that ? 
because they have instances all the time . 
yeah but the ontology is really not a smartkom thing . 
in in and of itself . 
that ' s more something that i kicked loose in in e . m . l . 
so it ' s a completely e . m . l . thing . 
but uh uh smartkom ' s going to need an ontology . 
yes a a lot of people are aware of that . 
i understand but is anybody doing anything about it ? 
um 
okay . 
it ' s a political problem . 
we won ' t worry about it . 
no but the uh i i still think that there is enough information in there . 
for example whether 
okay so it will know about the twenty object types there are in the world . 
let ' s assume there are only twenty object types in this world . 
and it will know if any of those have institutional meanings . 
so in a sense i used as institutions for some in some sense or the other . 
which makes them enterable right ? 
in a sense . 
you know . 
yeah . 
anyway so we may have to 
yep . 
this is with the whole thing . 
we may have to build another data 
yep . 
conceptually we know what should be done . 
when we see what people have done it may turn out that the easiest thing to do is to build a a separate thing that that just pools 
like it it may be that the the instance 
that we have to build our own instance uh things that with their types . 
yeah it ' s 
right we can just assume 
and then it goes off to the ontology once you have its type . 
so we build a little data structure . 
and so what we would do in that case is in our instance gadget have our e . v . a . ' s . 
and if there isn ' t one we ' d get the type . 
and then have the e . v . a . ' s for the type . 
so we ' d have our own little uh e . v . a . tree . 
yeah . 
and then for other uh vectors that we need . 
right . 
so we ' d have our own little things so that whenever we needed one we ' d just use the ontology to get the type . 
uhhuh . 
uhhuh . 
and then would hash or whatever we do to say uh ! 
if it ' s that type of thing and we want its e . v . a . vector pppt - pppt it ' s that . 
so i think we can handle that . 
and then but the combination functions and whether we can put those in java bayes and all that sort of stuff is uh is the bigger deal . 
yeah . 
i think that ' s where we have to get technically clever . 
um 
we could just steal the classes in javabayes and then interface to them with our own code . 
well i ye uh yeah the 
that requires understanding the classes in javabayes i guess . 
yeah i mean it ' s uh cute . 
i mean you ' ve been around enough to 
i mean 
just . 
well it depends on 
i mean there ' s this huge package which which may or may not be consistent . 
and 
you know . 
but yeah we could look at it . 
well i was 
okay yeah . 
yeah . 
it ' s it 
it ' s an sort of a kind of a it 
the thing is it ' s kind of an interpreter . 
and it expects its data structures to be in a given form . 
and if you say hey we ' re going to make a different kind of data structure to stick in there 
well no but that just means there ' s a protocol . 
right ? 
that you could 
it may or may not . 
i don ' t know . 
that ' s the question is to what extent does it allow us to put in these g . functions ? 
and i don ' t know . 
well no but i mean what i uh the 
so you could have four different bayes - nets that you ' re running . 
and then run your own write your own function that would take the output of those four . 
and make your own g . function is what i was saying . 
yeah that ' s fine . 
if it ' s if it comes only at the end . 
but suppose you want it embedded ? 
well then you ' d have to break all of your bayes - nets into smaller bayes - nets . 
with all the 
oh that 
yeah that ' s a truly horrible way to do it . 
one would hope 
yeah but i ' m just 
uhhuh . 
yeah yeah yeah yeah yeah you bet . 
but at that point you may say hey java bayes isn ' t the only package in town . 
let ' s see if there ' s another package that ' s uh more civilized about this . 
now srini is worth talking to on this . 
huh . 
because he said that he actually did hack some combining functions into javabayes . 
uh . 
but he doesn ' t remember at least when i talked to him he didn ' t remember whether it was an an easy thing a natural thing or whether he had to do some violence to it to make it work . 
uh 
but he did do it . 
yeah . 
i don ' t see why the uh combining functions have to be directly hacked into javabayes . 
i mean they ' re used to create tables . 
so we can just make our own little functions that create tables in x . m . l . 
well i say that ' s one way to do it is is to just convert it into a into a c . p . t . that you zip . 
it ' s blown up . 
and is a it ' s uh it ' s huge . 
but it doesn ' t require any data fitting or complication . 
uhhuh . 
yeah . 
i don ' t think i mean the fact that it blown blows up is a huge issue in the sense that 
i mean okay . 
so say it blows up right ? 
so there ' s like the you know ten ten fifteen uh things . 
it ' s going to be like two to the that . 
which isn ' t so bad . 
i understand . 
i ' m just saying that 
that was that was my note . 
the little note i sent said that . 
uhhuh . 
it said here ' s the way you ' d take the logical g . function and turn it into a c . p . t . 
uhhuh . 
i mean that the the evidence combining function . 
so we could do that . 
and maybe that ' s what we ' ll do . 
but um 
don ' t know . 
so i will before next week uh push push some more on on this stuff that dekai wu did . 
and try to understand it . 
uh you ' ll make a couple of more copies of the heckerman paper to give to people . 
sure . 
yeah i i would like a copy . 
yeah . 
okay . 
okay . 
and um 
okay . 
i think 
okay and i ' ll i ' ll think through this uh uh getting eva vectors dynamically out of ontologies one more time . 
because i i i i ' m not quite sure whether we all think of the same thing or not here . 
well you and i should talk about it . 
yeah uhhuh . 
okay . 
all right great . 
and robert thank you for coming in under 
he he ' s been sick . 
robert . 
und 
uhhuh . 
i was thinking maybe we should just cough into the microphone and see if they can ' t see if they can handle it . 
yep . 
sure . 
um is this uh 
all right . 
yeah let ' s get started . 
um hopefully nancy will come . 
if not she won ' t . 
uh robert do you uh have any way to turn off your uh screensaver on there so that it ' s not going off every uh 
it seems to have about at two minute 
yeah i ' ve i uh it ' s not that i didn ' t try . 
okay . 
and um i i told it to stay on forever and ever but if it ' s not plugged in it just doesn ' t obey my commands . 
okay . 
it has a mind . 
got it . 
wants to conserve . 
but i i just you know sort of keep on wiggling . 
yeah okay . 
but uh we ' ll just be working on it at intensity so it doesn ' t happen . 
we ' ll see . 
should we plunge right into it ? 
yeah . 
so would you like to 
i think so . 
so what i ' ve tried to do here is list all the decision nodes that we have identified on this side . 
commented and what they ' re about and sort of the properties we may um give them . 
and here are the uh tasks to be implemented via our data collection . 
so all of these tasks 
the reading is out of these tasks more or less imply that the user wants to go there sometime or the other . 
and analogously for example here we have our eva um intention . 
and these are the data tasks where we can assume the person would like to enter view or just approach the thing . 
analogously the same on the object information . 
we can see that you know we have sort of created these tasks before we came up with our decision nodes . 
so there ' s a lot of things where we have no analogous tasks and that may or may not be a problem . 
we can change the tasks slightly if we feel that we should have data for sort of for every decision node . 
so trying to um implant the intention of going to a place now going to a place later on the same tour . 
or trying to plant the intention of going sometime on the next tour or the next day or whenever . 
right right . 
but i think that might be overdoing it a little . 
so yeah . 
so let me pop up a level . 
and uh make sure that we ' re all oriented the same . 
so what we ' re going to do today is two related things . 
uh one of them is to work on the semantics of the belief net which is going to be the main inference engine for the system uh making decisions . 
and decisions are going to turn out to be parameter choices for calls on other modules . 
so the natural language understanding thing is uh we think going to only have to choose parameters but you know a fairly large set of parameters . 
so to do that we need to do two things . 
one of which is figure out what all the choices are which we ' ve done a fair amount . 
then we need to figure out what influences its choices . 
and finally we have to do some technical work on the actual belief relations and presumably estimates of the probabilities and stuff . 
but we aren ' t going to do the probability stuff today . 
technical stuff we ' ll do uh another day . 
probably next week . 
but we are going to worry about all the decisions and the things that that contribute to them . 
and we ' re also sort of uh in the same process going to work with fey on what there should be in the dialogues . 
so one of the steps that ' s coming up real soon is to actually get subjects uh in here and have them actually record like this . 
uh record dialogues more or less . 
and depending on what fey sort of provokes them to say we ' ll get information on different things . 
so 
well how people phrase different intentions more or less . 
yeah people with the phrase them . 
huh ? 
and so uh for you know keith and people worrying about what constructions people use uh we have some we have some ways to affect that by the way the dialogues go . 
so what robert kindly did is to lay out a table of the kinds of uh things that that might come up . 
and the kinds of decisions . 
so the uh uh on the left are decision nodes and discreet values . 
so if if we ' re right you can get by with um just this middle column worth of decisions . 
and it ' s not all that many and it ' s perfectly feasible technically to build belief nets that will do that . 
and he has a handout . 
yeah . 
maybe it was too fast plunging in there because we have two updates . 
yeah . 
um you can look at this if you want . 
these are what our subject ' s going to have to fill out . 
any comments i can can still be made and the changes will be put in correspondingly . 
yes . 
let me summarize in two sentences . 
mainly for eva ' s benefit who probably has not heard about the data collection at all . 
okay . 
or have you heard about it ? 
not that much . 
no . 
you didn ' t 
okay we were going to put this in front of people . 
they give us some information on themselves . 
okay . 
then then they will read uh a task where lots of german words are sort of thrown in between . 
and um and they have to read isolated proper names . 
and these change 
i don ' t see a release 
no this is not the release form . 
this is the speaker information form . 
got it . 
okay fine . 
okay . 
the release form is over there in that box . 
all right fair enough . 
and um and then they going to have to um um choose from one of these tasks which are listed here . 
they they pick a couple . 
say three uh uh six as a matter of fact . 
six different things they sort of think they would do if they were in heidelberg or traveling someplace . 
and um and they have a map . 
huh . 
like this . 
very sketchy simplified map . 
and they can take notes on that map . 
and then they call this computer system that works perfectly and understands everything . 
okay . 
and um 
the yeah the computer system sits right in front of you . 
this is a fictional system obviously . 
huh ? 
that ' s fey . 
i ' ve i understand everything . 
and she does know everything . 
yes i do . 
and she has a way of making this machine talk . 
so she can copy sentences into a window or type really fast . 
and this machine will use speech synthesis to produce that . 
so if you ask how do i get to the castle then a several seconds later it ' ll come out of here in order to get to the castle you do 
okay ? 
yeah . 
and um and then after three tasks the system breaks down . 
and fey comes on the phone as a human operator . 
and says sorry the system broke down but let ' s continue . 
and we sort of get the idea what people do when they think they speak to a machine and what people say when they think they speak to a human or know or assume they speak to a human . 
okay . 
huh . 
uhhuh . 
uhhuh . 
that ' s the data collection . 
and um and fey has some thirty subjects lined up ? 
something 
yeah . 
and more and more every day . 
and um and they ' re ready uh to roll . 
and we ' re going to start tomorrow at three ? 
four ? 
one ? 
tomorrow 
well we don ' t know for sure . 
because we don ' t know whether that person is coming or not . 
okay . 
but 
around four - ish . 
and um we ' re still looking for a room on the sixth floor because they stole away that conference room um behind our backs . 
but 
well there are these uh uh 
oh i see we have to 
yeah it ' s tricky . 
we ' ll let ' s let we ' ll do that off line okay . 
yeah but i it ' s happening . 
david and and jane and and lila are working on that as we speak . 
okay . 
okay . 
that was the uh the data collection in a nutshell . 
and um i can report a so i did this but i also tried to do this 
so if i click on here 
isn ' t this wonderful ? 
we get to the uh uh belief net just focusing on on the go there node . 
uh analogously this would be sort of the reason node and the timing node and so forth . 
uhhuh . 
and what what happened is that um design wise i ' d sort of noticed that we can we still get a lot of errors from a lot of points to one of these sub go there user go there situation nodes . 
so i came up with a couple of additional nodes here where um 
whether the user is thrifty or not and what his budget is currently like is going to result in some financial state of the user . 
how much will he is he willing to spend ? 
or can spend . 
being the same at this just the money available which may influence us whether he wants to go there . 
if it is you know charging tons of dollars for admission or its going to cost a lot of 
whatever . 
twenty two million to fly to international space station you know . 
right . 
just not all people can do that . 
so and this actually turned out to be pretty key because having specified sort of these uh this this intermediate level um and sort of noticing that everything that happens here 
let ' s go to our favorite endpoint one . 
is again more or less we have um 
then the situation nodes contributing to the the endpoint situation node which contributes to the endpoint and so forth . 
um i can now sort of draw straight lines from these to here meaning it of course goes where the sub s . 
everything that comes from situation everything that comes from user goes with the sub u . 
and whatever we specify for the so called keith node or the discourse what comes from the um parser construction parser um will contribute to the d and the ontology to the sub o node . 
and um one just sort of has to watch which also final decision node so it doesn ' t make sense to figure out whether he wants to enter view or approach an object if he never wants to go there in the first place . 
but this makes the design thing fairly simple . 
and um now all that ' s left to do then is the c p g ' s the conditional probabilities for the likelihood of a person having enough money actually wanting to go a place if it costs you know this or that . 
and um okay . 
and once um bhaskara has finished his classwork that ' s where we ' re going to end up doing . 
you get involved in that process too . 
and um and for now uh the the question is how much of these decisions do we want to build in explicitly into our data collection ? 
so um one could sort of think of 
you know we could call the see or you know people who visit the zoo . 
we could call it visit the zoo tomorrow . 
so we have an intention of seeing something but not now but later . 
right . 
yeah . 
yeah so let ' s uh see i i think that from one point of view uh um all these places are the same . 
so that that um in terms of the linguistics and stuff there may be a few different kinds of places . 
so i it seems to me that we ought to decide you know what things are are actually going to matter to us . 
and um so the zoo and the university and the castle et cetera um are all big - ish things that um you know have different parts to them and one of them might be fine . 
huh . 
huh huh . 
and 
yeah the the reason why we did it that way as a as a reminder is uh no person is going to do all of them . 
they ' re just going to select um according to their preferences . 
yeah yeah . 
uh yeah i usually visit zoos or i usually visit castles or i usually 
and then you pick that one . 
right no no . 
but but point is to to to build a system that ' s got everything in it that might happen you do one thing . 
they ' re redundant . 
to build a system that um had the most data on a relatively confined set of things you do something else . 
and the speech people for example are going to do better if they if things come up uh repeatedly . 
now of course if everybody says exactly the same thing then it ' s not interesting . 
so all i ' m saying is there ' s there ' s a kind of question of what we ' re trying to accomplish . 
and i think my temptation for the data gathering would be to uh 
you know and each person is only going to do it once . 
so you don ' t have to worry about them being bored . 
so if if it ' s one service one luxury item you know one big - ish place and so forth and so on um then my guess is that that the data is going to be easier to handle . 
now of course you have this i guess possible danger that somehow there ' re certain constructions that people use uh when talking about a museum that they wouldn ' t talk about with a university and stuff . 
um but i guess i ' m i uh my temptation is to go for simpler . 
you know less variation . 
but i don ' t know what other people think about this in terms of 
uh 
so i don ' t exactly understand 
like i i i guess we ' re trying to limit the detail of our ontology or types of places that someone could go . 
right ? 
but who is it that has to care about this ? 
or what component of the system ? 
oh . 
well uh i think there are two places where it comes up . 
one is uh in the these people who are going to take this and and try to do speech with it . 
uhhuh . 
uh lots of pronunciations of of the same thing are going to give you better data than you know a few pronunciations of lots more things . 
okay . 
that ' s one . 
so we would rather just ask uh have a bunch of people talk about the zoo . 
uh and assume that that will that the constructions that they use there will give us everything we need to know about these sort of zoo castle whatever type things these bigger places . 
bigger . 
yeah well this is a question for 
and that way you get the speech data of people saying zoo over and over again or whatever too . 
yeah . 
yeah . 
yeah . 
okay . 
so this is a question for you . 
uhhuh . 
and you know if we if we do and we probably will actually try to uh build a prototype uh 
probably we could get by with the prototype only handling a few of them anyway . 
so um 
yeah this was sort of these are all different sort of activities . 
um but i think i i got the point and i think i like it . 
we can do put them in a more hierarchical fashion . 
so go to place and then give them a choice . 
you know either they ' re the symphony type or opera type or the tourist site guide type or the nightclub disco type person and they say yeah this is on that go to big - ish place . 
this is what i would do . 
uhhuh . 
and then we have the fix thing and then maybe do something the other day thing . 
so my question is 
i guess to some extent we should we just have to try it out and see if it works . 
it would be challenging in in a sense to try to make it so so complex that they even really should schedule or to plan it uh a more complex thing in terms of 
okay . 
you know they should get the feeling that there are these six things they have to do . 
and they can be done maybe in two days . 
well 
yeah . 
well i think 
so they make these decisions . 
yeah . 
can i go there tomorrow ? 
or you know influences . 
yeah . 
uhhuh . 
well i think it ' s easy enough to set that up if that ' s your expectation . 
so the uh system could say well uh we ' d like to to set up your program for two days in heidelberg . 
you know let ' s first think about all the things you might like to do . 
so there in i mean in i i i ' m sure that if that ' s what you did then they would start telling you about that and then you could get into um various things about ordering if you wanted . 
uhhuh . 
yeah . 
yeah but i think this is part of the instructor ' s job . 
and that can be done sort of to say okay now we ' ve picked these six tasks . 
now you have you can call the system and you have two days . 
and 
i ' m sorry . 
no we have to help we have to decide . 
fey will carry out whatever we decide . 
but we have to decide you know what is the appropriate scenario . 
that ' s what we ' re going to talk about yeah . 
yep yep . 
but these are two different scenarios entirely . 
i mean one is a planner the other it kind of give you instructions on the spot . 
yeah but the i don ' t i ' m not really interested in sort of phase planning capabilities . 
but it ' s more the how do people phrase these planning requests ? 
so are we going to masquerade the system as this as you said simple response system ? 
i have one question i get one response . 
or should we allow for a certain level of complexity ? 
and i think the data would be nicer if we get temporal references . 
well so keith what do you think ? 
well um it seems that 
yeah i mean 
off the top of my head it kind of seems like you would probably just want you know richer data . 
more complex stuff going on . 
people trying to do more complex sets of things . 
i mean you know if our goal is to really sort of be able to handle a whole bunch of different stuff then throwing harder situations at people will get them to do more linguistic more interesting linguistic stuff . 
but i mean i ' m i ' m not really sure . 
uh because i don ' t fully understand like what our choices are of ways to do this here yet . 
i mean we have tested this and 
have you heard listen to the first two or 
as a matter of fact the second person is uh is was faced with exactly this kind of setup . 
and 
i started to listen to one and it was just like um uh sort of depressing . 
i thought i ' d just sort of listen to the beginning part and the person was just sort of reading off her script or something . 
and 
oh okay . 
yeah . 
that was the first subject . 
yeah . 
first one wasn ' t very good . 
yeah . 
yeah . 
so um i 
although 
um it is already with this it got pretty with this setup and that particular subject it got pretty complex . 
uhhuh . 
maybe i suggest we make some fine tuning of these get sort of run through ten or so subjects . 
uhhuh . 
and then take a breather . 
and see whether we want to make it more complex or not depending on what what sort of results we ' re getting . 
right . 
yeah . 
it in fact um i am just you know today next couple days going to start really diving into this data . 
i ' ve basically looked at one of the files . 
you know one of these 
you gave me those dozens of files . 
and i looked at one of them which was about ten sentences found fifteen twenty different construction types that we would have to look for and so on . 
and like all right well let ' s start here . 
um so i haven ' t really gone into the you know looked at all of the stuff that ' s going on . 
so i don ' t really 
right i mean once i start doing that i ' ll have more to say about this kind of thing . 
okay . 
and and always 
but well but you did say something important which is that um you can probably keep yourself fairly well occupied uh with the simple cases for quite a while . 
yeah . 
although obviously so so that does suggest that 
uh now i have looked at all the data and it ' s it ' s actually at least to an amateur quite redundant . 
that that it was it was very stylized and quite a lot of people said more or less the same thing . 
yeah yeah . 
i um i did sort of scan it at first and noticed that and then looked in detail at one of them . 
yeah . 
but yeah yeah i noticed that too . 
so we we we want to do more than that . 
and with this we ' re getting more . 
okay . 
no question . 
right . 
so 
uh do we want to get going beyond more which is sort of the 
well okay so let ' s let ' s take let ' s i 
i think your suggestion is good which is we ' ll do a uh a batch . 
okay . 
and uh 
fey how long is it going to be till you have ten subjects ? 
couple days ? 
or a week ? 
or i don ' t i don ' t have a feel for 
um i can yeah i mean i i think can probably schedule ten people uh whenever . 
well it ' s it ' s up to you . 
i mean i i uh we don ' t have any huge time pressure . 
it ' s just when you have 
how long will it be ? 
um i i would say maybe two weeks . 
yeah . 
oh okay . 
so let ' s do this . 
let ' s plan next monday okay to have a review of what we have so far . 
and 
this means audio but 
huh ? 
no transcriptions of course . 
no we won ' t have the transcriptions . 
yeah . 
but what we should be able to do 
and i don ' t know if fey if you will have time to do this . 
but it would be great if you could um not transcribe it all but pick out uh some stuff . 
i mean we could uh just sit here and listen to it all . 
are you going to have the audio on the web site ? 
okay . 
until we reach the gigabyte thing and david johnson kills me and we ' re going to put it on the web site yeah . 
oh we could get 
i mean you can buy another disk for two hundred dollars . 
right ? 
i mean it ' s it ' s not like 
okay . 
so we ' ll take care of david johnson . 
okay . 
no he uh he he has been solving all our problems or is wonderful . 
take care of him . 
okay . 
so 
all right . 
so we ' ll buy a disk . 
but anyway so um if you if you can think of a way to uh point us to to interesting things sort of as you ' re doing this or or something . 
uh make your make notes or something that that this is you know something worth looking at . 
and other than that yeah i guess we ' ll just have to uh listen 
although i guess it ' s only ten minutes each . 
right ? 
roughly . 
well i guess . 
i ' m not sure how long it ' s actually going to take . 
the reading task is a lot shorter . 
that was cut by fifty percent . 
and the reading 
nobody ' s interested in that except for the speech people . 
right . 
no we don ' t care about that at all . 
so 
it ' s actually like five minutes dialogue . 
my guess is it ' s going to be ten . 
people 
ten minutes is long . 
i understand . 
but people people you know uh 
it feels like a long time . 
but 
yeah . 
yeah . 
it feels like forever when you ' re doing it . 
but then it turns out to be three minutes and forty five seconds . 
yeah . 
could be . 
yeah . 
okay . 
i was thinking people would you know hesitate and whatever . 
whatever it is we ' ll we ' ll deal with it . 
yeah it ' s not 
okay so that ' ll be that ' ll be um on on the web page . 
and it ' s fun . 
okay . 
that ' s great . 
um but anyway yeah so i think it ' s a good idea to start with the sort of relatively straight forward just response system . 
and then if we want to uh get them to start doing uh multiple step planning with a whole bunch of things and then organize them . 
um 
tell them which things are near each other . 
and 
you know any of that stuff . 
uh you know which things would you like to do tuesday morning . 
yeah . 
so yeah i that seems pretty straight forward . 
but were you saying that 
i need those back by the way . 
okay . 
yeah . 
okay . 
that ' s for 
i ' m sorry fey what ? 
that maybe one thing we should do is go through this list and sort of select things that are categories and then offer only one member of that category ? 
that ' s what i was suggesting for the first round yeah . 
okay . 
so rather than having zoo and castle 
and then i mean they could be alternate versions of the same if you wanted data on different constructions . 
they could but but uh they 
yeah but uh but 
like one person gets the version with the zoo as a choice and the other person gets the 
you could 
but but i i i think in the short run 
and 
no the 
the person don ' t get it . 
i mean this is why we did it because when we gave them just three tasks for part a and three tasks for part b 
right . 
yeah . 
well no they could still choose . 
they just wouldn ' t be able to choose both zoo and say touring the castle . 
exactly . 
this is limiting the choices but yeah . 
right . 
okay sorry . 
but um i i think this approach will very well work . 
but the person was able to look at it and say okay this is what i would actually do . 
yeah . 
okay . 
yeah . 
okay . 
he was vicious . 
okay we got to we got to disallow uh traveling to zoos and uh castles at the same time sort of 
i mean there they are significantly different but 
but no they ' re i mean they ' re sort of this is where tour becomes you know 
tourists maybe a bit different . 
yeah i guess so . 
and um these are just places where you you enter um much like here . 
yeah . 
but we can uh 
yeah in fact if if if you use the right verb for each in common 
like you know attend a theater symphony or opera is is a group . 
and tour the university castle or zoo . 
uhhuh yeah . 
all of these do have this kind of tour um aspect about the way you would go to them . 
and uh the movie theater is probably also uh is attend et cetera . 
attend . 
yeah . 
so it may turn out to be not so many different kinds of things . 
huh uhhuh . 
and then what one would expect is that that the sentence types would uh their responses would tend to be grouped according to the kind of activity you would expect . 
uhhuh . 
but i mean it seem that um there is a difference between going to see something and things like exchange money or dine out . 
oh absolutely . 
yeah . 
uh function yeah . 
yeah this is where 
yeah . 
the function stuff is definitely different and the getting information or stuff yeah . 
okay . 
but this is open . 
so since people going to still pick something we ' re not going to get any significant amount of redundancy . 
and for reasons we don ' t want it really in that sense . 
and um we would be ultimately more interested in getting all the possible ways of people asking oh for different things with or with a computer . 
and so if you can think of any other sort of high level tasks a tourist may do just always just mail them to us and we ' ll sneak them into the collection . 
we ' re not going to do much statistical stuff with it . 
we don ' t have enough . 
no . 
but it seems like since we since we are getting towards uh subject uh fifty subjects . 
and if we can keep it up um to a uh sort of five four - ish per week rate we may even reach the one hundred before fey takes off to chicago . 
that means that one hundred people have to be interested . 
good luck . 
yeah . 
well um these are all people off campus from campus so far . 
yeah . 
right ? 
yeah . 
so we yeah we don ' t know how many we can get next door at the uh shelter for example . 
huh . 
uh for ten bucks probably quite a few . 
yeah . 
that ' s right . 
yeah . 
so all right so let ' s go let ' s go back then to the the chart with all the decisions and stuff and see how we ' re doing . 
yep . 
do do people think that you know this is is going to um cover what we need or should we be thinking about more ? 
okay in terms of decision nodes ? 
yep . 
i mean go there is is a yes or no . 
right ? 
yep . 
uhhuh . 
i ' m also interested in in this property uh line here . 
so if you look at sorry look at that 
um timing was um i have these three . 
do we need a final differentiation there ? 
now later on the same tour sometimes on the next tour ? 
what ' s this idea of next tour ? 
i mean 
it ' s sort of next day . 
so you ' re doing something now and you have planned to do these three four things . 
uhhuh . 
and you can do something immediately . 
uhhuh . 
you could sort of tag it on to that tour . 
or okay . 
or you can say this is something i would do i want to do sometime in my life basically . 
okay . 
okay . 
so so this tour is sort of just like the idea of current round of of touristness or whatever . 
right . 
yeah . 
okay . 
yeah probably between stops back at the hotel . 
okay . 
got it . 
i mean if you if if you wanted precise about it uh you know 
got it . 
uh and i think that ' s the way tourists do organize their lives . 
sure sure sure . 
you know okay we ' ll go back to the hotel and then we ' ll go off . 
and 
okay . 
so all tours a tour happens only within one day ? 
yes . 
okay . 
so the next tour will be tomorrow ? 
it 
right . 
for this . 
okay . 
just to be totally clear . 
okay . 
well my visit to prague there were some nights where i never went back to the hotel . 
so whether that counts as a two day tour or not we ' ll have to think . 
you just spend the whole time at u fleku or something . 
yeah . 
i we will we will not ask you more . 
right . 
right . 
that ' s enough . 
i don ' t know . 
what is the uh the the english uh um cognate if you want for sankt nimmerlandstag ? 
keine ahnung . 
sort of we ' ll do it on when you say on that day it means it ' ll never happen . 
yeah . 
right . 
okay . 
do you have an expression ? 
probably you 
not that i know of actually . 
yeah when hell yep we ' ll do it when hell freezes over . 
yeah . 
so maybe that should be another property in there . 
right . 
never . 
yeah . 
yeah . 
okay . 
um the reason why why do we go there in the first place 
i e uh it ' s either uh for sightseeing for meeting people for running errands or doing business . 
entertainment is a good one in there i think . 
i agree . 
so business is supposed to uh be sort of it like professional type stuff ? 
right ? 
or something like that ? 
yep . 
okay . 
um 
i mean this this is uh an old uh johno thing . 
he sort of had it in there . 
who is the the is the person ? 
so it might be a tourist . 
it might be a business man who ' s using the system who wants to sort of go to some 
uhhuh . 
yeah . 
yeah or or both . 
yeah . 
yeah i mean like for example my my father is about to travel to prague . 
yep . 
he ' ll be there for two weeks . 
he is going to uh 
he ' s there to teach a course at the business school but he also is touring around . 
and so he may have some mixture of these things . 
huh . 
yep . 
sure . 
yep . 
right . 
he would 
what what do you have in mind in terms of um socializing ? 
what kind of activities 
uh just meeting people basically . 
oh 
i want to meet someone somewhere which puts a very heavy constraint on the eva . 
you know because then if you ' re meeting somebody at the town hall you ' re not entering it usually . 
yeah . 
you ' re just want to approach it . 
so i mean does this capture like where do you put 
exchange money is an errand . 
right ? 
but what about uh 
uhhuh . 
yep . 
so like go to a movie is now entertainment . 
dine out is 
socializing i guess . 
no i i 
well i don ' t know . 
let let well we ' ll put it somewhere . 
so i mean 
but but um 
right . 
i would say that if dine out is a special uh 
if you ' re doing it for that purpose then it ' s entertainment . 
yeah . 
and we ' ll also as as you ' ll further along we ' ll get into business about well you ' re you know this is going over a meal time . 
do you want to stop for a meal or pick up food or something ? 
uhhuh . 
and that ' s different . 
that ' s that ' s sort of part of that ' s not a destination reason that ' s sort of en passant right . 
right . 
that goes with the energy depletion function blech . 
yeah . 
right yeah . 
okay endpoint 
tourist needs food badly . 
right . 
endpoint is pretty clear . 
um mode . 
uh i have found three . 
drive there walk there uh or be driven which means bus taxi bart . 
okay . 
yeah . 
yep . 
obviously taxis are very different than buses . 
but on the other hand the system doesn ' t have any public transport this the planner system doesn ' t have any public transport in it yet . 
so this granularity would suffice i think if we say the person 
probably based on the utterance we on the situation we can conclude 
wants to drive there walk there or use some other form of transportation . 
how much of heidelberg can you get around by public transport ? 
i mean in terms of the interesting bits . 
there ' s lots of bits where you don ' t really 
i ' ve only was there ten years ago for a day so i don ' t remember but 
well 
i mean like the sort of the touristy bits 
everywhere . 
is it like 
you can ' t get to the philosophers ' way very well . 
but 
yeah . 
i mean there are hikes that you can ' t get to . 
but 
yeah . 
okay . 
but i think other things you can if i remember right . 
so is like biking there part of like driving there ? 
yeah um we actually biking should be should be a separate point because we have a very strong bicycle planning component . 
or 
oh ! 
so 
huh that ' s good . 
um 
put it in . 
bicycles should be in there . 
but 
will we have 
i mean is this realistic ? 
i mean 
yeah . 
okay we can leave it out i guess . 
yeah . 
we can we can sort of uh drive 
i would i would lump it with walk because hills matter . 
yeah . 
right ? 
you know . 
things like that . 
yeah . 
okay . 
skateboards . 
right ? 
right . 
anyway . 
scooters . 
right ? 
yep . 
all right . 
okay length is um you want to get this over with as fast as possible . 
you want to use some part of what of the time you have . 
um they can . 
but we should just make a decision whether we feel that they want to use some substantial or some fraction of their time . 
you know they want to do it so badly that they are willing to spend uh you know the necessary and plus time . 
huh . 
and um 
and you know if we feel that they want to do nothing but that thing then you know we should point out that to the planner that they probably want to use all the time they have . 
so stretch out that visit for that . 
uhhuh . 
wow ! 
it seems like this would be really hard to guess . 
i mean on the part of the system . 
it seems like it 
i mean you ' re you ' re talking about rather than having the user decide this you ' re supposed we ' re supposed to figure it out ? 
well 
the user can always say it but it ' s just sort of we we hand over these parameters if we make if we have a feeling that they are important . 
overrider . 
yeah . 
uhhuh . 
and that we can actually infer them to a significant degree or we ask . 
and 
and yeah and part of the system design is that if it looks to be important and you can ' t figure it out then you ask . 
okay . 
yeah . 
okay . 
but hopefully you don ' t ask you know all these things all the time . 
or uh so but there ' s but definitely a back off position to asking . 
yeah . 
yeah . 
right . 
yeah . 
and if no no part of the system ever comes up with the idea that this could be important no planner is ever going to ask for it . 
yeah . 
so and i like the idea that you know sort of 
jerry pushed this idea from the very beginning that it ' s part of the understanding business to sort of make a good question of what ' s sort of important in this general picture what you need 
uhhuh . 
if you want to simulate it for example what parameters would you need for the simulation ? 
and timing uh uh length would definitely be part of it . 
costs ? 
little money some money lots of money ? 
uhhuh . 
actually maybe uh uh so 
yeah okay . 
huh ? 
you could say some in there . 
i must say that this one looks a bit strange to me . 
um maybe it seems like appropriate if i go to las vegas . 
well but i decide kind of how much money uh i ' m willing to lose . 
but i as a tourist i ' ll just paying what ' s what ' s more or less is required . 
well no . 
i think there are there ' re different things where you have a choice . 
huh . 
for example uh this interacts with am i are you willing to take a taxi ? 
yeah . 
dinner . 
or uh you know if if you ' re going to the opera are you going to look for the best seats or the peanut gallery ? 
the best seat or or right . 
or you know ? 
whatever . 
okay so 
so i think there are a variety of things in which um 
tourists really do have different styles eating . 
another one . 
you know ? 
yeah . 
right that ' s true . 
right . 
the what what my sort of sentiment is they ' re 
well i i once had to write a a a a charter a carter for a a student organization . 
and they had wanted me to define what the quorum is going to be . 
and i looked at the other ones and they always said ten percent of the student body has to be present at their general meeting otherwise it ' s not a 
and i wrote in there enough people have to be there . 
and it was hotly debated but people agreed with me that everybody probably has a good feeling whether it was a farce a joke or whether there were enough people . 
yeah . 
and if you go to turkey you will find when people go shopping they will say how much cheese do you want . 
and they say uh enough . 
and the and the this used all over the place . 
because the person selling the cheese knows you know that person has two kids and you know a husband that dislikes cheese so this is enough . 
uhhuh . 
and um so the middle part is always sort of the the golden way . 
right ? 
so you can you can be really make it as cheap as possible or you can say i want uh you know i don ' t care . 
money is no object . 
uhhuh . 
yeah . 
money is no object . 
or you say i just want to spend enough . 
uhhuh . 
or the sufficient or the appropriate amount . 
yeah . 
but then again this may turn out to be insufficient for our purposes . 
but well this is my first guess . 
i mean 
in much the same way as how how you know should the route be ? 
yeah . 
should it be the easiest route even if it ' s a little bit longer ? 
uhhuh . 
no steep inclinations ? 
go the normal way ? 
whatever that again means uh or do you does the person want to rough it ? 
uhhuh . 
i mean so there ' s a couple of different ways you can interpret these things . 
right ? 
you know i want to go there and i don ' t care if it ' s really hard . 
or if you ' re an extreme sport person you know 
i want to go there and i insist on it being the hard way . 
right . 
right ? 
you know so i assume we ' re going for the first interpretation . 
right . 
right ? 
something like 
i ' ll go 
i mean 
i ' d 
i don ' t know . 
no i think he was going for the second one actually . 
it ' s different from thing to 
yeah ? 
anyway we ' ll sort yeah we ' ll sort that out . 
i i 
okay . 
right . 
yeah . 
absolutely . 
well this is all sort of um top of my head . 
no no research behind that . 
yeah . 
um object information . 
do i do i want to know anything about that object . 
is either true or false . 
and if i care about it being open accessible or not i don ' t think there ' s any middle ground there . 
um either i want to know where it is or not . 
i want to know about it ' s history or not . 
or um i want to know about what it ' s good for or not . 
maybe one could put scales in there too . 
so i want to know a lot about it . 
yeah now 
okay . 
i ' m sorry ! 
go ahead . 
what were you going to say ? 
one could put scales in there . 
so i want to know a lot about the history . 
just a bit 
yeah right . 
well if we 
right . 
so object becomes entity . 
right ? 
yep that ' s true . 
yeah but we don ' t have to do it now . 
yep . 
that was the wrong shortcut anyhow . 
and we think that ' s it interestingly enough that um you know 
or or or something very close to it is going to be uh going to be enough . 
and 
still wrong . 
yeah . 
okay . 
all right so um so i think the order of things is that um robert will clean this up a little bit although it looks pretty good . 
and 
what 
well this is the part that 
huh ? 
this is the part that needs the work . 
right . 
yeah so 
yeah . 
right . 
so so um in parallel uh three things are going to happen . 
uh robert and eva and bhaskara are going to actually build a belief net that that um has c p t ' s and you know tries to infer this from various kinds of information . 
and fey is going to start collecting data . 
and we ' re going to start thinking about uh what constructions we want to elicit . 
and then it may iterate on uh further data collection to elicit 
do you mean do you mean eliciting particular constructions ? 
or do you mean like what kinds of things we want to get people talking about semantically speaking uh 
well yes . 
both . 
okay . 
uh and though for us constructions are primarily semantic . 
right ? 
right . 
and and so uh 
sure . 
i mean from my point of view i ' m i ' m trying to care about the syntax so you know 
well that too . 
but um you know if if we in if we you know make sure that we get them talking about temporal order . 
okay . 
yeah . 
okay that would be great . 
and if if they use prepositional phrases or subordinate clauses or whatever . 
uhhuh . 
right okay . 
um 
you know whatever form they use is fine . 
okay . 
but i i think that probably we ' re going to try to look at it as you know what semantic constructions do we do we want them to uh do 
okay . 
you know um caused motion . 
i don ' t know . 
something like that . 
okay . 
uh but uh uh this is actually a conversation you and i have to have about your thesis fantasies and how all this fits into that . 
got it . 
yeah . 
uh yeah okay . 
but uh 
well i will tell you the german tourist data . 
okay . 
because i have not been able to dig out all the stuff out of the thirty d v ds . 
okay . 
um if you 
is that roughly the equivalent of of what i ' ve seen in english or is it 
no not at all . 
okay . 
dialogues . 
okay . 
smartkom human . 
wizard of oz . 
okay . 
same 
okay that . 
got it . 
like what what have i got now ? 
i mean i have uh what what i ' m what i 
those files that you sent me are the user side of some interaction with fey ? 
a little bit of data i 
is that what it is or 
with nothing . 
no no . 
just talking into a box and not hearing anything back . 
yep . 
okay . 
yep . 
some data i collected in a couple weeks for training recognizers and email way back when . 
okay okay . 
nothing to write home about . 
okay . 
and um the 
see this this this uh ontology node is probably something that i will try to expand . 
once we have the full ontology a p i what can we expect to get from the ontology ? 
and hopefully you can sort of also try to find out you know sooner or later in the course of the summer what we can expect to get from the discourse that might you know or the 
uhhuh . 
uhhuh . 
not the discourse the utterance as it were uh 
uhhuh . 
right . 
in terms of uh 
right but we ' re not expecting keith to actually build a parser . 
no no no no no . 
right right . 
okay . 
we are expecting johno to build a parser . 
yes . 
but that ' s a 
by the end of the summer too . 
no . 
no . 
no . 
uh he ' s he ' s hoping to do this for his masters ' thesis by a year from now . 
but it ' s sort of it ' s 
right . 
huh ! 
still pretty formidable actually . 
uh absolutely . 
uh limited . 
i mean you know the idea is is 
yeah . 
well the hope is that the parser itself is uh pretty robust . 
but it ' s not popular it ' s only only 
right right . 
existence proof you know . 
set up the infrastructure . 
right . 
it ' s only 
yeah . 
right . 
um sometime i have to talk to some subset of the people in this group at least about um what sort of constructions i ' m looking for . 
i mean you know obviously like just again looking at this one uh thing you know i saw things from sort of as general as argument structure constructions . 
oh you know i have to do verb phrase . 
i have to do uh uh unbounded dependencies . 
you know which have a variety of constructions in uh uh 
instantiate that . 
on the other hand i have to have you know 
there ' s particular uh fixed expressions or semi fixed expressions like get plus path expression for you know how how do i get there . 
uhhuh . 
how do i get in . 
how do i get away . 
right . 
and all that kind of stuff . 
um so there ' s a variety of sort of different sorts of constructions . 
absolutely . 
and it you know it ' s it ' s sort of like anything goes . 
like 
okay so this is i think we ' re going to mainly work on with george . 
okay and 
okay . 
let me say what i think is is 
so the idea is uh first of all i misspoke when i said we thought you should do the constructions . 
cause apparently for a linguist that means to do completely and perfectly . 
so what i yeah okay so what what i meant was do a first cut at . 
uh that ' s what 
yeah yeah . 
okay because uh we do want to get them perfectly but i think we ' re going to have to do a first cut at a lot of them to see how they interact . 
of course . 
right exactly . 
now it we talked about this before . 
right ? 
and i i it would it would be completely out of the question to really do more than say like oh i don ' t know ten over the summer . 
yeah . 
but uh but you know obviously we need to get sort of a general view of what things look like . 
so 
yeah . 
right . 
so the idea is going to be to do 
sort of like nancy did in some of uh these papers where you do enough of them so you can go from top to bottom . 
so you can do you know uh have a complete story of of some piece of dialogue . 
uhhuh . 
and that ' s going to be much more useful than having all of the clausal constructions and nothing else or or or something like that . 
yeah . 
sure . 
yeah . 
so that the the trick is going to be to take this and pick a some sort of lattice of constructions . 
uhhuh . 
some lexical and some phrasal and and you know 
uhhuh . 
whatever you need in order to uh be able to then uh by hand you know explain some fraction of the utterances . 
uhhuh . 
yeah . 
and so exactly which ones will partly depend on your research interests and a bunch of other things . 
uhhuh . 
sure . 
okay . 
but i mean in terms of the sort of level of uh of analysis . 
you know these don ' t necessarily have to be more complex than like the out of construction in the b c p paper where it ' s just like you know half a page on each one or something . 
correct . 
oh yeah yeah . 
a half a page is is what we ' d like . 
yeah . 
and if if there ' s something that really requires a lot more than that then it does . 
and we have to do it . 
but 
yeah . 
for the first cut that should be fine yeah . 
yeah . 
we could sit down and think of sort of the the ideal speaker utterances . 
and i mean two or three that follow each other . 
uhhuh . 
so where we can also sort of once we have everything up and running show the tremendous insane inferencing capabilities of our system . 
uhhuh . 
so you know as as the smartkom people have . 
this is sort of their standard demo dialogue which is you know what the system survives and nothing but that . 
uhhuh . 
uhhuh . 
um we could also sort of have the analogen of our sample sentences . 
the ideal sentences where we have complete construction coverage and sort of they match nicely . 
uhhuh . 
so the the how do i get to x ? 
you know that ' s definitely going to be uh a major one . 
yeah . 
yeah . 
that ' s about six times in this little one here so uh yeah . 
right . 
yep . 
where is x ? 
might be another one which is not too complicated . 
yeah . 
uhhuh . 
and um tell me something about x . 
yeah . 
and hey that ' s that ' s already covering eighty percent of the system ' s functionality . 
right but it ' s not covering eighty percent of the intellectual interest . 
yeah . 
no we can throw in an out of film construction if you want to . 
no no no . 
but 
well the the thing is there ' s a lot that needs to be done to get this right . 
okay i 
okay . 
we done ? 
i have one bit of news . 
good . 
um the action planner guy has wrote has written a a lengthy proposal on how he wants to do the action planning . 
good . 
and i responded to him also rather lengthy how he should do the action planning . 
and 
action planning meaning discourse modeling ? 
yes . 
and i tacked on a little paragraph about the fact that the whole world calls that module a dialogue manager . 
right . 
and wouldn ' t it make sense to do this here too ? 
right . 
and also rainer malaka is going to be visiting us shortly . 
most likely in the beginning of june . 
uhhuh . 
i ' ll be gone . 
yeah . 
he ' s just in a conference somewhere and he is just swinging through town . 
sure okay . 
and um making me incapable of going to n a a c l for which i had funding . 
but no no pittsburg this year . 
huh . 
when is the uh santa barbara 
who is going to 
uh should a lot of people 
that ' s something i will would sort of enjoy . 
probably should go . 
that was that ' s one you should probably go to . 
yep . 
how much does it cost ? 
there ' s 
i haven ' t planned to go . 
uh probably we can uh pay for it . 
okay . 
um a student rate shouldn ' t be very high . 
so if we all decide it ' s a good idea for you to go then you ' ll we ' ll pay for it . 
right . 
sure . 
then you can go . 
i mean i i don ' t have a feeling one way or the other at the moment . 
but it probably is . 
okay . 
okay great . 
thanks . 
as usual . 
yes . 
whew ! 
i almost forgot about the meeting . 
i woke up twenty minutes ago thinking what did i forget . 
it ' s great how the brain sort of does that . 
something ' s not right here . 
internal alarms . 
okay . 
so the news for me is a . my forthcoming travel plans . 
in two weeks from today . 
yes . 
yeah ? 
more or less . 
i ' ll be off to sicily and germany for a couple three days . 
now what are what are you doing there ? 
i forgot . 
okay i ' m flying to sicily basically to drop off simon there with his grandparents . 
and then i ' m flying to germany to go to a moku - treffen . 
which is the meeting of all the module responsible people in smartkom . 
huh . 
and represent i . c . i . 
and myself i guess there . 
and um 
that ' s the huh actual reason . 
and then i ' m also going up to e . m . l . for a day . 
and then i ' m going to meet the very big boss wolfgang walster in saarbruecken and the system system integration people in kaiserslautern . 
and then i ' m flying back via sicily . 
pick up my son . 
come back here on the fourth of july . 
and uh 
what a great time to be coming back to the u . s . of a . . 
god bless america . 
you ' ll see maybe see the fireworks from your plane coming in . 
and i ' m sure all the the people at the airport will be happy to work on that day . 
yeah . 
you ' ll get even better service than usual . 
uhhuh . 
wait aren ' t you flying on lufthansa though ? 
alitalia . 
oh well then the you know it ' s not a big deal . 
once you get to the united states it ' ll be a problem . 
but 
yeah . 
and um 
that ' s that bit of news . 
and the other bit of news is we had you know uh i was visited by my german project manager . 
who a . did like what we did . 
what we ' re doing here . 
and b . is planning to come here either three weeks in july or three weeks in august to actually work . 
on 
with us . 
oh . 
and we sat around and we talked . 
and he came up we came up with a pretty strange idea . 
and that ' s what i ' m going to lay on you now . 
and um maybe it might be ultimately the most interesting thing for eva . 
because she has been known to complain about the fact that the stuff we do here is not weird enough . 
okay . 
so this is so weird it should even make you happy . 
uh okay . 
oh great . 
imagine if you will that we have a system that does all that understanding that we want it to do based on utterances . 
uhhuh . 
it should be possible to make that system produce questions . 
so if you have the knowledge of how to interpret where is x . under given conditions situational user discourse and ontological conditions you should also be able to make that same system ask where is x . . 
uhhuh . 
in a certain way . 
based on certain intentions . 
so instead of just being able to observe phenomenon um and guess the intention we might be able just to sort of give it an intention and make it produce an utterance . 
huh . 
well like in a . i . they generally do the take in . 
and then they also do the generation phase like nancy ' s thing . 
or uh 
you remember in the the hand thing in one eighty two like not only was it able to recognize but it was also to generate based upon situations . 
you mean that sort of thing ? 
absolutely . 
okay . 
and once you ' ve done that what we can do is have the system ask itself . 
and answer . 
understand the answer . 
ask something else . 
and enter a dialogue with itself . 
so the the basic the same idea as having two chess computers play against each other . 
except this smacks a little bit more of a schizophrenic computer than a . i . 
yeah you if you want you can have two parallel machines um asking each other . 
what would that give us ? 
would a . be something completely weird and strange . 
and b . if you look at all the factors we will never observe people let ' s say in wheelchairs under you know in under all conditions . 
that ' s good . 
you know when they say x . and there is a ride at the goal and the parking is good we can never collect enough data . 
uhhuh . 
it ' s it ' s it ' s not possible . 
right right . 
but maybe one could do some learning . 
if you get the system to speak to itself you may find break downs and errors and you may be able to learn . 
and make it more robust . 
maybe learn new things . 
and um 
so there ' s no no end of potential things one could get out of it if that works . 
and he would like to actually work on that with us . 
so 
well then he probably should be coming back a year from now . 
yeah i 
see the the generation bit making the system generate generate something is shouldn ' t be too hard . 
well once the system understands things . 
yeah no problem . 
i just don ' t think i think we ' re probably a year away from getting the system to understand things . 
yeah well if we can get it to understand one thing like our where is run through we can also maybe make it say or ask where is x . or not . 
huh i don ' t know . 
i ' m sort of have the impression that getting it to say the right thing in the right circumstances is much more difficult than getting it to understand something given the circumstances and so on . 
you know i mean just because it ' s sort of harder to learn to speak correctly in a foreign language rather than learning to understand it right ? 
i mean 
just the fact that we ' ll get the point is that getting it to understand one construction doesn ' t mean that it will always know exactly when it ' s correct to use that construction right ? 
it ' s it ' s uh 
well i ' ve i ' ve done generation and language production research for four four and a half years . 
and so it ' s it ' s you ' re right . 
it ' s not the same as the understanding . 
it ' s in some ways easier and some ways harder nuh ? 
yeah . 
but um 
i think it ' d be fun to look at it or into that question . 
nnn yeah . 
it ' s a pretty strange idea . 
and so that ' s that ' s but 
the basic idea i guess would be to give allow the system to have intentions basically . 
because that ' s basically what needs to be added to the system for it . 
well look at 
eee i think even think even 
what it would be the the prior intention . 
so let ' s uh uh let ' s say we have this 
well we ' d have to seed that . 
i mean 
no let ' s we have to we have some some top down processing given certain setting . 
okay now we change nothing and just say ask something . 
right ? 
what would it ask ? 
it wouldn ' t know what to ask . 
i mean 
it 
unless it was in a situation . 
we ' d have to set up a situation where it didn ' t know where something was and it wanted to go there . 
yeah . 
uhhuh . 
yeah . 
which means that we ' d need to set up an intention inside of the system right ? 
uh 
which is basically i don ' t know where something is and i need to go there . 
yeah . 
ooh do we really need to do that ? 
because 
well no i guess not . 
it ' s i know it ' s it ' s strange . 
but look at it look at our bayes - net . 
if we don ' t have let ' s assume we don ' t have any input from the language right ? 
so there ' s also nothing we could query the ontology . 
but we have a certain user setting . 
if you just ask what is the likelihood of that person wanting to enter some something it ' ll give you an answer . 
right ? 
that ' s just how they are . 
sure . 
and so whatever that is it ' s the generic default intention that it would find out . 
which is wanting to know where something is . 
maybe nnn and wanting 
i don ' t know what it ' s going to be . 
but there ' s going to be something that 
well you ' re not going to are you going to get a variety of intentions out of that then ? 
i mean you ' re just talking about like given this user what ' s the what is it what is that user most likely to want to do . 
and have it talk about 
well you can observe some user and context stuff and ask what ' s the posterior probabilities of all of our decision nodes . 
okay . 
you could even say let ' s take all the priors . 
let ' s observe nothing and query all the posterior probabilities . 
it ' s going to tell us something . 
right ? 
and 
well it will assign values to all the nodes yes . 
yes and come up with posterior probabilities for all the values of the decision nodes . 
which if we have an algorithm that filters out whatever the the best or the most consistent answer out of that will give us the intention ex nihilo . 
and that is exactly what would happen if we ask it to produce an utterance . 
it would be based on that extension ex nihilo . 
which we don ' t know what it is . 
but it ' s there . 
so we wouldn ' t even have to to kick start it by giving it a certain intention or observing anything on the decision node . 
and whatever that maybe that would lead to what is the castle . 
i ' m just 
or what is that whatever . 
i guess what i ' m afraid of is if we don ' t you know set up a situation we ' ll just get a bunch of garbage out . 
like you know everything ' s exactly thirty percent . 
no . 
huh . 
yeah so what we actually then need to do is is write a little script that changes all the settings . 
you know goes through all the permutations . 
which is we did a 
didn ' t we calculate that once ? 
well that was that was absurdly low in the last meeting . 
it ' s a 
uh 
because i went and looked at it . 
because i was thinking that could not be right . 
and it would it was on the order of twenty output nodes and something like twenty 
and like thirty input nodes . 
thirty input nodes . 
or some 
so to test every output node uh would at least 
let ' s see so it would be two to the thirty for every output node . 
which is very very large . 
oh that ' s 
oh . 
that ' s that ' s nothing for those neural guys . 
i mean they train for millions and millions of epochs . 
so 
well i ' m talking about 
oh i was going to take a drink of my water . 
i ' m talking about billions and billions and billions and 
a number 
two to the thirty is like 
bhaskara said we had calculated out and bhaskara believes that it ' s larger than the number of particles in the universe . 
and if 
i don ' t know if that ' s right or not . 
that ' s big . 
that ' s just that ' s uh it ' s a billion right ? 
two to the thirty ? 
well two to the thirty is a billion . 
but if we have to do it two to the twenty times then that ' s a very very large number . 
right . 
argh . 
oh okay . 
yeah yeah that ' s big . 
because you have to query the node for every uh or query the net two to the twenty times . 
sure . 
all right . 
or not two to 
excuse me twenty times . 
okay so is it comes to twenty billion or something ? 
yes . 
that ' s pretty big though . 
as far as 
that ' s that ' s big . 
actually 
oh we calculated a different number before . 
how did we do that ? 
huh . 
i remember there being some other one floating around . 
but anyway uh 
i don ' t really know . 
yeah it ' s anyway the point is that given all of these different factors it ' s uh it ' s it ' s still going to be impossible to run through all of the possible situations or whatever . 
ooo it ' s just big . 
but i mean this ' ll get us a bit closer at least right ? 
i mean 
if it takes us a second to do for each one and let ' s say it ' s twenty billion then that ' s twenty billion seconds . 
which is 
yeah . 
eva do the math . 
long . 
can ' t . 
hours and hours and hours and hours . 
but we can do randomized testing . 
tah - dah ! 
which probabilistically will be good enough . 
uhhuh . 
yeah so it be it ' s an idea that one could for for example run run past um 
what ' s that guy ' s name ? 
you know he ' s usually here . 
here in the group ? 
jer 
jerry feldman ? 
oh yeah that ' s the guy . 
we we we we 
wait who ? 
yeah that would the the bald guy . 
oh my advisor . 
and um 
so this is just an idea that ' s floating around . 
and we ' ll see what happens . 
and um huh 
what other news do i have ? 
well we fixed some more things from the smartkom system . 
but that ' s not really of general interest . 
um 
oh questions . 
yeah . 
i ' ll ask eva about the e . bayes and she ' s working on that . 
how is the generation x . m . l . thing ? 
i ' m going to work on that today and tomorrow . 
okay no need to do it today or tomorrow even . 
do it next week or 
i ' m going to finish it today uh hopefully . 
okay . 
i want to do one of those things where i stay here . 
because uh if i go home i can ' t finish it . 
i ' ve tried about five times so far where i work for a while and then i ' m like i ' m hungry . 
so i go home and then i think 
i ' m not going back . 
yeah . 
either that or i think to myself i can work at home . 
and then i try to work at home but i fail miserably . 
yeah . 
like i ended up at blakes last night . 
non conducive . 
no . 
i almost got into a brawl . 
but i did not finish the uh smartkom . 
but i ' ve been looking into it . 
i it ' s not like it ' s a blank slate . 
i found everything that i need . 
and and uh 
but 
at the 
uh furthermore i told jerry that i was going to finish it before he got back . 
so 
okay . 
that ' s approaching . 
he ' s coming back when ? 
uh next 
well i think we think we ' ll see him definitely on tuesday for the next 
or no wait . 
the meetings are on thursday . 
maybe . 
who knows ? 
maybe . 
okay . 
well we ' ll see him next week . 
all right . 
that ' s good . 
yeah . 
the paper . 
huh . 
huh . 
i was thinking about that . 
i think 
i will try to work on the smartkom stuff . 
and i ' ll if i can finish it today i ' ll help you with that tomorrow . 
if you work on it . 
i don ' t have a problem with us working on it though . 
so 
okay . 
so you would say it ' s funky . 
and it 
cool . 
i mean we just i mean it wouldn ' t hurt to write up a paper . 
because then i mean yeah i was talking with nancy . 
and nancy said you don ' t know whether you have a paper to write up until you write it up . 
so 
yeah . 
well 
and since jerry ' s coming back we can run it by him too . 
so 
yep . 
um what ' s your input ? 
well um i don ' t have much experience with uh conference papers for in the computer science realm . 
and so when i looked at what you had which was apparently a complete submission i just sort of said 
what just 
i i didn ' t really know what to do with it . 
like this is the sort of the basic outline of the system or whatever . 
or 
or 
here ' s an idea right . 
that ' s what that paper was . 
here ' s here ' s one possible thing you could do . 
uhhuh . 
short . 
eight pages . 
and i just don ' t know what you have in mind for expanding . 
like i ' d i what i didn ' t do is go to the web site of the conference . 
and look at what they ' re looking for or whatever . 
uhhuh . 
well it seems to me that um 
wait is this a computer science conference ? 
or is it a 
um well it ' s more . 
it ' s both right ? 
it ' s it ' s sort of cognitive neural psycho linguistic . 
but all for the sake of doing computer science . 
so it ' s sort of cognitive psycho neural plausibly motivated architectures of natural language processing . 
so it seems pretty interdisciplinary . 
and i mean the keynote speaker is tomasello . 
right oh yeah . 
and blah blah blah . 
so 
the the question is what could we actually do and and and keep a straight face while doing it . 
and 
well i really can ' t keep a straight face doing anything . 
my idea is 
setting that aside . 
well you can say we have done a little bit . 
and that ' s this . 
and uh sort of the rest is position paper . 
we want to also do that . 
which is not too good . 
might be more interesting to do something like let ' s assume um we ' re right . 
we have as jerry calls it a delusion of adequacy . 
and take a where is x . sentence . 
uhhuh . 
and say we will just talk about this . 
and how we cognitively neurally psycho - linguistically construction grammar ally motivated envision uh understanding that . 
huh . 
so we can actually show how we parse it . 
that should be able to we should be able to come up with you know a sort of a a parse . 
right . 
it ' s on . 
just just put it on . 
okay . 
did ben harass you ? 
hi . 
yes . 
good . 
was he supposed to harass me ? 
yes . 
well he just told me that you came looking for me . 
you 
oh . 
you will suffer in hell . 
figure this out . 
you know that . 
backwards . 
there ' s a diagram somewhere which tells you how to put that 
i know . 
i didn ' t understand that either . 
this is it . 
no wait you have to put it on exactly like that . 
yeah . 
so put that those things over your ears like that . 
okay . 
see the how the plastic things arch out like that ? 
there we go . 
okay . 
it hurts . 
it hurts it hurts real bad . 
it does . 
but that ' s what you get for coming late to the meeting . 
i ' m sorry i didn ' t mean to 
i ' m sorry . 
i ' m sorry oh these are all the same . 
okay this is not very on target . 
is your mike on ? 
yeah it is . 
shoot . 
okay . 
all right you guys can continue talking about whatever you were talking about before . 
um 
we ' re talking about this um alleged paper that we may just sort of 
oh which johno mentioned to me . 
yeah . 
uhhuh . 
and i just sort of brought forth the idea that we take a sentence where is the powder tower . 
uhhuh . 
and we we pretend to parse it . 
we pretend to understand it . 
and we write about it . 
huh . 
about how all of these things 
what ' s the part that ' s not pretend ? 
the writing ? 
okay then we pretend to write about . 
the submitting to a major international conference yeah . 
which conference is it for ? 
it ' s the whatever architectures uh you know where 
there is this conference it ' s the seventh already international conference on neurally cognitively motivated architectures of natural language processing . 
oh wow interesting . 
and the keynote speakers are tomasello macwhinney . 
macwhinney i think . 
whinney macwhinney uhhuh . 
macwhinney . 
so interesting both like child language people . 
yeah . 
yep . 
okay . 
so maybe you want to write something too . 
yeah maybe i want to go . 
huh huh . 
um why are they speaking at it if it 
is is it normally like like dialogue systems or you know other n . l . p . ish things ? 
no no no no no no no no it ' s it ' s like a 
oh it ' s cognitive . 
okay . 
yeah yeah . 
even neuro . 
and 
uh both learning and like comprehension production that kind of stuff . 
psycho . 
you could look at the web site . 
okay . 
i ' ll 
okay . 
and the and and the deadline is the fifteenth of june . 
i don ' t know about it . 
yeah that ' s pretty soon . 
huh . 
hey plenty of time . 
why we ' ve got over a week ! 
it would be nice to go write two papers actually . 
yeah and one one from your perspective and one from our 
uhhuh . 
i mean that ' s the kind of thing that maybe like um the general uh sort of like n . t . l . ish like whatever the previous simulation based maybe you ' re talking about the same kind of thing a general paper about the approach here would probably be appropriate . 
yeah . 
and good to do at some point anyway . 
yeah . 
um 
well i i also think that if we sort of write about what we have done in the past six months we we we could sort of craft a nice little paper that if it gets rejected which could happen doesn ' t hurt . 
uhhuh . 
because it ' s something we uh 
having it is still a good thing . 
having it is a good good thing . 
yeah . 
it ' s a nice exercise . 
it ' s 
i usually enjoy writing papers . 
it ' s not i don ' t regard it as a painful thing . 
uhhuh it ' s fun . 
and um we should all do more for our publication lists . 
and it just never hurts . 
and keith and or johno will go probably . 
will i ? 
when is it and where ? 
huh . 
in case of 
it ' s on the twenty second of september in saarbruecken germany . 
uh it ' s in germany . 
uh okay i i see . 
tomasello ' s already in germany anyway . 
so makes sense okay . 
just 
um okay . 
so is the what are you just talking about you know the details of how to do it or whether to do it or what it would be ? 
what would one possibly put in such a paper . 
what to write about . 
or what to write about . 
what is our what ' s our take home message . 
what what do we actually 
because i mean it i don ' t like papers where you just talk about what you plan to do . 
i mean it ' s obvious that we can ' t do any kind of evaluation . 
and have no you know we can ' t write an a . c . l . type paper where we say okay we ' ve done this . 
uhhuh . 
and now we ' re whatever percentage better than everybody else you know . 
uhhuh . 
it ' s far too early for that . 
but uh we we can tell them what we think . 
i mean that ' s 
never hurts to try . 
and um 
maybe even that ' s maybe the time to introduce the the new formalism that you guys have cooked up . 
uhhuh . 
are in the process of 
but that 
how many pages ? 
don ' t they need to finish the formalism ? 
it ' s just like four pages . 
four pages ? 
i mean it ' s it ' s not even a 
yeah . 
okay so it ' s a little thing . 
uhhuh . 
oh . 
well you said it was four thousand lines . 
oh . 
is that what you 
okay four pages is like really not very much space . 
i don ' t know . 
did you look at it ? 
yeah it depends on the format . 
oh my gosh oh i thought you were i thought we were talking about something . 
which was much more like ten or something . 
no that ' s i mean that ' s actually a problem . 
it ' s it ' s more difficult to write on four pages than on eight . 
it ' s 
yeah . 
yeah . 
and it ' s also difficult to even if you had a lot of substance it ' s hard to demonstrate that in four pages basically . 
yeah . 
um 
that would be hard . 
well i uh maybe it ' s just four thousand lines . 
i mean it ' s still it ' s still 
i i don ' t they don ' t want any 
they don ' t have a tex style guide . 
uhhuh uhhuh . 
they just want ascii . 
pure ascii lines . 
okay . 
whatever . 
why for whatever reason . 
i don ' t know . 
not including figures and such ? 
i don ' t know . 
very unspecific unfortunately . 
okay . 
well 
we ' ll just uh 
i would say that ' s closer to six pages actually . 
four thousand lines of ascii ? 
okay then . 
four thousand lines . 
it ' s 
i mean isn ' t isn ' t it about fifty fifty five sixty lines to a page ? 
i don ' t quote me on this . 
this is numbers i i have from looking 
how many characters are on a line ? 
okay . 
ascii ? 
let ' s let ' s what should we should should we uh um discuss this over tea ? 
and all of us look at the web . 
oh i can ' t . 
i ' m wizarding today . 
okay look at the web page . 
um 
look at the web page and let ' s talk about it maybe tomorrow afternoon . 
more cues for us to find it are like neural 
johno will send you a link . 
oh you have a link okay okay . 
i got an email . 
okay . 
by the way keith is comfortable with us calling him cool keith . 
oh cool keith . 
he he decided i ' m chilling in the five one o . . 
cool cool keith . 
yeah . 
excellent . 
okay . 
that ' s a very cool t . shirt . 
thank you . 
and i ' m also flying 
i got this from the two one two . 
new york ? 
excellent . 
yeah . 
sorry yes ? 
i ' m flying to sicily next in a two weeks from now . 
oh lucky you . 
and a week of business in germany . 
i should mention that for you . 
and otherwise you haven ' t missed much . 
except for a really weird idea . 
but you ' ll hear about that soon enough 
the idea that you and i already know about ? 
that you already told me . 
not that 
no no no . 
okay . 
yeah that is something for the rest of the gang to to 
the thing with the goats and the helicopters ? 
change the watchband . 
it ' s time to walk the sheep . 
like 
okay . 
um 
did you catch that allusion ? 
it ' s time to walk the sheep . 
no . 
it ' s uh presumably one of the watergate codes they uh 
oh . 
anyways 
um um 
don ' t make any plans for spring break next year . 
that ' s 
oh shoot . 
that ' s the other thing . 
we ' re going to do an e . d . u . internal workshop in sicily . 
that ' s what that ' s what he says . 
i ' ve already got the funding . 
i that ' s great . 
so i mean 
does that mean does that mean you ' ll get you ' ll fly us there ? 
we ' ll see . 
no that ' s 
yeah that ' s what it means . 
hhh ! 
okay cool . 
huh . 
and he ' ll put us up too . 
i know i know about that part . 
i know about the the almond trees and stuff . 
not joking . 
okay . 
name a vegetable . 
okay oh um kiwi . 
yeah . 
huh too easy . 
coconut . 
pineapple . 
see ? 
mango . 
too easy . 
okay okay too easy ? 
yeah mangos go everywhere . 
so do kiwi . 
really ? 
oh okay but i was trying to find something that he didn ' t grow on his farm . 
but coconut pineapple that ' s that ' s tricky yeah . 
sorry . 
anyway 
cantaloupe . 
so but we have to decide what like sort of the general idea of 
potatoes . 
so sorry . 
um 
i mean we ' re going to have an example case . 
um right ? 
i the the point is to like this where is case or something . 
yeah maybe you have it would be kind of the paper would have in my vision a nice flow if we could say well here is the here is parsing if you want to do it right . 
here is understanding if you want to do it right . 
and you know without going into technical 
uhhuh . 
but then in the end we ' re not doing like those things right yet right ? 
would that be clear in the paper or not ? 
that would be clear . 
we would 
i i mailed around a little paper that i have . 
okay . 
it would be like this is the idea . 
we could sort of say this is 
oh i didn ' t get that . 
did i ? 
oops . 
no . 
did i ? 
oops sorry . 
no i don ' t think you got it . 
see this if if you ' re not around and don ' t partake in the discussions and you don ' t get any email . 
i ' m sorry i ' m sorry i ' m sorry sorry . 
and 
okay go on . 
so parsing done right is like chicken done right . 
so we could we could say this is what what ' s sort of state of the art today nuh ? 
okay . 
and say this is bad nuh ? 
yeah . 
and then we can say uh well what we do is this . 
okay . 
yeah . 
parsing done right interpretation done right example . 
uhhuh yeah and 
and how much to get into the cognitive neural part ? 
that ' s the only that ' s the question mark . 
don ' t you need to reduce it if it ' s a or reduce it if it ' s a cognitive neuro 
well you don ' t have 
i mean the conference may be cognitive neural . 
doesn ' t mean that every paper has to be both . 
yeah and you can you can just point to the to the literature . 
huh . 
like n . l . p . cognitive neural . 
you can say that construction based . 
you know 
so so this paper wouldn ' t particularly deal with that side . 
although it could reference the n . t . l . ish sort of like um approach . 
uhhuh . 
yeah . 
yeah . 
the fact that the methods here are all compatible with or designed to be compatible with whatever neurological stuff . 
uhhuh . 
yeah i guess four pages you could 
i mean you could definitely it ' s definitely possible to do it . 
it ' s just it ' d just be small . 
like introducing the formalism might be not really possible in detail . 
but you can use an example of it . 
well looking at 
yeah looking at that paper that that you had i mean you know like you didn ' t really explain in detail what was going on in the x . m . l . cases or whatever . 
you just sort of said well you know here ' s the general idea . 
some stuff gets put in there . 
you know hopefully you can you can say something like constituents tells you what the construction is made out of you know without going into this intense detail . 
yeah yeah . 
so it be like using the formalism rather than you know introducing it per se . 
yeah . 
so 
give them the one paragraph whirlwind tour of what this is for . 
yeah . 
and yeah . 
uhhuh . 
and people will sort of figure out or ask about the bits that are implicit . 
yeah . 
so this will be sort of documenting what we think and documenting what we have in terms of the bayes - net stuff . 
uhhuh . 
and since there ' s never a bad idea to document things no ? 
that ' s that ' s definitely a good idea . 
that would be my uh 
we we should sketch out the details maybe tomorrow afternoon - ish if everyone is around . 
i don ' t know . 
i think so . 
you probably wouldn ' t be part of it . 
maybe you want 
think about it . 
um 
you may may ruin your career forever if you appear . 
yeah you might get blacklisted . 
and um 
the uh other thing 
yeah we actually have we made any progress on what we decided uh last week ? 
i ' m sure you read the transcript of last week ' s meeting in red . 
so so you ' re up to dated caught up . 
no sorry . 
we decided that we ' re going to take a where is something question . 
and pretend we have parsed it . 
and see what we could possibly hope to observe on the discourse side . 
remember i came in and i started asking you about how we were going to sort out the uh decision nodes ? 
yes . 
what ' d you say ? 
i remember you talking to me just not what you said . 
i do remember you talking to me . 
um 
a few more bits . 
well there was like we needed to or uh in my opinion we need to design a bayes another sub - bayes - net . 
you know it was whether it was whether we would have a bayes - net on the output and on the input . 
oh . 
or whether the construction was going to be in the bayes - net . 
oh yeah okay . 
and outside of it . 
and 
okay . 
so that was was that the question ? 
was that what 
well that was related to what we were talking about . 
should i introduce it as sudo - square ? 
yeah sure . 
we have to put this in the paper . 
if we write it . 
this is this is my only constraint . 
the 
so 
the sudo - square is situation user discourse right ontology . 
oh i saw the diagram in the office . 
oh my god that ' s amazing ! 
huh . 
yeah whatever . 
no way ! 
way . 
is it ? 
someone ' s going to start making phil collins jokes . 
yeah . 
huh ? 
sorry . 
oh god i hope not . 
what ? 
you guys are too young . 
you know like sussudio . 
that horrible horrible song that should never have been created . 
yeah come on . 
oh oh oh oh . 
i know that was horrible . 
i ' ve blocked every aspect of phil collins out of my mind . 
sussudio . 
what ? 
i ' m sorry i haven ' t . 
not on purpose . 
in here . 
oh well also he ' s talking about suicide . 
and that ' s that ' s not a notion i want to have evoked . 
no he ' s not . 
he is . 
really ? 
oops i didn ' t really listen to it . 
the 
i was too young . 
huh . 
it sounds too rocking for that . 
anyway 
yeah . 
anyway so what ' s going on here ? 
so what are what 
was wollte der kuenstler uns damit sagen ? 
so 
stop excluding me . 
okay so we have tons of little things here . 
and we ' ve 
i can ' t believe that that ' s never been thought of before . 
wait what are the dots ? 
i don ' t remember what the dots were . 
those are little bugs . 
okay . 
cool keith . 
you know these are our whatever belief net decision nodes . 
and they all contribute to these things down here . 
oh oh . 
wait wait what ' s the middle thing ? 
that ' s e . d . u . 
that ' s a 
our 
but i mean 
that ' s 
you . 
we . 
us . 
but what is it ? 
well in the moment it ' s a bayes - net . 
and it has sort of fifty not yet specified interfaces . 
okay uh i have taken care that we actually can build little interfaces to other modules that will tell us whether the user likes these things and the or these things . 
and he whether he ' s in a wheelchair or not . 
okay . 
is that supposed to be the international sign for interface ? 
i think so yeah . 
huh okay . 
i ' d i ' d never seen it before either . 
okay just 
cool . 
huh so 
because things fit onto that see ? 
yeah . 
cool . 
in a vaguely obscene fashion . 
no this is a r . m . e . core by agent design . 
i don ' t know . 
that ' s so great . 
there ' s maybe a different 
so wait . 
what what are these letters again ? 
situation user discourse and 
situation user ontology . 
user ? 
ontology . 
what about the utterance ? 
that ' s here . 
it ' s 
discourse . 
oh discourse . 
yeah . 
discourse is all things linguistic yeah . 
so that ' s not like context okay . 
so this this includes the the current utterance plus all the previous utterances . 
interesting . 
uhhuh . 
user . 
and for example irena gurevich is going to be here uh end of july . 
user . 
she ' s a new linguist working for e . m . l . 
and what she would like to do for example is great for us . 
she would like to take the 
ouch . 
so 
we have discussed in terms of the eva 
grateful for us ? 
uh 
did you just say grateful for us ? 
okay sorry . 
anyway 
think of back at the eva vector . 
and johno coming up with the idea that if the person discussed the discussed the admission fee in uh previously that might be a good indication that how do i get to the castle ? actually he wants to enter . 
uhhuh . 
or you know how do i get to x . . 
discussing the admission fee in the previous utterance is a good indication . 
uhhuh . 
so 
we don ' t want a hard code a set of lexemes or things that person ' s you know sort of filter or uh search the discourse history . 
uhhuh . 
so what would be kind of cool is that if we encounter concepts that are castle tower bank hotel we run it through the ontology . 
and the ontology tells us it has um admission opening times . 
it has admission fees . 
it has this it has that . 
and then we we we make a thesaurus lexicon look up . 
and then search dynamically through the uh discourse history for occurrences of these things in a given window of utterances . 
uhhuh . 
and that might you know give us additional input to belief a . versus b . . 
or e . versus a . . 
so it ' s not just a particular word ' s 
okay so the you ' re looking for a few keys that you know are cues to sorry a few specific cues to some intention . 
you can dynamically look up keys yeah . 
yeah . 
uh so wait so um since this since this sort of technical stuff is going over my head . 
okay . 
and then grep basically . 
the the point is that you uh that when someone ' s talking about a castle you know that it ' s the sort of thing that people are likely to want to go into ? 
or is it the fact that if there ' s an admission fee then one of the things we know about admission fees is that you pay them in order to go in ? 
and then the idea of entering is active in the discourse or something and then . 
well 
blah blah blah . 
i mean 
the the idea is even more general . 
the idea is to say we encounter a certain entity in a in in a utterance . 
so let ' s look up everything we the ontology gives us about that entity . 
what stuff it does what roles it has . 
what parts whatever it has . 
functions . 
and then we look in the discourse whether any of that or any surface structure corresponding to these roles functions ah has ever occurred . 
oh okay . 
and then the discourse history can tell us yeah or no . 
okay . 
and then it ' s up for us to decide what to do with it . 
okay . 
so 
so 
no go ahead . 
so we may think that if you say um where is the theater um whether or not he has talked about tickets before then we he ' s probably want to go there to see something . 
uhhuh . 
okay . 
or where is the opera in paris . 
yeah . 
lots of people go to the opera to take pictures of it and to look at it . 
uhhuh okay . 
and lots of people go to attend a performance . 
uhhuh . 
and the discourse can maybe tell us what ' s more likely if we know what to look for in previous statements . 
and so we can hard code for opera look for tickets look for this look for that . 
okay . 
okay . 
or look for mozart look for 
but the smarter way is to go via the ontology . 
and dynamically then look up stuff . 
okay but you ' re still doing look up so that when the person so the point is that when the person says where is it then you sort of say let ' s go back and look at other things and then decide . 
rather than the other possibility which is that all through discourse as they talk about different things . 
you know like 
prior to the where is it question they say you know how much does it cost to get in you know to to see a movie around here . 
um where is the closest theater . 
the the the point is that by mentioning admission fees that just sort of stays active now . 
yeah . 
you know that becomes part of like their sort of current ongoing active conceptual structure . 
uhhuh . 
and then um over in your bayes - net or whatever when when the person says where is it you ' ve already got you know since they were talking about admission and that evokes the idea of entering um then when they go and ask where is it then you ' re enter node is already active . 
because that ' s what the person is thinking about . 
uhhuh . 
yeah . 
i mean that ' s the sort of cognitive linguistic y way . 
and probably not practical . 
yeah ultimately that ' s also what we want to get at . 
i think that ' s that ' s the correct way . 
so of course we have to keep memory of what was the last intention . 
uhhuh . 
and how does it fit to this and what does it tell us in terms of of the the what we ' re examining . 
huh yeah . 
and furthermore i mean we can idealize that you know people don ' t change topics . 
uhhuh . 
but they do . 
but even for that there is a student of ours who ' s doing a dialogue act um recognition module . 
right . 
uhhuh . 
so maybe we ' re even in a position where we can take your approach . 
which is of course much better as to say how how do these pieces 
huh . 
and much harder to program . 
huh ? 
and much harder to to program . 
yeah how how do these pieces fit together . 
uhhuh . 
and um 
but okay nevertheless so these are issues . 
but we what we actually decided last week is to and this is again for your benefit is to um pretend we have observed and parsed an utterance such as where is the powder tower . 
or where is the zoo . 
and specify um what what we think the the output uh observe out input nodes for our bayes - nets for the sub d . for the discourse bit should be . 
so that and i will i will then come up with the ontology side uh bits and pieces . 
so that we can say okay we we always just look at this utterance . 
that ' s the only utterance we can do . 
it ' s hard coded . 
like srini sort of hand parsed . 
hand crafted . 
but this is what we hope to be able to observe in general from utterances and from ontologies . 
and then we can sort of fiddle with these things to see what it actually produces in terms of output . 
uh . 
so we need to find out what the where is x . construction will give us in terms of semantics . 
and simspec type things . 
just 
okay just where is x . ? 
uhhuh . 
or any variants of that . 
yeah . 
no ! 
um look at it this way . 
yeah . 
what did we decide ? 
we decided sort of the the prototypical where is x . where you know we don ' t really know does he want to go there or just want to know where it is . 
well we were 
so the difference of where is the railway station versus where where where is greenland nuh . 
uhhuh . 
uh i was just dancing sorry . 
we ' re not videotaping any of this . 
so 
uh uh . 
so um we ' re supposed to 
i mean we ' re talking about sort of anything that has the semantics of request for location right ? 
actually 
or 
i mean anyway the node in the uh the ultimate uh in in the bayes - net thing when you ' re done the the node that we ' re talking about um is one that says request for location true or something like that right ? 
um and and exactly how that gets activated you know like whether we want the sentence how do i get there to activate that node or not you know that ' s that ' s sort of the issue that sort of the linguistic y side has to deal with right . 
yeah but it 
well actually more more the other way around . 
we wanted something that represents uncertainty uh in terms of going there or just wanting to know where it is for example . 
some generic information . 
okay . 
and so this is prototypically found in the where is something question surface structure . 
okay . 
which can be you know should be maps to something that activates both . 
i mean the idea is to 
i don ' t 
all right okay . 
hhh . 
let ' s have it fit nicely with the paper . 
i guess i don ' t 
i don ' t see how we would be able to distinguish between the two intentions just from the utterance though . 
the 
i mean uh or before we don ' t before we cranked it through the bayes - net . 
i mean 
yeah we we wouldn ' t . 
that ' s exactly what we want . 
we want to get 
we would ? 
no we wouldn ' t . 
okay . 
but then so basically it ' s just a for every construction we have a node in the net right ? 
and we turn on that node . 
yeah . 
oy . 
what what is this going to 
exactly . 
what is the uh 
well 
and then given that we know that the construction has these two things we can set up probabilities . 
we can basically define all the tables for for those . 
yeah it should be so we have 
um 
let ' s assume we we call something like a loc x . node and a path x . node . 
and what we actually get if we just look at the discourse where is x . should activate . 
or should 
huh . 
huh should be both . 
whereas maybe where is x . located we find from the data is always just asked when the person wants to know where it is . 
and how do i get to is always asked when the person just wants to know how to get there . 
right ? 
so we want to sort of come up with what gets uh input and how in case of a where is question . 
so what what would the outcome of of your parser look like ? 
and what other discourse information from the discourse history could we hope to get squeeze out of that utterance ? 
so define the the input into the bayes - net based on what the utterance where is x . gives us . 
so definitely have an entity node here which is activated via the ontology . 
so where is x . produces something that is stands for x . whether it ' s castle bank restroom toilet whatever . 
and then the ontology will tell us 
that it has a location or something like that . 
or the ontology will tell us where actually it is located . 
no not at all . 
okay . 
where it is located we have a user proximity node here somewhere . 
okay okay . 
which tells us how far the user how far away the user is in respect to that uh entity . 
okay . 
so you ' re talking about for instance the construction obviously involves this entity or refers refers to this entity . 
uhhuh . 
and from the construction also you know that it is a location . 
is or a thing thing that can be located . 
right ontology says this thing has a location slot . 
and that ' s the thing that is being that is the content of the question that ' s being queried by one interpretation of where is x . . 
and another one is um path from current user current location to that location . 
uhhuh . 
so 
so is the question 
i mean it ' s just that i ' m not sure what the 
is the question for this particular construction how we specify that that ' s the information it provides ? 
or or asked for ? 
both sides right ? 
yeah you don ' t need to even do that . 
it ' s just sort of what what would be observed in uh in that case . 
observed when you heard the speaker say where is x . or when when that ' s been parsed ? 
uhhuh . 
so these little circles you have by the d . . 
is that 
that ' s exactly what we ' re looking for . 
okay okay . 
i i just i don ' t like having characterizing the constructions with location and path . 
or characterizing them like that . 
because you don ' t it seems like in the general case you wouldn ' t know how how to characterize them . 
you wouldn ' t . 
i mean or for when . 
there could be an interpretation that we don ' t have a node for in the 
i mean it just seems like has to have uh a node for the construction and then let the chips fall where they may . 
versus uh saying this construction either can mean location or path . 
and in this and since since it can mean either of those things it would light both of those up . 
it ' s the same . 
thoughts ? 
questions ? 
i ' m thinking about it . 
um 
it will be the same . 
so i think in here we have i ' ll go there right . 
answers ? 
and we have our info on . 
so in my my case this would sort of make this happy and this would make the go there happy . 
what you ' re saying is we have a where x . question where x . node that makes both happy . 
right ? 
that ' s what you ' re proposing which is in my mind . 
just as fine . 
so if we have a construction node where is x . it ' s going to both get the posterior probability that it ' s info on up . 
huh yeah . 
info on is true up and that go there is true up as well . 
which would be exactly analogous to what i ' m proposing is this makes uh makes something here true . 
and this makes something also something here true . 
and this makes this true up and this makes this true up as well . 
i kind of like it better without that extra level of indirection too . 
you know with with this points to this points to that and so on . 
because i don ' t know it 
yeah because we get we get tons of constructions i think . 
uh 
yeah . 
because you know huh people have many ways of asking for the same thing . 
yeah sure . 
yeah . 
and 
so 
i i changed my mind actually . 
okay . 
so i agree with that . 
i have a different kind of question . 
might be related . 
which is okay so implicitly everything in e . d . u . we ' re always inferring the speaker intent right ? 
like what they want . 
either the information that they want or 
it ' s always information that they want probably of some kind . 
right ? 
or i i don ' t know . 
the system doesn ' t massage you no no . 
or what ' s something that they 
i i i don ' t 
okay . 
so um 
let ' s see . 
so i don ' t know if the i mean if just there ' s more here that ' s not shown that you it ' s already like part of the system whatever . 
but where is x . like the fact that it is you know a speech act whatever 
it is a question . 
it ' s a question that um queries on some particular thing x . . 
and x . is that location . 
there ' s like a lot of structure in representing that . 
yep yeah . 
so that seems different from just having the node location x . . 
and that goes into edu right ? 
yeah precisely . 
that ' s that ' s 
so 
so is that what you ' re talking about ? 
exactly we have we have specified two . 
what kinds of structure we want . 
okay the next one would be here just for mood . 
uhhuh . 
uhhuh . 
the next one would be what we can squeeze out of the uh 
i don ' t know maybe we want to observe the uh um uh the length of of the words used and or the prosody . 
huh . 
and and make conclusions about the user ' s intelligence . 
okay so in some ways 
i don ' t know . 
yeah . 
um so in some ways in the other sort of parallel set of more linguistic meetings we ' ve been talking about possible semantics of some construction . 
uhhuh . 
right ? 
where it was 
the simulation that ' s according to it you know that that corresponds to it and as well the as discourse . 
uhhuh . 
whatever discourse information . 
such as the mood . 
and you know other stuff . 
so are we looking for a sort of abbreviation of that that ' s tailored to this problem ? 
because that that has you know basically you know it ' s in progress still . 
it ' s in development still . 
but it definitely has various feature slots attributes um bindings between things . 
uhhuh . 
yeah . 
that ' s exactly um why i ' m proposing it ' s too early to have to think of them of all of these discourse things that one could possibly observe . 
uhhuh . 
uhhuh . 
so let ' s just assume 
for the subset of 
human beings are not allowed to ask anything but where is x . . 
okay . 
this is the only utterance in the world . 
what could we observe from that ? 
okay that exactly where is x . . 
in 
not the the choices of where is x . or how do i get to x . . 
just where is x . . 
yeah . 
just just where is x . . 
okay . 
and but you know do it do it in such a way that we know that people can also say is the town hall in front of the bank that we need something like a w . h . focus nuh . 
should be should be there that you know this the whatever we get from the 
wait so do or do not take other kinds of constructions into account ? 
well if you if you can oh definitely do . 
okay where possible . 
where possible right ? 
okay . 
if if if it ' s not at all triggered by our thing then it ' s irrelevant . 
uhhuh . 
and it doesn ' t hurt to leave it out for the moment . 
um but 
okay . 
um it seems like for instance where is x . the fact that it might mean um tell me how to get to x . 
like 
do so would you want to say that those two are both like 
those are the two interpretations right . 
the the ones that are location or path . 
so you could say that the construction is a question asking about this location . 
and then you can additionally infer if they ' re asking about the location it ' s because they want to go to that place . 
uhhuh . 
in which case the you ' re jumping a step step and saying oh i know where it is . 
yeah . 
but i also know how to get they want to seem they seem to want to get there so i ' m going to tell them . 
so there ' s like structure 
right this it ' s not it ' s not that this is sort of like semantically ambiguous between these two . 
do you sort of uh that 
uhhuh . 
it ' s really about this . 
but why would you care about this ? 
well it ' s because you also want to know this or something like that right . 
uhhuh . 
so it ' s like you infer the speaker intent . 
and then infer a plan a larger plan from that for which you have the additional information . 
yeah . 
uhhuh . 
you ' re just being extra helpful . 
yep . 
um 
think uh well this is just a mental exercise . 
yeah . 
if you think about 
focus on this question how would you design that . 
uhhuh . 
is it do you feel confident about saying this is part of the language already to to detect those plans ? 
and why would anyone care about location ? 
if not you know 
huh . 
and so forth . 
or do you actually 
i mean this is perfectly legitimate . 
and i i would not have any problems with erasing this . 
and say that ' s all we can activate based on the utterance out of context . 
uhhuh . 
and just by an additional link . 
oh . 
what ? 
right . 
right . 
and then the the the miracle that we get out the intention go there happens based on what we know about that entity about the user about his various beliefs goals desires blah blah blah . 
like 
with context and enough user information . 
yeah . 
yeah . 
absolutely fine . 
but this is the sort of thing i i propose that we think about . 
okay . 
so that we actually end up with um um nodes for the discourse and ontology . 
so that we can put them into our bayes - net . 
never change them . 
so we all there is is where is x . . 
and eva can play around with the observed things . 
and we can run our better javabayes and have it produce some output . 
and for the first time in in in the world we look at our output . 
and um and see uh whether it it ' s any good . 
okay . 
you know ? 
i mean 
here ' s hoping . 
huh ? 
here ' s hoping right . 
now cross your fingers . 
yeah i i mean for me this is just a matter of curiosity . 
i want to would like to look at uh what this ad hoc process of designing a belief net would actually produce . 
yeah yeah . 
huh . 
if if we ask it where is something . 
and maybe it also enables you to think about certain things more specifically . 
um come up with interesting questions to which you can find interesting answers . 
and additionally it might fit in really nicely with the paper . 
uhhuh . 
because if if if we want an example for the paper i suggest there it is . 
yeah . 
so this might be a nice opening paragraph for the paper as saying you know people look at kinds of at ambiguities . 
and um 
in the literature there ' s bank . 
and whatever kinds of garden path phenomenon . 
uhhuh . 
and we can say well that ' s all nonsense . 
a . uh these things are never really ambiguous in discourse . 
b . don ' t ever occur really in discourse . 
but normal statements that seem completely unambiguous such as where is the blah blah actually are terribly complex and completely ambiguous . 
uhhuh . 
uhhuh . 
and so what everybody else has been doing so far in in in you know has been completely nonsensical and can all go into the wastepaper bin . 
and the only 
that ' s always a good way to begin yeah yeah . 
yeah . 
and the the the only 
i am great . 
yeah . 
all others are useless . 
yeah . 
that ' s good . 
nice overture . 
but you know just not really . 
okay i ' m exaggerating . 
but that might be you know saying hey you know some stuff is is actually complex if you look at it in in in the vacuum . 
uhhuh . 
and and ceases to be complex in reality . 
and some stuff that ' s as that ' s absolutely straightforward in the vacuum is actually terribly complex in reality . 
would be nice sort of uh also nice um up linguistics um type message . 
uhhuh . 
true . 
versus the old top down school . 
i ' m running out of time . 
okay . 
when do you need to start wizarding ? 
at four ten . 
okay this is the other bit of news . 
the subjects today know fey . 
so she can ' t be here and do the wizarding . 
huh . 
so i ' m going to do the wizarding . 
and thilo ' s going to do the instructing . 
huh . 
also we ' re getting a a person who just got fired uh from her job . 
uh a person from oakland who is interested in maybe continuing the wizard bit once fey leaves in august . 
and um she ' s going to look at it today . 
which is good news in the sense that if we want to continue after the after july we can . 
we could . 
and um 
and that ' s also maybe interesting for keith and whoever if you want to get some more stuff into the data collection . 
remember this we can completely change the set - up any time we want . 
uhhuh . 
okay . 
look at the results we ' ve gotten so far for the first whatever fifty some subjects . 
fifty ? 
you ' ve had fifty so far ? 
or 
no we ' re approaching twenty now . 
okay . 
but until fey is leaving we surely will hit the some of the higher numbers . 
yeah . 
huh . 
and um 
so that ' s cool . 
can do more funky stuff . 
sure . 
yeah i ' ll have to look more into that data . 
is that around ? 
like because that ' s pretty much getting posted or something right away when you get it . 
or 
um 
i guess it has to be transcribed huh ? 
we have uh uh found someone here who ' s hand hand transcribing the first twelve . 
okay . 
first dozen subjects . 
uhhuh . 
just so we can build a a language model for the recognizer . 
okay . 
but um so those should be available soon . 
okay . 
the first twelve . 
and 
i can 
you know 
i mean you know that i that i looked at the first the first one and got enough data to keep me going for you know probably most of july . 
so but um 
yeah probably not the right way to do it actually . 
but you can listen to 
you can listen to all of them from your solaris box . 
okay . 
if you want . 
right . 
it ' s always fun . 
okay . 
okay . 
why is it so cold in here ? 
so uh 
we haven ' t sent around the agenda . 
so 
uh any agenda items anybody has wants to talk about what ' s going on ? 
i i could talk about the meeting . 
does everyone has everyone met don ? 
yeah . 
yeah . 
yeah . 
okay . 
now yeah . 
it ' s on ? 
hello . 
yeah . 
yeah . 
okay agenda item one . 
we went 
introduce don . 
okay we did that . 
uh 
well i had a just a quick quest ion . 
but i know there was discussion of it at a previous meeting that i missed . 
but just about the the wish list item of getting good quality close talking mikes on every speaker . 
okay so let ' s let ' s so let ' s just do agenda building right now . 
okay so let ' s talk about that a bit . 
i mean that was 
uh close talking mikes . 
better quality . 
okay uh we can talk about that . 
you were going to starting to say something ? 
well you you um already know about the meeting that ' s coming up . 
and i don ' t know if if this is appropriate for this . 
i don ' t know . 
i mean maybe maybe it ' s something we should handle outside of the meeting . 
what meeting ? 
no no that ' s okay . 
we can so we can so nist is nist folks are coming by next week . 
okay . 
yeah . 
and so we can talk about that . 
who ' s coming ? 
i think 
uh uh john fiscus . 
uhhuh . 
and uh i think george doddington will be around as well . 
uh okay so we can talk about that . 
uh i guess just hear about how things are going with uh uh the transcriptions . 
sure uhhuh . 
that ' s right ? 
that would sort of be an obvious thing to discuss . 
um 
anything else uh strike anybody ? 
uh we started running recognition on one conversation . 
but it ' s the isn ' t working yet . 
so 
okay . 
but if anyone has 
uh the main thing would be if anyone has um knowledge about ways to uh post process the wave forms that would give us better recognition . 
that would be helpful to know about . 
um 
dome . 
yeah it sounds like a topic of conversation . 
yeah . 
so uh 
what about uh is there anything new with the speech nonspeech stuff ? 
yeah we ' re working more on it . 
but it ' s not finished . 
okay . 
all right that seems like a a good collection of things . 
and we ' ll undoubtedly think of other things . 
i had thought under my topic that i would mention . 
the uh four items that i i uh put out for being on the agenda on that meeting . 
which includes like the pre segmentation and the and the developments in multitrans . 
oh under the nist meeting . 
yeah under the nist thing . 
yeah . 
okay . 
all right why don ' t we start off with this . 
i guess the order we brought them up seems fine . 
yeah . 
um 
so better quality close talking mikes . 
so the one issue was that the the uh lapel mike uh isn ' t as good as you would like . 
and so uh it it ' d be better if we had close talking mikes for everybody . 
right ? 
is that is that basically the point ? 
um 
yeah the 
and actually in addition to that that the the close talking mikes are worn in such a way as to best capture the signal . 
and the reason here is just that for the people doing work 
not on microphones but on sort of like dialogue and so forth 
uh or and even on prosody 
which don is going to be working on soon . 
it adds this extra you know variable for each speaker to to deal with when the microphones aren ' t similar . 
right . 
uhhuh . 
so and i also talked to mari this morning . 
and she also had a strong preference for doing that . 
and in fact she said that that ' s useful for them to know in starting to collect their data too . 
uhhuh . 
right so one 
well so 
uh well one thing i was going to say was that um i we could get more uh of the head mounted microphones . 
even beyond the number of radio channels we have . 
because i think whether it ' s radio or wire is probably second order . 
and the main thing is having the microphone close to you . 
although not too close . 
uhhuh . 
right . 
so uh actually the way jose is wearing his is is correct . 
yeah . 
is 
the good way . 
so you want to 
yeah . 
it ' s not it ' s correct ? 
is . 
yeah that ' s good . 
yeah . 
so it ' s towards the corner of your mouth so that breath sounds don ' t get on it . 
yes . 
yeah . 
yeah . 
and then just sort of about uh a thumb or a thumb and a half away from your from your mouth . 
yeah . 
yeah . 
uh yeah . 
right . 
how am i 
but we have more than one type of 
i mean for instance you ' re 
yeah . 
and this one isn ' t very adjustable . 
so this about as good as i can get . 
yeah . 
because it ' s a fixed boom . 
right . 
yeah . 
is fixed yeah . 
yeah . 
but if we could actually standardize you know the the microphones uh as much as possible that would be really helpful . 
uhhuh . 
yeah . 
uhhuh . 
well i mean it doesn ' t hurt to have a few extra microphones around . 
yeah . 
so why don ' t we just go out and and get an order of of 
if this microphone seems okay to people . 
uh i ' d just get a half dozen of these things . 
well the the only problem with that is right now um some of the jimlets aren ' t working . 
the little the boxes under the table . 
yeah . 
and so uh i ' ve only been able to find three jacks that are working . 
yeah . 
can we get these wireless ? 
so 
no but my point is 
but we could just record these signals separately and time align them with the start of the meeting . 
right 
i i ' m not sure i ' m follow . 
say that again . 
right now we ' ve got uh two microphones in the room that are not quote unquote standard . 
so why don ' t we replace those 
okay just two ? 
well however many we can plug in . 
okay . 
you know if we can plug in three let ' s plug in three . 
huh yeah . 
also what we ' ve talked before about getting another uh radio . 
right . 
and so then that would be you know three more . 
right okay . 
uhhuh . 
so uh so we should go out to our full complement of whatever we can do . 
but have them all be the same mike . 
i think the original reason that it was done the other way was because it it was sort of an experimental thing . 
and i don ' t think anybody knew whether people would rather have more variety or or uh more uniformity . 
right . 
but but uh 
sounds sounds fine . 
sounds like uniformity wins . 
right . 
yeah . 
well for short term research it ' s just there ' s just so much effort that would have to be done up front uh 
well 
so yeah uniformity would be great . 
yeah . 
is it because 
you you ' re saying the for dialogue purposes ? 
so that means that the transcribers are having trouble with those mikes ? 
is that what you mean ? 
or 
well jane would know more about the transcribers . 
and that ' s true . 
i mean i we did discuss this . 
uh and and 
yep . 
couple times . 
a couple times . 
so um yeah the transcribers notice 
and in fact there ' re some where um 
ugh . 
well i mean there ' s it ' s the double thing . 
it ' s the equipment and also how it ' s worn . 
and he ' s always they always they just rave about how wonderful adam ' s adam ' s channel is . 
right . 
what can i say ? 
and then 
so does the recognizer . 
oh really ? 
yeah . 
yeah . 
yeah i ' m not surprised . 
i mean baaah . 
yeah but i mean it ' s not just that it ' s also you know 
even if if you ' re talking on someone else ' s mike it ' s still you 
yeah . 
it ' s also like no breathing . 
yeah . 
no 
you know it ' s like it ' s it ' s um 
yeah . 
it ' s really it makes a big difference from the transcribers ' point of view . 
yeah it ' s an advantage when you don ' t breath . 
and also from the research point of view . 
when we ' re doing 
yeah i think that the point of doing the close talking mike is to get a good quality signal we ' re not doing research on close talking mikes . 
right . 
yeah . 
so we might as well get it as uniform as we can . 
yeah . 
right . 
now this is locking the barn door after the horse was stolen . 
we do have thirty hours of of speech which is done this way . 
yeah . 
that ' s okay . 
but 
but uh yeah for future ones we can get it a bit more uniform . 
great great . 
so i think just do a field trip at some point . 
yeah probably yeah to the store we talked about . 
yep . 
and that 
and there was some talk about uh maybe the headphones that are uncomfortable for people to 
yep . 
so as as i said we ' ll do a field trip and see if we can get all of the same mike that ' s more comfortable than than these things which i think are horrible . 
okay . 
so 
good . 
great thank you very much . 
especially for people with big heads . 
okay . 
it ' s makes our job a lot easier . 
and you know we ' re researchers . 
okay . 
so we all have big heads . 
yeah . 
okay . 
yeah . 
uh 
okay second item was the uh nist visit and what ' s going on there . 
yeah . 
okay so um uh 
jonathan fiscus is coming on the second of february . 
and i ' ve spoken with uh a lot of people here . 
not everyone . 
um and um 
he expressed an interest in seeing the room . 
and in um seeing a demonstration of the modified multitrans . 
which i ' ll mention in a second . 
and also um he was interested in the pre segmentation . 
and then he ' s also interested in the transcription conventions . 
uhhuh . 
and um so um it seems to me in terms of like 
um it 
you know okay . 
so the room it ' s things like the audio and and audio and acoustic acoustic properties of the room . 
and how it how the recordings are done . 
and that kind of thing . 
and um okay in terms of the multi trans well that that ' s being modified by dave gelbart to uh handle multi channel recording . 
oh i should ' ve 
i was just thinking i should have invited him to this meeting . 
i forgot to do it . 
so 
yeah okay . 
yeah . 
sorry . 
yeah . 
well that ' s okay i mean we ' ll 
yeah and it ' s and it looks really great . 
he he has a prototype . 
i i uh didn ' t didn ' t see it uh yesterday . 
but i ' m going to see it today . 
and uh that ' s that will enable us to do nice um tight time marking of the beginning and ending of overlapping segments . 
at present it ' s not possible with limitations of of the uh original design of the software . 
and um 
so i don ' t know . 
in terms of like pre segmentation that that continues to be um a terrific asset to the to the transcribers . 
do you i know that you ' re also supplementing it further . 
do you want to mention something about that thilo ? 
or 
um yeah . 
what what i ' m doing right now is i ' m trying to include some information about which channel uh there ' s some speech in . 
but that ' s not working at the moment . 
okay . 
i ' m just trying to do this by comparing energies uh normalizing energies and comparing energies of the different channels . 
and 
so to to give the transcribers some information in which channel there ' s there ' s speech in addition to to the thing we we did . 
now which is just uh speech nonspeech detection on the mixed file . 
this is good uhhuh . 
so i ' m i ' m relying on on the segmentation of the mixed file . 
but i ' m i ' m trying to subdivide the speech portions into different portions if there is some activity in in different channels . 
excellent so this would be like providing also speaker i d potentially . 
but 
yeah . 
yeah . 
wonderful . 
wonderful . 
um something i guess i didn ' t put in the list but uh on that uh same day later on in 
or maybe it ' s no actually it ' s this week . 
uh dave gelbart and i will be uh visiting with john canny . 
who you know is a c s professor . 
oh . 
h c c . 
who ' s interested in in array microphones . 
oh he ' s doing array mikes . 
yeah . 
and so we want to see what commonality there is here . 
you know maybe they ' d want to stick an array mike here when we ' re doing things . 
that would be cool . 
yeah that would be neat . 
or or maybe it ' s it ' s not a specific array microphone they want . 
yeah . 
that would be really neat . 
but they might want to just uh you know you could imagine them taking the four signals from these these table mikes and trying to do something with them . 
um i also had a discussion 
so uh we ' ll be over over there talking with him um after class on friday . 
um we ' ll let you know what what goes with that . 
also had a completely unrelated thing i had a uh discussion today with uh birger kollmeier who ' s a uh a german uh scientist . 
who ' s got a fair sized group doing a range of things . 
it ' s sort of auditory related largely for hearing aids and so on . 
but 
but uh he does stuff with auditory models and he ' s very interested in directionality and location and and uh head models and microphone things . 
and so uh he ' s he and possibly a student there 
there ' s uh a student of his who gave a talk here last year . 
uh may come here uh in the fall for uh sort of a five month uh sabbatical . 
so he might be around . 
get him to give some talks and so on . 
but anyway he might be interested in this stuff . 
uhhuh . 
that that reminds me i had a a thought of an interesting project that somebody could try to do with the data from here . 
either using you know the the mikes on the table or using signal energies from the head worn mikes . 
uhhuh . 
and that is to try to construct a map of where people were sitting . 
right . 
uhhuh . 
well dan dan had worked on that dan ellis . 
uh based on 
uhhuh . 
oh did he ? 
yeah . 
oh that ' s interesting . 
so that that ' s the cross correlation stuff was was doing beam forming . 
yeah . 
and so you could plot out who was sitting next to who . 
and 
a little bit . 
i mean he didn ' t do a very extreme thing but just it was just sort of 
yeah . 
yeah . 
no . 
he did start on it . 
given that the the the block of wood with the the the two mikes on either side . 
uhhuh . 
if i ' m speaking or if you ' re speaking or someone over there is speaking it if you look at cross correlation functions you end up with a 
yeah . 
if if someone who was on the axis between the two is talking then you you get a big peak there . 
and if if someone ' s talking on on on uh one side or the other it goes the other way . 
uhhuh . 
and then uh it it it even looks different if if the two two people on either side are talking than if one in the middle . 
it it actually looks somewhat different . 
huh . 
so 
well i was just thinking you know as i was sitting here next to thilo that um when he ' s talking my mike probably picks it up better than your guys ' s mikes . 
yeah . 
so if you just looked at 
yeah . 
oh that ' s another cue . 
that ' s true . 
yeah looked at the energy on my mike and you could get an idea about who ' s closest to who . 
yeah . 
yeah . 
uhhuh . 
yeah . 
right . 
yeah . 
and 
or who talks the loudest . 
yeah . 
yeah . 
yeah well you have to the appropriate normalizations are tricky and and and are probably the key . 
yeah . 
yeah . 
you just search for adam ' s voice on each individual microphone you pretty much know where everybody ' s sitting . 
yeah . 
yeah we ' ve switched positions recently so you can ' t . 
anyway . 
okay . 
so those are just a little couple of news items . 
can i ask one thing ? 
uh so um 
jonathan fiscus expressed an interest in uh microphone arrays . 
yes . 
um is there 
i mean and i also want to say his he can ' t stay all day . 
he needs to uh leave for uh from here to make a two forty five flight . 
oh so just morning . 
from from oakland . 
right . 
so it makes the scheduling a little bit tight . 
but do you think that um that uh john canny should be involved in this somehow or not ? 
i have no idea . 
probably not . 
but i i ' ll i ' ll i ' ll know better after i see him this friday what what kind of level he wants to get involved . 
it ' s premature . 
fine . 
good . 
uh he might be excited to and it might be very appropriate for him to uh or he might have no interest whatsoever . 
i i just really don ' t know . 
okay . 
is he involved in 
ach i ' m blanking on the name of the project . 
nist has has done a big meeting room instrumented meeting room with video and microphone arrays and very elaborate software . 
is is he the one working on that ? 
well that ' s what they ' re starting up . 
okay . 
yeah no i mean that ' s what all this is about they they haven ' t done it yet . 
okay . 
they wanted to do it . 
i had read some papers that looked like they had already done some work . 
uh well i think they ' ve instrumented a room . 
but i don ' t think they they haven ' t started recordings yet . 
they don ' t have the the transcription standards . 
are they going to do video as well ? 
they don ' t have the 
huh 
yeah . 
huh . 
i think . 
i think they are . 
oh because what what i had read was uh they had a uh very large amount of software infrastructure for coordinating all this . 
both in terms of recording and also live room where you ' re interacting the participants are interacting with the computer and with the video and lots of other stuff . 
well i ' m i ' m i ' m not sure . 
so 
all all i know is that they ' ve been talking to me about a project that they ' re going to start up recording people in meetings . 
okay well 
and uh it is related to ours . 
they were interested in ours . 
they wanted to get some uniformity with us uh about the transcriptions and so on . 
all right . 
and one one notable difference 
actually i can ' t remember whether they were going to routinely collect video or not . 
but one one uh difference from the audio side was that they are interested in using array mikes . 
so um i mean i ' ll just tell you the party line on that . 
the reason i didn ' t go for that here was because uh the focus uh both of my interest and of adam ' s interest was uh in impromptu situations . 
and 
we ' re not recording a bunch of impromptu situations . 
but that ' s because it ' s different to get data for research than to actually apply it . 
huh 
and so uh for scientific reasons we thought it was good to instrument this room as we wanted it . 
but the thing we ultimately wanted to aim at was a situation where you were talking with uh one or more other people uh in in an impromptu way where you didn ' t didn ' t actually know what the situation was going to be . 
and therefore it would not it ' d be highly unlikely that room would be outfitted with with some very carefully designed array of microphones . 
um so it was only for that reason it was just you know yet another piece of research . 
and it seemed like we had enough troubles just 
so there ' s no like portable array of mikes ? 
no so there ' s there ' s uh there ' s a whole range of things there ' s a whole array of things that people do on this . 
huh 
so um 
the uh the big arrays 
uh places uh like uh rutgers and brown and other other places . 
uh they have uh big arrays with i don ' t know a hundred hundred mikes or something . 
xerox . 
and so there ' s a wall of mikes . 
and you get really really good beam forming with that sort of thing . 
wow ! 
and it ' s and um 
in fact at one point we had a a proposal in with rutgers where we were going to do some of the sort of per channel signal processing . 
and they were going to do the multi channel stuff . 
but it it we ended up not doing it . 
but 
i ' ve seen demonstrations of the microphone arrays it ' s amazing how how they can cut out noise . 
yeah it ' s it ' s really neat stuff . 
and then they have little ones too . 
and then they had the little ones yeah . 
but i mean but they don ' t have our block of wood . 
right ? 
yeah our block of wood is unique . 
yeah . 
but the but the 
no there are these commercial things now you can buy that have four mikes or something . 
uhhuh . 
and and uh 
um 
so yeah there ' s there ' s there ' s a range of things that people do . 
huh . 
um so if we connected up with somebody who was interested in doing that sort of thing that ' s that ' s a good thing to do . 
i mean whenever i ' ve described this to other people who are interested on the with the acoustic side that ' s invariably the question they ask . 
just like someone who is interested in the general dialogue thing will always ask um are you recording video . 
um right ? 
right . 
and and the acoustic people will always say well are you doing uh uh array microphones . 
right . 
so it ' s it ' s a good thing to do but it doesn ' t solve the problem of how do you solve things when there ' s one mike or at best two mikes in in this imagined p d a that we have . 
so maybe maybe we ' ll do some more of it . 
well one thing i i mean i don ' t know 
i mean i know that having an array of i mean i would imagine it would be more expensive to have a an array of microphones . 
but couldn ' t you kind of approximate the natural situation by just shutting off uh channels when you ' re later on ? 
i mean it seems like if the microphones don ' t effect each other then couldn ' t you just you know record them with an array and then just not use all the data ? 
it ' s it ' s just a lot of infrastructure that for our particular purpose we felt we didn ' t need to set up . 
i see . 
fine . 
yeah . 
it ' s okay . 
yeah if ninety nine percent of what you ' re doing is is shutting off most of the mikes then going through the 
but if you get somebody who ' s who who has that as a primary interest then that put then that drives it in that direction . 
that ' s right i mean if someone if someone came in and said we really want to do it . 
right . 
i mean we don ' t care . 
that would be fine . 
so to save that data you you have to have one channel recording per mike in the array ? 
buy more disk space . 
is that 
well uh at some level at some level . 
i usually do a mix . 
but then you know there ' s it there ' s 
what you save i mean if you ' re going to do research with it yeah . 
there ' s 
i i don ' t know what they ' re going to do and i don ' t know how big their array is . 
obviously if you were going to save all of those channels for later research you ' d use up a lot of space . 
yeah . 
well their software infrastructure had a very elaborate design for plugging in filters and mixers and all sorts of processing . 
huh . 
and 
so that they can do stuff in real time and not save out each channel individually . 
yeah . 
huh 
yeah . 
so it was uh 
yeah . 
but i mean uh for optimum flexibility later you ' d want to save each channel . 
but i think in practical situations you would have some engine of some sort doing some processing to reduce this to some to the equivalent of a single microphone that was very directional . 
uh oh okay i see . 
right ? 
so 
i mean it seems 
sort of saving the result of the beam forming . 
yeah . 
it seems to me that there ' s you know there are good political reasons for for doing this . 
just getting the data . 
because there ' s a number of sites 
like right now s r i is probably going to invest a lot of internal funding into recording meetings also which is good . 
um but they ' ll be recording with video . 
and they ' ll be 
you know it ' d be nice if we can have at least uh make use of the data that we ' re recording as we go . 
since it ' s sort of this is the first site that has really collected these really impromptu meetings . 
um and just have this other information available . 
so if we can get the investment in just for the infrastructure 
and then 
i don ' t know . 
save it out 
or have whoever ' s interested 
save that data out . 
transfer it there . 
it ' d be it ' d be good to have have the recording i think . 
you mean to to actually get a microphone array and do that ? 
well if 
and video and 
even if we ' re not 
i ' m not sure about video . 
that ' s sort of an video has a little different nature since 
right right now we ' re all being recorded but we ' re not being taped . 
um but it definitely in the case of microphone arrays since if there was a community interested in this then 
well but i think we need a researcher here who ' s interested in it to push it along . 
see the problem is it it took uh uh it took at least six months for dan to get together the hardware and the software and debug stuff in in the microphones and in the boxes . 
and it was a really big deal . 
and so i think we could get a microphone array in here pretty easily . 
and uh have it mixed to to one channel of some sort . 
uhhuh . 
but i think for 
i mean how we ' re going to decide 
for for maximum flexibility later you really don ' t want to end up with just one channel that ' s pointed in the direction of the the the the person with the maximum energy or something like that . 
i mean you you want actually to you want actually to have multiple channels being recorded so that you can 
and to do that it we ' re going to end up greatly increasing the disk space that we use up . 
we also only have boards that will take up to sixteen channels . 
and in this meeting we ' ve got eight people and and six mikes . 
and there we ' re already using fourteen . 
and we actually only have fifteen . 
one of them ' s 
yeah . 
details . 
but fifteen not sixteen . 
uhhuh . 
yeah . 
yeah . 
well if there ' s a way to say time to sort of solve each of these those 
so suppose you can get an array in because there ' s some person at berkeley who ' s interested and has some equipment . 
uh and suppose we can as we save it we can you know transfer it off to some other place that that holds this this data . 
who ' s interested . 
and even if icsi itself isn ' t . 
um and it it seems like as long as we can time align the beginning do we need to mix it with the rest ? 
i don ' t know . 
you know 
yeah so i think you ' d need a separate a separate set up . 
so 
and the assumption that you could time align the two . 
yeah . 
and it ' d certainly gets skew . 
i mean it ' s just it ' s worth considering as sort of 
once you make the up front investment and can sort of save it out each time and and not have to worry about the disk space factor then it it might be worth having the data . 
i ' m not so much worried about disk space actually . 
i mentioned that as a practical matter . 
just 
but the real issue is that uh there is no way to do a recording extended to what we have now with low skew . 
so you would have a completely separate set up . 
which would mean that the sampling times and so forth would be all over the place compared to this . 
right . 
so it would depend on the level of processing you were doing later . 
but if you ' re the kind of person who ' s doing array processing you actually care about funny little times . 
and and so you actually would want to have a completely different set up than we have . 
i see . 
one that would go up to thirty two channels or something . 
huh . 
so basically 
or a hundred thirty two . 
or a 
yeah . 
so i ' m kind of skeptical . 
but um i think that 
huh . 
so uh i don ' t think we can share the resource in that way . 
but what we could do is if there was someone else who ' s interested they could have a separate set up which they wouldn ' t be trying to synch with ours . 
which might be useful for for them . 
right i mean at least they ' d have the data and the transcripts . 
and then we can offer up the room . 
and 
yeah we can offer the meetings and the physical space . 
right . 
and and yeah the transcripts and so on . 
okay . 
right i mean just it ' d be nice if we have more information on the same data . 
you know ? 
yeah . 
and 
but it ' s if it ' s impossible or if it ' s a lot of effort then you have to just balance the two . 
well i 
yeah the thing will be in in again in talking to these other people to see what you know what what we can do . 
so 
right . 
uh we ' ll see . 
is there an interest in getting video recordings for these meetings ? 
i mean 
right so we have we 
yes absolutely but it ' s exactly the same problem . 
that you have an infrastructure problem . 
you have a problem with people not wanting to be video taped . 
and you have the problem that no one who ' s currently involved in the project is really hot to do it . 
huh . 
so there ' s not enough interest to overcome all of 
uhhuh . 
right internally . 
but i know there is interest from other places that are interested in looking at meeting data and having the video . 
so it ' s just 
yeah although i i i have to mention the human subjects problems that increase with video . 
right that ' s true . 
yeah so it ' s uh people people getting shy about it . 
yeah . 
there ' s this human subjects problem . 
there ' s the fact that then um if 
i ' ve heard comments about this before . 
why don ' t you just put on a video camera . 
but you know it ' s sort of like saying uh well we ' re primarily interested in in some dialogue things . 
uh but uh why don ' t we just throw a microphone out there ? 
i mean the thing is once you actually have serious interest in any of these things then you actually have to put a lot of effort in . 
huh . 
and uh you really want to do it right . 
i know . 
yep . 
so i think nist or l d c or somebody like that i think is much better shape to do all that . 
we there will be other meeting recordings we won ' t be the only place doing meeting recordings . 
uhhuh . 
we are doing what we ' re doing . 
and uh hopefully it ' ll be useful . 
i it it occurred to me has don signed a human subject ' s form ? 
oh probably not . 
a permission form ? 
has don have you did you 
i thought you did actually . 
didn ' t you read a digit string ? 
i was yeah i was i was here i was here before once . 
you were here at a meeting before . 
you were here at a meeting before . 
yeah and you and you signed a form . 
yeah . 
so 
did you sign a form ? 
oh i think so . 
did i ? 
i ' m pretty sure . 
i don ' t know . 
well i ' ll i ' ll get another one before the end of the meeting . 
okay . 
thank you . 
yeah . 
okay . 
yeah . 
yeah . 
you don ' t you don ' t have to leave for it . 
but i just 
yeah we we 
you know . 
well i can ' t . 
can i verbally consent ? 
i ' m wired in . 
we we we we don ' t uh 
yeah . 
you ' re on you ' re being recorded . 
yeah . 
and 
i don ' t care . 
we don ' t we don ' t perform electro shock during these meetings . 
you can do whatever you want with it . 
that ' s fine . 
and 
usually . 
yeah . 
okay . 
uh transcriptions . 
transcriptions okay . 
um i thought about there are maybe three aspects of this . 
so first of all um i ' ve got eight transcribers . 
uh seven of them are linguists . 
one of them is a graduate student in psychology . 
um each i gave each of them uh their own data set . 
two of them have already finished the data sets . 
and the meetings run you know let ' s say an hour sometimes as much as an hour and a half . 
how big is the data set ? 
oh it ' s what i mean is one meeting . 
each each person got their own meeting . 
uh okay . 
i didn ' t want to have any conflicts of you know of of when to stop transcribing this one . 
or 
so i wanted to keep it clear whose data were whose . 
and and and so 
uhhuh . 
and uh meetings you know i think that they ' re they go as long as a almost two hours in some in some cases . 
so you know that means 
you know if we ' ve got two already finished and they ' re working on 
uh right now all eight of them have uh uh additional data sets that means potentially as many as ten might be finished by the end of the month . 
hope so . 
wow ! 
but the pre segmentation really helps a huge amount . 
okay . 
and uh also dan ellis ' s innovation of the uh the multi channel to here really helped a a lot in terms of clearing clearing up hearings that involve overlaps . 
but um 
just out of curiosity i asked one of them how long it was taking her one of these two who has already finished her data set . 
she said it takes about uh sixty minutes transcription for every five minutes of real time . 
so it ' s about twelve to one . 
which is what we were thinking . 
or 
yep . 
it ' s well in the range . 
it ' s pretty good . 
okay uh these still when they ' re finished um that means that they ' re finished with their pass through they still need to be edited and all . 
but but it ' s word level speaker change the things that were mentioned . 
okay now i wanted to mention the um teleconference i had with uh jonathan fiscus . 
we spoke for an hour and a half . 
huh . 
and um had an awful lot of things in common . 
he um um he indicated to me that they ' ve that he ' s been 
uh looking uh uh spending a lot of time with 
i ' m not quite sure the connection . 
but spending a lot of time with the atlas system . 
and i guess that i mean i i need to read up on that . 
and there ' s a web site that has lots of papers . 
but it looks to me like that ' s the name that has developed for the system that bird and liberman developed for the annotated graphs approach . 
uhhuh . 
so what he wants me to do 
and what we what we will do and uh is to provide them with the already transcribed meeting . 
for him to be able to experiment with in this atlas system . 
and they do have some sort of software . 
at least that ' s my impression related to atlas . 
and that he wants to experiment with taking our data . 
and putting them in that format and see how that works out . 
i i i explained to him in in detail the uh conventions that we ' re using here in this in this word level transcript . 
and um 
you know i i explained you know the reasons that that we were not coding more elaborately . 
and and the focus on reliability . 
he expressed a lot of interest in reliability . 
it ' s like he ' s he ' s really up on these things . 
he ' s he ' s very 
um independently he asked well what about reliability . 
so he ' s interested in the consistency of the encoding and that sort of thing . 
okay um 
sorry . 
can you explain what the atlas 
i ' m not familiar with this atlas system . 
well you know at this point i think 
uh well adam ' s read more in more detail than i have on this . 
i need to acquaint myself more with it . 
but um there there is a way of viewing 
uh whenever you have coding categories um and you ' re dealing with uh a taxonomy then you can have branches that that have alternative uh choices that you could use for each each of them . 
and it just ends up looking like a graphical representation . 
is is 
is atlas the his annotated transcription graph stuff ? 
i don ' t remember the acronym . 
the the one the what i think you ' re referring to they they have this concept of an annotated transcription graph representation . 
and that ' s basically what i based the format that i did 
yeah . 
oh oh . 
i based it on their work almost directly in combination with the t e i stuff . 
and so it ' s very very similar . 
and so it ' s it ' s a data representation and a set of tools for manipulating transcription graphs of various types . 
is this the project that ' s sort of uh between uh nist and and uh a couple of other places ? 
uhhuh . 
including l d c . 
the the 
i think so . 
yep . 
yeah . 
right . 
uhhuh then there ' s their web site that has lots of papers . 
okay . 
and i looked through them . 
and they mainly had to do with this um this uh tree structure uh annotated tree diagram thing . 
huh . 
so um um and you know in terms of like the conventions that i ' m that i ' ve adopted it there there ' s no conflict at all . 
right . 
and he was you know very interested . 
and oh and how ' d you handle this . 
and i said well you know this way . 
and and and we had a really nice conversation . 
um okay now i also wanted to say in a different a different direction is brian kingsbury . 
so um i corresponded briefly with him . 
i uh i 
he still has an account here . 
i told him he could s s h on and use multi trans and have a look at the already done uh transcription and he and he did . 
and what he said was that um what they ' ll be providing is will not be as fine grained in terms of the time information . 
and um that ' s uh you know i need to get back to him and and uh you know explore that a little bit more and see what they ' ll be giving us in specific . 
huh . 
the the people 
but i just haven ' t had time yet . 
sorry what ? 
the the folks that they ' re uh subcontracting out the transcription to are they like court reporters ? 
yes . 
or 
apparently well i get the sense they ' re kind of like that like it ' s like a pool of of somewhat uh secretarial . 
i don ' t think that they ' re court reporters . 
i don ' t think they have the special keyboards and that and that type of training . 
i i get the sense they ' re more secretarial . 
uhhuh . 
and that um uh what they ' re doing is giving them 
huh . 
like medical transcriptionist type people ? 
it ' s mostly it ' s for their speech recognition products . 
yep . 
that they ' ve hired these people to do . 
but aren ' t they ' re 
oh so they ' re hiring them they ' re coming it ' s not a service they send the tapes out to . 
well they they do send it out . 
but my understanding is that that ' s all this company does is transcriptions for i b m for their speech product . 
uh ! 
oh okay . 
i gotcha . 
so most of it ' s viavoice people reading their training material for that . 
i see . 
uhhuh . 
i see . 
up to now it ' s been monologues uh as far my understood it . 
yep . 
exactly . 
and and what they ' re doing is 
yep . 
uhhuh . 
brian himself downloaded so so um adam sent them a c d and brian himself downloaded 
uh because you know i mean we wanted to have it so that they were in familiar terms with what they wanted to do . 
he downloaded from the c d onto audio tapes . 
and apparently he did it one channel per audio tape . 
so each of these people is transcribing from one channel . 
right . 
and then what he ' s going to do is check it . 
oh ! 
before they go beyond the first one . 
check it and you know adjust it and all that . 
so each person gets one of these channels . 
right . 
okay . 
so if they hear something off in the distance they don ' t they just go 
well but that ' s okay because you know you ' ll do all them and then combine them . 
i i don ' t know . 
i have i you know i 
but there could be problems right with that ? 
yep . 
i think it would be difficult to do it that way i really do . 
yeah . 
well if you ' re if you got that channel right there 
uh in my case 
no no we ' re talking about close talking not the not the desktop . 
yeah . 
no close talk . 
are you ? 
yes . 
i sure hope so . 
well i i think so . 
it ' d be really foolish to do otherwise . 
yeah i i would think that it would be kind of hard to come out with yeah . 
i i think it ' s sort of hard just playing the you know just having played the individual files . 
and i i mean i know you i know what your voice sounds like i ' m sort of familiar with 
yeah . 
uh it ' s pretty hard to follow especially 
one side . 
i agree . 
there are a lot of words that are so reduced phonetically that make sense when you know what the person was saying before . 
yeah . 
that ' s 
yeah . 
and especially since a lot of these 
uh it sort of depends where you are in 
yeah . 
but i mean we had this we ' ve had this discussion many times . 
and the answer is we don ' t actually know the answer because we haven ' t tried both ways . 
yeah we have . 
well except i can say that my transcribers use the mixed signal mostly . 
so 
uhhuh . 
uhhuh . 
unless there ' s a huge disparity in terms of the volume on on the mix . 
right . 
in which case you know they they wouldn ' t be able to catch anything except the prominent channel . 
right . 
then they ' ll switch between . 
well i think that that might change if you wanted really fine time markings . 
yeah . 
but but really 
well okay . 
so 
yeah well 
but they ' re not giving really fine time markings . 
right . 
actually are so are they giving any time markings ? 
in other words if 
well i have to ask him . 
and that ' s that ' s my email to him that needs to be forthcoming . 
yeah 
because 
okay . 
but but the uh i did want to say that it ' s hard to follow one channel of a conversation even if you know the people . 
and if you ' re dealing furthermore with highly abstract network concepts you ' ve never heard of . 
so you know one of these people was was transcribing the uh networks group talk . 
and she said i don ' t really know what a lot of these abbreviations are . 
but i just put them in parentheses because that ' s the that ' s the convention and i just 
because you know if you don ' t know 
oh i ' d be curious to to look at that . 
just out of curiosity i mean 
they also all have heavy accents . 
the networks group meetings are all 
yeah . 
yeah . 
yeah . 
given all of the effort that is going on here in transcribing why do we have i b m doing it ? 
why not just do it all ourselves ? 
um it ' s historical . 
i mean 
uh some point ago we thought that uh it boy we ' d really have to ramp up to do that . 
no just 
uhhuh . 
you know like we just did . 
uhhuh . 
and um here ' s uh a a uh collaborating institution that ' s volunteered to do it . 
uhhuh . 
so that was a contribution they could make uh in terms of time money you know . 
uhhuh . 
and it still might be a good thing . 
i ' m just wondering now 
but 
well i ' m i ' m wondering now if it ' s 
yeah mari asked me the same question as sort of 
well we can talk about more details later . 
um you know 
yeah . 
yeah . 
whether to 
yeah . 
yeah . 
so 
huh 
we ' ll see . 
i mean i think you know they they they ' ve proceeded along a bit let ' s see what comes out of it and and uh you know have some more discussions with them . 
uhhuh . 
it ' s very a real benefit having brian involved . 
because of his knowledge of what the how the data need to be used and so what ' s useful to have in the format . 
yeah . 
uhhuh . 
yeah . 
so um liz with with the s r i recognizer can it make use of some time marks ? 
okay so this is a um 
i i guess i don ' t know what that means . 
and actually i should say this is what don has uh he ' s already been really helpful in uh chopping up these . 
so so first of all you 
um i mean for the s r i front end we really need to chop things up into pieces that are not too huge . 
um but second of all uh in general because some of these channels . 
i ' d say like i don ' t know at least half of them probably on average are are are 
have a lot of cross ta 
sorry some of the segments have a lot of cross talk . 
um it ' s good to get sort of short segments if you ' re going to do recognition . 
especially forced alignment . 
so 
uh don has been taking a first stab actually using jane ' s first the the meeting that jane transcribed . 
which we did have some problems with . 
and thilo uh i think told me why this was . 
but that people were switching microphones around in the very beginning . 
so 
the s r i 
no yeah no they they were not switching them but what they were they were adjusting them . 
and they 
they were not 
huh 
adjusting oh . 
so 
yeah . 
and after a minute or so it ' s it ' s way better . 
so 
so we have to sort of normalize the front end and so forth and have these small segments . 
yep . 
so we ' ve taken that and chopped it into pieces based always on your your um cuts that you made on the mixed signal . 
and so that every every speaker has the same cuts . 
and if they have speech in it we run it through . 
and if they don ' t have speech in it we don ' t run it through . 
and we base that knowledge on the transcription . 
on just on the marks . 
right ? 
um the problem is if we have no time marks 
then for forced alignment we actually don ' t know where you know in the signal the transcriber heard that word . 
and so 
oh i see . 
it ' s for the length . 
i mean if if it ' s a whole conversation and we get a long uh you know paragraph of of talk . 
i see . 
uh i don ' t know how they do this . 
um we actually don ' t know which piece goes where . 
i understand . 
and um i think with 
well you would need to like a forced alignment before you did the chopping . 
right ? 
no we used the fact that 
so when jane transcribes them the way she has transcribers doing this . 
it ' s already chunked . 
whether it ' s with the pre segmentation or not . 
they have a chunk and then they transcribes the words in the chunk . 
and maybe they choose the chunk or now they use a pre segmentation and then correct it if necessary . 
uhhuh . 
but there ' s first a chunk and then a transcription . 
then a chunk then a transcription . 
that ' s great . 
because the recognizer can 
uh it ' s all pretty good sized for the recognizer also . 
right and it it helps that it ' s made based on sort of heuristics and human ear i think . 
good . 
oh good . 
but there ' s going to be a real problem . 
uh even if we chop up based on speech silence these uh the transcripts from i b m we don ' t actually know where the words were . 
right . 
which segment they belonged to . 
so that ' s sort of what i ' m worried about right now . 
why not do a a a forced alignment ? 
that ' s what she ' s saying is that you can ' t . 
if you do a forced alignment on something really 
got uh sixty minutes of 
well even if you do it on something really long you need to know 
you can always chop it up . 
but you need to have a reference of which words went with which uh chop . 
now wasn ' t i thought that one of the proposals was that i b m was going to do an initial forced alignment . 
so 
after they 
yeah but 
i i think that they are . 
we ' ll have to talk to brian . 
um 
yeah i ' m sure they will . 
and so we we have to have a dialogue with them about it . 
yeah . 
i mean it sounds like liz has some concerns . 
maybe they have some you know maybe actually there is some even if they ' re not fine grained maybe the transcribers 
and 
uh i don ' t know maybe it ' s saved out in pieces or or something that would help . 
yeah . 
but 
uh it ' s just an unknown right now . 
yeah i i need to to write to him . 
so 
i just you know it ' s like i got over taxed with the timing . 
right but the it is true that the segments i haven ' t tried the segments that thilo gave you . 
but the segments that in your first meeting are great . 
uhhuh . 
i mean that ' s that ' s a good length . 
a good size . 
good . 
right because 
well i i was thinking it would be fun to to uh uh if if you wouldn ' t mind to give us a pre segmentation . 
yeah . 
yeah . 
uh maybe you have one already of that first of the meeting that uh the first transcribed meeting . 
the one that i transcribed . 
do you have a could you generate a pre segmentation ? 
um i ' m sure i have some . 
february sixteenth i think . 
but but that ' s the one where we ' re um training on . 
so that ' s a little bit 
oh . 
oh i see . 
oh darn . 
it ' s a little bit at odd to 
of course of course of course . 
yeah okay . 
yeah . 
and actually as you get transcripts just um for new meetings um we can try 
uhhuh . 
i mean the the more data we have to try the the alignments on um the better . 
so it ' d be good for just to know as transcriptions are coming through the pipeline from the transcribers . 
just to sort of we ' re playing around with sort of uh parameters on the recognizer . 
uhhuh . 
because that would be helpful . 
excellent good . 
especially as you get more voices . 
the first meeting had i think just four people . 
four speakers . 
uhhuh . 
yeah . 
yeah liz and i spoke at some length on tuesday . 
yeah . 
and and i and i was planning to do just a a preliminary look over of the two that are finished and then give them to you . 
oh great . 
great . 
yeah . 
so 
that ' s great . 
i guess the other thing 
i i can ' t remember if we discussed this in the meeting but uh i know you and i talked about this a little bit . 
there was an issue of uh 
suppose we get in the uh 
i guess it ' s enviable position although maybe it ' s just saying where the weak link is in the chain . 
uh where we we 
uh uh 
we have all the data transcribed . 
and we have these transcribers . 
and we were we ' re the 
we ' re still a bit slow on feeding 
at that point we ' ve caught up . 
and the the the uh the weak link is is recording meetings . 
okay . 
um 
two questions come is you know what how how do we 
uh it ' s not really a problem at the moment because we haven ' t reached that point . 
but how do we step out the recorded meetings ? 
and the other one is um uh is there some good use that we can make of the transcribers to do other things ? 
so um i i can ' t remember how much we talked about this in this meeting . 
we had spoken with them about it . 
but there was 
and there is one use that that also we discussed which was when uh dave finishes the 
and maybe it ' s already finished . 
the the modification to multi trans which will allow fine grained encoding of overlaps . 
uh then it would be very these people would be very good to shift over to finer grain encoding of overlaps . 
it ' s just a matter of you know providing 
so if right now you have two overlapping segments in the same time interval 
bin well with with the improvement in the database in in the uh sorry in the interface it ' d be possible to um you know just do a click and drag thing and get the uh the specific place of each of those the time tag associated with the beginning and end of of each segment . 
right so i think we talking about three level three things . 
uhhuh . 
yeah . 
one one was uh we had had some discussion in the past about some very high level labelings . 
the types of overlaps 
types of overlaps and so forth that that someone could do . 
uhhuh . 
second was uh somewhat lower level . 
just doing these more precise timings . 
and the third one is is uh just a completely wild hair brained idea that i have . 
which is that um if uh if we have time and people are able to do it to take some subset of the data and do some very fine grained analysis of the speech . 
for instance uh marking in some overlapping 
potentially overlapping fashion uh the value of uh articulatory features . 
yeah . 
you know just sort of say okay it ' s voiced from here to here . 
there ' s it ' s nasal from here to here and so forth . 
um as opposed to doing phonetic uh you know phonemic and the phonetic analysis . 
uhhuh . 
and uh assuming uh articulatory feature values for those those things . 
um obviously that ' s extremely time consuming . 
uh 
that would be really valuable i think . 
but uh 
we could do it on some small subset . 
also if you ' re dealing with consonants that would be easier than vowels . 
wouldn ' t it ? 
i mean i would think that that uh being able to code that there ' s a a fricative extending from here to here would be a lot easier than classifying precisely which vowel that was . 
which one ? 
huh . 
i think vowels vowels are i think harder . 
uhhuh . 
yeah . 
well yeah . 
but i think also it ' s just the issue that that when you look at the when you look at switchboard for instance very close up there are places where whether it ' s a consonant or a vowel you still have trouble calling it a particular phone . 
uhhuh . 
uhhuh okay . 
yeah but but just saying what the 
at that point . 
because it ' s you know there ' s this movement from here to here . 
yeah i ' m sure . 
uh yeah i i know . 
right . 
and and and it ' s 
you ' re saying sort of remove the high level constraints . 
so 
and go bottom up . 
yep just features . 
then just say 
yeah describe describe it . 
huh . 
now i ' m suggesting articulatory features . 
maybe there ' s there ' s even a better way to do it . 
but it but but that ' s you know sort of a traditional way of describing these things . 
uhhuh . 
um and uh 
that ' s nice . 
i mean actually this might be a neat thing to talk to 
acoustic features versus psychological categories . 
sort of . 
yeah . 
i mean it ' s still 
yeah . 
some sort of categories . 
but but something that allows for overlapping change of these things . 
and then this would give some more ground work for people who were building statistical models that allowed for overlapping changes different timing changes as opposed to just click . 
you ' re now in this state which corresponds to this speech sound and so on . 
uhhuh uhhuh . 
so this is like gestural uh these 
yeah something like that . 
right . 
i mean actually if we get into that it might be good to uh uh haul john ohala into this . 
okay . 
and ask his his views on it i think . 
yeah . 
right . 
but is is the goal there to have this on meeting data 
excellent . 
like 
so that you can do far field studies of those gestures ? 
or um 
or is it because you think there ' s a different kind of actual production in meetings that people use ? 
no i think i think it ' s for for for that purpose i ' m just viewing meetings as being a a neat way to get people talking naturally . 
or 
and then you have and then and then it ' s natural in all senses . 
just a source of data ? 
i see . 
in the sense that you have microphones that are at a distance that you know one might have . 
and you have the close mikes . 
and you have people talking naturally . 
and the overlap is just indicative of the fact that people are talking naturally . 
uhhuh . 
yeah . 
right ? 
so so i think that given that it ' s that kind of corpus 
right . 
yeah . 
if it ' s going to be a very useful corpus 
um if you say okay we ' ve limited the use by some of our uh uh censored choices . 
we don ' t have the video we don ' t and so forth . 
but there ' s a lot of use that we could make of it by expanding the annotation choices . 
uhhuh . 
and uh most of the things we ' ve talked about have been fairly high level . 
and being kind of a bottom up person i thought maybe we ' d do some of the others . 
huh . 
it ' s a nice balance . 
right yeah that would be good . 
that would be really nice to offer those things with that wide range . 
yeah . 
right . 
yeah . 
and hopefully someone would make use of it . 
really nice . 
i mean people didn ' t 
yeah . 
uh i mean people have made a lot of use of of timit . 
and uh due to its markings . 
and then the switchboard transcription thing . 
well i think has been very useful for a lot of people . 
right . 
that ' s true . 
so 
i guess i wanted to um sort of make a pitch for trying to collect more meetings . 
cool . 
um 
yeah . 
actually i talked to chuck fillmore . 
and i think they ' ve what vehemently said no before . 
but this time he wasn ' t vehement and he said you know well liz come to the meeting tomorrow . 
yeah . 
and try to convince people . 
so i ' m going to try go to their meeting tomorrow . 
uhhuh . 
and see if we can try uh to convince them . 
good . 
because they have something like three or four different meetings . 
because they have 
and they have very interesting meetings from the point of view of a very different type of of talk than we have here . 
right ? 
uhhuh . 
talk 
and definitely than the front end meeting probably . 
um 
you mean in terms of the topic topics ? 
well yes and in terms of the the fact that they ' re describing abstract things . 
and uh just dialogue wise . 
uhhuh . 
right . 
uhhuh . 
um so i ' ll try . 
and then the other thing is 
i don ' t know if this is at all useful . 
but i asked lila if i can maybe go around and talk to the different departments in this building . 
yes . 
to see if there ' s any groups that for a free lunch 
if we can still offer that . 
you mean non icsi ? 
great . 
might be willing 
non icsi non academic . 
yeah i guess you you can try . 
you know like government people . 
but 
i don ' t know . 
the problem is so much of their stuff is confidential . 
so 
it would be very hard for them . 
yeah . 
yeah . 
also it does seem like it takes us way out of the demographic . 
yeah . 
is is it in these departments ? 
i mean it seems like we we had this idea before of having like linguistics students brought down for free lunches . 
well i think that ' s her point . 
right and then we could also we might try advertising again . 
and that ' s a nice idea . 
because i think it ' d be good if if we can get a few different sort of non internal types of meetings . 
yeah . 
yeah . 
and just also more data . 
uhhuh . 
and i think uh if we could get 
does does john ohala have weekly phonetics lab meetings ? 
so 
so i actually wrote to him and he answered great that sounds really interesting . 
but i never heard back . 
because we didn ' t actually advertise openly . 
we i mean 
i told i asked him privately . 
um and it is a little bit of a trek for campus folks . 
yeah . 
uhhuh . 
you might give them a free lunch . 
but um 
um so it ' s still worthwhile 
it would be nice if we got someone other than me who knew how to set it up and could do the recording . 
so 
so i didn ' t have to do it each time . 
exactly . 
yeah that ' s right . 
and and 
and i was thinking 
he ' s supposed he ' s supposed to be trained to do it . 
yeah . 
plus we could also get you know a a student . 
okay next week you ' re going to do it all . 
yeah . 
and i ' m willing to try to learn . 
i mean i ' m i would do my best . 
um the other thing is that there was a number of things at the transcription side that um transcribers can do like dialogue act tagging . 
it ' s not that hard . 
disfluency tagging . 
um things that are in the speech that are actually something we ' re working on for language modeling . 
and mari ' s also interested in it . 
andreas as well . 
so if you want to process a utterance and the first thing they say is well and that well is coded as some kind of interrupt tag . 
uh and things like that . 
um 
of course some of that can be done lexically . 
and i also they are doing disfluency tagging to some degree already . 
a lot of it can be done 
great so a a lot of this kind of 
yeah . 
i think there ' s a second pass . 
and i don ' t really know what would exist in it . 
but there ' s definitely a second pass worth doing to maybe encode some kinds of you know is it a question or not . 
uhhuh . 
or 
um that maybe these transcribers could do . 
so 
they ' d be really good . 
yeah . 
they ' re they ' re very they ' re very consistent . 
uhhuh . 
uh i wanted to while we ' re uh so to return just briefly to this question of more meeting data . 
that ' d be great . 
um i have two questions . 
one of them is um jerry feldman ' s group . 
they they uh are they 
i know that they recorded one meeting . 
are they willing ? 
i think they ' re open to it . 
i think you know all these things are 
oh yeah . 
i think there ' s 
we should go beyond uh icsi . 
but i mean there ' s a lot of stuff happening at icsi that we ' re not getting now that we could . 
uhhuh . 
so it ' s just 
oh that we could . 
okay . 
yeah so the 
i thought that all these people had sort of said no twice already . 
no no no . 
if that ' s not the case then 
so there was the thing in fillmore ' s group . 
but even there he hadn ' t 
what he ' d said no to was for the main meeting . 
but they have several smaller meetings a week . 
so 
and uh the notion was raised before that that could happen . 
and it just you know it just didn ' t come together . 
just 
well and and the other thing too is when they originally said no they didn ' t know about this post editing capability thing . 
okay . 
but 
oh . 
right . 
yeah yeah . 
right that was a big fear . 
that ' s important . 
so 
yeah so i mean there ' s possibilities there . 
i think jerry ' s group yes . 
uh there ' s there ' s uh the networks group . 
okay . 
uh i don ' t know . 
do they still meeting regularly ? 
or 
well i don ' t know if they meet regularly or not . 
but they are no longer recording . 
but i mean have they said they don ' t want to anymore ? 
or 
um ugh what was his name ? 
uh 
joe sokol ? 
yeah . 
yeah . 
when with him gone it sort of trickled off . 
they and they stopped . 
okay so they ' re down to three or four people . 
yeah . 
but the thing is three or four people is okay . 
uhhuh . 
yep . 
we might be able to get the administration 
well he was sort of my contact . 
so i just need to find out who ' s running it now . 
so 
okay . 
i see that lila has a luncheon meeting in here periodically . 
i don ' t know 
yeah i mean it one thing that would be nice . 
and this it sounds bizarre . 
but i ' d really like to look at to get some meetings where there ' s a little bit of heated discussion . 
like arguments and or emotion and things like that . 
and so i was thinking if there ' s any like berkeley political groups or something . 
i mean that ' d be perfect . 
some group yes we must . 
who ' s willing to get recorded and distributed ? 
well you know something 
yeah i don ' t think the more political argumentative ones would be willing to 
yeah . 
um 
yeah . 
yeah . 
with with with potential use from the defense department . 
well okay 
yeah . 
yeah exactly . 
yeah . 
yeah . 
yeah . 
no but maybe student uh groups or um film makers or something a little bit colorful . 
yeah . 
yeah . 
of course there is this problem though that if we give them the chance to excise later we might end up with like five minutes out of a of one hour 
film maker . 
of beeps . 
yeah . 
yeah . 
yeah . 
is 
yes really . 
and i don ' t mean that they ' re angry . 
but just something with some more variation in prosodic contours and so forth would be neat . 
so if anyone has ideas . 
i ' m willing to do the leg work to go try to talk to people . 
but i don ' t really know which groups are worth pursuing . 
well there was this k p f a idea . 
no that ' s 
yeah there ' s a problem there in terms of uh the um commercial value of of uh 
but 
okay . 
legal . 
okay . 
okay . 
it it it it turned out to be a bit of a problem . 
or 
and i had one other one other aspect of this . 
which is um uh uh jonathan fiscus expressed uh a major interest in having meetings which were all english speakers . 
now he wasn ' t trying to shape us in terms of what we gather . 
uhhuh . 
but that ' s what he wanted me to show him . 
so i ' m giving him our um our initial meeting . 
because he asked for all english . 
and i think we don ' t have a lot of all english meetings right now . 
did he mean uh did he mean and non british ? 
of all all all native speakers . 
well 
the all native . 
that ' s what i mean yeah . 
well if he meant and non british i think we have zero . 
he doesn ' t care . 
no uh well british is okay . 
but but 
he said british was okay ? 
sure sure sure . 
british is english ? 
why ? 
different varieties of english . 
oh ! 
ooo ooo ! 
well i don ' t i don ' t i don ' t think if he didn ' t say that 
native speaking native speaking english . 
i bet he meant native speaking american . 
yes . 
i bet he did . 
american english ? 
oh really ? 
so why would he care ? 
knowing the application 
i remember i remember a study 
that ' s 
i was thinking knowing the uh national institute of standards it is all 
i remember a study that b b n did where they trained on 
this was in wall street journal days or something . 
they trained on american english . 
and then they tested on uh different native speakers from different areas . 
and uh 
uh the worst match was people whose native tongue was mandarin chinese . 
the second worst was british english . 
that ' s funny . 
so it ' s you know 
all right . 
and so that would make sense . 
the the the german was much better . 
i didn ' t have the context of that . 
ooo ooo . 
it was swiss 
yeah so it ' s 
so i think you know if he ' s if he ' s thinking in terms of recognition kind of technology i i i think he would probably want uh american english . 
i wonder if we have any . 
all america okay . 
yeah . 
it it yeah unless we ' re going to train with a whole bunch of 
i think that the feldman ' s meetings tend to be more that way . 
aren ' t they ? 
i mean i sort of feel like they have 
maybe . 
i think so . 
maybe . 
yeah . 
yeah . 
uhhuh . 
yeah . 
huh 
and maybe there are a few of with us where it was 
you know dan wasn ' t there . 
yeah . 
and before jose started coming . 
yeah . 
yeah . 
and 
it ' s pretty tough uh this group yeah . 
yeah . 
huh 
yeah . 
so uh what about what about people who involved in some artistic endeavor ? 
i mean film making or something like that . 
exactly that ' s what i was 
you ' d think like they would be 
a film maker . 
something where there there is actually discussion where there ' s no right or wrong answer but but it ' s a matter of opinion kind of thing . 
it ' s be fun . 
uh anyway if you if you have ideas . 
rasta p l p . 
rasta p l p . 
we can just we can just have a political discussion one day . 
yes . 
any department that calls itself science ring 
yeah we could 
department . 
uh i could make that pretty 
well like computer science . 
yeah . 
that 
computer 
we could get julia child . 
i know . 
that ' s 
i ' m i ' m actually serious . 
got a ticket . 
because uh you know we have the set up here . 
yeah i know you are . 
and and that that has a chance to give us some very interesting fun data . 
so 
if anyone has ideas . 
yeah . 
yeah . 
if you know any groups that are you know 
well i had asked some some of the students at the business school . 
yeah . 
i know . 
student groups like clubs things like that . 
i could 
put a little ad up saying come here and argue . 
not not 
yeah . 
the business school 
if you ' re really angry at someone use our conference room . 
uh the business school might be good . 
i actually spoke with some students up there . 
oh okay . 
and they they they expressed willingness back when they thought they would be doing more stuff with speech . 
really ? 
but when they lost interest in speech they also stopped answering my email about other stuff . 
so 
huh 
i 
they could have a discussion about 
or people who are really 
we should probably bleep that out . 
about about tax cuts or something . 
i heard that at cal tech they have a special room 
someone said that they had a special room to get all your frustrations out . 
that you can go to and like throw things and break things . 
so we can like post a 
yeah now that is not actually what we 
that ' s not what we want . 
no not to that extent . 
but um 
well far field mikes can pick up where they threw stuff on the wall . 
yeah . 
yeah but we don ' t want them to throw the far field mikes is the thing . 
that ' s right . 
oh yeah right . 
yeah . 
the 
yeah 
please throw everything in that direction . 
but 
yeah anyway . 
padded cell . 
it ' d be fun to get like a a visit from the 
there was a dorm room at tech that uh someone had coated the walls and the ceiling and uh the floor with mattresses . 
huh 
the entire room . 
i had as my fourth thing here processing of wave forms . 
yeah . 
what did we mean by that ? 
uh liz wanted to talk about methods of improving accuracy by doing pre processing . 
remember ? 
pre processing . 
well i think that that was just sort of 
i already asked thilo . 
oh . 
you already did that . 
but that um it would be helpful if i can stay in the loop somehow with um people who are doing any kind of post processing . 
whether it ' s to separate speakers or to improve the signal to noise ratio or both . 
um that we can sort of try out as we ' re running recognition . 
um so is that who else is 
i guess dan ellis and you 
dan . 
yeah . 
yep . 
yeah and dave uh gelbart again . 
and dave . 
yep . 
yeah . 
okay . 
he ' s he ' s interested in in fact we ' re starting to look at some echo cancellation kind of things . 
okay . 
which uh 
i am not sure how much that ' s an issue with the close talking mikes . 
huh ? 
but who knows ? 
well let ' s isn ' t that what what you want 
i don ' t know . 
i ' m bad . 
no so no what you what you want when you ' re saying improving the wave form you want the close talking microphone to be better . 
it ' s like like 
right . 
right ? 
and the question is to to what extent is it getting hurt by uh by any room acoustics ? 
or is it just uh given that it ' s close it ' s not a problem ? 
uh 
it doesn ' t seem like big room acoustics problems to my ear . 
but i ' m not an expert . 
okay so it ' s 
it seems like a problem with cross talk . 
i bet with the lapel mike there ' s plenty uh room acoustic . 
yeah . 
but i think the rest is cross talk . 
that that may be true . 
but i don ' t know how good it can get either by those the those methods . 
yeah . 
that ' s true . 
so i i think it ' s just 
okay . 
oh i don ' t know . 
yeah what you said cross talk . 
all i meant is just that as sort of as this pipeline of research is going on we ' re also experimenting with different a s r uh techniques . 
uhhuh . 
and so it ' d be good to know about it . 
so the problem is like uh on the microphone of somebody who ' s not talking they ' re picking up signals from other people and that ' s causing problems ? 
right although if they ' re not talking using the the inhouse transcriptions were sort of okay . 
because the no one transcribed any words there . 
and we throw it out . 
uhhuh . 
but if they ' re talking at all and they ' re not talking the whole time 
so you get some speech and then a uhhuh and some more speech . 
so that whole thing is one chunk . 
and the person in the middle who said only a little bit is picking up the speech around it . 
that ' s where it ' s a big problem . 
you know this does like seem like it would relate to some of what jose ' s been working on as well . 
the encoding of the 
yeah . 
and and he also he was 
the energy . 
yeah . 
right exactly . 
energy . 
i was i was trying to remember you have this interface where you you you showed us one time on your laptop . 
that you you had different visual displays as speech and nonspeech events . 
yeah . 
yeah may i i only display the different colors for the different situation . 
but uh for me and for my problems is uh is enough . 
because uh it ' s possible uh uh in a sample view uh to nnn to compare with with the segment the the kind of assessment . 
what happened with the the different parameters . 
and only with a different bands of color for the uh few situation uh i consider for acoustic event is enough to to 
uhhuh . 
i i i see that uh you are considering now uh a very sophisticated uh um uh set of uh graphic uh uh um symbols to to transcribe . 
no ? 
oh i uhhuh 
because uh before you you are talking about the the possibility to include in the transcriber program uh um a set of symbols of graphic symbol to to mark the different situations during the transcription . 
during the transcription . 
no ? 
well you ' re saying so uh symbols for differences between laugh and sigh and and and slam the door and stuff ? 
yeah . 
or some other kind of thing ? 
yeah yeah the the symbols you you talk of before . 
no ? 
to to mark 
well i wouldn ' t say symbols so much . 
the the main change that i that i see in the interface is is just that we ' ll be able to more finely uh time things . 
yeah . 
yeah . 
but i i also there was another aspect of your work that i was thinking about when i was talking to you . 
which is that it sounded to me liz as though you 
huh 
and uh maybe i didn ' t understand this . 
but it sounded to me as though part of the analysis that you ' re doing involves taking segments which are of a particular type and putting them together . 
and so if you have like a a you know speech from one speaker then you cut out the part that ' s not that speaker . 
yeah . 
uhhuh . 
and you combine segments from that same speaker to and run them through the recognizer . 
is that right ? 
well we try to find as close of start and end time of as we can to the speech from an individual speaker . 
uhhuh . 
because then we we ' re more guaranteed that the recognizer will 
for the forced alignment which is just to give us the time boundaries . 
because from those time boundaries then the plan is to compute prosodic features . 
uhhuh . 
and the sort of more space you have that isn ' t the thing you ' re trying to align the more errors we have . 
uhhuh . 
um so you know that that it would help to have either pre processing of a signal that creates very good signal to noise ratio 
because 
okay . 
which i don ' t know how possible this is for the lapel . 
um or to have very to have closer um time you know synch times basically around the speech . 
that gets transcribed in it or both . 
and it ' s just sort of a open world right now of exploring that . 
so i just wanted to see you know on the transcribing end from here things look good . 
uh the i b m one is more it ' s an open question right now . 
and then the issue of like global processing of some signal . 
and then you know before we chop it up is is yet another way we can improve things in that . 
what about increasing the flexibility of the alignment ? 
okay . 
do you remember that thing that michael finka did ? 
that experiment he did a while back ? 
uhhuh . 
right you can um 
uh 
the problem is just that the acoustic 
when the signal to noise ratio is too low um you you ' ll get uh an alignment with the wrong duration pattern . 
oh so that ' s the problem is the the signal to noise ratio . 
or it 
yeah it ' s not the fact that you have like 
i mean what he did is allow you to have uh words that were in another segment move over to the at the edges of of segmentations . 
uhhuh . 
or even words inserted that weren ' t weren ' t there . 
right things things near the boundaries where if you got your alignment wrong 
uhhuh . 
because what they had done there is align and then chop . 
uhhuh . 
um and this problem is a little bit more global . 
it ' s that there are problems even inside the alignments . 
uh because of the fact that there ' s enough acoustic signal there for the recognizer to to eat as part of a word . 
and it tends to do that . 
yeah . 
so uh 
but we probably will have to do something like that in addition . 
anyway so yeah bottom bottom line is just i wanted to make sure i can be aware of whoever ' s working on these signal processing techniques for uh detecting energies . 
yeah . 
because that that ' ll really help us . 
okay . 
uh 
tea has started out there i suggest we run through our digits . 
and 
okay . 
uh 
so 
okay we ' re done . 
i guess . 
okay we ' re on . 
so just make sure that your wireless mike is on if you ' re wearing a wireless . 
check one . 
check one . 
and you should be able to see which one which one you ' re on by uh watching the little bars change . 
so which is my bar ? 
mah 
number one . 
yep . 
sibilance . 
sibilance . 
so actually if you guys want to go ahead and read digits now as long as you ' ve signed the consent form that ' s all right . 
are we supposed to read digits at the same time ? 
no . 
oh okay . 
no . 
each individually . 
we ' re talking about doing all at the same time . 
but i think cognitively that would be really difficult to try to read them while everyone else is . 
everyone would need extreme focus . 
so when you ' re reading the digit strings the first thing to do is just say which transcript you ' re on . 
other way . 
we we may wind up with we we may need versions of all this garbage . 
for our stuff . 
yeah . 
yeah . 
um so the first thing you ' d want to do is just say which transcript you ' re on . 
yeah . 
so 
you can see the transcript . 
there ' s two large number strings on the digits . 
so you would just read that one . 
and then you read each line with a small pause between the lines . 
and the pause is just so the person transcribing it can tell where one line ends and the other begins . 
and i ' ll give i ' ll read the digit strings first so can see how that goes . 
um 
again i ' m not sure how much i should talk about stuff before everyone ' s here . 
huh . 
well we have one more coming . 
okay . 
well why don ' t i go ahead and read digit strings ? 
and then we can go on from there . 
thanks . 
so uh just also a note on wearing the microphones . 
all of you look like you ' re doing it reasonably correctly . 
but you want it about two thumb widths away from your mouth . 
and then at the corner . 
and that ' s so that you minimize breath sounds . 
so that when you ' re breathing you don ' t breathe into the mike . 
um 
yeah that ' s good . 
and uh 
so everyone needs to fill out only once the speaker form and the consent form . 
and the short form 
i mean you should read the consent form . 
but uh the thing to notice is that we will give you an opportunity to edit all the transcripts . 
so if you say things and you don ' t want them to be released to the general public which these will be available at some point to anyone who wants them uh you ' ll be given an opportunity by email uh to bleep out any portions you don ' t like . 
um 
on the speaker form just fill out as much of the information as you can . 
if you ' re not exactly sure about the region 
we ' re not exactly sure either . 
so don ' t worry too much about it . 
the it ' s just self rating . 
um . 
and i think that ' s about it . 
i mean should i do you want me to talk at all about why we ' re doing this and what this project is ? 
um yeah . 
or 
no there was there was let ' s see . 
does nancy know that we ' re meeting in here ? 
oh 
she got an she was notified . 
i sent an email . 
oh yeah she got an 
yeah yeah . 
whether she knows is another question . 
um 
so are the people going to be identified by name ? 
well what we ' re going to we ' ll anonymize it in the transcript . 
right . 
um but not in the audio . 
okay . 
so then in terms of people worrying about uh excising things from the transcript it ' s unlikely . 
so 
since it it isn ' t attributed . 
oh i see . 
but the but the but the 
right so if i said oh hi jerry how are you we ' re not going to go through and cancel out the jerry s . 
yeah . 
sure . 
um so we will go through and in the speaker i . d . tags there ' ll be you know m . one o . seven m . one o . eight . 
right . 
right . 
um but uh 
um it uh 
i don ' t know a good way of doing it on the audio and still have people who are doing discourse research be able to use the data . 
okay . 
uhhuh . 
no i i wasn ' t complaining . 
i just wanted to understand . 
yep . 
right . 
okay . 
well we can make up aliases for each of us . 
yeah i mean whatever you want to do is fine . 
right . 
okay . 
but we find that 
we want the meeting to be as natural as possible . 
okay . 
so we ' re trying to do real meetings . 
and so we don ' t want to have to do aliases . 
right . 
and we don ' t want people to be editing what they say . 
right . 
right . 
so i think that it ' s better just as a post process to edit out every time you bash microsoft . 
uhhuh . 
you know . 
right . 
um okay so why don ' t you tell us briefly 
your give give your normal schpiel . 
okay . 
so 
um so this is the project is called meeting recorder . 
and there are lots of different aspects of the project . 
um so my particular interest is in the p . d . a . of the future . 
this is a mock up of one . 
yes we do believe the p . d . a . of the future will be made of wood . 
um the idea is that you ' d be able to put a p . d . a . at the table at an impromptu meeting . 
and record it . 
and then be able to do querying and retrieval later on on the meeting . 
so that ' s my particular interest . 
is a portable device to do uh information retrieval on meetings . 
other people are interested in other aspects of meetings . 
um so the first step on that in any of these is to collect some data . 
and so what we wanted is a room that ' s instrumented with both the table top microphones . 
and these are very high quality pressure zone mikes . 
as well as the close talking mikes . 
what the close talking mikes gives us is some ground truth . 
gives us um high quality audio . 
um especially for people who aren ' t interested in the acoustic parts of this corpus . 
so for people who are more interested in language we didn ' t want to penalize them by having only the far field mikes available . 
and then also um it ' s a very very hard task in terms of speech recognition . 
um and so uh on the far field mikes we can expect very low recognition results . 
so we wanted the near field mikes to at least isolate the difference between the two . 
so that ' s why we ' re recording in parallel with the close talking and the far field at the same time . 
and then all these channels are recorded simultaneously and framed synchronously . 
so that you can also do things like um beam forming on all the microphones . 
and do research like that . 
our intention is to release this data to the public um probably through through a body like the l . d . c . 
and uh just make it as a generally available corpus . 
um there ' s other work going on in meeting recording . 
so we ' re we ' re working with s . r . i . 
with u . w . 
um nist has started an effort which will include video . 
we ' re not including video obviously . 
and uh and then also um a small amount of assistance from i . b . m . 
is also involved . 
um oh and the digit strings this is just a more constrained task . 
um so because the general environment is so challenging we decided to to do at least one set of digit strings . 
to give ourselves something easier . 
and it ' s exactly the same digit strings as in t . i . digits . 
which is a common connected digits corpus . 
so we ' ll have some um comparison to be able to be made . 
okay . 
anything else ? 
no . 
okay so when the last person comes in just have them wear a wireless . 
it should be on already . 
um 
either one of those . 
and uh read the digit strings and and fill out the forms . 
so the most important form is the consent form . 
so just be be sure everyone signs that if they consent . 
i ' m sure it ' s pretty usual for meetings that people come late . 
so you will have to leave what you set . 
yeah . 
right . 
and uh just give me a call . 
which my number ' s up there when your meeting is over . 
yep . 
and i ' m going to leave the mike here . 
but it ' s uh but i ' m not going to be on . 
so don ' t have them use this one . 
it ' ll just be sitting here . 
input ? 
yeah . 
there we go . 
by the way adam we will be using the uh screen as well . 
yep . 
so you know . 
wow ! 
organization . 
so you guys who got email about this oh uh friday or something about what we ' re up to . 
no . 
no . 
i got it . 
what was the nature of the email ? 
oh this was about um inferring intentions from features in context and the words . 
like go to see or visit or 
i uh i i 
you didn ' t get it ? 
i don ' t think i did . 
i guess these have got better filters . 
because i sent it to everybody . 
you just blew it off . 
uh . 
okay . 
it ' s really simple though . 
so this is the idea . 
um 
we could pursue um if we thought it ' s it ' s worth it but uh i think we we will agree on that um to come up with a with a sort of very very first crude prototype . 
and do some implementation work and do some some research and some modeling . 
so the idea is if you want to go somewhere 
um and 
focus on that object down 
oh i can actually walk with this . 
this is nice . 
down here . 
that ' s the powder tower . 
now um we found in our uh data and from experiments that there ' s three things you can do . 
um you can walk this way and come really really close to it . 
and touch it . 
but you cannot enter or do anything else . 
unless you ' re interested in rock climbing it won ' t do you no good standing there . 
it ' s just a dark alley . 
but you can touch it . 
if you want to actually go up or into the tower you have to go this way . 
and then through some buildings and up some stairs and so forth . 
if you actually want to see the tower and that ' s what actually most people want to do is just have a good look of it take a picture for the family you have to go this way and go up here . 
and there you have a really view it exploded the during the thirty . 
really uh interesting sight . 
huh . 
and um these uh these lines are um paths . 
or that ' s uh 
the street network of our geographic information system . 
and you can tell that we deliberately cut out this part . 
because otherwise we couldn ' t get our g . i . s . system to take to lead people this way . 
it would always use the closest point to the object . 
and then the tourists would be faced you know in front of a wall . 
but it would do them absolutely no good . 
so what we found interesting is first of all intentions differ . 
maybe you want to enter a building . 
maybe you want to see it . 
take a picture of it . 
or maybe you actually want to come as close as possible to the building . 
for whatever reason that may be . 
what ' s it what ' s it made out of ? 
um red limestone . 
so maybe you would want to touch it . 
yeah maybe you would want to touch it . 
um 
okay i this um these intentions we we could if we want to call it the the vista mode . 
where we just want to uh get the overview or look at it . 
the enter mode . 
and the well tango mode . 
i always come up with with silly names . 
so this tango means literally translated to touch . 
so but sometimes the the tango mode is really relevant in the in the sense that um if you want to uh 
if you don ' t have the intention of entering your building but you know that something is really close to it and you just want to approach it or get to that building 
consider for example the post office in chicago a building so large that it has its own zip code . 
so the entrance could be miles away from the closest point . 
so sometimes it makes sense maybe to to distinguish there . 
so um i ' ve looked uh through twenty some 
uh i didn ' t look through all the data . 
um and there there ' s uh a lot more different ways in people uh the ways people phrase how to get if they want to get to a certain place . 
and sometimes here it ' s it ' s a little bit more obvious . 
um maybe i should go back a couple of steps . 
and go through the 
no okay come in sit down . 
if you grab yourself a microphone . 
you need to sign some stuff and read some digits . 
well you can sign afterwards . 
or later . 
you have to also have to read some digits . 
afterwards . 
okay afterwards is fine . 
they are uncomfortable . 
uhhuh . 
really small ? 
okay i see . 
okay . 
yep . 
thank you . 
okay but that was our idea . 
and it it it it also has to be switched on nance . 
is 
no that one ' s already on i thought he said . 
i i think 
it ' s on ? 
okay good . 
yeah . 
okay it ' s on . 
okay that was the idea . 
um people when they when they want to go to a building sometimes they just want to look at it . 
sometimes they want to enter it . 
and sometimes they want to get really close to it . 
that ' s something we found . 
it ' s just a truism . 
and the places where you will lead them for these intentions are sometimes incredibly different . 
i i gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . 
so this is sort of how people may uh may phrase those requests to a a a mock up system at least that ' s the way they did it . 
and we get tons of of these how do i get to i want to go to . 
but also give me directions to and i would like to see . 
and um what we can sort of do if we look closer closer at the the data 
that was the wrong one . 
um we can look at some factors that may make a difference . 
first of all 
very important . 
and um that i ' ve completely forgot that when we talked . 
this is of course a crucial factor what type of object is it . 
so some buildings you just don ' t want to take pictures of . 
or very rarely . 
but you usually want to enter them . 
some objects are more picturesque . 
and you more more highly photographed . 
then of course the the actual phrases may give us some idea of what the person wants . 
um sometimes i found in the uh looking at the data in a superficial way i found some sort of modifiers that that may also give us a hint . 
um i ' m trying to get to . 
nuh ? 
i need to get to . 
sort of hints to the fact that you ' re not really sightseeing and and just there for pleasure and so forth and so on . 
and this leads us straight to the context which also should be considered . 
that whatever it is you ' re doing at the moment may also influence the interpretation of of a phrase . 
so this is uh really 
uh uh uh 
my suggestion is really simple . 
we start with um 
now let me uh say one more thing . 
what we do know is that the parser we use in the smartkom system will never differentiate between any of these . 
so basically all of these things will result in the same x . m . l . m . three l . structure . 
sort of action go . 
and then an object . 
uhhuh . 
yeah ? 
and a source . 
so it ' s it ' s it ' s way too crude to capture those differences in intentions . 
so i thought huh . 
maybe for a deep understanding task that ' s a nice sort of playground or first little thing . 
where we can start it and sort of look 
okay we need we going to get those m . three l . structures . 
the crude undifferentiated parse . 
interpreted input . 
we may need additional part of speech or maybe just some information on the verb and modifiers auxiliaries . 
we ' ll see . 
and i will try to to sort of come up with a list of factors that we need to get out of there . 
and maybe we want to get a switch for the context . 
so this is not something which we can actually monitor now . 
but just is something we can set . 
and then you can all imagine sort of a a constrained satisfaction program depending on on what um comes out . 
we want to have an a structure resulting 
if we feed it through a belief net or or something along those lines we ' d get an inferred intention we we produce a structure that differentiates between the vista the enter and the um tango mode . 
which i think we maybe want to ignore . 
but that ' s my idea . 
it ' s up for discussion . 
we can change all of it . 
any bit of it . 
throw it all away . 
now this email that you sent actually . 
what ? 
now i remember the email . 
okay . 
huh . 
still i have no recollection whatsoever of the email . 
i ' ll have to go back and check . 
not important . 
so what is important is that we understand what the proposed task is . 
and the the uh robert and i talked about this some on friday . 
and we think it ' s well formed . 
so we think it ' s a well formed uh starter task for this uh deeper understanding in the tourist domain . 
so where exactly is the uh deeper understanding being done ? 
like i mean is it before the bayes - net ? 
is it uh 
well it ' s the it ' s it ' s always all of it . 
so in general it ' s always going to be the answer is everywhere . 
uh so the notion is that uh this isn ' t real deep . 
but it ' s deep enough that you can distinguish between these three quite different kinds of uh going to see some tourist thing . 
and so that ' s that ' s the quote deep that we ' re trying to get at . 
and robert ' s point is that the current front end doesn ' t give you any way to 
not only doesn ' t it do it but it also doesn ' t give you enough information to do it . 
it isn ' t like if you just took what the front end gives you and used some clever inference algorithm on it you would be able to figure out which of these is going on . 
so uh 
and this is in general it ' s going to be true of any kind of deep understanding . 
there ' s going to be contextual things . 
there ' re going to be linguistic things . 
there ' re going to be discourse things . 
and they got to be combined . 
and my idea on how to combine them is with a belief net . 
although it may turn out that some totally different thing is going to work better . 
um the idea would be that you uh take your 
you ' re editing your slide ? 
yeah as sort of as i get ideas . 
uh uh 
oh . 
so discourse i i i thought about that . 
of course that needs to sort of go in there . 
oh i ' m sorry . 
okay so this is minutes taking minutes as we go . 
in his in his own way . 
yep . 
um but the the 
anyway so the thing is uh naively speaking you ' ve you ' ve got a for this little task a belief net . 
which is going to have as output the conditional probability of one of three things . 
that the person wants to uh to view it to enter it or to tango with it . 
um 
so that the the output of the belief net is pretty well formed . 
and then the inputs are going to be these kinds of things . 
and then the question is 
there are two questions . 
is uh one where do you get this information from ? 
and two what ' s the structure of the belief net ? 
so what are the conditional probabilities of this that and the other given these things ? 
and you probably need intermediate nodes . 
i we don ' t know what they are yet . 
so it may well be that uh for example that uh knowing whether 
oh another thing you want is some information i think about the time of day . 
now they may want to call that part of context . 
but the time of day matters a lot . 
uhhuh . 
and if things are obviously closed then you 
people won ' t want to enter it . 
people don ' t want to enter them . 
and if it ' s not obvious you may want to actually uh point out to people that it ' s closed you know what they ' re going to is closed and they don ' t have the option of entering it . 
so another thing that can come up and will come up as soon as you get serious about this is that another option of course is to have a more of a dialogue . 
so if someone says something you could ask them . 
yeah . 
okay . 
and now one thing you could do is always ask them . 
but that ' s boring . 
and it also it also be a pain for the person using it . 
so one thing you could do is build a little system that said whenever you got a question like that i ' ve got one of three answers . 
ask them which one you want . 
okay . 
but that ' s um not what we ' re going to do . 
but maybe that ' s a false state of the system that it ' s too close to call . 
oh yeah . 
you want the you want the ability to you want the ability to ask . 
but what you don ' t want to do is build a system that always asks every time . 
and 
that ' s not getting at the scientific problem . 
and it ' s 
uhhuh . 
in general you ' re you know it ' s going to be much more complex than that . 
this is purposely a really simple case . 
yeah . 
so uh 
yeah . 
i have one more point to to bhaskara ' s question . 
um i think also the the the deep understanding part of it is is going to be in there to the extent that we um want it in terms of our modeling . 
we can start you know basic from human beings . 
model that . 
its motions . 
going walking seeing . 
we can model all of that . 
and then compose whatever inferences we make out of these really conceptual primitives . 
that will be extremely deep in the in in in my understanding . 
yeah so so the way that might come up if you want to suppose you wanted to do that you might say um as an intermediate step in your belief net is there a source path goal schema involved ? 
okay ? 
and if so uh is there a focus on the goal ? 
or is there a focus on the path ? 
or something . 
and that could be uh one of the 
you know the in some piece of the belief net that could be the the appropriate thing to enter . 
so where would we extract that information from ? 
from the m . three l . . 
no . 
no see the m . three l . is not going to give 
what he was saying is the m . three l . does not have any of that . 
all it has is some really crude stuff saying a person wants to go to a place . 
right . 
the m . three l . is the old smartkom output . 
right . 
okay . 
m . well m . three l . itself refers to multimedia markup language . 
it ' s just a language . 
right yeah . 
so we have we we have to have a better way of referring to 
the parser output ? 
uhhuh . 
yeah . 
analyzed speech i think it ' s what they call it . 
the 
well okay . 
really oder 
yeah . 
no actually intention lattices is what we ' re going to get . 
but they they call it intention lattice . 
but 
intention lattice hypothesis . 
anyway 
they call it intention hypotheses . 
right . 
so they ' re going to give us some uh or we can assume that you get this crude information . 
about intention . 
and that ' s all they ' re going to provide . 
and they don ' t give you the kind of object . 
they don ' t give you any discourse history . 
if you want to keep that you have to keep it somewhere else . 
well they keep it . 
we have to request it . 
right . 
nuh ? 
but it ' s not in there . 
well they they they keep it by their lights . 
it may it may or may not be what what we want . 
huh . 
yeah or 
yeah . 
so if someone says i want to touch the side of the powder tower that would basically we need to pop up tango mode and the and the directions ? 
if if yeah if it got as simple as that yeah . 
yeah . 
but it wouldn ' t . 
okay . 
but that doesn ' t necessarily 
but we ' d have to infer a source path goal to some degree for touching the side right ? 
well uh there is a a point there if i understand you correct . 
um 
because um sometimes people just say things . 
this you find very often . 
where is the city hall . 
and this they don ' t want to see it on a map . 
or they don ' t want to know it ' s five hundred yards away from you or that it ' s to the your north . 
they want to go there . 
that ' s what they say is where is it . 
where is that damn thing . 
and the parser would output 
well that ' s a a question mark . 
a lot of parsers um 
just uh 
that ' s way beyond their scope is of interpreting that . 
you know . 
but um 
still outcome the outcome will be some form of structure . 
with the town hall and maybe saying it ' s a w . h . focus on the town hall . 
but to interpret it 
uhhuh . 
you know . 
somebody else has to do that job later . 
i ' m just trying to figure out what the smartkom system would output . 
yeah . 
depending on these things . 
um it will probably tell you how far away it is . 
at least that ' s that ' s even what deep map does . 
it tells you how far away it is . 
and and shows it to you on a map . 
because we can not differentiate at the moment between you know the intention of wanting to go there or the intention of just wanting to know where where it is . 
people might not be able to infer that either right ? 
like the fact like i could imagine if someone came up to me and asked where ' s the city hall i might say are you trying to get there . 
because how i describe um its location uh probably depend on whether i think i should give them you know directions now or say you know whatever it ' s half a mile away or something like that . 
uhhuh . 
it ' s a granularity factor . 
yeah . 
because where people ask you where is new york you will tell them it ' s on the east coast . 
uhhuh . 
yeah exactly . 
right . 
uh you won ' t tell them how to get there you know take that bus to the airport and blah blah blah . 
right . 
yeah . 
right . 
but if it ' s the post office you will tell them how to get there . 
uhhuh . 
so they have done some interesting experiments on that in hamburg as well . 
right . 
right . 
so 
but 
go go back to the the uh 
yeah that slide . 
so i this is onto is is knowledge about buildings . 
their opening times . 
and then coupled with time of day um this should 
you know . 
so that context was like um their presumed purpose context . 
like business or travel . 
as well as the utterance context like i ' m now standing at this place at this time . 
yeah well i think we ought to as we have all along we we ' ve been distinguishing between situational context . 
which is what you have as context . 
and discourse context . 
uhhuh . 
which you have as d . h . 
i don ' t know what the h . means . 
nuh . 
history . 
discourse history . 
okay . 
whatever . 
yeah . 
so we can work out terminology later . 
yep . 
so they ' re they ' re quite distinct . 
i mean you need them both . 
but they ' re quite distinct . 
and so what we were talking about doing as a first shot is not doing any of the linguistics . 
except to find out what seems to be useful . 
so the the the reason the belief net is in blue is the notion would be 
uh this may be a bad bad idea . 
but the idea is to take as a first goal see if we could actually build a belief net that would make this three way distinction uh in a plausible way . 
given 
these we have all these transcripts . 
and we ' re able to by hand extract the features to put in the belief net . 
saying aha . 
here are the things which if you get them out of out of the language and discourse and put them into the belief net it would tell you which of these three uh intentions is most likely . 
and if to actually do that build it um you know run it run it on the data where you hand transcribe the parameters . 
and see how that goes . 
if that goes well then we can start worrying about how we would extract them . 
so where would you get this information ? 
and expand it to to other things like this . 
but if we can ' t do that then we ' re in trouble . 
i mean if you can ' t do this task 
um 
we need a different uh engine . 
uh uh yeah or something . 
machine i mean . 
well it if it if it ' s the belief nets we ' ll switch to you know logic or some terrible thing . 
but i don ' t think that ' s going to be the case . 
i think that uh if we can get the information a belief net is a perfectly good way of doing the inferential combination of it . 
the real issue is what are the factors involved in determining this ? 
and i don ' t know . 
huh . 
but only 
hold on a hold on a second . 
muh 
so i know . 
uh uh is it clear what ' s going on here ? 
yep . 
um i missed the beginning . 
but um 
i guess 
could you back to the slide ? 
the previous one . 
so is it that it ' s um 
these are all factors that uh these are the ones that you said that we are going to ignore now ? 
or that we want to take into account ? 
you were saying 
take them into account . 
take the the linguistic factors too . 
but but you don ' t worry about 
oh how to extract these features . 
how to extract them . 
okay . 
so let ' s find out which ones we need first . 
got it . 
okay . 
and and it ' s clear from the data um like sort of the correct answer in each case . 
and 
no . 
but 
okay . 
no . 
that ' s that ' s the thing i ' m curious 
but 
let ' s go back to let ' s go back to the the the slide of data . 
like do we know from the data which 
um 
okay . 
so 
not from that data . 
but um since we are designing a a a an compared to this even bigger data collection effort um we will definitely take care to put it in there . 
uhhuh . 
uhhuh . 
uhhuh . 
in some shape way form over the other . 
yeah . 
to see whether we can then get sort of empirically validated data . 
right . 
um from this we can sometimes you know 
and that ' s that but that isn ' t that what we need for a belief net anyhow ? 
is sort of 
sometimes when people want to just see it they phrase it more like this . 
uhhuh . 
but it doesn ' t exclude anybody from phrasing it totally differently even if they still 
right . 
right . 
you know ? 
but then other factors may come into play that change the outcome of their belief net . 
right . 
so um this is exactly what 
because you can never be sure . 
and i ' m sure even the most sort of deliberate data collection experiment will never give you data that say well if it ' s phrased like that the intention is this . 
sure . 
you know because then uh you 
i mean the only way you could get that is if you were to give the subjects a task . 
right ? 
where you have where your uh current goal is to 
yeah . 
that ' s what we ' re doing . 
so that ' s what you want ? 
but but we will still get the phrasing all over the place . 
okay . 
so you will know . 
uhhuh . 
i ' m sure that you know 
yeah . 
the no that ' s fine . 
i guess it ' s just knowing the intention from the experimental subject . 
yeah . 
uhhuh . 
from that task yeah . 
so uh i think you all know this but we are going to actually use this little room . 
and start recording subjects probably within a month or something . 
so this is not any any of you guys ' worry . 
except that we may want to push that effort to get information we need . 
so our job is to figure out how to solve these problems . 
if it turns out that we need data of a certain sort then the sort of data collection branch can be uh asked to do that . 
and one of the reasons why we ' re recording the meeting for these guys is because we want their help when we we start doing uh recording of subjects . 
so yeah you ' re absolutely right though . 
no you you will not have 
and there it is . 
and uh 
but you know 
the um 
and i think the other concern that has come up before too is if it ' s 
um 
i don ' t know if this was collected what situation this data was collected in . 
was it is it the one that you showed in your talk ? 
like people 
no no . 
but 
no . 
okay . 
so was this like someone actually mobile like using a device ? 
uh 
no not 
it was mobile . 
but not not with a a real wizard system . 
so there were never answers . 
uhhuh . 
okay okay . 
but is it 
i guess i don ' t know the situation of of collecting the data . 
of like here you could imagine them being walking around the city as like one situation . 
and then you have all sorts of other situational context factors that would influence how to interpret like you said the scope and things like that . 
uhhuh . 
if they ' re doing it in a 
you know i ' m sitting here with a map and asking questions . 
i i would imagine that the data would be really different . 
um so it ' s just 
yeah . 
but it was never the goal of that data collection to to serve for for such a purpose . 
so that ' s why for example the tasks were not differentiated by intentionality . 
uhhuh . 
there was there was no label . 
uhhuh . 
right . 
you know intention a . intention b . intention c . . 
or task a . b . c . . 
um 
i ' m sure we can produce some if we need it . 
uhhuh . 
um that that will help us along those lines . 
but you know you got to leave something for other people to model . 
so to finding out what you know situational what the contextual factors of the situation really are you know is an interesting interesting thing . 
uhhuh . 
uhhuh . 
sort of i ' m at the moment curious and i ' m i ' m want to approach it from the end where we can sort of start with this toy system that we can play around with . 
uhhuh . 
so that we get a clearer notion of what input we need for that . 
uhhuh . 
what suffices and what doesn ' t . 
and then we can start worrying about where to get this input . 
what what do we need you know ? 
ultimately once we are all experts in changing that parser for example maybe there ' s just a couple three things we need to do . 
and then we get more whatever part of speech and more construction type like stuff out of it . 
uhhuh . 
huh . 
it ' s a pragmatic approach uh at the moment . 
how exactly does the data collection work ? 
do they have a map ? 
and then you give them a scenario of some sort . 
okay . 
imagine you ' re the the subject . 
you ' re going to be in here . 
and somebody 
and and you see uh either the three d . model or uh a quicktime animation of standing in a square in heidelberg . 
so you actually see that . 
um the uh 
um first thing is you have to read a text about heidelberg . 
so just off a textbook uh tourist guide to familiarize uh yourself with that sort of odd sounding german street names like fischergasse and so forth . 
so that ' s part one . 
part two is you ' re told that this huge new wonderful computer system exists that can tell you everything you want to know . 
and it understands you completely . 
and so you ' re going to pick up that phone . 
dial a number . 
and you get a certain amount of tasks that you have to solve . 
first you have to know find out how to get to that place . 
maybe with the intention of buying stamps in there . 
maybe so the next task is to get to a certain place and take a picture for your grandchild . 
the third one is to get information on the history of an object . 
the fourth one 
and then the system breaks down . 
it crashes . 
at the third ? 
and 
right then . 
after the third task . 
okay . 
and then 
or after the fourth . 
some find forget that for now . 
and then a human operator comes on and and apologizes that the system has crashed . 
but you know urges you to continue you know ? 
now with a human operator . 
and so you have basically the same tasks again . 
just with different objects . 
and you go through it again . 
and that was it . 
oh and one one little bit . 
and uh the computer you are you are being told the computer system knows exactly where you are via g . p . s . 
when the human operator comes on um that person does not know . 
so the g . p . s . is crashed as well . 
so the person first has to ask you where are you . 
and so you have to do some tell the person sort of where you are depending on what you see there . 
um this is a a a a a bit that i i don ' t think we 
did we discuss that bit ? 
uh i just sort of squeezed that in now . 
but it ' s something uh that would provide some very interesting data for some people i know . 
so 
so in the display you can oh you said that you you might have a display that shows like the 
yeah . 
additionally you have a a a sort of a map type display . 
a your perspective sort of ? 
and so as you 
uh two d . . 
oh two d . . 
okay . 
two d . . 
so as you move through it they just track it on the for themselves . 
yeah . 
you don ' t 
there . 
that ' s 
i don ' t know . 
i but i don ' t think you really move . 
okay . 
sort of . 
so 
yeah ? 
i mean that would be an an an enormous technical effort . 
unless we would 
we can show it walks to you know . 
we can have movies of walking . 
you walking through through heidelberg and ultimately arriving there . 
uhhuh . 
maybe we want to do that . 
yeah . 
uh i was just trying to figure out how how ambitious the system is . 
the map was sort of intended to 
you want to go to that place . 
uhhuh . 
you know and it ' s sort of there . 
and you see the label of the name . 
so we get those names pronunciation stuff and so forth . 
uhhuh . 
and we can change that . 
uhhuh . 
so your tasks don ' t require you to 
i mean uh you ' re told so when your task is i don ' t know go buy stamps or something like that . 
so do you have to respond ? 
or does your 
uh what are you what are you supposed to be telling the system ? 
like 
what you ' re doing now ? 
or 
well we ' ll see what people do . 
there ' s no 
okay so it ' s just like let ' s figure out what they would say under the circumstances . 
yeah and and we will record both sides . 
i mean we will record the the wizard . 
uhhuh . 
uhhuh . 
i mean in both cases it ' s going to be a human in the computer and in the operator case . 
and we will there will be some dialogue you know . 
so you first have to do this and that . 
yep . 
and and 
uhhuh . 
see what they say . 
we can instruct the uh wizard in how expressive and talkative he should be . 
but um 
maybe the maybe what you ' re suggesting 
is what you ' re suggesting that it might be too poor the data if we sort of limit it to this ping pong one uh task results in a question and then there ' s an answer and that ' s the end of the task ? 
you want to have it more more steps sort of . 
yeah i i don ' t know how much direction is given to the subject about what their interaction 
i mean they ' re unfamiliar with interacting with the system . 
all they know is it ' s this great system that could do stuff . 
uhhuh . 
uhhuh . 
oh yeah but to some extent this is a different discussion . 
right ? 
so 
okay ? 
so uh we we have to have this discussion of the experiment and the data collection and all that sort of stuff . 
uhhuh . 
and we do have um a student who is a candidate for wizard . 
uh she ' s going to get in touch with me . 
it ' s a student of eve ' s . 
f . e . y . 
fey ? 
spelled f . e . y . 
do you do you 
oh fey parrill . 
you know her ? 
yeah . 
uhhuh . 
okay . 
is 
she started taking the class last year . 
and then didn ' t um you know didn ' t continue . 
i she ' s a 
is she an 
she ' s graduated . 
she is a graduate okay . 
yeah . 
yeah i i know her very very briefly . 
i know she was you know interested in aspect and stuff like that . 
okay . 
so anyway she ' s looking for some more part time work while she ' s waiting actually for graduate school . 
and she ' ll be in touch . 
so we may have someone uh to do this . 
and she ' s got you know some background in in all this stuff . 
and is a linguist 
and so 
so that ' s so nancy we ' ll have at some point we ' ll have another discussion on exactly you know how that ' s going to go . 
uhhuh . 
and um jane but also uh liz have offered to help us do this uh data collection and design and stuff . 
uhhuh . 
huh . 
so when we get to that we ' ll have some people doing it that know what they ' re doing . 
okay . 
i guess the reason i was asking about the sort of the the details of this kind of thing is that um it ' s one thing to collect data for i don ' t know speech recognition or various other tasks that have pretty clear correct answers . 
but with intention um obviously as you point out there ' s a lot of other factors . 
and i ' m not really sure um how how the question of how to make it a appropriate toy version of that um it ' s it ' s just hard . 
so i mean obviously it ' s a 
yeah uh actually i guess that was my question . 
is the intention implicit in the scenario that ' s given ? 
like do the 
it is if they have these tasks that they ' re supposed to 
yeah i just wasn ' t sure to what level of detail the task was . 
to to give 
yeah . 
uh 
uhhuh . 
right . 
no one is at the moment . 
right . 
okay . 
so that ' s part of what we ' ll have to figure out . 
right . 
uhhuh . 
but uh 
the the problem that i was going to try to focus on today was let ' s suppose by magic you could collect dialogues in which one way or the other you were able to uh figure out both the intention . 
and set the context . 
and know what language was used . 
so let ' s suppose that we can get that kind of data . 
um 
the issue is can we find a way to basically featurize it ? 
so that we get some discrete number of features so that uh when we know the values to all those features or as many as possible we can come up with the best estimate of which of the in this case three little intentions are most likely . 
what are the three intentions ? 
is it to go there to see it and 
to come as close as possible to it . 
the terminology we ' re using is to 
yeah it ' s . 
go back . 
to 
okay . 
to view it . 
okay . 
to enter it . 
now those it seems to me those are you you have no trouble with those being distinct . 
take a picture of it . 
uhhuh . 
you you might well want to be a really rather different place than entering it . 
uhhuh . 
and for an object that ' s at all big uh sort of getting to the nearest part of it uh could be quite different than either of those . 
uhhuh . 
uhhuh . 
uhhuh . 
just sort of 
okay so now i understand the referent of tango mode . 
see i would have thought it was more of a waltz . 
i didn ' t get that before . 
to waltz it ? 
yeah like how close are you going to be ? 
well 
like tango ' s really close . 
yeah because a tango 
yeah . 
well anyway 
all these 
so 
so like the question is how what features can like do you want to try to extract from say the parse or whatever . 
right . 
like the presence of a word or the presence of a certain uh stem or certain construction or whatever 
right . 
is there a construction or the kind of object ? 
or uh anything else that ' s in the it ' s either in the in the the discourse itself or in the context . 
so if it turns out that whatever it is you want to know whether the person ' s uh a tourist or not okay that becomes a feature . 
now how you determine that is another issue . 
but for the current problem it would just be okay if you can be sure that it ' s a tourist versus a businessman versus a native or something uh that would give you a lot of discriminatory power . 
and then just have a little section in your belief net that said pppt . 
though in the short run you ' d set them . 
uhhuh . 
and see how it worked . 
and then in the longer run you would figure out how you could derive them from previous discourse or anything else you knew . 
right . 
so how should what ' s the uh plan ? 
like how should we go about figuring out these 
okay so first of all is 
uh do either of you guys you got a favorite belief net that you ' ve you know played with ? 
javabayes or something . 
oh . 
no not really . 
okay . 
well anyway get one . 
okay so so one of one of the things we want to do is actually uh pick a package . 
doesn ' t matter which one . 
uh presumably one that ' s got good interactive abilities . 
because a lot of what we ' re going to be 
you know we don ' t need the one that ' ll solve massive uh belief nets quickly . 
these are not going to get big in in the foreseeable future . 
but we do want one in which it ' s easy to interact with and uh modify . 
because that ' s a lot of what it ' s going to be is um playing with this . 
and probably one in which it ' s easy to have um what amounts to transcript files . 
so that if if we have all these cases 
okay . 
so we make up cases that have these features . 
okay and then you ' d like to be able to say okay here ' s a bunch of cases 
there ' re even ones that you can do learning . 
okay so you have all their cases and and their results . 
and you have a algorithms to go through and run around trying to set the the probabilities for you . 
um 
probably that ' s not worth it . 
i mean my guess is we aren ' t going to have enough data that ' s good enough to make the these data fitting ones worth it . 
but i don ' t know . 
so i would say you the first task for you two guys is to um pick a package . 
okay and you want to it you know the standard things . 
you want it stable you want it 
yeah . 
and as soon as we have one we can start trying to uh make a first cut at what ' s going on . 
nuh 
but it what i like about it is it ' s very concrete . 
okay we we have a we know what the outcomes are going to be . 
and we have some some data that ' s loose . 
we can use our own intuition . 
and see how hard it is . 
and importantly what intermediate nodes we think we need . 
so it if it turns out that just thinking about the problem you come up with things you really need to you know this is the kind of thing that is you know an intermediate little piece in your belief net that ' d be really interesting . 
uhhuh . 
and it and it may serve as a platform for a person maybe me or whoever who is interested in doing some linguistic analysis . 
i mean we have the framenet group here . 
and we can see what they have found out about those concepts already . 
that are contained in the data . 
um you know to come up with a nice little set of features . 
and um maybe even means of uh extracting them . 
and and that altogether could also be uh become a nice paper that ' s going to be published somewhere if we sit down and write it . 
and um 
when you said javabayes belief net you were talking about ones that run on coffee ? 
or that are in the program language java ? 
no it turns out that there is a uh the new end of java libraries . 
okay and it turns out one called javabayes . 
which is one that fair people around here use a fair amount . 
huh . 
okay . 
i have no idea whether that ' s 
the obvious advantage of that is that you can then relatively easily get all the other java packages for guis or whatever else you might want to do . 
uhhuh . 
so that that ' s i think why a lot of people doing research use that . 
but it may not be . 
i have no idea whether that ' s the best choice . 
and there ' re plenty of people around students in the department who you know live and breathe bayes - nets . 
so uh 
there ' s the tool kit that um kevin murphy has developed . 
right . 
it ' s okay . 
which might be useful too . 
right . 
so yeah kevin would be a good person to start with . 
and it ' s available matlab code . 
nancy knows him well . 
i don ' t know i don ' t know whether you guys have met kevin yet or not . 
uhhuh . 
but uh 
yeah i know him . 
but 
yeah . 
but since we all probably are pretty sure that um the 
for example this the dialogue history is is um producing x . m . l . documents . 
m . three l . of course is x . m . l . 
and the ontology that um uh the student is is constructing for me back in in e . m . l . is in oil and that ' s also in x . m . l . 
and so that ' s where a lot of knowledge about bakeries about hotels about castles and stuff is going to come from . 
uhhuh . 
yeah . 
um so if it has that i . o . capability and if it ' s a java package it will definitely be able we can couple . 
yeah . 
so yeah we ' re sort of committed to x . m . l . as the kind of uh interchange . 
but that ' s you know not a big deal . 
who isn ' t ? 
nuh ? 
so in terms of of interchanging in and out of any module we build it ' ll be x . m . l . 
and if you ' re going off to queries to the ontology for example you ' ll have to deal with its interface . 
but that ' s that ' s fine . 
and um 
all of these things have been built with much bigger projects than this in mind . 
so they they have worked very hard . 
it ' s kind of blackboards and multi wave blackboards . 
and ways of interchanging and registering your 
and so forth . 
so 
that i don ' t think is even worth us worrying about just yet . 
i mean if we can get the core of the thing to work in a way that we ' re comfortable with then we we can get in and out of it with uh x . m . l . um little descriptors . 
i believe . 
i don ' t i don ' t see 
huh . 
yeah yeah i like for example the what you said about the getting input from from just files about where you where you have the data have specified the features and so forth . 
that ' s of course easy also to do with you know x . m . l . 
uh you could have an x . yeah you could make and x . m . l . format for that sure . 
so 
that that 
um 
you know feature value x . m . l . format is probably as good a way as any . 
so it ' s yeah i guess it ' s also worth um while you ' re poking around poke around for x . m . l . packages that um do things you ' d like . 
doesn ' t does smartkom system have such packages ? 
yeah . 
sure . 
the the m . three l . library does that . 
and the question is you you you ' ll have to we ' ll have to 
it ' s also 
that should be we should be able to look at that . 
no . 
the 
what i what sort of came to my mind is was the notion of an idea that if if there are nets that can actually try to set their own um probability factors based on on on on input 
yeah . 
which is in file format . 
if we um get really wild on this we may actually want to use some some corpora that other people made . 
and for example if if they are in in mate then we get x . m . l . documents with discourse annotations 
uhhuh . 
you know from the discourse act down to the phonetic level . 
um michael has a project where you know recognizing discourse acts . 
and he does it all in mate . 
and so they ' re actually annotating data and data and data . 
so if we if we think it ' s worth it one of these days not not with this first prototype but maybe with a second and we have the possibility of of taking input that ' s generated elsewhere and learn from that that ' d be nice . 
right . 
it ' d be nice but but i i i i don ' t want to count on it . 
i mean you can ' t you can ' t run your project based on the speculation that that the data will come . 
no no uh just for 
and you don ' t have to actually design the nets . 
nuh 
just a back door that i i think we should devote 
could happen . 
yeah so in terms of of the um the what the smartkom gives us for m . three l . packages it could be that they ' re fine or it could be eeh . 
you don ' t you know you don ' t really like it . 
so we ' re not we ' re not we ' re not required to use their packages . 
we are required at the end to give them stuff in their format . 
but hey . 
right . 
um 
it ' s uh 
it doesn ' t control what you do you know internally . 
what ' s the time frame for this ? 
two days ? 
huh ? 
two three days . 
yeah i ' d like that this yeah this week to to to have guys uh you know pick the you know belief net package . 
no . 
and tell us what it is and give us a pointer so we can play with it or something . 
sure . 
and then as soon as we have it i think we should start trying to populate it for this problem . 
make a first cut at you know what ' s going on . 
and probably the easiest way to do that is some online way . 
i mean you can figure out whether you want to make it a web site . 
or you know 
uh i i i um okay i 
yeah . 
i was actually more joking with the two or three days . 
okay i wasn ' t . 
so this was was a usual 
um it will take as long as you guys need for that . 
yeah . 
right . 
but um maybe it might be interesting if if the two of you can agree on who ' s going to be the speaker next monday to tell us something about the net you picked . 
and what it does and how it does that . 
well well or both of them speak . 
sure . 
we don ' t care . 
yeah or you can split it up . 
so 
huh . 
so that will be sort of the assignment for next week is to to for slides and whatever net you picked . 
and what it can do and and how far you ' ve gotten . 
well i ' d like to also though uh have a first cut at what the belief net looks like . 
even if it ' s really crude . 
okay ? 
so you know here here are 
so we ' re supposed to about features and whatnot . 
and 
right yeah . 
uhhuh . 
and as i said what i ' d like to do is 
i mean what would be really great is you bring it in if if if we could uh in the meeting say you know here ' s the package . 
here ' s the current one we have . 
uh you know what other ideas do you have . 
and then we can think about this idea of making up the data file . 
of 
uh you know get a a tentative format for it . 
let ' s say x . m . l . that says you know these are the various scenarios we ' ve experienced . 
we can just add to that . 
and there ' ll be this this file of them . 
and when you think you ' ve got a better belief net you just run it against this um this data file . 
so we ' ll be like hand uh doing all the probabilities . 
okay . 
oh yeah until we know more . 
and what ' s the relation to this with changing the table so that the system works in english ? 
okay . 
so this is while you were doing this i received two lovely emails . 
the the full n . t . and the full linux version are there . 
i ' ve downloaded them both . 
and i started to unpack the linux one . 
uh the n . t . one worked fine . 
and i started pack the linux one . 
it told me that i can ' t really unpack it . 
because it contains a future date . 
so this is the time difference between germany . 
i had to wait until one o ' clock this afternoon before i was able to unpack it . 
now um then it will be my job to get this whole thing running both on swede and on this machine . 
and so that we have it . 
and then um hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along 
we i control 
maybe that ' s what i will do next monday . 
is show the state and show the system and show that . 
yeah . 
yeah so the answer johno is that these are at the moment separate . 
uh what one hopes is that when we understand how the analyzer works we can both worry about converting it to english and worry about how it could extract the parameters we need for the belief net . 
i guess my question was more about time frame . 
so we ' re going to do belief nets this week . 
and then 
oh yeah i don ' t know . 
none of this is neither of these projects has got a real tight timeline . 
in the sense that over the next month there ' s a there ' s a deliverable . 
okay . 
okay . 
so uh it ' s in that sense it ' s opportunistic . 
if if you know if we don ' t get any information for these guys for several weeks then we aren ' t going to sit around you know wasting time trying to do the problem or guess what they 
you know just pppt . 
go on and do other things . 
okay . 
yeah but uh but the uh this point is really i think very very valid that ultimately we hope that that both will merge into a harmonious and um wonderful um state . 
where we can not only do the bare necessities i . e . changing the table so it does exactly in english what it does in german but also that we can sort of have the system where we can say okay this is what it usually does . 
and now we add this little thing to it . 
you know . 
whatever 
johno ' s and bhaskara ' s great belief net . 
and we plug it in . 
and then for these certain tasks 
and we know that navigational tasks are going to be a core domain of the new system . 
it all all of a sudden it does much better . 
nuh ? 
because it can produce better answers . 
tell the person as i showed you on this map . 
you know produce either you know a red line that goes to the vista point . 
or a red line that goes to the tango point . 
or red line that goes to the door . 
which would be great . 
so not only can you show that you know something sensible but ultimately if you produce a system like this it takes the person where it wants to go . 
rather than taking him always to the geometric center of a building . 
huh . 
which is what they do now . 
and we even had to take out a bit . 
nancy you missed that part . 
we had to take out a bit of the road work . 
so that it doesn ' t take you to the wall every time . 
oh really ? 
so um 
so this was actually an actual problem that we encountered . 
which nobody have has 
because car navigation systems don ' t really care . 
you know they get you to the beginning of the street . 
some now do the house number . 
huh . 
uhhuh . 
but even that is problematic . 
if you go if you want to drive to the s . a . p . in waldorf 
i ' m sure the same is true of microsoft . 
it takes you to the the address . 
whatever street number blah blah blah 
you are miles away from the entrance . 
yep . 
because the postal address is maybe a mailbox somewhere . 
uhhuh . 
nuh ? 
but the entrance where you actually want to go is somewhere completely different . 
so unless you ' re a mail person you really don ' t want to go there . 
right yeah . 
probably not then . 
because you probably can ' t drop the mail there anyway . 
probably neither not even that . 
yeah . 
clear ? 
okay sounds good . 
the powder tower is made of red limestone . 
i was wondering . 
okay . 
do you want to see a picture ? 
sure . 
sure . 
have to reboot for that though . 
um 
so you two who ' ll be working on this are are you will you be doing well i mean are you supposed to just do it by thinking about the situation ? 
can you use the sample data ? 
is it like 
of course they use the sample data . 
yeah i mean is there more than 
is there a lot of sample data that is beyond what you what you have there ? 
there there ' s more than i showed . 
but um um i think this is sort of um in part my job to look at that . 
and and to see whether there are features in there that can be extracted . 
yeah . 
and to come up with some features that are not you know empirically based on on a real experiment or on on on reality . 
right . 
uhhuh . 
but sort of on your intuition of you know aha . 
uhhuh . 
uhhuh . 
this is maybe a sign for that . 
and this is maybe a sign for this . 
uhhuh . 
uhhuh . 
so yeah later this week we should sort of get together and sort of start thinking about that hopefully . 
talk features . 
yep . 
okay we can end the meeting . 
and call adam . 
and then we want to look at some filthy pictures of heidelberg . 
we can do that as well . 
uh is that okay ? 
well they had they used the ammunition they stored the ammunition in that tower . 
all right . 
and that ' s why when it was hit by uh a cannon ball it exploded . 
it exploded . 
oh . 
that ' s why they call it the powder tower . 
ahh . 
okay . 
i first thought it had something to do with the material . 
that it that ' s why i asked . 
that ' s right okay . 
huh . 
uh 
do we have an agenda ? 
liz liz and andreas can ' t can ' t uh can ' t come . 
i do . 
so they won ' t be here . 
i have agenda . 
did 
and it ' s all me . 
because no one sent me anything else . 
did they send uh the messages to you about the meeting today ? 
i have no idea . 
but i just got it a few minutes ago . 
oh . 
oh . 
right when you were in my office it arrived . 
okay because i checked my mail i didn ' t have anything . 
so does anyone have any agenda items other than me ? 
i actually have one more also which is to talk about the digits . 
uh right so so i i was just going to talk briefly about the n s f i t r . 
uhhuh yeah . 
oh great . 
uh 
and then you have 
can 
i mean i won ' t say much . 
but uh but then uh you said want to talk about digits ? 
i have a short thing about digits . 
and then uh i want to talk a little bit about naming conventions . 
although it ' s unclear whether this is the right place to talk about it . 
so maybe just talk about it very briefly . 
and take the details to the people who for whom it ' s relevant . 
right . 
yeah . 
i could always say something about transcription . 
i ' ve been but but uh well 
well if we yeah we shouldn ' t add things in just to add things in . 
i ' m actually pretty busy today . 
yeah . 
so if we can we 
yeah yeah yeah . 
a short meeting would be fine . 
this does sound like we ' re doing fine . 
yeah . 
that won ' t do . 
so the only thing i want to say about digits is we are pretty much done with the first test set . 
there are probably forms here and there that are marked as having been read that weren ' t really read . 
so i won ' t really know until i go through all the transcriber forms . 
and extract out pieces that are in error . 
so i uh two things . 
the first is what should we do about digits that were misread ? 
my opinion is um we should just throw them out completely . 
and have them read again by someone else . 
you know the grouping is completely random . 
uhhuh . 
so it it ' s perfectly fine to put a a group together again . 
of errors . 
and have them re read 
just to finish out the test set . 
oh by throw them out completely ? 
um the other thing you could do is change the transcript to match what they really said . 
so those are those are the two options . 
uhhuh . 
yeah . 
but there ' s often things where people do false starts . 
i know i ' ve done it where i say say a 
what the transcribers did with that is if they did a correction and they eventually did read the right string you extract the right string . 
oh you ' re talking about where they completely read the wrong string and didn ' t correct it . 
yeah . 
yeah and didn ' t notice . 
uh ! 
yeah . 
which happens in a few places . 
yeah . 
well and and you ' re talking string wise . 
so so 
you ' re not talking about the entire page . 
yeah . 
correct . 
i get it . 
and so the the two options are change the transcript to match what they really said . 
but then but then the transcript isn ' t the aurora test set anymore . 
i don ' t think that really matters . 
because the conditions are so different . 
and that would be a little easier . 
well how many are how how often does that happen ? 
huh five or six times . 
oh so it ' s not very much . 
no it ' s not much at all . 
seems like we should just change the transcripts . 
yeah . 
okay . 
to match . 
yeah it ' s five or six times out of thousands ? 
yeah . 
four thousand . 
four uh four thousand . 
four thousand ? 
yeah . 
it ' s 
yeah i would uh do the easy way . 
yeah . 
okay . 
yeah . 
yeah . 
it it ' s kind of nice 
huh . 
i mean who knows what studies people will be doing on on speaker dependent things ? 
and so i think having having it all 
yeah . 
the speakers who we had is is at least interesting . 
so you um how many digits have been transcribed now ? 
four thousand lines . 
and each line is between one and about ten digits . 
four thousand lines ? 
i didn ' t i didn ' t compute the average . 
i think the average was around four or five . 
so that ' s a couple hours of of uh speech probably . 
wow . 
yep . 
yep . 
which is a yeah reasonable reasonable test set . 
uhhuh . 
uhhuh . 
and jane i do have a set of forms which i think you have copies of somewhere . 
uhhuh yeah true . 
oh you do ? 
uhhuh uhhuh . 
oh okay good good . 
yeah i was just 
i thought i had had all of them back from you . 
no not yet . 
and then the other thing is that uh the forms in front of us here that we ' re going to read later were suggested by liz . 
because she wanted to elicit some different prosodics from digits . 
uhhuh . 
uhhuh . 
and so uh i just wanted people to take a quick look at the instructions . 
eight eight two two two nine . 
and the way it worked and see if it makes sense . 
and if anyone has any comments on it . 
i see . 
and the decision here uh was to continue with uh the words rather than the the numerics . 
uh yes . 
although we could switch it back . 
the problem was o and zero . 
although we could switch it back and tell them always to say zero or always to say o . 
oh . 
or neither . 
yeah . 
but it ' s just two thing ways that you can say it . 
uhhuh . 
right ? 
oh . 
sure . 
yeah . 
um um 
that ' s the only thought i have . 
because if you start talking about these you know 
she ' s trying to get at natural groupings . 
right . 
but it there ' s there ' s nothing natural about reading numbers this way . 
i mean if you saw a telephone number you would never see it this way . 
the the problem also is she did want to stick with digits . 
i mean i ' m speaking for her since she ' s not here . 
yeah . 
but um the other problem we were thinking about is if you just put the numerals they might say forty three instead of four three . 
yeah . 
huh ! 
yeah . 
yeah . 
yeah . 
well if there ' s space though between them 
i mean you can 
with when you space them out they don ' t look like uh forty three anymore . 
yeah . 
well she and i were talking about it . 
yeah . 
and she felt that it ' s very very natural to do that sort of chunking . 
she ' s right it ' s it it ' s a different problem . 
i mean it ' s a it ' s a it ' s an interesting problem . 
i mean we ' ve done stuff with numbers before . 
and yeah sometimes people 
if you say three nine eight one sometimes people will say thirty nine eighty one . 
or three hundred three hundred eighty nine one . 
yeah . 
or i don ' t think they ' d say that . 
but 
not very frequently . 
but 
no . 
but they certainly could . 
but 
yeah . 
uh thirty eight ninety one is probably how they ' d do it . 
so i mean this is something that liz and i spoke about . 
but 
and since this was something that liz asked for specifically i think we need to defer to her . 
i see . 
uhhuh . 
yeah . 
okay well we ' re probably going to be collecting meetings for a while . 
and if we decide we still want to do some digits later we might be able to do some different different versions . 
do something different . 
yeah . 
but this is the next suggestion . 
so 
okay . 
okay so uh i guess let me uh get my my short thing out about the n s f . 
i sent this 
actually this is maybe a little side thing . 
um i i sent to what i thought we had uh in some previous mail as the right joint thing to send to . 
it was . 
which was m m t g r c d r hyphen joint . 
joint . 
yep . 
but then i got some sort of funny mail saying that the moderator was going to 
it ' s 
uhhuh . 
that ' s because they set the one up at u w . 
that ' s not on our side that ' s on the u dub side . 
oh . 
and so u u w set it up as a moderated list . 
yeah . 
oh okay . 
and i have no idea whether it actually ever goes to anyone . 
so you might just want to mail to mari . 
no no i got i got uh little excited notes from mari and jeff and so on . 
and 
okay good . 
so it ' s 
yeah . 
so the moderator actually did repost it . 
yeah . 
because i had sent one earlier . 
actually the same thing happened to me i had sent one earlier . 
the message says you ' ll be informed . 
and then i was never informed . 
but i got replies from people indicating that they had gotten it . 
so 
right . 
it ' s just to prevent spam . 
i see . 
yeah so o okay well anyway i guess everybody here are are . 
you are on that list . 
uhhuh . 
right ? 
so you got the note . 
yeah . 
yeah okay . 
um 
so this was uh a uh proposal that we put in . 
before on on more more higher level uh issues in meetings . 
from i guess higher level from my point of view . 
and uh meeting mappings . 
and uh 
so is for it was a proposal for the i t r program . 
uh information technology research program ' s part of national science foundation . 
it ' s the second year of their doing uh these grants . 
they ' re they ' re 
a lot of them are 
some of them anyway are larger larger grants than the usual small n s f grants . 
and 
so they ' re very competitive . 
and they have a first phase where you put in pre proposals . 
and we we uh got through that . 
and so the the next phase will be we ' ll actually be doing a larger proposal . 
and i ' m i i hope to be doing very little of it . 
and 
uh which was also true for the pre proposal . 
so 
uh there ' ll be bunch of people working on it . 
so 
when ' s when ' s the full proposal due ? 
uh i think april ninth or something . 
so it ' s about a month . 
yep . 
um 
and they said end of business day you could check on the reviewer forms . 
tomorrow . 
is that 
tomorrow . 
tomorrow . 
march second i said . 
yeah . 
tomorrow . 
i ' ve been a day off all week . 
i guess that ' s a good thing . 
because that way i got my papers done early . 
it would be interesting 
so that ' s amazing you showed up at this meeting ! 
it is it is actually quite amazing . 
yeah . 
it ' ll be interesting to see the reviewer ' s comments . 
yeah . 
yeah . 
my favorite is was when when when one reviewer says uh you know this should be far more detailed . 
and the the next reviewer says you know there ' s way too much detail . 
yep . 
or this is way too general . 
and the other reviewer says this is way too specific . 
yeah . 
yeah . 
yeah . 
yeah . 
this is way too hard . 
way too easy . 
we ' ll see . 
maybe there ' ll be something useful . 
and and uh 
well it sounded like they they the first gate was pretty easy . 
is that right ? 
that they didn ' t reject a lot of the pre proposals . 
do you know anything about the numbers ? 
no . 
it ' s just from his message it sounded like that . 
just just 
yeah yeah . 
i said something yeah . 
gary strong ' s 
there was a sentence at the end of one of his paragraphs . 
i 
yeah . 
i should go back and look . 
i didn ' t i don ' t think that ' s true . 
yeah okay . 
huh . 
he said the next phase will be very competitive . 
very very 
because we didn ' t want to weed out much in the first phase . 
yeah . 
yeah . 
or something like that . 
well we ' ll have to see what the numbers are . 
uhhuh . 
so 
huh . 
yeah . 
but they they have to weed out enough so that they have enough reviewers . 
right . 
yeah . 
so uh you know maybe they didn ' t weed out as much as usual . 
but it ' s it ' s usually a pretty 
but it 
yeah it ' s it ' s certainly not i ' m sure that it ' s not down to one in two or something . 
right . 
of what ' s left . 
i ' m sure it ' s you know 
how how many awards are there ? 
do you know ? 
well there ' s different numbers of awards for different size . 
they have three size grants . 
this one there ' s 
um 
see the small ones are less than five hundred thousand total over three years . 
and that they have a fair number of them . 
um 
and the large ones are 
uh 
boy i forget . 
i think more than 
uh 
more than a million and a half more than two million or something like that . 
and and we ' re in the middle 
uhhuh . 
middle category . 
i think we ' re 
uh uh 
i forget what it was . 
but um 
uh i don ' t remember . 
but it ' s probably along the 
i i could be wrong on this . 
yeah but probably along the lines of fifteen or that they ' ll fund or twenty . 
i mean when they do you do you know how many they funded when they in in chuck ' s ? 
that he got last year . 
i don ' t i don ' t know . 
yeah . 
i thought it was smaller . 
that it was like four or five . 
wasn ' t it ? 
i i ' m 
well they fund 
i don ' t remember . 
they 
yeah . 
uh it doesn ' t matter . 
i mean 
we ' ll find out one way or another . 
yeah . 
i mean last time i think they just had two categories . 
small and big . 
uhhuh . 
and this time they came up with a middle one . 
so it ' ll there ' ll be more of them that they fund than of the big . 
if we end up getting this um what will it mean to icsi in terms of where will the money go to ? 
what would we be doing with it ? 
uh 
exactly what we say in the proposal . 
i i mean uh which part is icsi though ? 
you know it 
i mean 
none of it will go for those yachts that we ' ve talking about . 
dang ! 
um well 
no i mean it ' s 
it 
it ' s just for the research . 
to continue the research on the meeting recorder stuff . 
it ' s extending the research . 
right ? 
yeah . 
because the other 
yeah it ' s higher level stuff than we ' ve been talking about for meeting recorder . 
yeah . 
yeah the other things that we have uh been working on with uh the with communicator . 
uh especially with the newer things . 
with the more acoustically oriented things are are are are lower level . 
and 
this is dealing with uh mapping on the level of of um the conversation . 
uhhuh . 
of mapping the conversations . 
right right . 
to different kind of planes . 
so um but um 
so it ' s it ' s all stuff that none of us are doing right now . 
or none of us are funded for . 
so it ' s so it ' s it would be new . 
so assuming everybody ' s completely busy now it means we ' re going to have to hire more students or something ? 
well there ' s evenings and there ' s weekends . 
and uh 
yeah there there would be there would be new hires . 
and and there there would be expansion . 
but 
also there ' s always for everybody there ' s there ' s always things that are dropping off . 
grants that are ending . 
or other things that are ending . 
right . 
so 
uhhuh . 
there ' s there ' s a continual need to to bring in new things . 
right . 
yep . 
i see . 
but but there definitely would be new new new uh students . 
and so forth both at at u w and here . 
are there any students in your class who are expressing interest ? 
um not clear yet . 
other than the one who ' s already here . 
not clear yet . 
i mean we got we have 
yeah two of them are two in the there ' re two in the class already here . 
and then 
and and uh uh 
then there ' s a third who ' s doing a project here . 
uhhuh . 
who uh but he he he won ' t be in the country that long . 
and 
maybe another will end up 
yep . 
actually there is one other guy who ' s looking that that ' s that 
guy uh 
jeremy i think . 
huh . 
uhhuh . 
anyway yeah that ' s that ' s all i was going to say is that that that ' s you know that ' s nice . 
and we ' re sort of preceding to the next step . 
and it ' ll mean some more work uh you know in in march in getting the proposal out . 
and then it ' s uh you know we ' ll see what happens . 
uh the last one was that you had there was about naming ? 
yep . 
it just uh we ' ve been cutting up sound files in for both digits and for uh doing recognition . 
and liz had some suggestions on naming . 
and it just brought up the whole issue that hasn ' t really been resolved about naming . 
so uh one thing she would like to have is for all the names to be the same length . 
so that sorting is easier . 
yeah . 
um 
same number of characters . 
so that when you ' re sorting filenames you can easily extract out bits and pieces that you want . 
and that ' s easy enough to do . 
and i don ' t think we have so many meetings that that ' s a big deal just to change the names . 
so that means uh instead of calling it m r one m r two you ' d call it m r m zero zero one . 
m r m zero zero two things like that . 
just so that they ' re they ' re all the same length . 
but you know when you do things like that you can always 
as long as you have 
uh you can always search from the beginning or the end of the string . 
you know so zero zero two 
the problem is that they ' re a lot of fields . 
yeah . 
all right . 
so we we have we ' re going to have the speaker i d . 
the session . 
uh uh 
yeah well your example was really 
information on the microphones . 
uhhuh . 
information on the on the channels and all that . 
okay . 
and so if each one of those is a fixed length the sorting becomes a lot easier . 
she wanted to keep them the same lengths across different meetings also . 
so like the n s a meeting lengths all filenames are going to be the same length as the meeting recorder meeting names ? 
yep . 
and as i said it ' s we just don ' t have that many that that ' s a big deal . 
because of digits ? 
and so uh um at some point we have to sort of take a few days off 
let the transcribers have a few days off . 
make sure no one ' s touching the data . 
and re organize the file structures . 
and when we do that we can also rationalize some of the naming . 
i i would think though that the transcribe the transcripts themselves wouldn ' t need to have such lengthy names . 
so i mean you ' re dealing with a different domain there and with start and end times and all that . 
right . 
and channels and stuff . 
so it ' s a different set . 
right so the only thing that would change with that is just the directory names . 
i would change them to match . 
so instead of being m r one it would be m r m zero zero one . 
but i don ' t think that ' s a big deal . 
fine . fine . 
so for for the meetings we were thinking about three letters and three numbers . 
for meeting i ds . 
uh for speakers m or f and then three numbers . 
for uh and uh 
that also brings up the point that we have to start assembling a speaker database so that we get those links back and forth . 
and keep it consistent . 
um 
and then uh the microphone issues . 
we want some way of specifying more than looking in the key file what channel and what mike what channel what mike and what broadcaster . 
or i don ' t know how to say it . 
so i mean with this one it ' s this particular headset with this particular transmitter as a wireless . 
yeah . 
yep . 
and you know that one is a different headset and different channel . 
and so we just need some naming conventions on that . 
yeah . 
and uh 
uhhuh . 
that ' s going to become especially important once we start changing the microphone set up . 
we have some new microphones that i ' d like to start trying out . 
um 
once i test them . 
and then we ' ll we ' ll need to specify that somewhere . 
so i was just going to do a fixed list of uh microphones and types . 
yeah . 
okay . 
so as i said 
that sounds good . 
yeah . 
um since we have such a short agenda list i guess i i will ask how how are the transcriptions going ? 
yeah . 
the the news is that i ' ve i uh 
so in um 
so i ' ve switched to 
start my new sentence . 
i i switched to doing the channel by channel transcriptions to provide uh the uh tighter time bins for partly for use in thilo ' s work . 
and also it ' s of relevance to other people in the project . 
and um i discovered in the process a couple of of interesting things . 
which um 
one of them is that um it seems that there are time lags involved in doing this . 
uh uh 
using an interface that has so much more complexity to it . 
and i and i wanted to maybe ask uh chuck to help me with some of the questions of efficiency . 
maybe i was thinking maybe the best way to do this in the long run may be to give them single channel parts . 
and then piece them together later . 
and i i have a script . 
i can piece them together . 
i mean so it ' s like i i know that i can take them apart and put them together and i ' ll end up with the representation . 
which is where the real power of that interface is . 
and it may be that it ' s faster to transcribe a channel at a time with only one uh sound file and one uh set of of uh utterances to check through . 
uhhuh . 
yeah . 
i ' m a little confused . 
i thought that that one of the reason we thought we were so much faster than than uh the the other transcription uh thing was that that we were using the mixed file . 
oh yes okay . 
but um with the mixed when you have an overlap you only have a a choice of one start and end time for that entire overlap . 
which means that you ' re not tightly uh tuning the individual parts of that overlap by different speakers . 
uhhuh . 
so someone may have only said two words in that entire big chunk of overlap . 
yeah . 
yeah . 
and for purposes of of uh things like 
well so things like training the speech nonspeech segmentation thing . 
yeah . 
it ' s necessary to have it more tightly tuned than that . 
okay . 
and and and you know it would be wonderful if uh it ' s possible then to use that algorithm to more tightly tie in all the channels after that . 
but um you know i ' ve the 
so 
i don ' t know exactly where that ' s going at this point . 
but i was experimenting with doing this by hand . 
and 
i really do think that it ' s wise that we ' ve had them start the way we have . 
with uh working off the mixed signal . 
um 
having the interface that doesn ' t require them to do the uh the time bins for every single channel at a uh through the entire interaction . 
uhhuh . 
um i did discover a couple other things by doing this though . 
and one of them is that . 
um um 
once in a while a backchannel will be overlooked by the transcriber . 
as you might expect . 
uhhuh . 
because when it ' s 
sure . 
a backchannel could well happen in a very densely populated overlap . 
and if we ' re going to study types of overlaps 
which is what i want to do . 
an analysis of that 
then that really does require listening to every single channel all the way through the entire length for all the different speakers . 
now for only four speakers that ' s not going to be too much time . 
but if it ' s nine speakers then that that is more time . 
so it ' s you know kind of wondering 
and i think again it ' s like this it ' s really valuable that thilo ' s working on the speech nonspeech segmentation . 
because maybe um we can close in on that without having to actually go to the time that it would take to listen to every single channel from start to finish through every single meeting . 
yeah but those backchannels will always be a problem i think . 
uh especially if they ' re really short . 
and they ' re not very loud . 
and so it it can it it will always happen that also the automatic detection system will miss some of them . 
so 
okay . 
well so then then maybe the answer is to uh listen especially densely in places of overlap . 
just so that they ' re they ' re not being overlooked because of that . 
yeah . 
and count on accuracy during the sparser phases . 
yeah . 
because there are large spaces of the 
that ' s a good point . 
there are large spaces where there ' s no overlap at all . 
someone ' s giving a presentation . 
yeah . 
or whatever . 
that ' s that ' s a good that ' s a good thought . 
and um let ' s see there was one other thing i was going to say . 
i i think it ' s really interesting data to work with . 
i have to say it ' s very enjoyable . 
really not not a problem spending time with these data . 
really interesting . 
and not just because i ' m in there . 
no it ' s real interesting . 
uh well i think it ' s a short meeting . 
uh you ' re you ' re you ' re still in the midst of what you ' re doing from what you described last time i assume . 
is true . 
uhhuh . 
i haven ' t results uh yet . 
and 
but uh 
yeah . 
i i ' m continue working with the mixed signal now after the the last experience . 
yeah yeah . 
and and i ' m tried to to uh adjust the to to improve uh an harmonicity uh detector that uh i i implement . 
yeah . 
but i have problem . 
because uh i get uh 
uh 
very much harmonics now . 
yeah . 
um harmonic possible harmonics . 
uh 
uh and now i ' m i ' m i ' m trying to to find uh some kind of a um of of help uh using the energy to to distinguish between possible harmonics and and other frequency peaks that uh not harmonics . 
and 
uh i have to to talk with with you with the group uh about the instantaneous frequency . 
because i have uh an algorithm . 
and i get 
huh uh 
results similar results like uh the paper uh that i i am following . 
but uh the the rules uh that uh people used in the paper to to distinguish the harmonics is doesn ' t work well . 
uhhuh . 
and i i i i not sure that uh the the way to the way to obtain the the instantaneous frequency is right . 
or it ' s it ' s not right . 
uh 
yeah . 
i haven ' t enough feeling to to to distinguish what happened . 
yeah i ' d like to talk with you about it . 
if if if uh if i don ' t have enough time and you want to discuss with someone else 
someone else besides us that you might want to talk to uh might be stephane . 
yeah . 
i talked with stephane and and thilo . 
yeah and and thilo . 
yeah . 
and 
yeah but 
they nnn they they they didn ' t 
i ' m not too experienced with harmonics . 
they think that the experience is not enough to 
i see . 
and 
is is this the algorithm where you hypothesize a fundamental and then get the energy for all the harmonics of that fundamental ? 
no no it ' s no 
no . 
and then hypothesize a new fundamental and get the energy . 
no . 
yeah that ' s 
no i i i i don ' t process the the fundamental . 
i i um i calculate the the phase derivate using the f f t . 
yeah . 
and 
the algorithm said that uh if you if you change the the the 
uh nnn 
the x the frequency x uh using the the instantaneous frequency . 
you can find uh how uh in several frequencies that probably the the harmonics uh 
uhhuh . 
the errors of peaks the frequency peaks uh uh move around these uh uh frequency harmonic . 
the frequency of the harmonic . 
and uh if you if you compare the the instantaneous frequency uh of the of the uh continuous uh uh filters that uh that uh they used uh to to to get uh the the instantaneous frequency 
uhhuh . 
it probably too you can find uh that the instantaneous frequency for the continuous uh uh the output of the continuous filters are very near . 
and in my case in equal with our signal it doesn ' t happened . 
yeah i ' d have to look at that and think about it . 
and 
it ' s it ' s it ' s i haven ' t worked with that either . 
so i ' m not sure . 
the way the simple minded way i suggested was what chuck was just saying is that you could make a a sieve . 
yeah . 
you know you actually say that here is 
let ' s let ' s hypothesize that it ' s this frequency or that frequency . 
and and uh 
yeah . 
maybe you maybe you could use some other cute methods to uh short cut it by by uh making some guesses . 
but but uh uh uh 
i would uh 
i mean you could make some guesses from uh from the auto correlation or something . 
but but then given those guesses try 
um uh 
only looking at the energy at multiples of the of that frequency . 
and and see how much of the 
take the one that ' s maximum . 
call that the 
yeah . 
using the energy of the of the multiple of the frequency . 
but 
of all the harmonics of that yeah . 
yeah . 
do you have to do some kind of uh low pass filter before you do that ? 
i don ' t use . 
or 
but i i know many people use uh low pass filter to to to get uh the pitch . 
no ? 
to get the pitch yes . 
i don ' t use . 
to get the pitch yeah . 
to get the pitch yes . 
but the harmonic no . 
but 
but the harmonics are going to be 
uh uh 
i don ' t know what the right word is . 
um 
they ' re going to be dampened by the uh vocal tract . 
right ? 
the response of the vocal tract . 
yeah . 
yeah . 
and so just looking at the energy on those at the harmonics is that going to 
well so the thing is that the 
this is for 
uh a um 
i what you ' d like to do is get rid of the effect of the vocal tract . 
right ? 
yeah . 
and just look at the at at the signal coming out of the glottis . 
yeah . 
uh well 
yeah that ' d be good . 
yeah . 
but uh but i but but i don ' t know that you need to . 
open wide ! 
but i don ' t need you know if you need to get rid of it . 
i mean that ' d that ' d be nice . 
but i don ' t know if it ' s if it ' s essential . 
um i mean because i think the main thing is that uh you ' re trying 
uhhuh . 
what are you doing this for ? 
you ' re trying distinguish between the case where there is uh where where there are more than uh where there ' s more than one speaker . 
and the case where there ' s only one speaker . 
sorry . 
so if there ' s more than one speaker 
um 
yeah i guess you could i guess 
yeah you ' re so you ' re not distinguished between voiced and unvoiced . 
so so if you don ' t if you don ' t care about that 
yeah . 
see if you also want to just determine if you also want to determine whether it ' s unvoiced then i think you want to look look at high frequencies also . 
because the the fact that there ' s more energy in the high frequencies is going to be an sort of obvious cue that it ' s unvoiced . 
yeah . 
but uh i mean 
but um 
other than that i guess as far as the one person versus two persons it would be primarily a low frequency phenomenon . 
and if you looked at the low frequencies yes the higher frequencies are going to there ' s going to be a spectral slope . 
the higher frequencies will be lower energy . 
but so what ? 
i mean that ' s that ' s 
i will prepare for the next week uh all my results about the harmonicity . 
and will will try to come in 
and to discuss here 
because uh i haven ' t enough feeling to to many time to to understand what happened with the with uh so many peaks . 
uh uh 
and i i see the harmonics there many time . 
but uh there are a lot of peaks . 
uh that uh they are not harmonics . 
um 
yeah . 
i have to discover what what is the the the best way to to to to use them . 
well but yeah i don ' t think you can i mean you ' re not going to be able to look at every frame . 
so i mean 
i i mean i i really i really thought that the best way to do it . 
and i ' m speaking with no experience on this particular point . 
but my impression was that the best way to do it was however you you ' ve used instantaneous frequency whatever however you ' ve come up you with your candidates you want to see how much of the energy is in that . 
yeah . 
yeah . 
as as opposed to all of the all the total energy . 
and um if it ' s voiced 
i guess so so i think maybe you do need a voiced unvoiced determination too . 
but if it ' s voiced 
yeah . 
um and the uh 
the fraction of the energy that ' s in the harmonic sequence that you ' re looking at is relatively low then it should be then it ' s more likely to be an overlap . 
is height . 
yeah . 
this this is the idea the idea i i i had . 
to to compare the the ratio of the the energy of the harmonics with the uh with the uh total energy in the spectrum . 
and try to get a ratio to to distinguish between overlapping and speech . 
huh . 
but you ' re looking you ' re looking at 
let ' s take a second with this . 
uh uh 
you ' re looking at at the phase derivative . 
um 
in in uh 
what domain ? 
i mean this is this is in in in in bands ? 
or or 
no no no . 
just just overall 
it ' s a it ' s a 
the band the band is uh from zero to to four kilohertz . 
and i i i 
and you just take the instantaneous frequency . 
yeah . 
yeah . 
right . 
oh . 
but the instantaneous frequency 
wouldn ' t that give you something more like the central frequency of the you know of the where most of the energy is ? 
i mean i think if you 
does does it why would it correspond to pitch ? 
yeah . 
digital camera . 
keep forgetting . 
yeah . 
yeah . 
oh so you scale you you do a a scaling along that axis according to instantaneous . 
it ' s a kind of normalization . 
okay . 
yeah . 
i see . 
huh . 
yeah . 
okay yeah well i i guess i ' m not following it enough . 
probably going to have to look at the paper . 
but which i ' m not going to have time to do in the next few days . 
but but i ' m i ' m curious about it . 
um uh 
okay . 
i did it did occur to me that this is uh the return to the transcription . 
that there ' s one third thing i wanted to to raise as a as an issue . 
which is um how to handle breaths . 
so i wanted to raise the question of whether people in speech recognition want to know where the breaths are . 
and the reason i ask the question is 
um aside from the fact that they ' re obviously very time consuming to encode 
uh the fact that there was some 
i had the indication from dan ellis in the email that i sent to you . 
and you know about 
yeah . 
that in principle we might be able to um handle breaths by by using cross talk from the other things . 
be able that 
in principle maybe we could get rid of them . 
so maybe 
and i was 
i i don ' t know . 
i mean we had this 
and i didn ' t couldn ' t get back to you . 
yeah . 
but the question of whether it ' d be possible to eliminate them from the audio signal . 
which would be the ideal situation . 
because 
i don ' t know think it ' d be ideal . 
uh uh . 
see we ' re we ' re dealing with real speech . 
and we ' re trying to have it be as real as possible . 
yeah . 
and breaths are part of real speech . 
well except that these are really truly 
i mean there ' s a segment in the one i did 
the first one that i did for for this . 
yeah . 
where truly we ' re hearing you breathing like as if we ' re you ' re in our ear . 
you know and it ' s like it ' s like 
yeah . 
i mean breath is natural . 
but not 
it is but it is if you record it . 
yeah . 
except that we ' re we ' re trying to mimic 
oh i see what you ' re saying . 
you ' re saying that the p d a application would have uh have to cope with breath . 
yeah . 
well 
but 
any application may have to . 
no . 
the p d a might not have to . 
no 
but more people than just p d a users are interested in this corpus . 
yeah . 
okay then the then i have two questions . 
so so mean you ' re right . 
we could remove it . 
yeah . 
but i i think we don ' t want to remove it from the corpus in terms of delivering it . 
because the people will want it in there . 
okay so maybe the question is notating it . 
yeah if it gets 
yeah ? 
yeah i right . 
if if it gets in the way of what somebody is doing with it then you might want to have some method which will allow you to block it . 
but you it ' s real data . 
you don ' t want to but you don ' t 
okay well 
if you know if there ' s a little bit of noise out there and somebody is is talking about something they ' re doing that ' s part of what we accept as part of a real meeting 
even and 
we have the uh the uh the the fan and the in the projector up there . 
and uh this is it ' s this is actual stuff that we we want to work with . 
well this is very interesting . 
so 
because it basically has a it shows very clearly the contrast between uh speech recognition research and discourse research . 
because in in discourse and linguistic research what counts is what ' s communicative . 
uhhuh . 
and breath 
you know everyone breathes . 
they breathe all the time . 
and once in a while breath is communicative . 
but very rarely . 
okay so now i had a discussion with chuck about the data structure . 
uhhuh . 
and the idea is that the transcripts will that get stored as a 
there ' ll be a master transcript . 
which has in it everything that ' s needed for both of these uses . 
uhhuh . 
and the one that ' s used for speech recognition will be processed via scripts . 
you know like don ' s been writing scripts . 
and and 
uhhuh . 
uh to process it for the speech recognition side . 
discourse side will have 
this this side over the we ' ll have a 
sorry not being very fluent here . 
but um 
this the discourse side will have a script which will strip away the things which are non communicative . 
okay so then the then let ' s let ' s think about the practicalities of how we get to that master copy with reference to breaths . 
so what i would what i would wonder is would it be possible to encode those automatically ? 
could we get a breath detector ? 
oh just to save the transcribers time . 
well i mean you just have no idea . 
i mean if you ' re getting a breath several times every minute . 
uhhuh . 
and just simply the keystrokes it takes to negotiate to put the boundaries in to to type it in it ' s just a huge amount of time . 
uhhuh . 
oops . 
what 
and you want to be sure it ' s used . 
and you want to be sure it ' s done as efficiently as possible . 
and if it can be done automatically that would be ideal . 
what if you put it in but didn ' t put the boundaries ? 
well but 
so you just know it ' s between these other things . 
well okay so now there ' s there ' s another another possibility . 
right ? 
which is um the time boundaries could mark off words from nonwords . 
and that would be extremely time effective if that ' s sufficient . 
yeah i mean i ' m if it ' s too if it ' s too hard for us to annotate the breaths per se we are going to be building up models for these things . 
and these things are somewhat self aligning . 
so if so we if we say there is some kind of a thing which we call a breath or a breath in or breath out the models will learn that sort of thing . 
uh so but you but you do want them to point them at some region where where the breaths really are . 
okay but that would maybe include a pause as well . 
so 
well there ' s there ' s 
and that wouldn ' t be a problem to have it uh pause plus breath plus laugh plus sneeze . 
yeah 
you know there is there ' s this dynamic tension between between marking absolutely everything as you know . 
and and and 
marking just a little bit and counting on the statistical methods . 
basically the more we can mark the better . 
but if there seems to be a lot of effort for a small amount of reward in some area 
and this might be one like this . 
although i i i ' d be interested to get get input from liz and andreas on this to see if they 
because they ' ve got lots of experience with the breaths in in uh uh their transcripts . 
i 
they have lots of experience with breathing ? 
actually 
well yes they do . 
but we we can handle that without them here . 
but but but uh 
you were going to say something about 
yeah i i think um one possible way that we could handle it is that 
um 
you know as the transcribers are going through and if they get a hunk of speech that they ' re going to transcribe 
they ' re going to transcribe it because there ' s words in there or what not . 
if there ' s a breath in there they could transcribe that . 
yeah . 
that ' s what they ' ve been doing . 
yeah . 
right . 
so within an overlap segment they they do this . 
but 
right but if there ' s a big hunk of speech let ' s say on morgan ' s mike where he ' s not talking at all um don ' t don ' t worry about that . 
yeah . 
so what we ' re saying is there ' s no guarantee that um 
so for the chunks that are transcribed everything ' s transcribed . 
but outside of those boundaries there could have been stuff that wasn ' t transcribed . 
so you just somebody can ' t rely on that data and say that ' s perfectly clean data . 
uh do you see what i ' m saying ? 
yeah you ' re saying it ' s uncharted territory . 
so i would say don ' t tell them to transcribe anything that ' s outside of a grouping of words . 
that sounds like a reasonable reasonable compromise . 
yeah and that ' s that that quite corresponds to the way i i try to train the speech nonspeech detector . 
as i really try to not to detect those breaths . 
which are not within a speech chunk but with which are just in in a silence region . 
yeah . 
and they so they hopefully won ' t be marked in in those channel specific files . 
yeah so 
but 
i i wanted to comment a little more just for clarification about this business about the different purposes . 
uhhuh . 
see in a in a way this is a really key point . 
that for speech recognition uh research 
uh um 
a it ' s not just a minor part . 
in fact the i i would say the core thing that we ' re trying to do is to recognize the actual meaningful components in the midst of other things that are not meaningful . 
so it ' s critical 
it ' s not just incidental . 
it ' s critical for us to get these other components that are not meaningful . 
because that ' s what we ' re trying to pull the other out of . 
that ' s our problem . 
if we had nothing 
yeah . 
if we had only linguistically relevant things 
if if we only had changes in the spectrum that were associated with words with different spectral components 
and uh we we didn ' t have noise 
we didn ' t have convolutional errors . 
we didn ' t have extraneous uh behaviors and so forth . 
and moving your head . 
and all these sorts of things . 
then actually speech recognition isn ' t that bad right now . 
i mean you can 
you know it ' s it ' s the technology ' s come along pretty well . 
the the the reason we still complain about it is because is when when you have more realistic conditions then then things fall apart . 
okay fair enough . 
i guess um i uh what i was wondering is what what at what level does the breathing aspect enter into the problem ? 
because if it were likely that a p d a would be able to be built which would get rid of the breathing so it wouldn ' t even have to be processed at at this computational 
well let me see it ' d have to be computationally processed to get rid of it . 
but if there were uh likely on the frontier a good breath extractor 
then um and then you ' d have to 
but that ' s a research question . 
you know ? 
and so 
yeah well see and that ' s what i wouldn ' t know . 
that 
and we don ' t either . 
i mean so so the thing is it ' s it 
right now it ' s just raw it ' s just data that we ' re collecting . 
and so we don ' t want to presuppose that people will be able to get rid of particular degradations . 
because that ' s actually the research that we ' re trying to feed . 
okay . 
so you know and maybe maybe in five years it ' ll work really well . 
and and it ' ll only mess up ten percent of the time . 
but then we would still want to account for that ten percent . 
i guess there ' s another aspect . 
so 
which is that as we ' ve improved our microphone technique we have a lot less breath in the in the more recent uh recordings . 
so it ' s in a way it ' s an artifact that there ' s so much on the on the earlier ones . 
uhhuh . 
i see . 
one of the 
um just to add to this 
one of the ways that we will be able to get rid of breath is by having models for them . 
i mean that ' s what a lot of people do nowadays . 
right . 
right . 
and so in order to build the model you need to have some amount of it marked . 
so that you know where the boundaries are . 
yeah . 
so 
i mean i don ' t think we need to worry a lot about breaths that are happening outside of a you know conversation . 
we don ' t have to go and search for them to to mark them at all . 
but i mean if they ' re there while they ' re transcribing some hunk of words i ' d say put them in if possible . 
okay and it ' s also the fact that they differ a lot from one channel to the other . 
because of the way the microphone ' s adjusted . 
uhhuh . 
okay . 
should we do the digits ? 
yep . 
okay . 
okay so the one one thing i knew i wanted to talk about was about uh sort of last minute stuff to uh try to get some recognition results . 
recognition results . 
yeah . 
for 
so uh on on on meeting data . 
and so i ' m i ' m not sure exactly what you ' re doing already . 
and and there ' s some stuff i ' ve talked to dave 
well i just started recognition on the on thilo ' s segments . 
which was 
but using the 
the close talking microphone . 
okay so um 
and you wanted i know you wanted the far field data . 
right so so we have some stuff with no overlap uh for which there would be near near field results . 
uhhuh . 
we wanted to get the far field results for that . 
and then this this real uh long shot thing would be that we ' d apply dave ' s processing to uh potentially training and test data . 
uhhuh . 
and do the look at the same thing . 
and in talking this morning with uh chuck and with dave one thought was to use 
we couldn ' t remember how different the numbers were . 
but if you just worked with males only and used the short training there ' re there ' re 
uh i think chuck ' s recollection was that when he was doing the feature stuff it took maybe a day and a half . 
to do the training . 
to re train ? 
yeah . 
uh 
yeah . 
um 
that ' s about right . 
actually it should probably be 
it depends on who else is using machines . 
but we have more machines now . 
so 
that ' s true . 
it ' s more like a day probably . 
um how much worse is the short training set than the large one in terms of the ultimate performance ? 
huh it ' s like something like three three percent . 
three or four percent absolute . 
yep . 
so it ' s that should be fine for this i would think . 
so we and you have the short you have short training results for the close case ? 
um not for meetings . 
because we didn ' t train we didn ' t ever recognize with the with the small models on meeting data . 
but i i have the models . 
so i could run 
so how do you know it ' s 
oh it ' s three percent on on uh on hub five . 
on 
hub five . 
i see . 
yeah but we have the models so we could get that number . 
and 
so the question is what 
i mean the the huh 
the recognition also takes non negligible amount of time . 
so we might want to restrict it to maybe a few meetings . 
if you want to do a full comparison . 
it has to be enough so that 
uh 
i mean it ' s the non overlap only . 
um and 
it has to be enough to be sort of comparable to what you folks were seeing and what you reported already . 
huh . 
i mean 
well do we have the do we have the processed data ? 
that that ' s also 
no he has to create that . 
but but but so 
right . 
um 
we have a whole parallel set of things over here which are all with digits . 
huh . 
i see . 
and and and dave has been working with that and there ' s all of those issues . 
but i know that if i go in with something that ' s not just digits it would be good . 
and um so 
we already have these results that you 
i mean on uh a a a particular test set that you that we reported at h l t . 
uhhuh . 
right . 
um it ' d be nice to have something more than that . 
and we had talked about was having distant 
um and then 
uh if we could on top of that 
i mean so this is going to be a lot worse . 
right ? 
whatever comparison we one would presume . 
uhhuh . 
but we don ' t know how much worse 
right . 
uh which is certainly one interesting thing . 
and then um 
dave 
i think we figured that it ' d probably take a day or two to compute the the 
uh uh 
well how many hours of training 
actually i did re train 
i recently re trained um for another reason on the full training set . 
and that took only i think it took only two days . 
yeah . 
so it ' s actually conceivable to do use the full training set . 
yeah but we also have to do this other processing so having a smaller training set . 
if it ' s only a few percent difference it might be be worth doing it . 
oh i see . 
how big is the small training set ? 
do you remember ? 
huh uh hhh . 
i don ' t know . 
something something like something between thirty and fifty hours maybe . 
i i forget the 
it ' s around there . 
and and and male is roughly half of that ? 
right . 
or 
well that ' s only male . 
or or or was that only male ? 
uh actually i don ' t know . 
i i can look it up . 
it ' s it ' s it ' s just 
uh i don ' t know the remember the the number . 
we could only just do the male only . 
okay . 
right ? 
or will we run into trouble when we 
well the males account for most of this meeting data anyhow . 
yeah . 
so 
yeah i would say we you do only males . 
yeah . 
so 
yeah so that ' s certainly part of the issue is that right now he ' s he hasn ' t written his stuff for efficiency . 
yeah it ' s it ' s in matlab . 
and so on . 
and and uh it ' s not an impossible amount of time . 
uhhuh . 
we we were guesstimating it was like one and a half times faster than real time or something . 
so if there ' s thirty hours of data you can calculate that he can do uh the enhancement in a day . 
and something . 
uhhuh . 
so 
but if we were dealing with two hundred hours or something i think it ' d be prohibitive . 
no it ' s definitely it ' s less than a hundred hours for sure . 
it ' s 
yeah . 
it ' s probably actually uh it ' s uh i think it ' s around thirty hours . 
just for for one gender . 
that ' s what i was thinking . 
yeah . 
yeah . 
yeah . 
yeah so i mean it ' s a bit of a push . 
but it seems like 
okay we ' ve got some models . 
we ' ve got some training data we have software that works he ' s got a method that helps with you know other another task . 
um 
it you know appears to be you know debugged . 
uhhuh . 
um 
so so one thing i was wondering is did you already do that middle one or should we re do that one too ? 
no i didn ' t do that . 
because we haven ' t even cut the waveforms for that . 
you didn ' t do that okay . 
yeah that ' s what i was going to say next . 
so 
we have to cut the uh 
right . 
so 
so is morgan is the plan to just pick one of the far field mikes ? 
uh 
and there ' s a bit of a question whether you want to use um what segmentations you want to use . 
yes . 
uh 
uh david just 
um i ' m sorry . 
don just uh created a new version of the first meetings that we had previously recognized . 
but with different segmentation . 
and so um 
it would be nice 
i mean if the results are comparable to what we had before 
to use those segmentations . 
because then we could claim that everything ' s automatic . 
do you know when he ' ll have the the comparison ? 
right ? 
well i ' m as i said i just started the recognizer um 
it will uh it will probably be a couple hours before before i have some results . 
oh well that ' s not bad . 
oh okay . 
so 
so because i don ' t think the new data will be ready uh for a couple days probably . 
you mean the training . 
so 
the training . 
but the segmentations matter for the filtering . 
yeah . 
right ? 
because 
for the test . 
for the test set yeah . 
so 
yeah 
yeah . 
need to be 
but first first of course you would want to process the training data . 
because we want to get that started . 
right . 
yeah . 
yeah . 
i mean it it ' d be really great if it was all automatic but i think that you know given the pressure of time if 
i mean since you ' re going to find out in a short amount of time that ' s great . 
uhhuh . 
but if if it doesn ' t work out i think we would rather charge ahead with the older segmentations . 
uhhuh . 
right . 
and um 
and we were going to use one of the p z m ' s . 
i i don ' t know what 
probably whatever one you ' ve been using for for for the digits . 
i think it ' s that one . 
right ? 
is it this one ? 
it ' s f . 
f . 
yeah that ' s it . 
i i ' d which 
that ' s f ? 
how do you know ? 
that ' s f . 
it ' s the second nearest the machine room . 
oh . 
bien sur 
all right so 
bet they ' ll have fun with that one . 
okay so . 
uh 
okay so uh i just want to make sure i understand what we need to run . 
um 
let ' s see . 
so it ' s 
okay so if we ' re talking about 
let ' s let ' s assume that we ' re going to use the new segmentations . 
we need to um run recognition just looking at the no overlap column . 
basically we have to do recognitions for all three of those cases . 
right ? 
uhhuh . 
right . 
um because we ' re going to be using the just the male uh model . 
short training set for the male . 
uhhuh . 
so we need to have results for all three of those . 
even though we have 
maybe you should limit ourselves to the meeting recorder meetings . 
okay . 
um 
if you were going to cut down on the test set i would suggest that . 
well maybe . 
but i i mean how long does it take for the test ? 
actually the longer the robustness meetings take longer . 
because there ' s this one speaker who talks a lot . 
and so 
the um 
no it ' s because for all the for the adaptation and normalization steps you cannot 
you have to you have to uh um 
you cannot chop it up into small pieces . 
so you ' re sort of limited by how long the longest speaker uh is speaking . 
so how much data there is from the the speaker who talks the most . 
so um you parallelize across different speakers . 
uhhuh . 
but you know if you have a bunch of speakers who speak very little and then one who who speaks a lot then effectively everybody waits for the longest one to process . 
right . 
right . 
yeah . 
but what what was your result for uh that we had at the h l t ? 
so 
was that a combination of me ? 
that was both types of meetings . 
but most but there were only two robustness meetings and four or five uh meeting recorders . 
and if we ' re re doing the baseline anyways it it it would be okay . 
right . 
to to just limit ourselves to a smaller 
how long would it take to run recognition if we did that ? 
oh . 
uh i i 
i don ' t have i don ' t have a good 
i mean is is it like a day or is it a few hours or 
roughly . 
for everything ? 
for all the meetings ? 
for 
yeah let ' s say we just did the meeting recorder meetings for our test set . 
uh 
um 
it ' s probably more than a day . 
but probably less than two . 
oh really ? 
i didn ' t realize each test took that long . 
well no i mean for all the meetings . 
because it ' s again it ' s 
um 
so you were doing like 
so each meeting each meetings takes uh something like 
again we we i ran when we ran these we were sort of short on machines . 
and um 
uhhuh . 
i don ' t know . 
i i would estimate maybe four hours per meeting . 
something like that . 
four hours per meeting . 
right . 
wow ! 
yeah but if you so if you do half a dozen meetings that ' s that ' s about a day . 
we also have more machines now . 
right right so that ' s why i ' m saying i ' m not sure how they would scale with more machines . 
well 
yeah . 
yeah . 
i mean if we had about six a six hour test set ' s not bad . 
right ? 
right . 
six hour test set . 
six meetings okay . 
you know ? 
right ? 
i mean a lot of the evaluations have been 
yeah we did . 
we have m r 
two we have two three four 
i think there are four meeting recorder meetings that we worked with . 
four that you worked with ? 
i think it ' s 
is it the same set as the alignments ? 
yeah . 
i think it ' s five meeting recorder meetings . 
five ? 
okay . 
that would be okay too . 
i mean i ' m 
so if they have a set that they worked with 
and you you got 
did you do similarly in performance between them and the other meetings ? 
or was it 
uh with the compared to robustness ? 
yeah . 
the big variation is by whether it ' s a native speaker or not . 
yeah . 
and whether it ' s um 
uh i think that ' s the actually 
and and of course what um you know whether it ' s lapel or uh headset microphone . 
and overlap or not . 
yeah . 
yeah . 
so maybe just with the the the meeting recorder set of the that you did before . 
and we can exclude we don ' t need to recognize the non natives . 
because we know that 
i mean in fact we excluded them previously from 
yeah so we want to do the same same thing . 
right . 
okay so all right so if we got a list of the uh segmentations for these five meeting recorder meetings we could start uh the first two experiments going right away using the short male models . 
uhhuh . 
so you could get those going while dave is um creating waveforms for the re training the short male models . 
yeah once we know which segmentations we ' re using . 
yeah . 
right okay okay . 
and then 
okay so do we also want to run that bottom experiment without re training the short male models on his thing ? 
did you want that ? 
or 
um i i agree that that would be an interesting thing to do . 
but i sort of regard it as secondary . 
okay so we ' ll save that . 
so if there ' s sort of machines sitting around and people sitting around and they ' re waiting for other things to finish then sure . 
but 
uh chuck had been asking about that earlier as kind of a control to know um 
because i mean you could imagine a fantasy in which you said that dave ' s processing made the uh far microphone like the near microphone . 
in which case you shouldn ' t have to actually re train . 
uhhuh . 
but it ' s it ' s not really true . 
it ' s it ' s sort of fantasy . 
it does it does muck up the data in in some funny ways . 
uhhuh . 
and so 
i ' m i ' m kind of questioning that . 
well it 
but but 
well on a more basic level also it means that that third experiment there are actually two differences between the other experiments . 
not one . 
right . 
so it ' s hard to know 
it involves re training and it involves a 
right . 
uh that ' s right . 
i mean the other thing which which it might come in to is if there was some problem in the re training . 
i mean maybe you ' d just have some mechanical thing we do wrong . 
uhhuh . 
uh that uh since dave ' s experience was that it didn ' t help as much if you didn ' t re train but it does help some that we would hopefully see that . 
right . 
uhhuh . 
so that that ' s that ' s true . 
wait did 
so when you used original the original models and you just process the test set in this way do you get any do you get decent performance or not ? 
i i i think um for the far mike h t k system i was using it did help somewhat . 
uhhuh . 
i could re check that . 
but it was such a bad baseline that i don ' t know what that means . 
uhhuh . 
right . 
right . 
okay . 
because the baseline word error rate was around forty percent on digits . 
uhhuh . 
on the far field ? 
right . 
right so 
okay well i ' ll i can get started on the 
well the first the one that already has a 
cross there . 
we need to re do that with small models . 
right ? 
yeah . 
and then have to ask um i guess don to uh cut the um cut the segments for the for the distant mike . 
uh uh that ' s so we would be using the same channel for each for everything ? 
yeah . 
uhhuh . 
okay . 
so 
i mean do you do you have to rely on his segmentations at all to do the top one ? 
no no we would use the same segmentations . 
but he needs to extract extract the form segments from a different channel . 
oh okay . 
got it . 
right . 
so when you said you were going to start that top one were you going to use the new segmentations ? 
uhhuh . 
um yeah . 
okay . 
if assuming that the performance turns out to be comparable with with the old experiments and the old segmentations . 
right okay . 
now there ' s the issue of 
oh okay so there ' s the issue of speaker normalization . 
so with the distant microphone you wouldn ' t know which speaker is talking . 
right ? 
can we 
we we talked about this before . 
i think what we were saying was that um the very fact that in both cases we ' re ignoring the overlap section means that um uh we ' re to some extent finessing that . 
so um 
i think for the purposes of just determining whether a far field microphone uh what the effect of the far field microphone is we should do the same to both . 
uhhuh . 
i see so you want to cheat ? 
i mean 
we want to incorporate certain data that would not be available during final tests uh under a a full fair test of it much as we are in the all the numbers that we have so far . 
okay so we assume we assume knowledge of the speakers as as um in a way that ' s compatible with the close talking test set . 
oops ! 
yeah . 
we we simply want to determine what ' s the difference in performance due to being distant versus close . 
okay . 
oh okay . 
so does that mean you turn off speaker normalization when you run it or you just let it do what it would do 
no it means no it just means 
you you group together the segments that by magic you know belong to one speaker . 
and and treat 
i mean to a lesser extent you had that same magic the other way too . 
because you have leakage into other microphones . 
right ? 
but it ' s just you ' re using the fact that this is where this person is . 
right . 
right . 
right ? 
so 
but um 
it ' s just easier to do . 
well in the new test actually that ' s not true . 
so again if this if these new segmentations work okay then we then it ' s a fair it ' s a completely fair test . 
yeah . 
so how do you determine what you use to group together to be a a 
you group together all the data coming in through one channel . 
and where thilo ' s speech detector has has determined that there is speech . 
and that speech is is deemed to come from that speaker whether that ' s true or not . 
so if you get some cross talk from another microphone then you just process this it as if it were from that speaker . 
the only other alternative would be to turn off speaker adaptation in both . 
well that ' s more of a problem . 
i mean because it ' s you can just pretend it ' s some kind of 
i mean you can pretend it ' s all from one speaker . 
and do all this processing the same . 
but then you ' re going to get results that are worse on account of not doing proper speaker normalization . 
uhhuh . 
and you ' re going to have 
so you could certainly do better than that by doing for instance uh cluster the segments . 
which is what we do say in a broadcast news system where you don ' t have speaker labels . 
but that would be another processing step that i ' m i would have to debug first and so forth . 
uhhuh . 
and so we want to avoid that . 
so i agree with you we should we should uh do the you know this sort of cheating experiment . 
okay . 
yeah and so that will tell us what the difference it between the mikes . 
and then uh in order to 
the the other difference that we ' d have to take care of is that 
uh yeah we we don ' t have a mike that uh is particular to a person . 
and so we ' ll have to do some clustering . 
and that ' ll be another another uh issue too . 
uhhuh . 
but it it i could be wrong . 
but it seems to me that that the speaker 
the the level of degradation that you get from having the distant mike in a normal acoustic is much greater than what you get from say not applying speaker adaptation or applying speaker adaptation . 
uhhuh . 
i think that the 
i mean we ' ll see . 
but but i think that the kind of gains that we ' ve seen from speaker adaptation on hub five sort of things are like a few percent . 
right ? 
and 
it ' s not just speaker adaptation . 
it ' s the whole feature normalization process . 
it ' s uh all that is speaker based . 
you know so we 
so in that i ' m 
um 
you know the most important of course is the cepstral mean subtraction . 
yeah . 
and that 
i don ' t know if we 
we never really 
i don ' t remember 
because it ' s so far so long ago that we didn ' t do that on a per speaker basis . 
it doesn ' t make that much difference i think . 
but 
i would doubt that it would be a huge amount of difference for that . 
so i mean i i think that that difference would definitely be marginal . 
i think the main thing is to do something . 
to do some cepstral mean subtraction on some level . 
and uh so what ' s different about this processing is just that we ' re doing it at a much longer time scale . 
uhhuh . 
uhhuh . 
right ? 
but um 
and by the way 
what 
it ' s actually we ' re we ' re already if we use the same segmentations that we use for the close talking microphone then the segmentations assume that we have access to all channels . 
and cross correlate them . 
that ' s right . 
so there ' s no point in not using that knowledge for speaker identification . 
yeah . 
uhhuh . 
uh i think also for the log spectral mean subtraction uh we want to know which speaker ' s talking when . 
yeah . 
because we want to chain together the audio from one particular speaker to calculate the mean . 
yeah . 
and subtract it . 
and we don ' t 
right . 
right . 
okay . 
um yeah i guess . 
but um 
i also think that again once we got into it that um using some kind of clustering would probably work reasonably well there too . 
certainly for the the two microphone case 
which we ' re not going to mess with because it ' s another whole deal with the low quality microphones . 
um 
we ought to be able to at least tell that it appears that things are coming from a particular direction . 
uhhuh . 
so we ought to be able to use that information um as well . 
but i think we might be able to do not too bad a job of separating out uh segments that appear to come from a single speaker . 
both in terms of acoustic similarity and in terms of direction . 
so i mean but that ' s another research thing to do . 
and probably won ' t get done the next week . 
right so what what is the schedule here ? 
well i mean i ' m i ' m leaving for for the uh the new orleans meeting uh next saturday . 
and and um 
uhhuh . 
it ' d be kind of nice to have some results at least a day or two before that so that i could figure out what i wanted to say about it . 
uhhuh . 
oh we ' ll call you when you get there . 
you ' ll have email ? 
right ? 
yeah . 
uh not to mention that that uh mari ' s putting together this report next week too you know . 
uhhuh . 
so uh 
what we were hoping was that over the weekend we could do uh the um calculation on the training set . 
uhhuh . 
and uh 
uh maybe you know we could by the end of the weekend we could have the top one . 
and and then early next week do these . 
uhhuh . 
if we had enough machines maybe do them in parallel . 
uhhuh . 
so that by the middle of the week we had had some kind of result . 
i mean it ' s it ' s one of these hail mary kinds of things . 
i mean it 
it uh might might not work out . 
uhhuh . 
but uh figured i may as well ask for it . 
okay . 
i ' ll ask 
so 
the other thing is um 
and i ' ll ask don which is easier to process in terms of creating these . 
the the test data for the far far microphone . 
if if it turns out that for some reason it ' s easier for him to use the old um the the the old 
uh 
segmentation . 
segmentations then we ' ll just use that i figure . 
right . 
um 
so um 
i don ' t want you to have to be burdened with doing a lot of stuff . 
what what can i do to 
you said it would be easy for you to do that top one there . 
and i guess don can do the segmentations of the uh channel f . 
uhhuh . 
um 
i mean i can certainly help with uh re training the short male models . 
right . 
uh once we have the new data . 
you have models of short males ? 
yeah . 
um right uh let ' s see the the 
you you can i mean you could you could you could run the 
um 
you basically once the um the top the top one ' s done you could easily re run the whole set of experiments . 
the top one is done i 
i can re do the next one . 
yeah . 
uhhuh . 
uh i mean manage the jobs and so forth . 
yeah sure . 
uh um 
yeah the the bottom one would just be a matter of pointing it at a new set of files and kicking it off . 
that ' s all 
so that would be 
i mean not the bottom one . 
but the middle one 
uhhuh . 
would be really easy once you ' ve got the top one going . 
yeah . 
i could do that . 
right . 
okay so i guess i just need to get don to uh 
right so somehow the 
assuming he uses the new naming scheme then he should call the waveforms 
the so the waveform names have the you know meeting meeting i d . 
and the microphone . 
and the um 
i guess the channel and the microphone and the speaker um speaker 
something that identifies the speaker . 
uhhuh . 
so 
to keep it the same but just change them all to channel f ? 
exactly so uh well you still need to be able to distinguish the different speakers . 
that ' s the key point . 
right right . 
because if we want to do what we just discussed 
so uh uh the the best the easiest way to do that would be to just take you know you make the channel be channel f . 
yeah . 
but then keep the speaker names the same as they would be in the old in the close talking uh version . 
yeah . 
okay . 
okay . 
okay . 
and so that ' s something that don would do . 
right ? 
when he creates these . 
right exactly . 
okay okay . 
so will you talk to him about that ? 
or do you want me to talk to him ? 
i uh i i can talk to him . 
okay . 
and then the bottom one in terms of the test will be 
uh 
that will just be a copy of the one above it except for different models from training . 
well we also have to mean subtract the test data . 
uh okay . 
so we need to run 
okay . 
well once we have the new uh 
well once i do that uh second experiment we ' ll have the um files . 
and i can give you those to to process . 
okay . 
and there ' s um 
so the way this means subtraction expects to work is it expects to have um this continuous stream of audio data from a particular speaker to operate on . 
and it goes along it with this sliding window calculating the mean using the data in the window . 
and then subtracting that . 
so do you create this continuous stream from the individual utterance files ? 
i mean uh 
that ' s that ' s how i ' ve been doing it . 
just by concatenating files together . 
uhhuh . 
um and if these files and 
since they ' re individual utterance files um long silence periods are removed . 
which is a good thing . 
because this method might estimate the mean badly if it had to face long silence periods . 
but that does mean that i need as much i need twice as much disk space as the original set . 
because i need while i ' m running it because i need to create this intermediate set um of these big files . 
uhhuh . 
yeah . 
and then create the finally the mean subtracted um little files . 
and then i can get rid of the big files . 
but while i ' m doing the processing i ' ll i need twice as much disk space . 
okay i ' m going to i ' ll check with um markham . 
and see what happened with the the disks . 
he went to put those on a couple of weeks ago . 
and something 
i think markham ' s out on vacation . 
i think check with dave . 
oh okay i ' ll ask david then . 
yeah . 
yeah . 
you haven ' t seen new disks pop up ? 
have you ? 
nope . 
i was wondering if they were in . 
okay . 
yeah . 
well they grow them on trees now . 
i thought they were like mushrooms . 
well he went to put them on 
just you shake them and they fall down . 
they ' re popping up . 
yeah . 
he went to put them on and then something happened . 
and he sent around a note saying oh uh it didn ' t work and we ' ll have to schedule another time . 
yeah . 
yeah . 
something went wrong . 
and then 
didn ' t see 
nothing happened . 
nothing happened . 
no yeah . 
so 
i ' ll check with david about that . 
okay . 
okay . 
yeah . 
because we still all have the that other one going . 
which is the uh the macrophone training . 
right . 
and 
so so andreas um 
uhhuh . 
in u doctor speech data s r i hub five there ' s this uh hub five training set . 
uhhuh . 
now is that the long training set there ? 
uhhuh . 
uhhuh . 
that ' s everything yeah . 
okay . 
so 
so i can give you a list of the short version . 
okay i i think you already did actually . 
so you can 
oh okay . 
okay and so say the macrophone files that are included in this short training are just a subset of the macrophone files . 
right ? 
that ' s right . 
okay . 
so so um when you you did some t i digits experiments training on macrophone . 
yeah . 
um 
but that ' s not necessarily any less data than the s r i hub five 
set it ' s not a it ' s not a subset of the short s r i hub five set . 
right ? 
um 
no it is . 
the 
sorry . 
um can you repeat the question ? 
uh when you trained on macrophone um to do those digits experiments did you use the entire macrophone corpus ? 
there it is a 
yeah . 
no only the portion that was in the hub five training set . 
oh okay . 
that was in the hub five small training set ? 
well the hub five small training set contains as much macrophone as the large training set for historical reasons . 
yes . 
yeah . 
okay . 
so um 
so do you have that processed there then . 
right ? 
because you already did did didn ' t you already do that experiment ? 
i i got confused . 
because i thought i thought you were using the whole macrophone set . 
uhhuh . 
no . 
um okay . 
well if if if i just need to use that subset i i can get it processed . 
i actually got i think i got into it before . 
and then i thought i was doing the wrong thing . 
uhhuh . 
and i stopped . 
and it it shouldn ' t take that long to do . 
okay . 
right . 
okay . 
and you need only the males . 
so 
oh okay . 
so basically dave so for you to get your processing going you need the list of the uh 
well i guess it ' ll 
you ' ll you ' ll we ' ll need to get the segmentations . 
yeah . 
figure out whether we ' re using the new or the old from don . 
uhhuh . 
and then 
uh 
from that you need the from the segmentations you ' ll have the list of wavefiles that the short uh set is trained on . 
and then you ' ll need disk space . 
and once you ' ve got those things then you can start your processing . 
right ? 
yeah . 
okay . 
does this this 
it ' s sort of not very nice to use the small training set for another reason . 
which is that the you also are losing on again because you don ' t use all the data you have for one speaker . 
so the normalizations you compute for your training speakers will be uh crummier than they would in the large training set . 
so um i have to so to make it really a matching experiment i have to find 
uh i have to use short models that were trained on normalizations that were also only estimated on the short set . 
which is uh 
do you have this uh 
i think so . 
i ' ve i i have to check . 
in any case i could re train short models within a few hours actually at if i use machines at s r i . 
i wonder about that though . 
uhhuh . 
i mean because all we ' re doing the only reason we ' re using the short training set is is for speed . 
and there we ' re not really making any claims about using a smaller training set . 
yeah . 
so as long as we ' re not using any testing data from 
no but the thing is if if we used if we used the whole training set for normalizations then david would have to process much more data . 
yeah . 
which that ' s a that ' s one bottleneck for us . 
right ? 
in terms of 
oh you mean for for his normalizations . 
yeah . 
oh oh oh i ' m sorry . 
right . 
so you want to do the exact same thing . 
right . 
or else you ' ll have apples and oranges . 
yeah . 
so 
it doesn ' t make i don ' t think it makes that much of a difference . 
it ' s just this little detail that if you can take care of that then you should . 
uhhuh . 
i i think i have i have the models . 
i have i have 
um 
let ' s see um 
yeah and if not i can re train those models very quickly . 
oh there ' s there ' s one other issue . 
uh and that is that dave throws out speakers that have less than twelve seconds of training data . 
and he said there were a few in the macrophone set like that . 
so do we need to wait to find out who he ' s going to throw out ? 
so that we create a new set of short models that don ' t include those speakers . 
uh 
say this again . 
sorry i missed it . 
so in the problem is that if we proceed like we just described um when he goes to um create the new training data with his processing he throws out some speakers . 
so the two training sets won ' t be identical . 
yeah . 
he throws out some speakers that are that are very small . 
yeah have just a little bit . 
yeah i don ' t think it ' ll make a matter . 
yeah i think there was only a few 
okay . 
we thought to be the case . 
in fact i thought about throwing those out too . 
because when i heard how little speech there was for some of them i thought they can only hurt your models . 
because they ' re again their normalizations will be all all all over the map . 
yeah . 
right . 
and you won ' t get very very clean models from them anyhow . 
so 
so you think it ' s okay then ? 
yeah . 
in fact if if you want to do this uh to speed things up um you we can leave out the macrophone data altogether . 
that hurt 
actually 
oh no sorry . 
not in the short . 
then you have too little data . 
okay . 
sorry forget that . 
um 
when you use when you go to the large training set then leaving out macrophone actually sometimes helps you . 
because it ' s it ' s just not relevant to the to the meeting and or to conversational speech anyway . 
it ' s read . 
okay . 
yeah leave it out . 
and um in the event that i re train the short models 
um why don ' t you give me a list of the files that you throw out ? 
and i i ' ll throw them out too . 
right . 
and then we have complete completely identical training conditions . 
we 
right . 
actually you should be able to figure out dave . 
right ? 
once you know the segmentations uh who you ' re going to which speakers will get left out even before you run your processing . 
uhhuh . 
right ? 
the segmentations ? 
yeah the segmentations from don . 
but the segmentations are only they only affect the test set . 
once we 
oh . 
we ' re talking about the training speakers . 
uh right right right right right . 
no the training set he could go through right now and see how how long the 
right . 
right but i ' m just wondering how long it will take to get that information . 
um 
he already has the you already have the information . 
i i have i have it for for macrophone um already i think . 
right ? 
and um i think by tomorrow i ' ll have it for for the rest . 
uhhuh . 
okay all right . 
okay . 
okay . 
at that one maybe . 
uh 
been looking at synthesizers ? 
synthesizers ? 
you were looking at festival . 
yeah yeah i was doing something for the smartkom data collectioners . 
yeah . 
robert has taken his laptop back to germany so we needed a new synthesis machine . 
and we have now a sun workstation in the library which does the synthesis . 
and the festival speech system is running on 
sorry robert did what ? 
robert took what ? 
his laptop where uh which we used for the smartkom data collection for the synthesis . 
uhhuh . 
and so he took it to germany . 
and so we couldn ' t do any data collection . 
oh . 
is he gone now ? 
uh 
no he ' s just gone to a smartkom workshop . 
oh oh oh oh okay . 
and so we have now the sun in the library which can do that . 
uhhuh . 
and i looked into the f zero thing and talked to to liz . 
and it seems that it ' s quite what she wants . 
but we ' ll have to think about the the energy thing . 
uh what we want to do . 
right . 
this was a business about uh um coming up with something that that was purely prosodic . 
uhhuh . 
and so uh we ' re just going to use a pitch detector . 
drive a synthesizer . 
and since it doesn ' t have a hook in it for uh modifying energy we ' ll have a little box at the output that ' ll modify the energy . 
so 
uhhuh . 
uhhuh . 
okay . 
so rrrrr rrrrm . 
something like that . 
are you are you interfacing to that thing with the c plus plus routines ? 
or are you is there another interface that you use ? 
for for festival ? 
yeah . 
uh you can just use it from the 
yeah basically from the command line . 
and defining the phones whatever you want to have synthesized . 
oh . 
and give the f zero targets . 
and it saves it in a 
and then get gives out a a waveform . 
and i i want to manipulate the the waveform then . 
i see . 
oh that ' s neat . 
uhhuh . 
okay ? 
digits ? 
uh okay . 
okay so here we are . 
once again . 
once again . 
right . 
together . 
um so we haven ' t had a meeting for a while . 
and and probably won ' t have one next week . 
i think a number of people are gone . 
um so robert why don ' t you bring us up to date on where we are with e d u ? 
um 
uh in a in a smaller group we had uh talked and decided about continuation of the data collection . 
so fey ' s time with us is almost officially over . 
and she brought us some thirty subjects and collected the data . 
and ten dialogues have been transcribed . 
and can be looked at . 
if you ' re interested in that talk to me . 
um and we found another uh cogsci student who ' s interested in playing wizard for us . 
here we ' re going to make it a little bit more complicated for the subjects uh this round . 
she ' s actually suggested to look um at the psychology department students . 
because they have to partake in two experiments in order to fulfill some requirements . 
so they have to be subjected before they can actually graduate . 
and um 
we want to design it so that they really have to think about having some time . 
two days for example . 
to plan certain things and figure out which can be done at what time . 
and 
um sort of package the whole thing in a in a in a few more complicated um structure . 
that ' s for the data collection . 
as for smartkom i ' m the last smartkom meeting i mentioned that we have some problems with the synthesis . 
which as of this morning should be resolved . 
good . 
and so 
should be means they aren ' t yet . 
but but i think i have the info now that i need . 
plus johno and i are meeting tomorrow . 
so maybe uh uh when tomorrow is over we ' re done . 
and we ' ll never have to look at it again . 
maybe it ' ll take some more time . 
to be realistic . 
but at least we ' re we ' re seeing the end of the tunnel there . 
that was that . 
um 
the uh 
uh i don ' t think we need to discuss the formalism . 
that ' ll be done officially once we ' re done . 
um 
something happened in on eva ' s side with the p r m that we ' re going to look at today . 
and um 
we have a visitor from bruchsal from the international university . 
andreas i think you ' ve met everyone except nancy . 
sorry . 
yeah . 
hi hi . 
hi hi . 
and um 
so when you said andreas i thought you were talking about stolcke . 
now i know that we aren ' t . 
okay . 
andy you actually go by andy . 
right ? 
yeah . 
oh okay . 
because there is another andreas around . 
uh 
huh . 
so to avoid some confusion . 
that will be reuter ? 
yeah . 
oh okay . 
so my scientific director of the e m l is also the dean of the international university . 
one of his many occupations that just contributes to the fact that he is very occupied . 
and um 
the 
um he might tell us a little bit about what he ' s actually doing . 
and why it is somewhat related . 
and by uh using maybe some of the same technologies that we are using . 
and um was that enough of an update ? 
i think so . 
in what order shall we proceed ? 
okay . 
maybe you have your online 
uh 
yeah sure . 
um so i ' ve just been looking at um 
ack ! 
what are you doing ? 
yeah . 
okay . 
um 
i ' ve been looking at the p r m stuff . 
um 
so this is sort of like the latest thing i have on it . 
and 
i sort of constructed a couple of classes . 
like a user class a site class and and you know a time a route and then and a query class . 
and i tried to simplify it down a little bit . 
so that i can actually um look at it more . 
it ' s the same paper that i gave to jerry last time . 
um 
so basically i took out a lot of stuff a lot of the decision nodes . 
and then tried to 
the red lines on the um graph are the um relations between the different um classes . 
like a user has like a query . 
and then also has you know um reference slots to its preferences . 
um the special needs and you know money and the user interest . 
and so 
this is more or less similar to the flat bayes net that i have you know with the input nodes and all that . 
and 
so i tried to construct the dependency models . 
and 
a lot of these stuff i got from the flat bayes net . 
and what they depend on . 
and it turns out you know the c p t ' s are really big if i do that . 
so i tried to see how i can do um put in the computational nodes in between . 
and what that would look like in a p r m . 
and so i ended up making several classes . 
actually you know a class of with different attributes that are the intermediate nodes . 
and one of them is like time affordability money affordability site availability and the travel compatibility . 
and so some of these classes are 
some of these attributes only depend on stuff from say the user . 
or just from i don ' t know like the site . 
like um these here . 
it ' s only like user . 
but if you look at travel compatibility for each of these factors you need to look at a pair of you know what the um preference of the user is . 
versus you know what type of an event it is . 
or you know which form of transportation the user has . 
and whether you know the onsite parking matters to the user in that case . 
and that makes the scenario a little different in a p r m . 
because um then you have one user objects . 
and potentially you can have many different sites in in mind . 
and so 
for each of the site you ' ll come up with this rating of travel compatibility . 
and they all depend on the same users but different sites . 
and that makes a 
i ' m i i have been trying to see whether the p r m would make it more efficient if we do inferencing like that . 
and so 
i guess you end up having fewer number of nodes than in a flat bayes net . 
because otherwise you would 
well it ' s probably the same . 
but um 
no you would definitely have 
be able to re use like um all the user stuff . 
and not not having to recompute a lot of the stuff . 
because it ' s all from the user side . 
so if you changed sites you you can you know save some work on that . 
but 
you know in the case where it depends on both the user and the site then i ' m still having a hard time trying to see how um using the p r m will help . 
um so anyhow using those intermediate nodes then this this would be the class that represent the intermediate nodes . 
and that would basically it ' s just another class in the model . 
with you know references to the user and the site and the time . 
and then after you group them together this 
the dependencies would of the queries would be reduced to this . 
and so you know it ' s easier to specify the c p t and all . 
um so i think that ' s about as far as i ' ve gone on the p r m stuff . 
well 
right ? 
no . 
so you didn ' t yet tell us what the output is . 
the output . 
so what decisions does this make ? 
okay so it only makes two decisions in this model . 
and one is basically how desirable a site is . 
meaning um how good it matches the needs of a user . 
and the other is the mode of the visit . 
whether it ' s the e v a decision . 
um 
so instead of um doing a lot of you know computation about you know which one site it wants of the user wants to visit i ' ll come well try to come up with like sort of a list of sites . 
and for each site you know where how how well it fits . 
and basically a rating of how well it fits and what to do with it . 
so 
anything else i missed ? 
so that was pretty quick . 
she ' s uh uh eva ' s got a little write up on it . 
that uh probably gives the the details to anybody who needs them . 
um 
so 
the you you didn ' t look at all yet to see if there ' s anybody has a implementation ? 
no not yet . 
um 
okay . 
so one so one of the questions you know about these p r m ' s is 
uhhuh . 
uh we aren ' t going to build our own interpreter . 
so if if we can ' t find one then we uh go off and do something else and wait until one appears . 
uh so one of the things that eva ' s going to do over the next few weeks is see if we can track that down . 
uh 
the people at stanford write papers as if they had one . 
but um we ' ll see . 
so anyway so that ' s a a major open issue . 
if there is an interpreter it looks like you know what eva ' s got should run . 
and we should be able to actually um try to solve you know the problems . 
to actually take the data and do it . 
uh and we ' ll see . 
uh i actually think it is cleaner . 
and the ability to instantiate you know instance of people and sites and stuff um will help in the expression . 
whether the inference gets any faster or not i don ' t know . 
uh it wouldn ' t surprise me if it if it doesn ' t . 
uhhuh . 
you know it ' s the same kind of information . 
i think there are things that you can express this way which you can ' t express in a normal belief net . 
uh without going to some incredible hacking . 
of sort of rebuilding it on the fly . 
i mean the notion of instantiating your elements from the ontology and stuff fits this very nicely and doesn ' t fit very well into the extended belief net . 
so that was one of the main reasons for doing it . 
um 
i don ' t know . 
so uh people who have thought about the problem like robert 
it looked to me like if eva were able to come up with a you know value for each of a number of uh sites plus its e v a thing . 
that a travel planner should be able to take it from there . 
and you know with some other information about how much time the person has and whatever . 
and then plan a route . 
uhhuh um well first of all uh uh great looks much cleaner . 
nnn nnn 
certain certain beauty in it . 
so um if beauty is truth then uh we ' re in good shape . 
but 
the um 
as uh mentioned before we probably should look at the details . 
so if you have a write up then uh i ' d love to read it . 
uhhuh . 
and uh 
because um 
can you go all the way back to the the very top ? 
yeah . 
um uh these these when these are instantiated they take on the same values that we had before ? 
i can ' t really see the whole thing . 
or are they have they changed in a sense ? 
well i think i basically leave them to similar things . 
uhhuh . 
some of the things might that might be different maybe like are that the hours for the site . 
huh 
and eventually i meant that to mean whether they ' re open at this hour or not . 
and status would be you know more or less like whether they ' re under construction . 
uhhuh . 
and and or stuff like that . 
and the uh other question i would have is that presumably from the way the stanford people talk about it you can put the probabilities also on the relations . 
if 
which is the structural uncertainty ? 
yeah . 
yeah i that ' s 
that i think was actually in the previous the ubenth stuff . 
i don ' t remember whether they carried that over to this or not . 
huh 
uh structural uncertainty . 
it ' s sort of in the definition or in the in daphne ' s definition of a p r m . 
is that classes and relations . 
okay . 
and you ' re going to have c p t ' s over the classes and their relations . 
all right . 
more uncertainty or or 
uh 
i remember them learning when you know you don ' t know the structure for sure . 
i should say 
yeah . 
but i don ' t remember reading how you specify . 
right . 
yeah that would be exactly my question . 
to start with . 
yeah . 
well 
yeah . 
yeah . 
so uh the the plan is is when daphne gets back we ' ll get in touch . 
and supposedly um we ' ll actually get deep seriously connected to to their work . 
and 
yep . 
somebody will uh you know if it ' s a group meeting once a week probably someone will go down and whatever . 
so we ' ll actually figure all this out . 
okay . 
okay . 
then i think the long term perspective is is pretty clear . 
we get rocking and rolling on this again once we get a package . 
if when and how . 
then this becomes foregrounded . 
uhhuh . 
profiled . 
focused again . 
designated ? 
of course . 
and um 
until then we ' ll come up with a something that ' s that ' s way more complicated for you . 
right ? 
okay . 
because this was laughingly easy . 
right ? 
actually i had to take out a lot of the complicated stuff . 
because i i made it really complicated in the beginning . 
and jerry was like this is just too much . 
yeah so um 
you could from this go on and say suppose there ' s a group of people traveling together . 
and you wanted to plan something that somehow with some pareto optimal uh uh thing for 
that ' s good . 
that ' s definitely a job for artificial intelligence . 
uh or 
well that ' s not not even something humans 
except for humans can ' t really solve it either so . 
yeah . 
right . 
right . 
well that ' s the that would that would be a uh you could sell it as a 
yeah . 
okay uh you don ' t have to fight about this just give your preferences to the 
and then you can blame the computer . 
exactly . 
huh 
so 
but what does it uh would a potential result be to to split up and never talk to each other again ? 
you know . 
that should be one of them . 
yeah . 
yeah right . 
that ' d be nice . 
huh 
anyway . 
so so there there are some some uh you know uh elaborations of this . 
that you could try to put in to this structure . 
but i don ' t think it ' s worth it now . 
because we ' re going to see what what else uh what else we ' re going to do . 
anyway . 
but uh 
it ' s good yeah . 
and and there were a couple other ideas of of uh things for eva to look at . 
in in the interim . 
good then we can move on and see what andreas has got out his sleeve . 
or andy for that matter . 
okay so uh uh well thanks for having me here first of all . 
um so maybe just a a little background on on my visit . 
so uh i ' m not really involved in any project that ' s uh that ' s relevant to you uh at the moment . 
uh the the reason is really for me uh to have an opportunity to talk to some other researchers in the field . 
and and so i ' ll just sort of give you a real quick introduction to what i ' m working on . 
and um i just hope that you have some comments . 
or maybe you ' re interested in it to find out more . 
and and so i ' ll be uh happy to talk to you . 
and and uh i ' d also like to find out some more . 
and and maybe i ' ll just walk around the office . 
and 
and then and ask some some questions uh in a couple days . 
so i ' ll be here for uh tomorrow and then uh the remainder of uh next week . 
okay so um what i started looking at uh to begin with is just uh content management systems uh in general . 
so 
um uh what ' s uh sort of the state of the art there is to um uh you have a bunch of of uh documents or learning units or learning objects . 
um and you store meta data uh associate to them . 
so there ' s some international standards . 
like the i triple e uh there ' s an i triple e l o n standard . 
and um these fields are pretty straightforward you have uh author information you have uh size information format information and so on . 
uh but they ' re two uh fields that are um more interesting . 
one is uh you store keywords associated with the uh with the document . 
and one is uh you have sort of a um 
well what is the document about so it ' s some sort of taxonomic uh ordering of of the of the units . 
now if you sort of put on your semantic glasses uh you say well that ' s not all that easy . 
because there ' s an implicit um uh assumption behind that . 
is that uh all the users of this system share the same interpretation of the keyword and the same interpretation of uh whichever taxonomy is used . 
and uh 
i think that ' s a that ' s a very that ' s a key point of these systems . 
and they sort of always brush over this real quickly without really elaborating much of that . 
and uh as a matter of fact the only thing that apparently really works out so far are library ordering codes . 
which are very very coarse grain . 
so you have some like science biology and then 
but that ' s really all that we have at the moment . 
so i think there ' s a huge um uh need for improvement there . 
now what this uh a standard like this would give us is we could um sort of uh with a search engine just query uh different repositories all over the world . 
but we can ' t really 
um so what i ' m what i try to do is um to have um 
uh so so the scenario is the following you ' re working on some sort of project and you encounter a certain problem . 
now what what we have at our university quite a bit is that uh students um try to program a certain assignment for example . 
they always run into the same problems . 
uh and they always come running to us . 
and they ' ll say why ' s it not it ' s not working . 
and we always give out the same answer . 
so we thought well it ' d be nice to have a system that could sort of take care of this . 
and so what i want to build is basically a a smart f a q system . 
now what you uh need to do here is you need to provide some context information . 
which is more elaborate than i ' m looking for this and this and this keyword . 
so 
and i think that i don ' t need to tell you this . 
i ' m i ' m sure you have the same when when somebody utters a sentence in a certain uh context . 
it and and the same sentence in another context makes a huge difference . 
so i want to be able to model information like um so in the in the context of in the context of developing distributed systems of at a computer science school . 
um what kind of software is the person using . 
which homework assignment is he or she working on at the moment . 
um maybe what ' s the background of that student ' s . 
um which um which error message was encountered . 
so this sort of information i think should be transmitted uh when a certain document is retrieved . 
now 
um 
basically giving this um uh 
so we somehow need to have a formalized um way of writing this down basically . 
and that ' s where the shared interpretation of of certain terms and keywords comes in again . 
and using this and some some uh knowledge about the domain i think you can do some some simple inferences . 
like you know that when somebody ' s working about uh working on on servlets for example . 
he ' s using java because servlets are used are written in java . 
so some some inferences like that . 
now um using this you can infer more information . 
and you could then match this to the meta data of um off the documents you ' re you ' re searching against . 
so uh what i want to do is basically have some sort of um given these inputs . 
and then i can compute how many documents match . 
and use this as a metric in the search . 
now what i plan to do is i want to uh sort of do a uh uh try to improve the quality of the search results . 
and i want to do this by having a depth uh um um steepest descent approach . 
so if i knew which operating system the person was working on would this improve my search result . 
and and having uh uh a symbolic formalized model of this i could simply compute that . 
and find out which um which questions are worth um asking . 
and that ' s what i then propagate back to the user . 
and and sort of try to optimize the search in this way . 
now the big problem that i ' m facing right now is um it ' s fairly easy to hack up a system uh quickly that that works in the small domain . 
but the problem is obviously the scalability . 
and uh uh so robert was mentioning uh earlier today is that uh microsoft for example with their printer set up program has a bayesian network . 
which does exactly this . 
but there you face a problem that these are very hard to extend . 
and so uh what i ' m what i try to do is basically try to model this uh in a way that you could really combine uh knowledge from very different sources . 
and and um sort of looking into some of the ideas that the semantic web community uh came up with . 
trying to to have uh an approach how to integrate uh certain uh representation of certain concepts and also some computational rules . 
um what you can do with those . 
um 
what i ' m also looking into is a probabilistic approach into this . 
because document retrievals is a very fuzzy procedure . 
so it ' s probably not that easy to simply have a symbolic uh computational model . 
that that probably isn ' t expressive enough . 
so so that ' s another thing . 
um which i think you ' re also uh uh looking into right now . 
and then um uh sort of as an add on to this whole idea um uh that would be 
now depending on what the search engine or the content repository depending on which um uh which uh rules and which ontologies it it uses or basically its view of the world uh you can get very different results . 
so it might make a lot of sense to actually query a lot of different search engines . 
and there you could have an idea where you actually have sort of a a peer to peer approach . 
where we ' re all sort of carrying around our individual bookshelves . 
and um if you have a question about a homework it ' s probably makes sense to ask somebody who ' s in your class with you sort of the guru in the certain area . 
rather than going to some yahoo like uh search engine . 
so these are some of the just in a nutshell some of the ideas . 
and i think a lot of the even though it ' s a it ' s a very different domain but i think a lot of the um issues are are fairly similar . 
so 
okay . 
and so some of the i don ' t know how much you know about the larger heidelberg project . 
i are you 
uh i know yeah i know about it . 
so it seems like a lot of some of the issues are the same . 
it ' s like um you know the context based factors that influence how you interpret 
uhhuh uhhuh . 
um how to interpret 
in in this case in knowing wanting to know what kinds of things to ask . 
we ' ve kind of talked about that . 
but we haven ' t worried too much about that end of the discourse . 
uhhuh . 
but maybe you guys had that in the previous models . 
well in a in one one huh small difference in a in a way is that he doesn ' t have to come up with an answer . 
but he wants to point to the places 
yeah so so i ' m i ' m not i ' m not building an expert . 
documents that have the answers . 
uh i want to build a smart librarian basically . 
uhhuh . 
right . 
that can point you to the right reference . 
right . 
i don ' t want to compute the answer . 
so it ' s a little bit easier for me . 
well uh you have to still understand what the content says about itself and then match it to what you think the informational needs . 
uhhuh . 
uhhuh . 
so you also don ' t have to figure out what the content is . 
you ' re just taking the keywords as a topic text . 
i i assume that that there will be learning systems that that tag their their content . 
as 
okay . 
and um um 
right . 
and basically what i what i envision is that you rather than just supplying a bunch of keywords you could basically for for an f a q for example you could state sort of like a logic condition when this document applies . 
so this document explains how to set up your uh mail account on linux or something like this . 
uhhuh . 
so so something something very specific that you can then 
but the i think that the key point with these uh learning systems is that uh a learning system is only as good as uh the amount of content it it carries . 
huh . 
uhhuh . 
you can have the best learning system with the best search interface . 
if there ' s no content inside of it it ' s not very useful . 
so i think ultimately because um uh developing these these rules and these inference uh inferences i think is very costly . 
so um uh i think you must be able to reuse some some existing um domain domain information or or or ontologies that that uh other people wrote . 
and then try to integrate them . 
and then also search the entire web basically rather than just the small uh content management system . 
okay . 
uhhuh . 
so i think that ' s that ' s crucial for for the success of or 
so you ' re not 
i guess i ' m trying to figure out how how it maps to the kinds of things that we ' ve talked about in this group and actually associated groups . 
uhhuh . 
because some of us do pretty detailed linguistic analyses . 
and i ' m guessing that you you won ' t be doing that . 
no . 
okay . 
just checking . 
so okay 
huh 
no . 
so you take the query and and 
on the other hand uh framenet could well be useful . 
so do you know the framenet story ? 
um yeah . 
uh not not too much . 
okay . 
but uh 
oh that ' s another thing you might want to look into while you ' re here . 
i have a rough overview . 
because um you know the standard story is that keyworks keywords evoke frames and the frames may well give you additional keywords . 
or uh if you know that that that a a bunch of keywords uh indicate a frame then you can find documents that actually have the whole frame rather than just uh individual 
huh huh 
so there ' s a lot of stuff . 
and people are looking at that . 
most of the work here is just trying to get the frames right . 
there ' s linguists and stuff . 
and there ' s a lot of it . 
and they ' re they ' re busily working away . 
but there are some application efforts trying to exploit it . 
and this looks it seems to be that this is a place where you might be able to do that . 
yeah yeah . 
yeah i ' m sure i could learn a lot about um yeah just how to how to come up with these structures . 
huh 
because it ' s it ' s very easy to whip up something quickly . 
but it maybe then makes sense to to me but not to anybody else . 
and and if we want to share and integrate things they must well they must be well designed really . 
remember the uh prashant story ? 
right . 
the absolutely no no linguistic background person that the i u sent over here . 
right . 
and andreas and i tried to come up or we had come up actually with a uh with him working on an interface for framenet as it was back then that would do some of the work for this machine . 
right . 
yeah . 
which uh never got done because prashant found a happy occupation . 
yeah i know i mean it it he he did what what he did was much more sensible for him . 
which in the 
i think uh 
absolutely yeah . 
but so i ' m just saying the uh we had that idea . 
you know 
yeah . 
the idea was there yeah okay . 
uh to to exploit framenet there as well . 
yeah . 
huh 
and um 
yeah actually you guys never 
and srini ' s doing information extraction also . 
right ? 
right . 
with that framenet base . 
huh 
yeah . 
so you you guys never sent anybody else from i u . 
uhhuh . 
you were no 
except except prashant ? 
yeah . 
uh this was supposedly an exchange program . 
um 
and i we you know it ' s fine we don ' t care . 
but it just i ' m a little surprised that uh andreas didn ' t come up with anyone else he wanted to send . 
all right . 
uh i don ' t know i mean the uh 
i mean i had forgotten i to be honest with you i ' d totally forgotten we had a program . 
huh 
uh it ' s in the program ? 
uh i i think it ' s it ' s really the lack of students uh at i u at the moment . 
yeah . 
yeah . 
no no there was a whole there was a little contract signed . 
it was 
yeah . 
yeah yeah i think it ' s it ' s more the lack of of students really . 
and we have all these sponsors that are always sort of eager to get some teams . 
yeah i know . 
huh 
right . 
but 
right . 
well i mean if if i were a student i ' d love to come here rather than work for some german company or 
yeah . 
right . 
you are being recorded right now so beware . 
oh right ! 
well i didn ' t say anybody to anything to offend . 
well except for the sponsors maybe . 
but 
right . 
anyway . 
right so i that ' s that ' s one of the things that might be worth looking into while you ' re here . 
uhhuh . 
uh unfortunately srini who is heavily involved in daml and all this sort of stuff is himself out of town . 
uhhuh . 
well i ' ll go to the uh semantic web workshop uh in two weeks . 
right . 
and 
yeah for for some reason he ' s not doing that . 
yeah . 
i don ' t know why he 
well he had other things to do . 
oh i who knows ? 
yeah you ' ll see you ' ll certainly see a lot of the people there . 
the uh 
the other person i thought of is dan gildea . 
because he did some work on topic spotting 
yeah . 
statistical stuff . 
that would be a very good idea . 
um which is i mean you i mean i don ' t depending on how well you want to integrate with that end 
uhhuh . 
you know like taking the data and you said the learning systems that figure out 
we there ' s someone in icsi who actually has been working on has worked on that kind of stuff . 
and he ' s worked with frame net . 
so you could talk to him about you know both of those things at once . 
uhhuh uhhuh 
so 
and he just finished writing a draft of his thesis . 
so 
so uh who is that again ? 
dan gildea g i l d e a . 
and he ' s in one of the rooms on the fifth floor and stuff . 
who ? 
i can take you to his office . 
it ' s just around the corner . 
and 
okay great . 
huh 
well if you solve the problem hope you can do one for us too . 
all right was there anything else for this ? 
one of these times soon we ' re going to hear about construal . 
yeah i ' m sure . 
i have um i think it was november two thousand three or some 
no i had something in my calendar . 
oh okay right . 
um 
wait a second . 
that ' s a long way away . 
good thinking ! 
uh well maybe i can i can bribe my way out of this . 
so 
so i did some double checking . 
and it seems like spring break in two thousand one 
talk about changing the topic . 
no . 
well no but he ' s he ' s he ' s he ' s as you said he ' s like the state legislature he ' s trying to offer us bribes . 
at least this is a private meeting . 
right exactly . 
okay that ' s the link . 
this uh oh they refused the budget again ? 
is it so about citris ? 
yeah still nothing . 
uh this this this the 
we ' re uh involved in a literally three hundred million dollar uh program . 
uh with the state of california . 
and the state of california is now a month and a half behind its its legally required date to approve a budget . 
so the budget has not been approved . 
and two days ago there ' s two you know so two branches of legislature one branch approved it . 
uhhuh . 
and um 
yesterday day there was this uh uh i thought that the other branch would just approve it . 
but now there ' s actually a little back sliding to people who who approved it got flak from there . 
uh anyway . 
so um 
oh i have to tell you a wonderful story about this . 
okay ? 
and then we ' ll go . 
so i it turns out i wound up having lunch today with a guy named tom kalil . 
k i l l . 
k a l i l . 
and uh he now works at berkeley . 
in fact he ' s hired to run a lot of citris . 
even though we don ' t have the money they so they ' ve been hiring people right and left . 
so uh they think the money ' s coming . 
so and he was i think the chief staffer to clinton on technology matters . 
he was in the white house . 
i don ' t remember what he was saying . 
anyway like that . 
and is now doing all the politics for citris . 
but also has a uh a lot of interest in uh actually doing things for society . 
so digital divide and stuff like that . 
so that ' s interesting to me but maybe not to you . 
but the really interesting thing was he he he said something about you know i ' m interested in things that have high social multiplier . 
something that is of great social value . 
he said for example 
this was his only example . 
if you had a adult literacy program that was as good as an individual tutor . 
and as compelling as a video game . 
then that would have a huge social impact . 
i said oh great that ' s a good problem to work on . 
anyway so it was nice that uh he ' s got this view of a that ' s what you should try to do and b uh language would be a good way to do it . 
so that ' s 
huh definitely . 
so anyway that ' s the end of the story . 
but for adults and not for the children . 
this was 
yeah i didn ' t push him on the on the child thing . 
uhhuh . 
but uh 
you know again if if you if you 
oh . 
um 
and this was this was literacy . 
which actually is somewhat different problem . 
uhhuh . 
maybe easier . 
i don ' t know . 
so this is reading rather than teaching . 
another project we started on and and didn ' t get funded for was uh to try to build an automatic tutoring program for kids whose first language wasn ' t english . 
which is like half the school population in california . 
something like that . 
isn ' t it ? 
uhhuh . 
yeah . 
so 
enormous problem in california . 
and the idea was if we ' re so smart about language understanding and speech understanding couldn ' t we build uh programs that would be tutors for the kids . 
we think we could . 
anyway so so but this is a slightly different problem . 
uhhuh . 
and 
um 
i know none of us have the spare time to look at it right now . 
but it it ' s it ' s interesting . 
and i may um talk to him some more about is somebody already doing this and stuff like that . 
so anyway that was that was today ' s little story . 
huh 
okay so i i did manage to get pull my head out of the sling by sidetracking into citris . 
no no . 
but uh or temporarily putting it out of the sling . 
right . 
but i i ' ll volunteer to put it right back in by stating that i am uh among some other things in the process of writing up stuff that we have been discussing at our daily meetings . 
yeah . 
and also revising 
thanks for all the comments . 
the the original construal proposal . 
and if i put one and one together i may end up with a number that ' s greater than one and that i i can potentially present once you get back . 
greater than two ? 
you ' re good . 
nnn sometimes you know the sum is not uh less than the 
uh right right . 
right . 
right . 
anyway yeah so okay so that ' d be great . 
but i ' d i think it ' s it ' s time again . 
right ? 
absolutely yeah . 
yeah okay . 
but um and hopefully all sidetracking um other things will have disappeared soon . 
good . 
yep . 
done ? 
are you doing something ? 
okay then i guess i ' m doing something . 
so um 
so basically the result of much thinking since the last time we met um but not as much writing um is a sheet that i have a lot of like thoughts and justification of comments on . 
but i ' ll just pass out as is right now . 
so um 
here . 
if you could pass this around . 
and there ' s two things . 
and so one on one side is on one side is a sort of the revised sort of updated semantic specification . 
um 
and the other side is um sort of a revised construction formalism . 
the 
wait . 
this is just one sheet right ? 
uh . 
it ' s just one sheet . 
just one sheet . 
it ' s just a nothing else . 
okay . 
front back . 
um 
enough to go around ? 
okay . 
and in some ways it ' s it ' s it ' s very similar to 
there are very few changes in some ways from what we ' ve um uh done before . 
but i don ' t think everyone here has seen all of this . 
so uh i ' m not sure where to begin . 
um as usual the disclaimers are there are all these things are 
it ' s only slightly more stable than it was before . 
uhhuh . 
and um after a little bit more discussion and especially like keith and i i have more linguistic things to settle in the next few days um it ' ll probably change again some more . 
yeah . 
um maybe i will 
let ' s start let ' s start on number two actually on the notation . 
um because that ' s 
i ' m thinking possibly a little more familiar to um to people . 
okay so the top block is just sort of a sort of abstract 
it ' s sort of like um listings of the kinds of things that we can have . 
and certain things that have um changed have changed back to this . 
there there ' s been a little bit of um going back and forth . 
but basically obviously all constructions have some kind of name . 
i forgot to include that you could have a type included in this line . 
what i was going to 
so something like um 
right . 
well there ' s an example . 
the textual example at the end has clausal construction . 
so 
um just to show it doesn ' t have to be beautiful latex . 
it could be you know simple old text as well . 
um there are a couple of 
uh these three have various ways of doing certain things . 
so i ' ll just try to go through them . 
so they could all have a type at the beginning . 
um and then they say the key word construction . 
oh i see . 
and they have some name . 
so so the current syntax is if it if there ' s a type it ' s before 
yeah right . 
okay that ' s fine . 
okay and then it has a block that is constituents . 
and as usual i guess all the constructions all the examples here have only um tsk one type of constituent . 
that is a constructional constituent . 
i think that ' s actually going to turn out to be certainly the most common kind . 
but in general instead of the word construct here you might have meaning or form as well . 
okay ? 
so if there ' s some element that doesn ' t that isn ' t yet constructional in the sense that it maps form and meaning . 
okay . 
um the main change with the constructs which each of which has um the key word construct and then some name and then some type specification is that it ' s 
it ' s it ' s often sometimes the case in the first case here that you know what kind of construction it is . 
so for example whatever i have here is going to be a form of the word throw . 
or it ' s going to be a form of the word you know i don ' t know happy or something like that . 
or you know it ' ll be a specific word . 
or maybe you ' ll have the type . 
you ' ll say i need a uh spatial relation phrase here . 
or i need a directional specifier here . 
uh you could have a a actual type here . 
um or you could just say in the second case that you only know the meaning type . 
so a very common example of this is that you know in directed motion the first person to do something should be an agent of some kind . 
often a human . 
right ? 
so if i you know um uh run down the street then i 
i i run down the street . 
it ' s typed uh i . 
meaning category is what ' s there . 
the the new kind is this one that is sort of a pair . 
and um 
sort of skipping fonts and whatever . 
the idea is that sometimes there are um general constructions that you know that you ' re going to need . 
it ' s it ' s the equivalent of a noun phrase or a prepositional phrase or something like that there . 
uhhuh . 
and usually it has formal um considerations that will go along with it . 
uhhuh . 
and then uh you might know something much more specific depending on what construction you ' re talking about . 
about what meaning what specific meaning you want . 
so the example again at the bottom which is directed motion . 
you might need a nominal expression to take the place of you know um the big you know the big the tall dark man you know walked into the room . 
uhhuh . 
but because of the nature of this particular construction you know not just that it ' s nominal of some kind . 
but in particular that it ' s some kind of animate nominal . 
and which will apply just as well to like you know a you know a simple proper noun . 
or to some complicated expression . 
um 
so i don ' t know if the syntax will hold but something that gives you a way to do both constructional and meaning types . 
so 
okay then i don ' t think the um 
at least 
yeah none of these examples have anything different for formal constraints . 
but you can refer to any of the um sort of available elements and scope . 
right which here are the constructs to say something about the relation . 
and i think if you if you compare like the top block and the textual block um we dropped like the little f . subscript . 
the f . subscripts refer to the form piece of the construct . 
good . 
and i think that um in general it ' ll be unambiguous . 
like if you were giving a formal constraint then you ' re referring to the formal pole of that . 
so so by saying if i just said name one then that means name one formal . 
and we ' re talking about formal which which makes sense . 
uh there are certain times when we ' ll have an exception to that . 
in which case you could just indicate here i mean the meaningful for some reason . 
right . 
or actually it ' s more often that only to handle this one special case of you know george and jerry walk into the room in that order . 
so we have a few funny things where something in the meaning might refer to something in the form . 
uhhuh . 
but but we ' re not going to really worry about that for right now . 
and there are we can be more specific if we have to later on . 
okay and so in terms of the the relations . 
you know as usual they ' re before and ends . 
i should have put an example in of something that isn ' t an interval relation . 
but in form you might also have a value binding . 
you know you could say that um you know name one dot you know number equals you know a plural or something like that . 
uhhuh . 
there are certain things that are attribute value similar to the bindings below . 
but i mean they ' re just usually they ' re going to be value value fillers right ? 
okay and then again semantic constraints here are just are just bindings . 
there was talk of changing the name of that . 
and johno and i i you you and i can like fight about that if you like . 
but about changing it to semantic effects . 
which i thought was a little bit too order biased . 
well 
and semantic bindings . 
which i thought might be too restrictive in case we don ' t have only bindings . 
and so it was an issue whether constraints um there were some linguists who reacted against constraints saying oh if it ' s not used for matching then it shouldn ' t be called a constraint . 
but i think we want to be uncommitted about whether it ' s used for matching or not right ? 
because there are i think we thought of some situations where it would be useful to use whatever the bindings are for . 
actual you know sort of like modified constraining purposes . 
well you definitely want to de couple the formalism from the parsing strategy . 
yeah . 
so that whether or not it ' s used for matching or only for verification i 
yeah yeah . 
it ' s used shouldn ' t matter right . 
uhhuh . 
for sure . 
uhhuh . 
i mean i don ' t know what uh term we want to use . 
but we don ' t want to 
yeah uh there was one time when when hans explained why constraints was a misleading word for him . 
yep . 
and i think the reason that he gave was similar to the reason why johno thought it was a misleading term . 
which was just an interesting coincidence . 
um but uh 
and so i was like okay well both of you don ' t like it . 
fine we can change it . 
it ' s it ' s gone . 
but i i i ' m starting to like it again . 
so that ' s why that ' s why i ' ll stick with it . 
but 
so 
well you know what ? 
if you have an if then phrase do you know what the then phrase is called ? 
what ? 
uh a consequent ? 
yeah . 
yeah but it ' s not an if then . 
i know . 
anyway so the other the other strategy you guys could consider is when you don ' t know what word to put you could put no word . 
no but 
uhhuh . 
just meaning . 
okay ? 
yeah . 
and then let 
yeah that ' s true . 
so that ' s why you put semantic constraints up top and meaning bindings down down here ? 
oh oops ! 
no that was just a mistake of cut and paste from when i was going with it . 
okay . 
okay . 
so i ' m sorry . 
i didn ' t mean that one ' s an unintentional . 
so this should be semantic and 
sometimes i ' m intentionally inconsistent . 
because i ' m not sure yet . 
here i actually it was just a mistake . 
so this definitely should be semantic constraints down at the bottom . 
sure . 
yeah . 
okay . 
well unless i go with meaning . 
but i mean i kind of like meaning better than semantic . 
or 
oh whatever . 
but i think there ' s vestiges of other people ' s biases . 
or 
like 
right . 
minor problem . 
minor point . 
extremely . 
okay . 
okay um 
so i think the middle block doesn ' t really give you any more information than the top block . 
and the bottom block similarly only just you know all it does is illustrate that you can drop the subscripts and and that you can drop the um uh that you can give dual types . 
oh one thing i should mention is about designates . 
i think i ' m actually inconsistent across these as well . 
so um strike out the m . subscript on the middle block . 
uhhuh . 
so basically now um this is actually this little change actually goes along with a big linguistic change . 
which is that designates isn ' t only something for the semantics to worry about now . 
good . 
so we want designates to actually know one of the constituents which acts like a head in some respects . 
but is sort of um really important for say composition later on . 
so for instance if some other construction says you know are you of type is this part of type whatever um the designates tells you which sort of part is the meaning part . 
okay so if you have like the big red ball you know you want to know if there ' s an object or a noun . 
well ball is going to be the designated sort of element of that kind of phrase . 
huh . 
um 
there is a slight complication here which is that when we talk about form it ' s useful sometimes to talk about um to talk about there also being a designated object . 
and we think that that ' ll be the same one right . 
so the ball is the head of the phrase . 
the the um big red ball . 
and the entity denoted by the word ball is sort of the semantic head in some ways of of this sort of um interesting larger element . 
and the 
yeah . 
and there ' s uh there ' s some cases where the grammar depends on some form property of the head . 
uhhuh . 
yeah . 
and and this enables you to get that if i understand you right . 
yeah . 
right right . 
that ' s the idea . 
yeah . 
yeah yeah . 
and uh you might be able to say things like if the head has to go last in a head final language you can refer to the head as a the you know the formal head as opposed to the rest of the form having to be at the end of that decision . 
right . 
so that ' s a useful thing . 
so that you can get some internal structural constraints in . 
okay so that all looks good . 
let me 
oh oh 
i don ' t know . 
were you finished ? 
um there was a list of things that isn ' t included . 
but you you can you can ask a question . 
that might it . 
okay . 
so if i understand this the 
aside from uh construed and all that sort of stuff the the differences are mainly that we ' ve gone to the possibility of having form meaning pairs for a type . 
uhhuh . 
or actually gone back to . 
right . 
if we go back far enough 
well except for their construction meaning . 
so it ' s not clear that 
uh 
well right now it ' s a uh construction type and meaning type . 
so i don ' t know what a form type is . 
oh i see . 
yeah yeah yeah . 
i ' m sorry . 
yeah . 
you ' re right . 
a construction type . 
uh that ' s fine . 
right . 
but it um 
well and a previous um you know version of the notation certainly allowed you to single out the meaning bit by it . 
so you could say construct of type whatever designates something . 
yeah . 
but that was mostly for reference purposes . 
just to refer to the meaning pole . 
i don ' t think that it was often used to give an extra meaning type constraint on the meaning . 
which is really what we want most of the time i think . 
uhhuh . 
um 
i i don ' t know if we ' ll ever have a case where we actually 
if there is a form category constraint you could imagine having a triple there that says you know that ' s kind of weird . 
no no no i don ' t think so . 
i think that you ' ll you ' ll do fine . 
i 
in fact these are um 
as long as as mark isn ' t around these are form constraints . 
so a nominal expression is uh the fact that it ' s animate is semantic . 
the fact that it ' s uh a nominal expression i would say on most people ' s notion of of you know higher form types this this is one . 
uhhuh . 
yeah . 
right right . 
yeah yeah . 
and i think that ' s just fine . 
which is fine yeah . 
it ' s that now um i ' m mentioned this . 
yeah . 
i i don ' t know if i ever explained this . 
but the point of um 
i mentioned in the last meeting the point of having something called nominal expression is um 
because it seems like having the verb subcategorize for you know like say taking as its object just some expression which um designates an object or designates a thing or whatever um that leads to some syntactic problems basically . 
so you want to you know you sort of have this problem like okay well i ' ll put the word uh let ' s say the word dog . 
you know and that has to come right after the verb . 
uhhuh . 
because we know verb meets its object . 
and then we have a construction that says oh you can have the preceding a noun . 
and so you ' d have this sort of problem that the verb has to meet the designatum . 
right . 
and you could get you know the kicked dog or something like that meaning kicked the dog . 
right . 
um so you kind of have to let this phrase idea in there . 
but 
that i i have no problem with it at all . 
yeah . 
yeah . 
i think it ' s fine . 
right 
you may be you may not be like everyone else in in berkeley . 
yeah . 
yeah . 
but that ' s okay . 
i mean we we we sort of thought we were getting away with uh with a 
uh we don ' t mind either . 
so 
i mean this is not reverting to the x . bar theory of of phrase structure . 
right . 
but uh 
right . 
i just know that this is like we didn ' t originally have in mind that uh that verbs would subcategorize for a particular sort of form . 
uhhuh . 
but they do . 
um 
but they does . 
well there ' s an alternative to this . 
at least in english . 
which is um the question was did we want directed motion 
yeah . 
which is an argument structure construction 
yeah . 
uhhuh . 
did we want it to worry about um anything more than the fact that it you know has semantic 
you know it ' s sort of frame based construction . 
so one option that you know keith had mentioned also was like well if you have more abstract constructions such as subject predicate basically things like grammatical relations . 
uhhuh . 
those could intersect with these . 
in such a way that subject predicate or subject predicate subject verb you know verb object would require that those things that fill a subject and object are nom expressions . 
right . 
and that would be a little bit cleaner in some way . 
but you know for now i mean 
yeah . 
but it it ' s yeah just moving it moving the the the constraints around . 
uh you know . 
moving it to another place right . 
yeah . 
okay so that ' s 
but there does basically the point is there has to be that constraint somewhere right ? 
right . 
so 
yeah . 
and so that was the 
robert ' s not happy now ? 
no . 
oh okay . 
okay and sort of going with that is that the designatum also now is a pair . 
yes . 
instead of just the meaning . 
uhhuh . 
and that aside from some terminology that ' s basically it . 
right . 
i just want to i ' m i ' m asking . 
yep . 
uhhuh . 
yeah . 
yeah . 
um the sort of the un addressed questions in this um definitely would for instance be semantic constraints we talked about . 
yeah . 
here are just bindings . 
but 
right . 
we might want to introduce mental spaces . 
you know there ' s all these things that we don ' t 
the whole the mental space thing is clearly not here . 
right . 
so there ' s going to be some extra you know definitely other notation we ' ll need for that which we skip for now . 
uhhuh . 
by the way i do want to get on that as soon as robert gets back . 
uh 
yeah . 
okay . 
so uh the the mental space thing . 
uhhuh . 
um obviously construal is a is a is a big component of that . 
so this probably not worth trying to do anything till he gets back . 
but sort of as soon as he gets back i think um we ought to 
uhhuh . 
uhhuh . 
so what ' s the what ' s the time frame ? 
i forgot again when 
you ' re going away for how long ? 
just uh as a sort of a mental bridge i ' m not i ' m skipping fourth of july . 
okay . 
so uh right afterwards i ' m back . 
okay . 
what ? 
you ' re missing like the premier american holiday ? 
what ' s the point of spending a year here ? 
uh i ' ve had it often enough . 
so anyway 
well he he went to college here . 
oh yeah i forgot . 
oops sorry . 
yeah . 
okay . 
and furthermore it ' s well worth missing . 
not in california . 
yeah that ' s true . 
yes . 
i like i i like spending fourth of july in other countries whenever i can . 
right . 
um 
okay so that ' s great . 
construal . 
okay so 
oh so there was one question that came out . 
i hate this thing . 
sorry . 
um which is 
so something like past which you know we think is a very simple uh we ' ve often just stuck it in as a feature . 
right . 
you know oh this event takes place before speech time okay is what this means . 
right . 
um it ' s often thought of as it is also considered a mental space . 
right . 
you know by you know lots of people around here . 
right . 
so there ' s this issue of well sometimes there are really exotic explicit space builders that say in france blah blah blah . 
uhhuh . 
and you have to build up you you would imagine that would require you you know to be very specific about the machinery . 
whereas past is a very conventionalized one . 
and we sort of know what it means . 
but it we doesn ' t don ' t necessarily want to you know unload all the notation every time we see that it ' s past tense . 
right . 
so you know we could think of our uh just like x . schema walk refers to this complicated structure past refers to you know a certain configuration of this thing with respect to it . 
i think that ' s exactly right . 
so so we ' re kind of like having our cake and eating it . 
you know having it both ways right ? 
yeah . 
so 
yeah no i think i think that we ' ll have to see how it works out when we do the details . 
uhhuh . 
but my intuition would be that that ' s right . 
uhhuh . 
yeah okay . 
do you want to do the same for space ? 
sorry ? 
space . 
space ? 
here . 
now . 
oh oh oh oh instead of just time ? 
yeah yeah yeah . 
uhhuh . 
same thing . 
so there are very conventionalized like deictic ones right ? 
and then i think for other spaces that you introduce you could just attach 
whatever . 
you could build up an appropriately uh appropriate structure according to the the sentence . 
huh . 
yeah . 
huh . 
well this this basically would involve everything you can imagine to fit under your c . dot something . 
yeah . 
you know where where it ' s contextually dependent . 
right . 
uhhuh . 
what is now ? 
what was past ? 
what is in the future ? 
where is this ? 
what is here ? 
what is there ? 
what is 
uhhuh . 
yeah . 
so time and space . 
um we ' ll we ' ll get that on the other side a little like very minimally . 
there ' s a sort there ' s a slot for setting time and setting place . 
good . 
and 
you know you could imagine for both of those are absolute things you could say about the time and place . 
and then there are many more interestingly linguistically anyway there are relative things that you know you relate the event in time and space to where you are now . 
if there ' s something a lot more complicated like or so hypothetical or whatever then you have to do your job . 
uhhuh . 
like or somebody ' s job anyway . 
yeah . 
i ' m going to point to at random . 
yeah . 
i mean i ' m i ' m curious about how much of the mental 
i mean i ' m not sure that the formalism sort of the grammatical side of things is going to have that much going on in terms of the mental space stuff . 
you know um basically all of these so - called space builders that are in the sentence are going to sort of 
i think of it as sort of giving you the coordinates of you know 
assuming that at any point in discourse there ' s the possibility that we could be sort of talking about a bunch of different world scenarios whatever and the speaker ' s supposed to be keeping track of those the um the construction that you actually get is just going to sort of give you a cue as to which one of those that you ' ve already got going um you ' re supposed to add structure to . 
uhhuh . 
so in france uh watergate wouldn ' t have hurt nixon or something like that . 
um well you say all right i ' m supposed to add some structure to my model of this hypothetical past france universe or something like that . 
the information in the sentence tells you that much . 
but it doesn ' t tell you like exactly what it what the point of doing so is . 
so for example depending on the linguistic uh context it could be 
like the question is for example what does watergate refer to there ? 
does it you know does it refer to um 
if you just hear that sentence cold the assumption is that when you say watergate you ' re referring to a watergate like scandal as we might imagine it happening in france . 
but in a different context oh you know if nixon had apologized right away it wouldn ' t you know watergate wouldn ' t have hurt him so badly in the u . s . 
and in france it wouldn ' t have hurt him at all . 
now we ' re now that watergate we ' re now talking about the real one . 
they ' re real right . 
and the would sort of it ' s a sort of different dimension of hypothe - theticality right ? 
i see right . 
we ' re not saying what ' s hypothetical about this world . 
in the first case hypothetically we ' re imagining that watergate happened in france . 
huh . 
in the second case we ' re imagining hypothetically that nixon had apologized right away . 
uhhuh . 
right . 
or something right ? 
so a lot of this isn ' t happening at the grammatical level . 
uh um and so 
correct . 
uhhuh . 
i don ' t know where that sits then . 
huh . 
sort of the idea of sorting out what the person meant . 
it seems like um the grammatical things such as the auxiliaries that you know introduce these conditionals whatever give you sort of the the most 
uhhuh . 
those we i think we can figure out what the possibilities are right ? 
uhhuh . 
there are sort of a relatively limited number . 
and then how they interact with some extra thing like in france or if such and such that ' s like there are certain ways that they they can 
yeah . 
you know one is a more specific version of the general pattern that the grammar gives you . 
i think . 
yeah . 
but you know whatever . 
we we ' re 
yeah in the short run all we need is a enough mechanism on the form side to get things going . 
uhhuh . 
yeah . 
uh i uh you you 
but the whole point of the whole point of what fauconnier and turner have to say about uh mental spaces and blending and all that stuff is that you don ' t really get that much out of the sentence . 
you know there ' s not that much information contained in the sentence . 
it just says here . 
add this structure to this space . 
and exactly what that means for the overall ongoing interpretation is quite open . 
an individual sentence could mean a hundred different things depending on quote what the space configuration is at the time of utterance . 
uhhuh . 
uhhuh . 
and so somebody ' s going to have to be doing a whole lot of work but not me i think . 
well 
i think that ' s right . 
oh i yeah i uh uh i think that ' s not i 
i don ' t think it ' s completely right . 
i mean in fact a examples you gave in did constrain the meaning 
the form did constrain the meaning . 
yeah . 
and so um it isn ' t uh 
sure but like what what was the point of saying that sentence about nixon and france ? 
that is not there is nothing about that in the in the sentence really . 
that ' s okay . 
we usually don ' t know the point of the sentence at all . 
yeah . 
but we know what it ' s trying to say . 
we we know that it ' s what predication it ' s setting up . 
yeah . 
yeah . 
but but bottom line i agree with you . 
yeah . 
that ' s all . 
yeah . 
that that that we ' re not expecting much out of the uh 
purely linguistic cues right ? 
uh the purely form cues yeah . 
so 
huh . 
and um i mean you ' re you ' re the linguist . 
but uh it seems to me that these we we you know we ' ve talked about maybe a half a dozen linguistics theses in the last few minutes or something . 
yeah yeah . 
yeah i mean 
yeah . 
oh yeah . 
uh i i mean that that ' s my feeling that that these are really hard uh problems that decide exactly what what ' s going on . 
uhhuh . 
yeah . 
yeah . 
okay . 
okay so um one other thing i just want to point out is there ' s a lot of confusion about the terms like profile designate focus et cetera et cetera . 
uhhuh . 
uh right right right . 
um for now i ' m going to say like profile s often used 
like two uses that come to mind immediately . 
one is in the traditional like semantic highlight of one element with respect to everything else . 
so hypotenuse you profiled this guy against the background of the right right triangle . 
uhhuh . 
okay . 
and the second use um is in framenet . 
it ' s slightly different . 
oh i was asking hans about this . 
they use it to really mean um this in a frame this is the profiles on the these are the ones that are required . 
so they have to be there or expressed in some way . 
which which i ' m not saying one and two are mutually exclusive . 
but they ' re they ' re different meanings . 
right . 
uhhuh . 
so the closest thing 
so i was thinking about how it relates to this notation . 
for us um 
okay so how is it 
so designate 
does that is that really what they mean in in 
framenet ? 
framenet . 
i didn ' t know that . 
yeah yeah . 
i i mean i i was a little bit surprised about it too . 
i knew that 
yeah . 
i thought that that would be something like 
there ' s another term that i ' ve heard for that thing . 
right okay . 
but they i mean uh well at least hans says they use it that way . 
and 
well i ' ll check . 
and maybe he ' s wrong . 
anyway so 
i think the the designate that we have in terms of meaning is really the highlight this thing with respect to everything else okay ? 
right . 
so this is what what it means . 
but the second one seems to be useful . 
but we might not need a notation for it . 
we don ' t have a notation for it . 
but we might want one . 
so for example we ' ve talked about if you ' re talking about the lexical item walk . 
you know it ' s an action . 
well it also has this idea it carries along with it the idea of an actor . 
or somebody ' s going to do the walking . 
or if you talk about an adjective red it carries along the idea of the thing that has the property of having color red . 
so we used to use the notation with for this . 
and i think that ' s closest to their second one . 
right . 
so i don ' t yet know i have no commitment as to whether we need it . 
it might be 
it ' s the kind of thing that a parser might want to think about whether we require 
you know these things are like it ' s semantically part of it . 
no no . 
well uh critically they ' re not required syntactically . 
often they ' re presupposed and all that sort of stuff . 
right . 
right right yeah um definitely . 
so um 
in was a good example . 
if you walk in like well in what ? 
you know like you have to have the so so it ' s only semantically is it 
right there ' s 
it is still required say by simulation time though . 
to have something . 
right . 
so it ' s that i meant the idea of like that the semantic value is filled in by simulation . 
i don ' t know if that ' s something we need to to to like say ever as part of the requirement . 
or the construction . 
or not . 
we ' ll we ' ll again defer . 
or i mean or or uh 
so the 
have it construed . 
is that the idea ? 
yeah yeah . 
just point at robert . 
whenever i ' m confused just point to him . 
right . 
you tell me . 
it ' s it ' s his thesis right ? 
okay . 
anyway 
right yeah this is going to be a 
you ' re right this is a bit of in a mess . 
and we still have emphasis as well or stress or whatever . 
okay well we ' ll get uh uh i we have thoughts about those as well . 
yeah . 
great . 
um 
i i would 
some of this is just like my you know by fiat . 
i ' m going to say this is how we use these terms . 
i you know there ' s lots of different ways in the world that people use it . 
yeah . 
i that ' s fine . 
i think that um the other terms that are related are like focus and stress . 
so 
uhhuh . 
i think that the way i we would like to think uh i think is focus is something that comes up in i mean lots of 
basically this is the information structure . 
okay it ' s like uh it ' s not it might be that there ' s a syntactic uh device that you use to indicate focus . 
uhhuh . 
or that there are things like you know 
i think keith was telling me things toward the end of the sentence post verbal tend to be the focused focused element . 
huh . 
the new information . 
you know if i i walked into the room you tend to think that whatever into the room is sort of like the more focused kind of thing . 
uhhuh . 
yeah . 
and when you uh uh you have stress on something that might be you know a cue that the stressed element or for instance the negated element is kind of related to information structure . 
so that ' s like the new the sort of like import or whatever of of this thing . 
uh so so i think that ' s kind of nice to keep focus being an information structure term . 
stress 
i and then there are different kinds of focus that you can bring to it . 
so um like stress stress is kind of a pun on you might have like whatever like um accent kind of stress . 
uhhuh . 
and that ' s just a 
uh we ' ll want to distinguish stress as a form device . 
you know like oh high volume or whatever . 
yeah . 
um 
uh and distinguish that from it ' s effect . 
which is oh the kind of focus we have is we ' re emphasizing this value often as opposed to other values right . 
so focus carries along a scope . 
like if you ' re going to focus on this thing and you want to know it sort of evokes all the other possibilities that it wasn ' t . 
um so my classic my now classic example of saying oh he did go to the meeting . 
uhhuh . 
yeah . 
that was my way of saying as opposed to you know oh he didn ' t or there was a meeting . 
i think that was the example that was caught on by the linguists immediately . 
yeah . 
yeah . 
and so um the like if you said he 
you know there ' s all these different things that if you put stress on a different part of it then you ' re focusing whatever on uh 
uhhuh . 
he walked to the meeting as opposed to he ran . 
or he did walk to the meeting as opposed to he didn ' t walk you know . 
uhhuh . 
so we need to have a notation for that . 
which um 
i think that ' s still in progress . 
so sort of i ' m still working it out . 
but it did one one implication it does have for the other side which we ' ll get to in a minute is that i couldn ' t think of a good way to say here are the possible things that you could focus on . 
because it seems like any entity in any sentence you know or any meaning component of you know all the possible meanings you could have any of them could be the subject of focus . 
huh . 
but i think one the one thing you can schematize is the kind of focus right ? 
so for instance you could say it ' s the the tense on this as opposed to um the the action okay . 
or it ' s uh it ' s an identity thing or a contrast with other things . 
or stress this value as opposed to other things . 
so um 
it ' s it is kind of like a profile profile background thing . 
but i i can ' t think of like the limited set of possible meanings that you would that you would 
light up with focus yeah . 
light highlight . 
as opposed to other ones . 
so it has some certain complications for the uh uh later on . 
i mean uh the best thing i can come up with is that information has a list of focused elements . 
for instance you oh one other type that i forgot to mention is like query elements . 
and that ' s probably relevant for the like where is you know the castle kind of thing . 
uhhuh . 
because you might want to say that um location or certain w . h . words bring you know sort of automatically focus in a you know i don ' t know the identity of this thing kind of way on certain elements . 
so 
okay anyway so that ' s there are there are many more things that are that are sort of like a little bit unstable about the notation . 
but it ' s most i think it ' s this is you know the current current form . 
other things we didn ' t totally deal with um 
well we ' ve had a lot of other stuff that keith and i have them working on in terms of like how you deal with like an adjective . 
oh there ' s a bunch . 
yeah . 
you know a a nominal expression . 
and um 
yeah . 
i mean we should have put an example of this . 
and we could do that later . 
yeah . 
but i think the inherently like the general principles still work though . 
that um we can have constructions that have sort of constituent structure in that there is like you know for instance one 
uh you know they they have constituents right ? 
so you can like nest things when you need to . 
but they can also overlap in a sort of flatter way . 
so if you don ' t have like a lot of grammar experience then like this this might you know be a little opaque . 
but you know we have the properties of dependency grammars and some properties of constituents constituent based grammar . 
so that ' s i think that ' s sort of the main thing we wanted to aim for . 
uhhuh . 
and so far it ' s worked out okay . 
good . 
so 
okay . 
i can say two things about the 
yes . 
maybe you want to forget stress . 
this my 
as a word ? 
no as as just don ' t don ' t think about it . 
as a 
what ' s that ? 
sorry . 
if 
canonically speaking you can if you look at a a curve over sentence you can find out where a certain stress is . 
and say hey that ' s my focus exponent . 
uhhuh . 
right . 
it doesn ' t tell you anything what the focus is . 
uhhuh . 
if it ' s just that thing 
or the constituent that it falls in . 
a little bit more or the whole phrase . 
uhhuh . 
um 
you mean forget about stress the form cue ? 
the form bit . 
yeah . 
because uh as a form cue um not even trained experts can always well they can tell you where the focus exponent is sometimes . 
okay . 
and that ' s also mostly true for read speech . 
in in real speech um people may put stress . 
it ' s so context dependent on what was there before phrase breaks um restarts . 
yeah . 
uhhuh . 
it ' s just um 
it ' s absurd . 
it ' s complicated . 
okay . 
yeah i mean i i ' m sort of inclined to say let ' s worry about specifying the information structure focus of the sentence . 
and all 
i believe you yeah . 
uhhuh . 
and then 
ways that you can get it come from 
hhh the phonology component can handle actually assigning an intonation contour to that . 
right . 
you know i mean later on we ' ll worry about exactly how 
or or map from the contour to to what the focus exponent is . 
yeah . 
uhhuh . 
exactly . 
but figure out how the 
yeah . 
but uh if you don ' t know what you ' re what you ' re focus is then you ' re you ' re hopeless - uh - ly lost anyways . 
right . 
that ' s fine yeah . 
uhhuh . 
and the only way of figuring out what that is is um by sort of generating all the possible alternatives to each focused element decide which one in that context makes sense and which one doesn ' t . 
uhhuh . 
and then you ' re left with a couple three . 
uhhuh . 
so you know again that ' s something that humans can do . 
um but far outside the scope of of any anything . 
so 
you know 
it ' s 
okay well uh yeah i wouldn ' t have assumed that it ' s an easy problem in in absence of all the 
you need all the other information i guess . 
but it ' s it ' s what it uh it ' s pretty easy to put it in the formalism though . 
i mean because 
yeah . 
you can just say whatever stuff is the container being focused or the the entire whatever both and so forth . 
uhhuh uhhuh . 
uhhuh . 
yeah exactly so the sort of effect of it is something we want to be able to capture . 
yeah so but i think the 
i ' m not sure i understand . 
but here ' s what i think is going on . 
that if we do the constructions right when a particular construction matches it the fact that it matches does in fact specify the focus . 
uh 
i ' m not sure about that . 
or it might limit it certainly constrains the possibilities of focus . 
okay . 
uh uh at the very least it 
i think that ' s that ' s that ' s certainly true . 
and depending on the construction it may or may not specify the focus right ? 
oh uh for sure yes . 
there are yeah it ' s not every but there are constructions uh where you explicitly take into account those considerations 
yeah . 
uhhuh . 
that you need to take into account in order to decide which what is being focused . 
uhhuh . 
uhhuh . 
so we talked about that a little bit this morning . 
john is on the bus . 
uhhuh . 
not nancy . 
huh . 
so that ' s focuses on john . 
right . 
john is on the bus and not on the train . 
uhhuh . 
right . 
john is on the bus versus john is on the train . 
right . 
and john is on the bus versus was and 
is on . 
john is on the bus . 
it ' s the so 
yeah yeah . 
right . 
yeah all all of those . 
yeah . 
right . 
all of these . 
and will we have 
is it all the same constructions ? 
just with a different focus constituent . 
yeah i would say that argument structure in terms of like the main like sort of 
uhhuh . 
i don ' t know . 
the fact that you can get it without any stress and you have some whatever is predicated anyway should be the same set of constructions . 
so that ' s why i was talking about overlapping constructions . 
so then you have a separate thing that picks out you know stress on something relative to everything else . 
yeah . 
uhhuh . 
so the question is actually 
and it would 
oh i ' m sorry . 
yeah . 
go ahead . 
finish . 
and it and that would have to uh it might be ambiguous as uh whether it picks up that element or the phrase or something like that . 
but it ' s still is limited possibility . 
huh . 
so that should you know interact with it should overlap with whatever other construction is there . 
yeah . 
the question is do we have a way on the other page uh when we get to the semantic side of saying what the stressed element was or stressed phrase or something ? 
uhhuh . 
well so that ' s why i was saying how 
since i couldn ' t think of an easy like limited way of doing it um all i can say is that information structure has a focused slot . 
right . 
and i think that should be able to refer to 
so that ' s down at the bottom here when we get over there . 
yeah . 
okay . 
and infer and i don ' t have i don ' t have a great way or great examples . 
i ' ll wait . 
but i think that something like that is probably going to be uh more more what we have to do . 
okay . 
huh . 
but um 
okay . 
so 
okay that was one comment . 
and you had another one ? 
yeah well the once you know what the focus is the everything else is background . 
how about topic comment ? 
that ' s the other side of information . 
how about what ? 
topic comment . 
yeah so that was the other thing . 
and so i didn ' t realize it before . 
it ' s like oh ! it was an epiphany that it you know topic and focus are a contrast set . 
so topic is 
topic focused seems to me like um background profile okay ? 
or a landmark trajector or something like that . 
there ' s there ' s definitely um that kind of thing going on . 
huh . 
now i don ' t know whether 
i i don ' t have as many great examples of like topic indicating constructions . 
on like focus right ? 
um topic it seems kind of you know i think that might be an ongoing kind of thing . 
uhhuh . 
japanese has this though . 
topic marker ? 
you know 
yeah that ' s what wa is . 
yeah . 
uhhuh . 
uh just to mark which thing is the topic . 
uhhuh . 
it doesn ' t always have to be the subject . 
right . 
so again information structure has a topic slot . 
and you know i stuck it in thinking that we might use it . 
uhhuh . 
um i think i stuck it in . 
yep it ' s there . 
um and 
one thing that i didn ' t do consistently um is when we get there is like indicate what kind of thing fits into every role . 
i think i have an idea of what it should be . 
but 
you know so far we ' ve been getting away with like either a type constraint or um you know whatever . 
i it ' ll be a frame . 
you know it ' ll be it ' ll be another predication or it ' ll be um i don ' t know some value from from something some variable and scope or something like that . 
or a slot chain based on a variable and scope . 
okay so well that ' s 
should we flip over to the other side officially then ? 
uhhuh huh . 
i keep uh like pointing forward to it . 
okay side one . 
yeah . 
now we ' ll go back to 
okay so this doesn ' t include something which may have some effect on on it . 
which is um the discourse situation context record . 
right so i didn ' t i i meant just like draw a line . 
and like you know you also have uh some tracking of what was going on . 
right . 
and sort of this is a big scale comment before i you know look into the details of this . 
but for instance you could imagine instead of having 
i i changed the name of um it used to be entities . 
so you see it ' s scenario referent and discourse segment . 
and scenario is essentially what kind of what ' s the basic predication . 
what event happened . 
and actually it ' s just a list of various slots from which you would draw draw in order to paint your picture a bunch of frames and bindings right ? 
um and obviously there are other ones that are not included here . 
general cultural frames and general like uh other action 
you know specific x . schema frames . 
uhhuh . 
okay whatever . 
the middle thing used to be entities . 
because you could imagine it should be like really a list . 
where here was various information . 
and this is intended to be grammatically specifiable information about a referent uh you know about some entity that you were going to talk about . 
so harry walked into the room . 
harry and room . 
you know the room 
but they would be represented in this list somehow . 
and it could also have for instance it has this category slot . 
um it should be either category or or instance . 
basically it could be a pointer to ontology . 
so that everything you know about this could be could be drawn in . 
but the important things for grammatical purposes are for things like number gender . 
um the ones i included here are slightly arbitrary . 
but you could imagine that um you need to figure out 
if it ' s a group whether um some event is happening . 
linear time linear spaces . 
like you know are are they doing something serially . 
or is it like 
um uh i ' m i ' m not sure . 
because this partly came from uh talmy ' s schema . 
and i ' m not sure we ' ll need all of these actually . 
but 
um and then the status i used was like again in some languages you know like for instance in child language you might distinguish between different status . 
so the the big and and finally discourse segment is about sort of speech act y information structure y . 
like utterance - specific kinds of things . 
so the comment i was going to make about um changing entity the entity ' s block to reference is that you can imagine your discourse 
like situation context 
you have a set of entities that you ' re sort of referring to . 
and you might that might be sort of a general i don ' t know database of all the things in this discourse that you could refer to . 
and i changed to reference . 
because i would say for a particular utterance you have particular referring expressions in it . 
and those are the ones that you get information about that you stick in here . 
for instance i know it ' s going to be plural . 
i know it ' s going to be feminine or something like that . 
and and these could actually just point to you know the the i . d . in my other list of active entities right ? 
so um 
uh there ' s there ' s all this stuff about discourse status we ' ve talked about . 
i almost listed discourse status as a slot where you could say it ' s active . 
you know there ' s this um hierarchy uh there ' s a schematization of you know things can be active or they can be um accessible inaccessible . 
yeah . 
it was the one that you know keith um emailed to us once to some of us . 
not all of us . 
and 
the thing is that that i noticed that that um list was sort of discourse dependent . 
it was like in this particular set you know instance it has been referred to recently or it hasn ' t been . 
yeah . 
or this is something that ' s like in my world knowledge but not active . 
this 
uh yeah well there there seems to be context properties . 
so 
yeah they ' re and for instance i used to have a location thing there . 
yeah . 
but actually that ' s a property of the situation . 
and it ' s again time you know at certain points things are located you know near or far from you . 
well uh uh this is recursive . 
and 
because until we do the uh mental space story we ' re not quite sure 
yeah . 
which is fine . 
yeah yeah . 
we ' ll just we ' ll 
so some of these are uh 
we just don ' t know yet . 
right . 
so i so for now i thought well maybe i ' ll just have in this list the things that are relevant to this particular utterance right ? 
everything else here is utterance - specific . 
um and i left the slot predications open . 
because you can have um things like the guy i know from school . 
or you know like your referring expression might be constrained by certain like unbounded amounts of you know predications that you might make . 
uhhuh . 
and it ' s unclear whether 
i mean you could just have in your scenario here are some extra few things that are true right ? 
uhhuh . 
and then you could just sort of not have this slot here right ? 
you ' re but but it ' s used for identification purposes . 
so it ' s it ' s a little bit different from just saying all these things are true from my utterance . 
yeah . 
right . 
yeah . 
um 
right this guy i know from school came for dinner does not mean um there ' s a guy i know him from school . 
and he came over for dinner . 
that ' s not the same effect . 
yeah it ' s a little bit it ' s a little bit different . 
right so 
or maybe that ' s like a restrictive non restrictive 
you know it ' s like it gets into that kind of thing for 
yeah . 
um but maybe i ' m mixing you know this is kind of like the final result after parsing the sentence . 
so you might imagine that the information you pass to you know in identifying a particular referent would be oh some you know it ' s a guy . 
uhhuh . 
and it ' s someone i know from school . 
so maybe that would you know be some intermediate structure that you would pass into the to the whatever construal engine or whatever discourse context to find you know either create this reference . 
yeah . 
in which case it ' d be created here . 
uhhuh . 
and 
you know so so you could imagine that this might not 
so uh i ' m uncommitted to a couple of these things . 
but to make it precise at least in my mind uh it ' s not precise . 
um 
so house is gender neuter ? 
um it could be in 
in reality ? 
or in 
semantically . 
semantically yeah yeah . 
semantically . 
so 
so it uh uh a table . 
you know a thing that doesn ' t have a gender . 
so uh it could be that i mean 
maybe you ' d maybe not all these 
i mean i i would say that i tried to keep slots here that were potentially relevant to most most things . 
no just to make sure that we everybody that ' s completely agreed that it it has nothing to do with uh form . 
yeah . 
okay that is semantic as opposed to 
yeah yeah that ' s right . 
um 
so again 
then predications makes sense to to have it open for something like uh accessibility or not . 
open to various things . 
yeah . 
right . 
okay so let ' s see . 
so maybe having made that big sort of like large scale comment should i just go through each of these slots uh each of these blocks um a little bit ? 
sure . 
um mostly the top one is sort of image schematic . 
and just a note . 
which was that um 
so when we actually 
so for instance um 
some of them seem more inherently static okay . 
like a container or sort of support - ish . 
and others are a little bit seemingly inherently dynamic . 
like source path goal is often thought of that way . 
or force or something like that . 
but in actual fact i think that they ' re intended to be sort of neutral with respect to that . 
and different x . schemas use them in a way that ' s either static or dynamic . 
so path you could just be talking about the path between this and this . 
huh . 
and you know container that you can go in and out . 
all of these things . 
and so um 
i think this came up when uh ben and i were working with the spaniards um the other day . 
the spaniettes as we called them . 
um to decide like how you want to split up like image schematic contributions versus like x . schematic contributions . 
how do you link them up ? 
and i think again um it ' s going to be something in the x . schema that tells you is this static or is this dynamic . 
so we definitely need that sort of aspectual type gives you some of that . 
um that you know is it uh a state or is it a change of state or is it a um action of some kind . 
uh is there any meaning to when you have sort of parameters behind it and when you don ' t ? 
uh 
yeah . 
just means 
oh oh you mean in the slot ? 
uhhuh . 
um no it ' s like x . it ' s it ' s like i was thinking of type constraints . 
but x . schema well it obviously has to be an x . schema . 
agent i mean the the performer of the x . schema . 
that depends on the x . schema . 
you know and i in general it would probably be you know 
so the difference is basically whether you thought it was obvious what the possible fillers were . 
yeah basically . 
uhhuh . 
okay . 
um aspectual type probably isn ' t obvious . 
but i should have so i just neglected to stick something in perspective actor undergoer observer um 
huh . 
i think we ' ve often used agent patient 
whee ! 
that ' s that one right ? 
yeah exactly exactly . 
um and so one nice thing that uh we had talked about is this example of like if you have a passive construction then one thing it does is you know definitely it is one way to for you to you know specifically take the perspective of the undergoing kind of object . 
and so then we talked about you know whether well does that specify topic as well ? 
well maybe there are other things . 
you know now that it ' s subject is more like a topic . 
and now that you know 
anyway so 
sorry i ' m going to trail off on that one . 
because it ' s not that important right now . 
um 
now for the moment we just need the ability to write it down if if somebody figured out what the rules were . 
to know how 
yeah yeah exactly . 
yeah . 
um 
some of these other ones 
let ' s see . 
so 
uh one thing i ' m uncertain about is how polarity interacts . 
so polarity uh is using for like action did not take place for instance . 
uhhuh . 
so by default it ' ll be like true i guess . 
you know if you ' re specifying events that did happen . 
you could imagine that you skip out this you know leave off this polarity . 
you know not don ' t have it here . 
and then have it part of the speech act in some way . 
uhhuh . 
there ' s some negation . 
but the reason why i left it in is because you might have a change of state let ' s say where some state holds and then some state doesn ' t hold . 
and you ' re just talking you know 
if you ' re trying to have the nuts and bolts of simulation you need to know that you know whatever the holder doesn ' t and 
no i i think at this which is it should be where you have it . 
okay it ' s so it ' s it ' s it ' s fine where it is . 
so 
i mean how you get it may may will often involve the discourse . 
okay . 
may come from a few places . 
but but by the time you ' re simulating you you should know that . 
right . 
right . 
so i ' m still just really not clear on what i ' m looking at . 
the scenario box . 
like what does that look like for an example ? 
yeah . 
like not all of these things are going to be here . 
uhhuh . 
correct . 
this is just basically says 
it ' s a grab bag of 
part of what i ' m going to hand you is a whole bunch of uh schemas image and x . schemas . 
here are some examples of the sorts of things you might have in there . 
so that ' s exactly what it is . 
okay . 
and for a particular instance which i will you know make an example of something is that you might have an instance of container and path let ' s say as part of your you know into you know definition . 
uhhuh . 
uhhuh . 
so you would eventually have instances filled in with various various values for all the different slots . 
uhhuh . 
and they ' re bound up in you know their bindings and and and values . 
okay . 
it 
do you have to say about the binding in your 
is there a slot in here for that tells you how the bindings are done ? 
no no no . 
i let ' s see i think we ' re we ' re not . 
i don ' t think we have it quite right yet . 
okay . 
so uh what this is 
let ' s suppose for the moment it ' s complete . 
okay . 
okay uh then this says that when an analysis is finished the whole analysis is finished you ' ll have as a result uh some resulting semspec for that utterance in context . 
uhhuh . 
which is made up entirely of these things and uh bindings among them . 
uhhuh . 
and bindings to ontology items . 
uhhuh . 
so that that the that this is the tool kit under out of which you can make a semantic specification . 
uhhuh . 
so that ' s a . . 
okay . 
but b . which is more relevant to your life is this is also the tool kit that is used in the semantic side of constructions . 
uhhuh . 
so this is that anything you have in the party line anything you have as the semantic side of constructions comes from pieces of this ignoring 
okay . 
i mean in general you ignore lots of it . 
right . 
but it ' s got to be pieces of this along with constraints among them . 
okay . 
uh so that the you know goal of the uh uh source path goal has to be the landmark of the you know the interior of this container . 
uhhuh . 
or whatever . 
yeah . 
so those constraints appear in constructions . 
uhhuh . 
but pretty much this is the full range of semantic structures available to you . 
okay . 
except for cause that i forgot . 
but anyway there ' s some kind of causal structure for composite events . 
yeah . 
okay good . 
let ' s let ' s mark that . 
so we need a 
uh i mean so it gets a little funny . 
these are all so far these structures especially from path and on down these are sort of relatively familiar um image schematic kind of slots . 
now with cause uh the fillers will actually be themselves frames right ? 
so you ' ll say event one causes event b . . 
right . 
uhhuh . 
and and and and this this this again may our um and we and and of course worlds . 
uh event two 
and 
yeah so that ' s uh these are all implicitly one within uh within one world . 
uhhuh . 
um 
even though saying that place takes place whatever . 
uh if if i said time is you know past that would say set that this world you know somewhere before the world that corresponds to our current speech time . 
uhhuh . 
uhhuh . 
yeah . 
so but that that that ' s sort of okay . 
the the within the event it ' s it ' s still one world . 
um 
yeah so cause and 
other frames that could come in i mean unfortunately you could bring in say for instance um uh desire or something like that . 
uhhuh . 
like want . 
and actually there is right now under discourse segments um attitude . 
uhhuh . 
volition . 
could fill that . 
so there are a couple things where i like oh i ' m not sure if i wanted to have it there . 
well that ' s 
or basically there was a whole list of of possible speaker attitudes that like say talmy listed . 
and like well i don ' t you know it was like hope wish desire . 
right . 
uhhuh . 
blah blah blah . 
and it ' s like well i feel like if i wanted to have an extra meaning 
i don ' t know if those are grammatically marked in the first place . 
so they ' re more lexically marked right ? 
at least in english . 
huh . 
so if i wanted to i would stick in an extra frame in my meaning saying . 
so it ' d be a hierarchical frame them right ? 
you know like naomi wants wants a certain situation . 
and that situation itself is a state of affairs . 
right . 
so so want itself can be 
can be just another frame that ' s part of your . 
well and basically it ' s an action . 
in in our in our in our 
yeah . 
situation right right . 
in in our in our terminology want can be an action . 
and what you want is a world . 
uhhuh . 
huh . 
huh . 
so that ' s i mean it ' s certainly one way to do it . 
uhhuh . 
yeah there there are other things . 
causal stuff we absolutely need . 
mental space we need . 
uhhuh . 
the context we need . 
um so anyway keith 
so is this comfortable to you ? 
that uh once we have this defined it is your tool kit for building the semantic part of constructions . 
uhhuh . 
and then when we combine constructions semantically the goal is going to be to fill out more and more of the bindings needed in order to come up with the final one . 
uhhuh . 
yeah . 
and that ' s the and and i mean that according to the party line that ' s the whole story . 
uhhuh . 
yeah . 
um 
right that makes sense . 
so i mean there ' s this stuff in the off in the scenario . 
which just tells you how various what schemas you ' re using . 
and they ' re how they ' re bound together . 
and i guess that some of the discourse segment stuff 
uhhuh . 
is that where you would 
i mean that ' s 
okay that ' s where the information structure is . 
which sort of is a kind of profiling on different parts of um of this . 
right . 
exactly . 
i mean what ' s interesting is that the information structure stuff 
huh . 
there ' s almost i mean we keep coming back to how focus is like this this uh trajector - landmark thing . 
yeah . 
so if i say um you know in france it ' s like this . 
you know great . 
we ' ve learned something about france . 
but the fact is that utterances of that sort are generally used to help you draw a conclusion also about some implicit contrast . 
like in france it ' s like this . 
right . 
and therefore you ' re supposed to say boy life sure 
you know in france kids are allowed to drink at age three . 
and you ' re that ' s not just a fact about france . 
right right . 
you also conclude something about how boring it is here in the u . s . right ? 
right . 
and so 
so i would prefer not to worry about that for right now . 
okay . 
and to think that there are um 
that comes in . 
discourse level constructions in a sense topic topic focus constructions that would say oh when you focus something then 
and uh 
uhhuh . 
yeah . 
just done the same way just actually in the same way as the lower level . 
if you stressed you know john went to the you know the bar whatever you ' re focusing that . 
uhhuh . 
and a possible inference is in contrast to other things . 
yeah . 
so similarly for a whole sentence you know in france such and such happens . 
yeah . 
yeah yeah . 
so the whole thing is sort of like again implicitly as opposed to other things that are possible . 
yeah . 
uh just just uh look read uh even semi formal mats rooth . 
i mean 
yeah . 
uhhuh . 
if you haven ' t read it it ' s nice . 
and just pick any paper on alternative semantics . 
uhhuh . 
okay . 
so that ' s his that ' s the best way of talking about focus is i think his way . 
okay what was the name ? 
mats . 
m . a . t . s . 
okay . 
rooth . 
i think two o . ' s . 
yes t . h . 
okay . 
i never know how to pronounce his name . 
because he ' s sort of 
swede ? 
uh he is dutch . 
dutch ? 
yeah . 
oh dutch . 
and um but very confused background i think . 
uhhuh . 
so and um 
mats gould . 
and sadly enough he also just left the i . m . s . in stuttgart . 
so he ' s not there anymore . 
huh . 
but um 
i don ' t know where he is right now . 
but alternative semantics is if you type that into an uh uh browser or search engine you ' ll get tons of stuff . 
okay . 
okay . 
okay thanks . 
and what i ' m kind of confused about is is what the speaker and the hearer is is sort of doing there . 
so for a particular segment it ' s really just a reference to some other entity again in the situation right ? 
so for a particular segment the speaker might be you or might be me . 
yeah . 
um hearer is a little bit harder . 
it could be like multiple people . 
i guess that that that that ' s not very clear from here . 
i mean that ' s not allowed here . 
yeah but you don ' t we ultimately want to handle that analogously to the way we handle time and place ? 
because you me he they . 
you know these guys 
all these expressions nuh are in in much the same way contextually dependent as here and now and there . 
uhhuh . 
now this is this is assuming you ' ve already solved that . 
yeah . 
so it ' s it ' s fred and mary . 
so 
so the speaker would be fred . 
and the 
uh . 
right so the constructions might of course will refer using pronouns or whatever . 
uhhuh . 
in which case they have to check to see uh who the uh speaker in here in order to resolve those . 
but when you actually say that he walked into whatever um the he will refer to a particular 
you you will already have figured who he or you huh or i maybe is a better example who i refers to . 
um and then you ' d just be able to refer to harry you know in wherever that person whatever role that person was playing in the event . 
huh . 
that ' s up at the reference part . 
yeah yeah . 
and down there in the speaker - hearer part ? 
so that ' s i think that ' s just 
for instance speaker is known from the situation right ? 
you ' re when you hear something you ' re told who the speaker is . 
i mean you know who the speaker is . 
in fact that ' s kind of constraining how 
in some ways you know this before you get to the you fill in all the rest of it . 
i think . 
huh . 
i mean how else would you um 
you know uh uh it ' s the speaker may in english is allowed to say i . 
yeah . 
well here 
yeah . 
uh among the twenty five percent most used words . 
right . 
but wouldn ' t the i then set up the the referent ? 
uhhuh . 
that happens to be the speaker this time . 
right right . 
and not they whoever they are . 
so 
or you 
much like the you could 
so okay so i would say under referent should be something that corresponds to i . 
and maybe each referent should probably have a list of whatever the way it was referred to . 
so that ' s i . 
but uh uh should we say it it refers to what ? 
uh if it were harry it would refer to like some ontology thing . 
if it were if it ' s i it would refer to the current speaker . 
okay which is given to be like you know whoever it is . 
well not not always . 
i mean so there ' s and then he said i uhhuh 
i within the current world . 
uh 
yeah . 
yeah . 
that ' s right . 
yeah yeah yeah yeah . 
so so again this uh this this is going to to get us into the mental space stuff . 
and because you know fred said that mary said and whatever . 
uhhuh . 
huh . 
and and so we ' re uh going to have to um chain those as well . 
uhhuh . 
twhhh - whhh . 
but 
uhhuh . 
so this entire thing is inside a world . 
right . 
not just like the top part . 
right . 
i i think uh 
that ' s 
uhhuh . 
except it ' s it ' s trickier than that . 
because um the reference for example 
so where it gets really tricky is there ' s some things 
yeah . 
and this is where blends and all 
yeah . 
so some things which really are meant to be identified and some things which aren ' t . 
right . 
and again all we need for the moment is some way to say that . 
right . 
so i thought of having like for each referent having the list of of the things with which it is identified . 
you know which which uh you know you you you 
you could do that . 
for instance um 
so i guess 
it sort of depends on if it is a referring if it ' s identifiable already or it ' s a new thing . 
uhhuh . 
if it ' s a new thing you ' d have to like create a structure or whatever . 
if it ' s an old thing it could be referring to um usually something in a situation right . 
or something in ontology . 
uhhuh . 
so 
there ' s you know whatever it it could point at one of these . 
i just had a i just had an an idea that would be very nice if it works . 
for what ? 
if it works . 
uh uh uh i haven ' t told you what it is yet . 
uhhuh huh . 
this was my buildup . 
an an idea that would be nice 
yeah . 
okay we ' re crossing our fingers . 
right . 
if it worked . 
so we ' re building a mental space good . 
yeah . 
okay . 
right it was a space builder . 
um we might be able to handle context in the same way that we handle mental spaces . 
because uh you have somewhat the same things going on of uh things being accessible or not . 
uhhuh . 
and so 
yep . 
it it it uh i think if we did it right we might be able to get at least a lot of the same structure . 
use the same yep . 
so that pulling something out of a discourse context is i think similar to other kinds of uh mental space phenomena . 
i see . 
uhhuh . 
and 
uh i ' ve i ' ve i ' ve never seen anybody write that up . 
and 
but maybe they did . 
i don ' t know . 
that may be all over the literature . 
yeah . 
so so by default 
there ' s things like you know there ' s all kinds of stuff like um in i think i mentioned last time in czech if you have a a verb of saying then 
um you know you say something like or or i was thinking you can say something like oh i thought uh you are a republican or something like that . 
where as in english you would say i thought you were . 
right . 
um you know sort of the past tense being copied onto the lower verb doesn ' t happen there . 
so you have to say something about you know tense is determined relative to current blah blah blah . 
uhhuh . 
uhhuh . 
same things happens with pronouns . 
there ' s languages where um 
if you have a verb of saying then 
uh 
where 
okay so a situation like bob said he was going to the movies where that lower subject is the same as the person who was saying or thinking you ' re actually required to have i there . 
uhhuh . 
um and it ' s sort of in an extended function 
uhhuh . 
so we would have it be in quotes in english . 
yeah . 
right . 
right . 
but it ' s not perceived as a quotative construction . 
i mean it ' s been analyzed by the formalists as being a logophoric pronoun . 
yeah . 
um which means a pronoun which refers back to the person who is speaking or that sort of thing right ? 
oh right yeah that makes sense . 
okay . 
um 
but uh that happens to sound like the word for i . 
but is actually semantically unrelated to it . 
oh no ! 
oh good i love the 
um 
really ? 
yeah yeah . 
you ' re kidding . 
there ' s a whole book which basically operates on this assumption . 
uh mary dalrymple . 
uh this book a ninety three book on uh on pronoun stuff . 
no that ' s horrible . 
okay . 
that ' s horrible okay . 
well yeah and then the same thing for a . s . l . 
where you know you ' re signing . 
and someone says something . 
and then you know so he say and then you sort of do a role shift . 
and then you sign i this that and the other . 
uhhuh . 
and you know i did this . 
that ' s also been analyzed as logophoric and having nothing to do with i . 
and the role shift thing is completely left out and so on . 
so 
i mean the point is that pronoun references uh you know sort of ties in with all this mental space stuff and so on and so forth . 
uhhuh . 
and so yeah i mean 
yeah . 
so that that that does sound like it ' s consistent with what we ' re saying yeah . 
right . 
yeah . 
okay so it ' s kind of like the unspecified mental spaces just are occurring in context . 
and then when you embed them sometimes you have to pop up to the you know depending on the construction or the whatever um you you you ' re scope is might extend out to the the base one . 
uhhuh . 
uhhuh . 
yeah . 
it would be nice to actually use the same um mechanism . 
since there are so many cases where you actually need 
it ' ll be one or the other . 
yeah . 
it ' s like oh actually it ' s the same same operation . 
oh okay so this this is worth some thought . 
so 
it ' s like it ' s like what ' s happening that yeah what ' s happening uh there is that you ' re moving the base space or something like that right ? 
yeah yeah . 
so that ' s that ' s how fauconnier would talk about it . 
uhhuh . 
and it happens under different circumstances in different languages . 
and so 
uhhuh . 
um things like pronoun reference and tense which we ' re thinking of as being these discourse y things actually are relative to a bayes space . 
which can change . 
uhhuh . 
and we need all the same machinery . 
right . 
uhhuh . 
robert . 
well but uh this is very good actually . 
schade . 
because it it it to the extent that it works it 
ties it all into it . 
it it ties together several of of these things . 
yeah . 
yep . 
uhhuh . 
uhhuh . 
and i ' m sure going to read the transcript of this one . 
so 
but the uh but it ' s too bad that we don ' t have a camera . 
you know all the pointing is going to be lost . 
oh yeah . 
yeah . 
yeah that ' s why i said point to robert when i did it . 
well every time nancy giggles it means it means that it ' s your job . 
uh 
yeah . 
huh isn ' t i mean i ' m i was sort of dubious why why he even introduces this sort of reality you know as your basic mental space . 
and then builds up 
uhhuh . 
doesn ' t start with some because it ' s so it should be so obvious at least it is to me that whenever i say something i could preface that with i think . 
yeah . 
nuh ? 
so there should be no categorical difference between your base and all the others that ensue . 
yeah . 
no but there ' s there ' s a gricean thing going on there . 
that when you say i think you ' re actually hedging . 
huh . 
yeah i mean 
it ' s like i don ' t totally think . 
yeah . 
right . 
i mostly think uh 
yeah it ' s absolutely . 
yeah it ' s an it ' s an evidential . 
it ' s sort of semi - grammaticalized . 
people have talked about it this way . 
and you know you can do sort of special things . 
you can 
put just the phrase i think as a parenthetical in the middle of a sentence and so on and so forth . 
actually one of the child language researchers who works with tomasello studied a bunch of these constructions . 
yeah . 
so 
and it was like it ' s not using any kind of interesting embedded ways . 
just to mark you know uncertainty or something like that . 
yeah . 
so 
yeah but about linguistic hedges . 
i mean those those tend to be um funky anyways . 
because they blur 
so we don ' t have that in here either do we ? 
yeah . 
hedges ? 
yeah yeah . 
hhh i there used to be a slot for speaker um 
it was something like factivity . 
i couldn ' t really remember what it meant . 
so i took it out . 
yeah . 
but it ' s something 
um 
well we were just talking about this sort of evidentiality and stuff like that right ? 
we we were talking about sarcasm too right ? 
oh oh . 
i mean 
oh yeah yeah right . 
that ' s what i think is . 
um sort of telling you what percent reality you should give this . 
so we probably should . 
yeah . 
or the you know 
uhhuh . 
confidence or something like that . 
yeah . 
and the fact that i ' m you know the fact maybe if i think it versus he thinks that might you know depending on how much you trust the two of us or whatever . 
yeah . 
you know 
uh great word in the english language is called about . 
if you study how people use that it ' s also 
what ' s the word ? 
about . 
about . 
it ' s about 
oh that in that use of about yeah . 
clever . 
oh oh oh as a hedge . 
yeah . 
and i think and i think if you want us to spend a pleasant six or seven hours you could get george started on that . 
he wrote a paper about thirty five years ago on that one . 
i i read that paper . 
yeah . 
the hedges paper ? 
yeah . 
i read some of that paper actually . 
would you believe that that paper lead directly to the development of anti - lock brakes ? 
yeah . 
what ? 
no . 
ask me about it later . 
i ' ll tell you how . 
when we ' re not on tape . 
i ' d love to know . 
oh man . 
so and and i think uh someone had raised like sarcasm as a complication at some point . 
there ' s all that stuff . 
yeah let ' s i i don ' t i think 
and 
we just won ' t deal with sarcastic people . 
yeah i mean 
i don ' t really know what like 
we we don ' t have to care too much about the speaker attitude right ? 
like there ' s not so many different 
certainly not as some 
hhh i don ' t know 
well they ' re intonational markers i think for the most part . 
yeah . 
i don ' t know too much about the like grammatical 
i just mean 
there ' s lots of different attitudes that that the speaker could have and that we can clearly identify and so on and so forth . 
yeah . 
but like what are the distinctions among those that we actually care about for our current purposes ? 
right . 
right so uh this this raises the question of what are our current purposes ? 
uhhuh . 
right ? 
oh yeah do we have any ? 
oh shoot . 
here it is three fifteen already . 
huh . 
yeah . 
uh so um 
i i don ' t know the answer . 
but but um it does seem that 
you know this is this is coming along . 
i think it ' s it ' s converging . 
it ' s as far as i can tell there ' s this one major thing we have to do . 
which is the mental the whole mental space thing . 
and then there ' s some other minor things . 
uhhuh . 
um and we ' re going to have to sort of bound the complexity . 
i mean if we get everything that anybody ever thought about you know we ' ll go nuts . 
yeah . 
so we had started with the idea that the actual uh constraint was related to this tourist domain . 
and the kinds of interactions that might occur in the tourist domain 
assuming that people were being helpful and weren ' t trying to 
you know there ' s all sorts of god knows irony and stuff like 
yeah . 
which you isn ' t probably of much use in dealing with a tourist guide . 
yeah . 
yeah ? 
uh 
mockery . 
right . 
whatever . 
so 
uh no end of things that that you know we don ' t deal with . 
but it 
and 
go ahead . 
isn ' t that part easy though ? 
because in terms of the simspec it would just mean you put one more set of brackets around it . 
and then just tell it to sort of negate whatever the content of that is in terms of irony . 
yeah . 
no . 
huh . 
or 
right . 
no . 
maybe . 
yeah in model theory because the semantics is always like speaker believes . 
no . 
you know ? 
like the speaker says p . and believes not p . . 
right . 
we have a theoretical model of sarcasm now . 
but 
yeah right i mean 
right right but 
right . 
no no . 
anyway so so um i guess 
uh let me make a proposal on how to proceed on that . 
which is that um 
it was keith ' s uh sort of job over the summer to come up with this set of constructions . 
uh and my suggestion to keith is that you over the next couple weeks 
huh . 
don ' t try to do them in detail or formally . 
but just try to describe which ones you think we ought to have . 
okay . 
uh and then when robert gets back we ' ll look at the set of them . 
okay . 
just just sort of you know define your space . 
yeah okay . 
and um so these are this is a set of things that i think we ought to deal with . 
yeah . 
and then we ' ll we ' ll we ' ll go back over it . 
and people will will give feedback on it . 
okay . 
and then then we ' ll have a at least initial spec of of what we ' re actually trying to do . 
yeah . 
and that ' ll also be useful for anybody who ' s trying to write a parser . 
uhhuh . 
knowing uh 
in case there ' s any around . 
if we knew anybody like that . 
right . 
who might 
et cetera . 
so uh 
okay . 
so and we get this this uh portals fixed . 
and then we have an idea of the sort of initial range . 
and then of course nancy you ' re going to have to uh do your set of 
but you have to do that anyway . 
for the same yeah data yeah uhhuh . 
so so we ' re going to get we ' re basically dealing with two domains . 
the tourist domain and the and the child language learning . 
huh . 
and we ' ll see what we need for those two . 
and then my proposal would be to um not totally cut off more general discussion . 
but to focus really detailed work on the subset of things that we ' ve we really want to get done . 
uhhuh . 
uhhuh . 
and then as a kind of separate thread think about the more general things and and all that . 
uhhuh . 
well i also think the detailed discussion will hit you know bring us to problems that are of a general nature . 
uh without doubt . 
and maybe even 
yeah . 
yeah . 
but what i want to do is is is to to constrain the things that we really feel responsible for . 
even suggest some solutions . 
yeah . 
huh . 
uhhuh . 
so that that we say these are the things we ' re really going to try do by the end of the summer . 
and other things we ' ll put on a list of of research problems or something . 
because you can easily get to the point where nothing gets done . 
because every time you start to do something you say oh yeah but what about this case . 
uhhuh . 
this is this is called being a linguist . 
huh . 
yeah . 
and uh 
basically . 
or me . 
huh ? 
or me . 
anyways . 
there ' s that quote in jurafsky and martin where where it goes where some guy goes every time i fire a linguist the performance of the recognizer goes up . 
right . 
yeah . 
exactly . 
right . 
but anyway 
so is is that does that make sense as a uh a general way to proceed ? 
sure yeah . 
yeah yeah we ' ll start with that . 
just figuring out what needs to be done . 
then actually the next step is to start trying to do it . 
exactly right . 
got it . 
huh . 
huh . 
okay . 
we have a little bit of news uh just minor stuff . 
the one big 
ooo can i ask a 
you ran out of power . 
huh ? 
can i ask a quick question about this side ? 
yes . 
yeah . 
is this uh was it intentional to leave off things like inherits ? 
and 
oops . 
um 
no . 
not really . 
just on the constructions right ? 
yeah . 
um 
like constructions can inherit from other things . 
am i right ? 
yeah . 
yeah . 
i didn ' t want to think too much about that for for now . 
okay . 
so uh maybe it was subconsciously intentional . 
yeah . 
yeah uh 
um yeah there should be i i wanted to find out someday if there was going to be some way of dealing with uh if this is the right term multiple inheritance . 
yeah . 
where one construction is inheriting from uh from both parents . 
uhhuh . 
uhhuh . 
yep . 
uh or different ones . 
or three or four different ones . 
yeah . 
yeah . 
because the problem is that then you have to 
so let me 
refer to them . 
which of you know which are how they ' re getting bound together . 
yeah right right right . 
yeah and and there are certainly cases like that . 
yeah yeah yeah . 
even with just semantic schemas we have some examples . 
right . 
so 
and we ' ve been talking a little bit about that anyway . 
yeah so what i would like to do is separate that problem out . 
inherits . 
so um 
okay . 
my argument is there ' s nothing you can do with that that you can ' t do by just having more constructions . 
yeah yes . 
it ' s uglier and it doesn ' t have the deep linguistic insights and stuff . 
that ' s right . 
uh 
but whatever . 
uh those are over rated . 
yeah no no no no . 
right . 
no by all means . 
right uh sure . 
and so i what i ' d like to do is is in the short run focus on getting it right . 
and when we think we have it right then saying aha . 
yeah . 
can we make it more elegant ? 
yeah that ' s 
yeah . 
can can we uh what are the generalizations and stuff ? 
connect the dots . 
yeah . 
but rather than try to guess a inheritance structure and all that sort of stuff before we know what we ' re doing . 
yep . 
yeah . 
so i would say in the short run we ' re not going to 
yeah . 
first of all we ' re not doing them yet at all . 
and and it could be that half way through we say aha . 
we we now see how we want to clean it up . 
uhhuh . 
uh and inheritance is only one i mean that ' s one way to organize it . 
but there are others . 
yeah . 
and it may or may not be the best way . 
i ' m sorry . 
you had news . 
huh . 
oh just small stuff . 
um thanks to eva on our web site we can now 
if you want to run javabayes uh you could see get download these classes . 
and then it will enable you 
she modified the gui so it has now a a a button menu item for saving it into the embedded javabayes format . 
uhhuh . 
huh . 
so that ' s wonderful . 
great . 
and um and she you tested it out . 
do you want to say something about that that it works right ? 
i was just checking like when we want to um get the posterior probability of like variables . 
with the 
you know how you asked whether we can like just observe all the variables like in the same list ? 
you can ' t . 
you have to make separate queries every time . 
uhhuh . 
okay that ' s that ' s a bit unfortunate . 
so 
yeah . 
but 
for the time being it ' s it ' s it ' s fine to do it 
you just have to have a long list of you know all the variables . 
yeah . 
basically . 
but uh 
uh all the things you want to query you just have to like ask for separately . 
yeah yeah . 
well that ' s probably maybe in the long term that ' s good news . 
because it forces us to think a little bit more carefully how how we want to get an output . 
um but that ' s a different discussion for a different time . 
and um 
i don ' t know . 
we ' re really running late . 
so i had uh an idea yesterday . 
but uh i don ' t know whether we should even start discussing . 
what 
yeah sure tell us what it is . 
um the construal bit that um has been pointed to but hasn ' t been um made precise by any means um may may work as follows . 
i thought that we would uh 
that the following thing would be incredibly nice . 
and i have no clue whether it will work at all or nothing . 
so that ' s just a tangent a couple of mental disclaimers here . 
um imagine you you write a bayes - net . 
um 
bayes ? 
bayes - net . 
okay . 
um completely from scratch every time you do construal . 
so you have nothing . 
just a white piece of paper . 
huh . 
right . 
you consult consult your ontology . 
which will tell you a bunch of stuff and parts and properties uhuh uh 
grout out the things that that you need . 
right . 
then you ' d simply write uh these into onto your your white piece of paper . 
and you will get a lot of notes and stuff out of there . 
you won ' t get you won ' t really get any c . p . t . ' s . 
therefore we need everything that that configures to what the situation is . 
i . e . the context dependent stuff . 
so you get whatever comes from discourse . 
but also filtered . 
uh so only the ontology relevant stuff from the discourse . 
uhhuh . 
plus the situation and the user model . 
and that fills in your c . p . t . ' s with which you can then query um the the net that you just wrote . 
and find out how thing x . is construed as an utterance u . . 
and the embedded javabayes works exactly like that . 
that once you 
we have you know precise format in which to write it . 
so we write it down . 
you query it . 
you get the result . 
and you throw it away . 
and the the nice thing about this idea is that you don ' t ever have to sit down and think about it or write about it . 
you may have some general rules as to how things can be can be construed as what so that will allow you to craft the the the initial notes . 
but it ' s in that respect it ' s completely scalable . 
because it doesn ' t have any prior um configuration . 
it ' s just you need an ontology of the domain . 
and you need the context dependent modules . 
and if this can be made to work at all that ' d be kind of funky . 
um it sounds to me like you want p . r . m . ' s . 
p . r . uh p . r . 
i mean since you can unfold a p . r . m . into a straightforward bayes - net . 
because it because 
no no you can ' t . 
see the the critical thing about the p . r . m . is it gives these relations in general form . 
so once you have instantiated the p . r . m . with the instances and then you can then you can unfold it . 
then you can . 
uhhuh yeah . 
no i was using it generic . 
so uh probabilistic whatever relational models 
whatever you write it 
well no but it matters a lot . 
in 
because you what you want are these generalized rules . 
about the way things relate 
that you then instantiate in each case . 
and then then instantiate them . 
yeah and that ' s 
that ' s maybe the the way the only way it works . 
yeah that ' s the only way it could work . 
i we have a our local expert on p . r . m . ' s . 
uh but my guess is that they ' re not currently good enough to do that . 
but we ' ll we ' ll have to see . 
uh 
but uh 
yes . 
this is that ' s that would be a good thing to try . 
it ' s related to the hobbs abduction story . 
in that you you throw everything into a pot . 
and you try to come up with the uh 
except there ' s no no theorem prover involved . 
best explanation . 
no there isn ' t a theorem prover . 
but there but but the um the the the p . r . m . ' s are like rules of inference . 
and you ' re you ' re coupling a bunch of them together . 
uhhuh yeah . 
and then instead of proving you ' re trying to you know compute the most likely . 
uh 
tricky . 
but you yeah it ' s a good it ' s a it ' s a good thing to put in your thesis proposal . 
what ' s it ? 
so are you going to write something for us before you go ? 
yes . 
um 
oh you have something . 
in the process thereof or whatever . 
okay . 
so what ' s what when are we going to meet again ? 
when are you leaving ? 
thursday ? 
uh 
friday ? 
thursday ' s my last day here . 
okay . 
yeah . 
so 
i would suggest as soon as possible . 
do you mean by we the whole gang ? 
no i didn ' t mean just the two of us . 
we obviously we can we can do this . 
but the question is do you want to for example send the little group uh a draft of your thesis proposal ? 
and get uh another session on feedback on that . 
or 
we can do it thursday again . 
yeah . 
fine with me . 
should we do the one p . m . time ? 
for thursday since we were on that before ! 
or 
sure . 
okay . 
all right . 
huh . 
thursday at one ? 
i can also maybe then sort of run through the uh the talk i have to give at e . m . l . 
which highlights all of our work . 
okay . 
and we can make some last minute changes on that . 
okay . 
you can just give him the abstract that we wrote for the paper . 
that ' ll tell him exactly what ' s going on . 
yeah that 
can we do can we do one thirty ? 
all right . 
no . 
oh you already told me no . 
one . 
but we can do four . 
okay it ' s fine . 
i can do one . 
it ' s fine . 
it ' s fine . 
one or four . 
i don ' t care . 
to me this is equal . 
i don ' t care . 
if it ' s equal for all ? 
what should we do ? 
yeah it ' s fine . 
fine . 
four ? 
yeah 
no no no uh i don ' t care . 
it ' s fine . 
it ' s equal to all of us . 
so you can decide . 
one or four . 
the pressure ' s on you nancy . 
liz actually said she likes four . 
because it forces the meeting recorder people to cut you know the discussions short . 
okay . 
okay four . 
okay ? 
okay i am . 
well if you insist then . 
okay . 
so 
topic of this meeting is i want to talk a little bit about transcription . 
um i ' ve looked a little bit into commercial transcription services . 
and jane has been working on doing transcription . 
uh and so we want to decide what we ' re going to do with that . 
and then get an update on the electronics . 
and then uh maybe also talk a little bit about some infrastructure and tools and so on . 
um you know eventually we ' re probably going to want to distribute this thing . 
and we should decide how we ' re going to how we ' re going to handle some of these factors . 
so 
distribute what ? 
huh ? 
the data . 
right . 
right . 
i mean so we ' re we ' re collecting a corpus . 
and i think it ' s going to be generally useful . 
i mean it seems like it ' s not a corpus which is uh has been done before . 
oh . 
and so i think people will be interested in having having it . 
using like audio d . v . d . ' s or something like that ? 
and so we will 
yes . 
excuse me ? 
audio d . v . d . ' s ? 
well or something . 
yeah audio d . v . d . ' s . 
c . d . ' s . 
or 
you know . 
yeah . 
tapes . 
and and so how we do we distribute the transcripts . 
how do we distribute the audio files . 
how do we how do we just do all that infrastructure . 
well i think i mean for that particular issue there are known sources where people go to to find these kind of things like the l . d . c . for instance . 
yeah . 
that ' s right . 
right . 
but but so should we do it in the same format as l . d . c ? 
and what does that mean to what we ' ve done already ? 
right . 
the 
it ' s not so much the the logistics of distribution are secondary to preparing the data in a suitable form for distribution . 
right . 
right . 
so uh 
as it is it ' s sort of a ad hoc combination of stuff dan set and stuff i set up . 
which we may want to make a little more formal . 
so 
and the other thing is that um university of washington may want to start recording meetings as well . 
right . 
in which case we ' ll have to decide what we ' ve actually got so that we can give them a copy . 
a field trip . 
that ' s right . 
yeah . 
i was actually thinking i wouldn ' t mind spending the summer up there . 
that would be kind of fun . 
oh really ? 
yeah . 
different for you . 
visit my friends and spend some time 
yes . 
well and then also i have a bunch of stuff for doing this digits . 
so i have a bunch of scripts with x . waves and some perl scripts and other things that make it really easy to extract out and align where the digits are . 
and if u . u . w . ' s going to do the same thing i think it ' s worth while for them to do these digits tasks as well . 
uhhuh . 
and what i ' ve done is pretty ad hoc . 
um so we might want to change it over to something a little more standard . 
huh . 
you know s . t . m . files or x . m . l . or something . 
and there ' s interest up there ? 
what ' s that ? 
there ' s interest up there ? 
well they they certainly want to collect more data . 
and so they ' re applying i think i . b . m . 
is that right ? 
i don ' t know . 
something like that . 
um for some more money to do more data . 
so we were planning to do like thirty or forty hours worth of meetings . 
they want to do an additional hundred or so hours . 
so they want a very large data set . 
um but of course we ' re not going to do that if we don ' t get money . 
so 
i see . 
and i would like that just to get a disjoint speaker set and a disjoint room . 
uhhuh . 
i mean one of the things morgan and i were talking about is we ' re going to get to know this room really well . 
the the acoustics of this room . 
including the fan . 
all about that . 
did you notice the fan difference ? 
including the fan . 
oh now you ' ve touched the fan control . 
now all our data ' s going to be 
hear the difference ? 
oh that ' s better . 
yeah it ' s great . 
oh it ' s enormous . 
that ' s better . 
do you want to leave it off or not ? 
all the others have been on . 
yeah the you sure ? 
that ' s 
oh yeah . 
you you think that 
absolutely . 
things after the then 
yeah . 
this fan ' s wired backwards by the way . 
uh i think this is high speed here . 
yeah it ' s noticeable . 
well not clear . 
maybe it maybe it isn ' t . 
well it ' s well like low is mid mid scale . 
that ' s right . 
so it could be that it ' s not actually wired backwards . 
it ' s just that ambiguous . 
i was wondering also get ready whether the lights made any noise . 
uhhuh . 
there ' s definitely 
yeah a little bit . 
oh they do . 
yep . 
yeah . 
high pitch hum . 
wow . 
so do our meetings in the dark with no air conditioning in the future . 
yeah . 
just get a variety . 
i think candles would be nice if they don ' t make noise . 
oh yeah . 
they ' re very good . 
it would you know it would really mean that we should do short meetings when you turn off the turn off the air conditioning . 
carbon monoxide poisoning . 
short meetings . 
that ' s right . 
or 
yeah sort of 
got to finish this meeting . 
tear tear your clothing off to stay cool . 
that ' s right . 
actually the air the air conditioning ' s still working . 
that ' s just an auxiliary fan . 
right . 
i see . 
so 
um in addition to this issue about the u . w . stuff there was announced today uh via the l . d . c . um a corpus from i believe santa barbara . 
yeah . 
i saw it . 
i ' ve been watching for that corpus . 
um of general spoken english . 
yeah . 
yep . 
and i don ' t know exactly how they recorded it . 
but apparently there ' s a lot of different styles of speech and what not . 
uhhuh . 
and 
they had people come in to a certain degree and they and they have dat recorders . 
i see . 
so it is sort of far field stuff . 
right ? 
i i assume so actually . 
i hadn ' t thought about that . 
unless they added close field later on . 
but um i ' ve listened to some of those data . 
and i um i ' ve been i i was actually on the advisory board for when they set the project up . 
uhhuh . 
oh okay . 
i ' m glad to see that it got released . 
what ' s it sound like ? 
so it ' s a very nice thing . 
yeah i i wish 
i wish we had someone here working on adaptation . 
because it would nice to be able to take that stuff and adapt it to a meeting setting . 
how do you mean do you mean mechanical adaptation or 
but it may be it may be useful in 
you know . 
no . 
software . 
okay . 
to adapt the speech recognition . 
well what i was thinking is it may be useful in transcribing if it ' s far field stuff . 
uhhuh . 
right ? 
in doing um some of our first automatic speech recognition models it may be useful to have that kind of data . 
great idea . 
because that ' s very different than any kind of data that we have so far . 
that ' s true . 
and and their recording conditions are really clean . 
i mean i ' ve i ' ve heard i ' ve listened to the data . 
well that ' s not good right ? 
it sounds 
that ' s that ' s not great . 
well but what i mean is that um 
but far field means great distance ? 
i mean 
just these . 
not head mounted ? 
yeah . 
and so that ' s why they ' re getting away with just two channels or something ? 
or are they using multiple dats ? 
um oh . 
good question . 
and i can ' t answer it . 
i don ' t know . 
well we can look into it . 
no and their web their web page didn ' t answer it either . 
okay . 
so i ' m uh was thinking that we should contact them . 
so it ' s that ' s sort of a beside the point point . 
but 
so we can get that just with uh media costs . 
still a point . 
right . 
is that right ? 
uh in fact we get it for free . 
because they ' re distributing it through the l . d . c . 
oh . 
great . 
yep . 
so that would be yeah that would be something to look into . 
so i can i can actually arrange for it to arrive in short order if we ' re 
so 
the other thing too is from from a 
well it ' s silly to do unless we ' re going to have someone to work on it . 
so maybe we need to think about it a little bit . 
the other thing too is that their their transcription format is really nice and simple in in the discourse domain . 
huh . 
but they also mentioned that they have it time aligned . 
i mean i i i saw that write up . 
yeah . 
maybe we should maybe we should get a copy of it just to see what they did . 
yeah . 
absolutely . 
so so that we can we can compare . 
it ' s very nice . 
yeah . 
absolutely . 
okay why don ' t you go ahead and do that then eric ? 
all right i ' ll do that . 
i can ' t remember the name of the corpus . 
it ' s 
c . s . a . e . 
corpus of spoken american english . 
s . 
right . 
okay . 
yeah i ' ve been i was really pleased to see that . 
i knew that they they had had some funding problems in completing it . 
but um 
yeah . 
uhhuh . 
well they ' re 
this is clever . 
apparently this was like phase one . 
got it through the l . d . c . 
and there ' s still more that they ' re going to do apparently or something like that . 
great . 
unless of course they have funding issues . 
great . 
and then then it they may not do phase two . 
but from all the web documentation it looked like oh this is phase one . 
super . 
whatever that means . 
super . 
great . 
yeah that i mean they ' re really well respected in the linguistics side too and the discourse area . 
and 
okay . 
so this is a very good corpus . 
but it would also maybe be helpful for liz if she wanted to start working on some discourse issues you know looking at some of this data and then 
you know . 
right . 
so when she gets here maybe that might be a good thing for her . 
actually that ' s another thing i was thinking about is that maybe jane should talk to liz to see if there are any transcription issues related to discourse that she needs to get marked . 
okay . 
maybe we should have a big meeting meeting . 
sure . 
of course . 
that would be a meeting meeting meeting ? 
a meeting meeting meeting . 
yeah . 
well this is the meeting about the meeting meeting meeting . 
so 
oh . 
right . 
um 
but maybe we should find some day that liz uh liz and andreas seem to be around more often . 
uhhuh . 
so maybe we should find a day when they ' re going to be here and and morgan ' s going to be here . 
and we can meet . 
at least this subgroup . 
i mean not necessarily have the u . dub people down . 
well i was even thinking that maybe we need to at least ping the u . dub to see 
we need we need to talk to them some more . 
you know say this is what we ' re thinking about for our transcription if nothing else . 
uhhuh . 
so well shall we move on and talk a little bit about transcription then ? 
yeah . 
let ' s . 
okay . 
so since that ' s what we ' re talking about . 
what we ' re using right now is a tool um from this french group called transcriber . 
that seems to work very well . 
um 
so it has a uh nice useful tcl t . k . user interface . 
and uh 
this is the process of converting audio to text ? 
right . 
and this requires humans just like the the s . t . p . stuff ? 
yes . 
yeah . 
right right . 
so we ' re we ' re at this point only looking for word level . 
so all all so what you have to do is just identify a segment of speech in time and then write down what was said within it . 
and identify the speaker . 
and so the things we that we know that i know i want are the text the start and end and the speaker . 
but other people are interested in for example stress marking . 
and so jane is doing primary stress um stress marks as well . 
um and then things like repairs and false starts and filled pauses and all that other sort of stuff we have to decide how much of that we want to do . 
i did include a uh a certain first pass . 
my my view on it was when you have a repair then uh it seems 
i mean we saw there was this presentation in the one of the speech group meetings about how 
uhhuh . 
and i think liz has done some stuff too on that that it uh that you get it bracketed in terms of like 
well if it ' s parenthetical which i know that liz has worked on then uh you ' ll have different prosodic aspects . 
uhhuh . 
huh . 
and then also if it ' s a if it ' s a repair where they ' re like what i just did then it ' s nice to have sort of a sense of the continuity of the utterance . 
the start to to the finish . 
and uh it ' s a little bit deceptive if you include the the pre repair part . 
and sometimes or of it ' s in the middle . 
anyway so what i was doing was bracketing them to indicate that they were repairs . 
which isn ' t uh very time - consuming . 
uhhuh . 
is there already some sort of plan in place for how this going to be staffed or done ? 
or is it real is that what we ' re talking about here ? 
well . 
that ' s part of the thing we ' re talking about . 
so what we wanted to do was have jane do basically one meeting ' s worth . 
uhhuh . 
you know forty minutes to an hour . 
as a pilot study . 
and 
yourself ? 
yeah . 
yeah . 
as a pilot study . 
it this is this is like five times real time or ten times real time . 
ten times about . 
is and so one of the things was to get an estimate of how long it would take . 
and then also what tools we would use . 
and so the next decision which has to be made actually pretty soon is how are we going to do it . 
and so you make jane do the first one . 
so 
so then she can decide oh we don ' t need all this stuff . 
just the words are fine . 
that ' s right . 
that ' s right . 
that ' s right . 
i want to hear about these uh we have a you were continuing with the transcription conventions for 
right . 
so so one one option is to get linguistics grad students and undergrads to do it . 
and apparently that ' s happened in the past . 
and i think that ' s probably the right way to do it . 
um it will require a post pass . 
i mean people will have to look at it more than once to make sure that it ' s been done correctly . 
but i just can ' t imagine that we ' re going to get anything that much better from a commercial one . 
and the commercial ones i ' m sure will be much more expensive . 
can ' t we get joy to do it all ? 
no that ' s 
yeah right . 
is wasn ' t that what she was doing before ? 
we will just get joy and jane to do everything . 
yeah . 
that ' s right . 
but you know that ' s what we ' re talking about is getting some slaves who who need money . 
right . 
and uh 
duh again 
i object to that characterization ! 
oh really ? 
i meant joy . 
and so again i have to say are we recording . 
oh thank you . 
okay . 
and then say uh morgan has has consistently resisted telling me how much money we have . 
right . 
well the answer is zero . 
so 
there ' s a reason why he ' s resisted . 
but 
well if it ' s zero then we can ' t do any transcription . 
right . 
i mean because we ' re we 
i have such a hard name . 
i mean i i can ' t imagine us doing it ourselves . 
well we already we already we already have a plan in place for the first meeting . 
right ? 
right ? 
right . 
that ' s 
well there is 
yeah really . 
there is also the other possibility which is if you can provide not money but instructional experience or some other perks you can you could get people to to um to do it in exchange . 
well but seriously i i mean morgan ' s obviously in a bind over this . 
right . 
and thing to do is just the field of dreams theory . 
which is we go ahead as though there will be money at the time that we need the money . 
uhhuh . 
and that ' s that ' s the best we can do . 
yeah . 
to not do anything until we get money is is ridiculous . 
right . 
right . 
right . 
we ' re not going to do any get anything done if we do that . 
uhhuh . 
yeah . 
so at any rate jane was looking into the possibility of getting students . 
at is that right ? 
talking to people about that ? 
i ' m afraid i haven ' t made any progress in that front yet . 
okay . 
i should ' ve sent email and i haven ' t yet . 
yeah right . 
so uh 
do so until you actually have a little experience with what this this french thing does we don ' t even have 
and i do have 
she ' s already done quite a bit . 
i have a bunch of hours . 
oh we have . 
i ' m sorry . 
yeah . 
yeah . 
so that ' s where you came up with the the ten x . number ? 
or is that really just a guess ? 
actually that ' s the the one people usually use ten x . . 
and i haven ' t really calculated 
how fast are you ? 
how fast am i ? 
i haven ' t done a 
yeah 
see i ' ve been at the same time doing kind of a boot strapping in deciding on the transcription conventions that that are you know and and stuff like you know how much 
huh . 
right . 
there ' s some interesting human factors problems like yeah what span of of time is it useful to segment the thing into in order to uh transcribe it the most quickly . 
because then you know you get like if you get a span of five words that ' s easy . 
yeah . 
but then you have to take the time to mark it . 
yeah . 
and then there ' s the issue of it ' s easier to hear it right the first time if you ' ve marked it at a boundary instead of somewhere in the middle . 
because then the word ' s bisected or whatever . 
uhhuh . 
and 
and 
so i mean i ' ve been sort of playing with uh different ways of because i ' m thinking you know i mean if you could get optimal instructions you could cut back on the number of hours it would take . 
does uh this tool you ' re using is strictly 
yeah . 
it doesn ' t do any speech recognition does it ? 
no . 
no it doesn ' t . 
but what a super tool . 
it ' s a great environment . 
but but is there anyway to to wire a speech recognizer up to it ? 
and actually run it through 
that ' s an interesting idea . 
hey ! 
we ' ve we ' ve thought about doing that . 
but the recognition quality is going to be horrendous . 
well a couple things . 
first of all the time marking you ' d get you could get by a tool . 
wow . 
that ' s true . 
and so if the if if the issue 
that ' s interesting . 
uh i ' m think about the close caption that you see running by on on live news casts . 
you know 
most of those are done by a person . 
yeah . 
i know i know that . 
no i understand . 
and in a lot of them you see typos and things like that . 
uhhuh . 
but it but it occurs to me that it may be a lot easier to correct things than it is to do things from scratch no matter how wonderful the tool is . 
yeah . 
yeah we 
but if if there was a way to merge the two 
well i mean but sometimes it ' s easier to type out something instead of going through and figuring out which is the right 
that ' d be fun . 
i mean we ' ve talked about it . 
but 
i mean it depends on the error rate . 
right ? 
well but but again the timing is for should be for free . 
the timing should be 
but we don ' t care about the timing of the words . 
well i thought you just that ' s said that was a critical issue . 
no . 
we don ' t care about the timing of the words just of the utterances . 
uh the the boundary . 
we cut it 
we don ' t we don ' t know actually . 
boundary . 
we haven ' t decided which which time we care about . 
and that ' s kind of one of the things that you ' re saying is like you have the option to put in more or less timing data . 
and uh in the absence of more specific instructions we ' re trying to figure out what the most convenient thing to do is . 
yeah . 
so so what what she ' s done so far is sort of more or less breath not breath groups sort of phrases continuous phrases . 
yeah . 
and so um that ' s nice because you you separate when you do an extract you get a little silence on either end . 
so that seems to work really well . 
that ' s ideal . 
um 
although i was i you know the alternative which i was sort of experimenting with before i ran out of time recently was um that you know if it were like an arbitrary segment of time pre marked . 
yeah . 
because it does take time to put those markings in . 
yeah . 
it ' s really the the interface is wonderful . 
because you know the time it takes is you listen to it and then you press the return key . 
but then you know it ' s like uh you press the tab key to stop the flow and and uh the return key to to put in a marking of the boundary . 
but you know obviously there ' s a lag between when you hear it and when you can press the return key . 
yeah . 
so it ' s slightly delayed . 
so then you you listen to it a second time and move it over to here . 
so that takes time . 
now if it could all be pre marked at some you know good 
are are those delays adjustable ? 
huh . 
those delays adjustable ? 
see a lot of people who actually build stuff with human computer interfaces understand that delay . 
and and so when you by the time you click it it ' ll be right on because it ' ll go back in time to put the 
yeah . 
yeah . 
yeah . 
uh not in this case . 
it could do that . 
couldn ' t it ? 
we could program that pretty easily . 
it has other 
couldn ' t we dan ? 
yeah mister t . c . l . 
yeah . 
oh interesting point . 
i would have thought so . 
yeah . 
uh interesting point . 
okay that would make a difference . 
huh . 
but um 
i mean it ' s not bad . 
but if we tried to do automatic speaker i . d . 
but it does take twice . 
i mean because primarily the markings are at speaker change . 
yeah yeah . 
but 
but we ' ve got we ' ve got the most channel data . 
but that would be 
we ' d have to do it from your signal . 
right . 
oh good point ! 
i mean we ' ve we ' ve got we ' ve got a lot of data . 
uh . 
we ' ve got volume . 
yeah i guess the question is how much time will it really save us versus the time to write all the tools to do it . 
right . 
but the chances are if if we ' re talking about collecting ten or a hundred hours which is going to take a hundred or a thousand hours to transcribe 
if 
but 
if we can go from ten x . to five x . we ' re doing a big 
we ' re going to need we ' re going to need ten to a hundred hours to train the tools and validate the tools the do the to to do all this anyway . 
right . 
so maybe 
wow . 
but but it 
if we ' re just doing silence detection 
i knew you were going to do that . 
just saw it coming . 
i ' m sorry . 
i wish you had told me . 
wish you ' d told me . 
put put it on your sweater . 
at what part ? 
okay . 
i ' m all right . 
um it seems like 
well . 
uh i don ' t know . 
yeah . 
i mean it it ' s it ' s maybe like a week ' s work to get to do something like this . 
so forty or fifty hours . 
could you get it so that with so it would it would detect volume on a channel and insert a marker ? 
right . 
and the the format ' s really transparent . 
sure . 
yeah . 
it ' s just a matter of a very clear 
it ' s x . m . l . isn ' t it ? 
uhhuh . 
it ' s very i mean i looked at the the file format and it ' s just it has a a time a time indication and then something or other and then an end time or something or other . 
so 
maybe maybe we could try the following experiment . 
take the data that you ' ve already transcribed . 
uhhuh . 
and 
is this already in the past or already in the future ? 
already in the past . 
you ' ve already you ' ve already done some ? 
she she ' s done one she ' s one 
yes i have . 
she ' s she ' s done about half a meeting . 
oh i see . 
right . 
okay . 
right . 
good . 
right ? 
about half ? 
i ' m 
i ' m not sure if it ' s that ' s much . 
but anyway enough to work with . 
right . 
several minutes . 
um 
and and throw out the words . 
but keep the time markings . 
and then go through i mean and go through and and try and re transcribe it given that we had perfect boundary detection . 
okay . 
good idea . 
and see if it see if it see if it feels easier to you . 
okay . 
and forgetting all the words because you ' ve been 
yeah that ' s what i was thinking . 
i ' d i ' d be cheating a little bit with familiarity effect . 
yeah i mean uh that ' s part of the problem is is that what we really need is somebody else to come along . 
well no you should do it you should do it do it again from scratch . 
and then do it again at the boundaries . 
so you do the whole thing three times . 
and then we get 
yeah . 
no . 
now there ' s a plan . 
and then then since we need some statistics do it three more . 
okay . 
and so you ' ll get you ' ll get down to one point two x . by the time you get done . 
oh yeah . 
i ' ll do that tomorrow . 
i should have it finished by the end of the day . 
no but the thing is the fact that she ' s she ' s did it before just might give a lower bound . 
that ' s all . 
exactly . 
uh which is fine . 
yeah . 
right . 
it ' s 
yeah . 
and if the lower bound is nine x . then it ' s a waste of time . 
right . 
well but there ' s an extra problem which is that i didn ' t really keep accurate 
uh it wasn ' t a pure task the first time . 
oh . 
so uh it ' s going to be an upper bound in in that case . 
yeah . 
and it ' s not really strictly comparable . 
so i think though it ' s a good proposal to be used on a new a new batch of text that i haven ' t yet done yet in the same meeting could use it on the next segment of the text . 
the point we where do we get the the the oracle boundaries from ? 
right . 
or the boundaries . 
yeah one person would have to assign the boundaries and the and the other person would have to 
well but couldn ' t i do it for the next 
we we we could get fake 
oh i see what you mean . 
i mean that ' s easy enough . 
i could do that . 
well but the oracle boundaries would come from volume on a specific channel wouldn ' t they ? 
that would be the automatic boundaries . 
no no no no . 
no no . 
you want to know given given a perfect human segmentation i mean you want to know how well 
yeah . 
i mean the the question is is it worth giving you the segmentation . 
oh i see what you mean . 
yeah . 
i mean that that ' s easy enough . 
right . 
i could generate the segmentation and and you could do the words and time yourself on it . 
a little double blind ear kind of thing . 
so 
yep . 
i see . 
okay . 
so it that might be worth doing . 
that ' s good . 
i like that . 
that would at least tell us whether it ' s worth spending a week or two trying to get a tool that will compute the segmentations . 
and the thing to keep in mind too about this tool guys is that sure you can do the computation for what we ' re going to do in the future . 
right . 
but if if u . w . ' s talking about doing two or three or five times as much stuff and they can use the same tool then obviously there ' s a real multiplier there . 
right . 
and the other thing too is with with speaker identification . 
if if that could handle speaker identification that ' s a big deal . 
well it 
well use it . 
right . 
okay . 
yeah that ' s why we bought the expensive microphones . 
yeah i mean that ' s a nice feature . 
yep . 
yeah yeah . 
that ' s a major that ' s like one of the two things that 
i mean there ' s going to there ' s going to be in the meeting like the reading group meeting that we had the other day that ' s it ' s going to be a bit of a problem . 
okay . 
because like i wasn ' t wearing a microphone . 
and there were other people that weren ' t wearing microphones . 
yes . 
but you didn ' t say anything worth while anyway right ? 
that 
right . 
that ' ll 
yeah . 
that ' s pretty much true . 
but 
it might save ninety percent of the work though . 
but yes . 
so 
so i i need to we need to look at what what the final output is . 
but it seems like we it doesn ' t it seems like it ' s not really not that hard to have an automatic tool to generate the phrase marks and the speaker and speaker identity without putting in the words . 
yeah . 
i ' ve already become pretty familiar with the format . 
that ' d be so great . 
so 
yeah . 
uhhuh . 
it would be easy . 
yeah . 
we didn ' t finish the the part of work already completed on this . 
if you ' d tell me where it is huh ? 
did we ? 
i mean you you talked a little bit about the transcription conventions . 
uhhuh . 
and i guess you ' ve mentioned in your progress report or status report that you had written a script to convert it into 
so i when i the it ' s quickest for me in terms of the transcription part to say something like you know if if adam spoke to um to just say a . colon . 
like who could be you know i mean at the beginning of the line . 
huh . 
and e . colon instead of entering the interface for speaker identification and clicking on the thing uh indicating the speaker i . d . 
so and then he has a script that will convert it into the the thing that uh would indicate speaker i . d . 
if that ' s clear . 
it ' s pretty cute . 
okay . 
but at any rate . 
it ' s perl script . 
so um 
right . 
so so i think the guess at ten x . seems to be pretty standard . 
everyone more or less everyone you talk to says about ten times for hard technical transcription . 
uhhuh . 
yeah . 
using using stone 
using stone age tools . 
that ' s right . 
using using stone age tools . 
yeah well that ' s true . 
i mean i looked at cyber transcriber . 
but 
which is a service that you send an audio file . 
they do a first pass speech recognition . 
and then they they do a clean up . 
but it ' s going to be horrible . 
they ' re never going to be able to do a meeting like this . 
what just approximately what did you find out in terms of price or or whatever ? 
right . 
no . 
well for cyber transcriber they don ' t quote a price . 
they want you to call and and talk . 
so for other services um they were about thirty dollars an hour . 
of of tape ? 
or of action ? 
thirty 
so yeah . 
for thirty dollars an hour for of their work . 
okay . 
okay . 
oh of their 
oh . 
so so if it ' s ten times it ' s three hundred dollars an hour . 
so that ' s three that ' s three hours . 
did you talk to anybody that does closed captioning for for uh t . v ? 
okay . 
right . 
no . 
because they usually at the end of the show they ' ll tell what the name of the company is the captioning company that ' s doing it . 
uhhuh . 
interesting . 
yeah . 
so so my my search was pretty cursory . 
it was just a net search . 
and uh so it was only people who have web pages and are doing stuff through that . 
well you know the the thing the thing about this is thinking kind of maybe a little more globally than i should here . 
but that really this could be a big contribution we could make . 
uh i mean we ' ve been through the s . t . p . thing . 
we know what it what it ' s like to to manage the manage the process . 
and admittedly they might have been looking for more detail than what we ' re looking for here . 
but it was a it was a big hassle . 
right ? 
i mean uh you know they they constantly could ' ve reminding people and going over it . 
yeah . 
and clearly some new stuff needs to be done here . 
and it ' s it ' s only our time where our of course includes dan dan and you guys . 
it doesn ' t include me at all . 
uh 
just seems like 
yeah i mean i don ' t know if we ' d be able to do any thing to help s . t . p . type problems . 
but certainly for this problem we can do a lot better than 
why ? 
because they wanted a lot more detail ? 
no . 
right . 
because they had because they only had two speakers right ? 
i mean the the segmentation problem is 
only had two . 
trivial . 
they had two speakers over the telephone . 
oh i see . 
so what took them so long ? 
um mostly because they were doing much lower level time . 
yeah . 
so they were doing phone and syllable transcription as well as uh word transcription . 
right . 
right . 
right . 
uhhuh . 
and so we ' re we decided early on that we were not going to do that . 
i see . 
but there ' s still the same issue of managing the process of of reviewing and keeping the files straight and all this stuff that which is clearly a hassle . 
yep . 
yeah . 
right . 
and so so what i ' m saying is that if we hire an external service i think we can expect three hundred dollars an hour . 
yeah . 
i think that ' s the ball park . 
there were several different companies that and the the range was very tight for technical documents . 
twenty eight to thirty two dollars an hour . 
and 
who knows if they ' re going to be able to manage multiple channel data ? 
yeah they won ' t . 
they won ' t . 
they they ' ll refuse to do it . 
uhhuh . 
we ' ll have to mix them . 
right . 
yeah . 
and then there ' s the problem also that 
no but i mean they they they won ' t they won ' t they will refuse to transcribe this kind of material . 
that ' s not what they ' re quoting for right ? 
well they might they might quote it 
yes it is . 
for quoting meetings ? 
several of them say that they ' ll do meetings and conferences and and so on . 
wow . 
none of them specifically said that they would do speaker i . d . or speaker change mark . 
yeah . 
there may be just multiplier for five people costs twice as much and for ten people something like that . 
they all just said transcription . 
yeah yeah yeah . 
well the the way it worked is it it was scaled . 
so what they had is if it ' s an easy task it costs twenty four dollars an hour . 
and it will take maybe five or six times real time . 
and what they said is for the hardest tasks bad acoustics meeting settings it ' s thirty two dollars an hour . 
and it takes about ten times real time . 
i see . 
so i think that we can count on that being about what they would do . 
yeah . 
yeah . 
it would probably be a little more . 
right . 
because we ' re going to want them to do speaker marking . 
a lot of companies i ' ve worked for the uh the person leading the meeting the executive or whatever would sort of go around the room and and mentally calculate how many dollars per hour this meeting was costing . 
so 
right ? 
in university atmosphere you get a little different thing . 
but 
you know it ' s a lot like he ' s worth fifty an hour . 
he ' s worth 
and so so here we ' re thinking well let ' s see if the meeting goes another hour it ' s going to be another thousand dollars . 
you know ? 
it ' s 
yep . 
so so everybody talk really fast . 
we have to have a short meeting . 
that ' s very interesting . 
stop talking ! 
yeah . 
let ' s get it over with . 
talk slowly but with few words . 
and clearly . 
and 
that ' s right . 
only talk when you ' re pointed to . 
there you go . 
content words only . 
we could have some telegraphic meetings . 
that might be interesting . 
yeah it ' d be cheap . 
cheap to transcribe . 
so 
but at any rate so we we have a ballpark on how much it would cost if we send it out . 
and we ' re talking about doing how many hours worth of meetings ? 
thirty or forty . 
so thirty or forty thousand dollars . 
yeah . 
well for ten thousand dollars . 
so meanwhile 
oh . 
what well it was thirty times 
three hundred . 
three hundred dollars an hour . 
oh i ' m sorry . 
three hundred . 
right . 
i got an extra factor of three there . 
right . 
so it ' s thirty dollars an hour essentially right ? 
yeah . 
but we can pay a graduate student seven dollars an hour . 
and the question is what ' s the difference 
how how much lower are they ? 
or eight dollars . 
what do you know what the going rate is ? 
it ' s it ' s on the order of eight to ten . 
i think that would give us a a good good estimate . 
i think . 
but i ' m not sure . 
i ' d i ' d say 
ten . 
yeah i was going to say eight . 
you ' d say ten ? 
let ' s say ten . 
yeah give them a break . 
these are not for engineering graduate students right ? 
because it ' s easier . 
right . 
these are linguistics grad students . 
that ' s right . 
yeah i i i don ' t i don ' t know what the i don ' t know what the standard 
six . 
but there is a standard pay scale . 
i just don ' t know what it is . 
yeah that ' s right . 
uhhuh . 
that ' s right . 
um 
so that means that even if it takes them thirty times real time it ' s cheaper to to do graduate students . 
and there ' s another aspect too . 
i mean that ' s why i said originally that i couldn ' t imagine sending it out ' s going to be cheaper . 
no it isn ' t . 
the other thing too is that uh if they were linguistics they ' d be you know in terms of like the post editing uh uh content wise they might be easier to handle . 
so 
because they might get it more right the first time . 
and also we would have control of i mean we could give them feedback . 
whereas if we do a service it ' s going to be limited amount . 
huh . 
yep yep . 
good point . 
i mean we can ' t tell them you know for this meeting we really want to mark stress . 
yep . 
and for this meeting we want 
no . 
good point . 
and and they ' re not going to provide they ' re not going to provide stress . 
they ' re not going to provide repairs . 
they ' re not going to provide 
they they may or may not provide speaker i . d . 
so that we would have to do our own tools to do that . 
uhhuh . 
so 
yeah . 
just hypothetically assuming that that we go ahead and ended up using graduate students . 
i just 
who who ' s the person in charge ? 
who ' s going to be the steve here ? 
you ? 
i hope it ' s jane . 
oh interesting . 
is that all right ? 
um now would this involve some manner of uh monetary compensation ? 
or would i be the voluntary uh coordinator of multiple transcribers for checking ? 
um i would imagine there would be some monetary involved . 
but we ' d have to talk to morgan about it . 
yeah . 
out of out of adam ' s pocket . 
yeah . 
okay . 
you know it just means you have to stop working for dave . 
oh . 
see ? 
i don ' t want to stop working for dave . 
that ' s why dave should have been here . 
to protect his people . 
well i would like you to do it . 
oh cool . 
because you have a lot more experience than i do . 
yeah . 
uhhuh . 
but if if that ' s not feasible i will do it with you as an advisor . 
we ' d like you to do it . 
we ' ll see . 
and we ' d like to pay you . 
not being morgan though it ' s 
okay . 
yeah . 
oh i see . 
right . 
we ' d like to . 
well 
unfortunately . 
yeah . 
yeah six dollars an hour . 
yeah . 
yeah i see . 
that ' s a 
okay . 
and and then 
boy if i wanted to increase my income i could start doing the transcribing again . 
yeah that ' s right . 
and and be sure and say would you like fries with that when you ' re thinking about your pay scale . 
yeah . 
i see . 
good . 
yeah no that i i would be interested in that in becoming involved in the project in some aspect like that . 
okay . 
more . 
more . 
yeah . 
uhhuh . 
yeah . 
um any more on transcript we want to talk about ? 
what so what are you so you ' ve done some portion of the first meeting . 
yes . 
and what ' s your plan ? 
uhhuh . 
to carry on doing it ? 
what well you know what i thought was right now we have 
so i gave him the proposal for the transcription conventions . 
he made his uh suggestion of improvement . 
okay . 
the the it ' s a good suggestion . 
so as far as i ' m concerned those transcription conventions are fixed right now . 
and so my next plan would be 
what what do they what do they cover ? 
they ' re very minimal . 
so it would be good to just to summarize that . 
so um one of them is the idea of how to indicate speaker change . 
yeah . 
and this is a way which meshes well with with uh making it so that uh you know on the at the . 
yeah . 
boy it ' s such a nice interface . 
when you when you get the um you you get the speech signal you also get down beneath it an indication of uh 
if you have two speakers overlapping in a in a single segment you see them one displayed one above each other . 
and then at the same time the top part of the screen is the actual verbatim thing . 
you can clip click on individual utterances and it ' ll take you immediately to that part of the speech signal and play it for you . 
and you can you can work pretty well between those two these two things . 
is there a limit to the number of speakers ? 
um the user interface only allows two . 
huh . 
and so if if you ' re using their interface to specify overlapping speakers you can only do two . 
but my script can handle any . 
and their save format can handle any . 
and so um using this the convention that jane and i have discussed you can have as many overlapping speakers as you want . 
do is this a uh university project ? 
this is the french software right ? 
yeah . 
yeah . 
yeah yeah . 
french . 
yeah . 
their academic . 
and they ' re they ' ve been quite responsive . 
i ' ve been exchanging emails on various issues . 
oh really ? 
oh . 
uh did you ask them to change the interface for more speakers ? 
yes . 
and they said that ' s on in in the works for the next version . 
good . 
good . 
oh so multichannels . 
multichannels was also 
well they said they wanted to do it but that the code is really very organized around single channels . 
i see . 
so i think that ' s unlikely to happen . 
okay . 
do you know what they ' re using it for ? 
why ' d they develop it ? 
for this exact task ? 
are they linguists ? 
for transcription . 
it ' s 
but i mean are they are they linguists or are they speech recognition people ? 
i think they ' re linguists . 
huh . 
linguists . 
they ' re they have some connection to the l . d . c . 
yeah . 
because the l . d . c . has been advising them on this process . 
the linguistic data consortium . 
uhhuh . 
um 
so 
but apart from that . 
yeah . 
it ' s also all the source is available . 
so 
right . 
great . 
if you if you speak t . c . l . t . k . 
uhhuh . 
and they have they ' ve actually asked if we are willing to do any development . 
and i said well maybe . 
good . 
right . 
uhhuh . 
so if we want if we did if we did something like programmed in a delay which actually i think is a great idea um i ' m sure they would want that incorporated back in . 
yeah i do too . 
uhhuh . 
their pre lay . 
pre lay . 
pre lay . 
way . 
well and they ' ve thought about things . 
you know i mean they they do have 
so you have when you when you play it back um it ' s it is useful to have uh a a break mark to segment it . 
but it wouldn ' t be strictly necessary . 
because you can use the uh the tabbed key to toggle the sound on and off . 
i mean it ' ll stop the speech you know if if you press a tab . 
and um 
and so 
uh that ' s a nice feature . 
and then also once you ' ve put a break in then you have the option of cycling through the unit . 
you could do it like multiply . 
until you get crazy and decide to stop cycling through that unit . 
loop it ? 
or or 
you you know there ' s also the the user interface that ' s missing . 
or 
it ' s missing from all of our offices . 
and that is some sort of analog input for something like this . 
it ' s what audio people actually use of course . 
it ' s something that when you move your hand further the sound goes faster past it . 
like fast forward . 
you know like a joy stick . 
or a uh you could wire a mouse or trackball to do something like that . 
why that ' s 
that ' s not something i wanted to have happen . 
no but i ' m saying if this is what professionals who actually do this kind of thing for for for for video or for audio where you you need to do this . 
i see . 
uhhuh . 
and so you get very good at sort of jostling back and forth rather than hitting tab and backspace and carriage return and enter and things like that . 
huh . 
huh . 
uhhuh . 
yeah . 
yeah we talked about things like foot pedals and other analog 
uhhuh . 
so i mean those are things we could do . 
but 
i i just don ' t know how much it ' s worth doing . 
yeah . 
i mean we ' re just going to have 
yeah . 
right . 
i i agree . 
yeah . 
they they have several options . 
so uh you know i mentioned the looping option . 
another option is it ' ll pause when it reaches the end of the boundary . 
and then to get to the next boundary you just press tab . 
and it goes on to the next unit . 
huh . 
i mean it ' s very nicely thought out . 
cool . 
they thought about 
huh . 
and also it ' ll go around the the uh 
i want to say cursor . 
but i ' m not sure if that ' s the right thing . 
point . 
whatever . 
anyway you can so they thought about different ways of having windows that you uh work within . 
uhhuh . 
and but so in terms of the the conventions then uh basically uh it ' s strictly orthographic . 
which means with some provisions for uh uh colloquial forms . 
so if a person said because instead of because then i put a an apostrophe at the beginning of the word and then in in double angle brackets what the full lexical item would be . 
uhhuh . 
and this could be something that was handled by a table or something . 
but i think to have a convention marking it as a nonstandard or i don ' t mean standard but a a a uh orthographic uh whatever . 
uhhuh . 
uhhuh . 
non - canonical . 
going to or want to . 
you know the same thing . 
and and there would be limits to how much refinement you want in indicating something as nonstandard pronunciation . 
how are you handling backchannels ? 
backchannels . 
um 
comments ? 
you know 
oh yes . 
there was some 
in my view when when you ' ve got it densely overlapping um i didn ' t worry about i didn ' t worry about specific start times . 
what do you mean by 
i sort of thought that this is not going to be easily processed anyway . 
and maybe i shouldn ' t spend too much time getting exactly when the person said no or you know uh immediate . 
yeah . 
and instead just sort of rendered within this time slot there were two people speaking during part of it . 
yeah . 
and if you want more detail figure it out for yourself . 
uhhuh . 
i see . 
well i think what what eric was talking about was channels other than the direct speech . 
was sort of the way i felt . 
right ? 
well yeah . 
what i mean is i mean when somebody says uhhuh in the middle of uh a 
yep . 
uhhuh . 
that happened very seldom . 
oh because i was i was listening to dan was agreeing a lot to things that you were saying as you were talking . 
uhhuh . 
uhhuh . 
oh well thank you dan . 
so 
appreciate it . 
well if it if there was a word like right you know then i i would indicate that it happened within the same time frame . 
yeah there ' s an overlapping mark . 
and 
yeah . 
but wouldn ' t say exactly when it happened . 
i ' ll be right back . 
i transcribed a minute of this stuff . 
i see . 
and there was a lot of overlapping . 
it was 
a lot of overlapping yeah . 
well there ' s a lot of overlapping at the beginning and end . 
yeah . 
yeah . 
huge amounts . 
it was at the beginning . 
um when when no one when we ' re not actually in the meeting and we ' re all sort of separated and and doing things . 
but even during the meeting there ' s a lot of overlap . 
but it it ' s marked pretty clearly . 
um some of the backchannel stuff jane had some comments . 
and but i think a lot of them were because you were at the meeting . 
and so i think that that often often you can ' t tell . 
yeah . 
well that ' s true . 
that ' s another issue . 
i mean jane had had comments like uh to who who the person was speaking to . 
yeah . 
yeah . 
uhhuh . 
only when it was otherwise going to be puzzling . 
because he was in the other room talking . 
yeah . 
yeah but someone who uh was just the transcriber wouldn ' t have known that . 
yeah . 
that ' s true . 
right . 
or when dan said i i wasn ' t talking to you . 
i know . 
so you take a bathroom break in the middle and and keep your head 
you have to turn off your mike . 
yeah . 
oh you do ? 
well he was 
you don ' t have to . 
so so he was checking the meter levels . 
and and we were handling things while he was labeling the the whatever it was . 
the p . d . a ? 
uhhuh . 
uhhuh . 
and and so he was in sort of you were sort of talking . 
you know . 
so i was saying like and i could label this one left . 
right ? 
and he and he said i don ' t see anything . 
and he said he said i wasn ' t talking to you . 
or it wasn ' t it didn ' t sound quite that rude . 
but 
but really no uh you know in the context if you know he can ' t hear what he ' s saying 
but when you when you listen to it 
it was a lot funnier if you were there though . 
uh yeah . 
i know . 
well you ' ll see . 
well what what it what happens is if you ' re a transcriber listening to it it sounds like dan is just being a total totally impolite . 
you can listen to it . 
oh i thought it was you who was . 
no well but you were you were asking off the wall questions . 
um 
but but if you knew that that i wasn ' t actually in the room and that dan wasn ' t talking to me it it became okay . 
i see . 
so 
so 
and that ' s that ' s where i added comments . 
huh . 
the rest of the time i didn ' t bother with who was talking to who . 
but but this was unusual circumstance . 
so this is this is going to go on the meeting meeting transcriber bloopers tape right ? 
yes . 
right . 
well and part of it was funny uh reason was because it was a mixed signal . 
so you couldn ' t get any clues from volume that you know he was really far away from this conversation . 
stereo . 
yeah . 
you couldn ' t do that symmetrically in any case . 
no . 
oh . 
i should rewrite the mix tool to put half the people in one channel and half in the other . 
i have a auto gain mixer tool that mixes all the head mounted microphones into one signal . 
that ' s a good idea . 
uhhuh . 
and that seems to work really well for the uh transcribers . 
great . 
but i thought it would be you know i i didn ' t want to add more contextual comments than were needed . 
but that it seemed to me clarified that the what was going on . 
and uh 
okay . 
so normalization . 
so 
i was just going to ask uh so i just wanted to sort of finish off the question i had about backchannels . 
yeah . 
if that ' s okay . 
huh . 
okay . 
which which was so say somebody ' s talking for a while . 
yeah . 
and somebody goes uhhuh in the middle of it and and and what not . 
does the conversation come out from the or the person who ' s speaking for the long time as one segment and then there ' s this little tiny segment of this other speaker ? 
or does it does the fact that there ' s a backchannel split the the the it in two ? 
okay my my focus was to try and maintain content continuity and uh to keep it within what he was saying . 
like i wouldn ' t say breath groups but prosodic or intonational groups as much as possible . 
so if someone said uhhuh in the middle of a of someone ' s uh uh intonational contour i i indicated it as like what you just did . 
okay . 
then i indicated it as a segment which contained this utterance plus an overlap . 
okay . 
but that ' s but there ' s only one there ' s only one time boundary for both speakers . 
yeah . 
that ' s right . 
right ? 
and you know it could be made more precise than that . 
but i just thought 
i see . 
i see . 
okay . 
yeah . 
right . 
i think whenever we use these speech words we should always do the thing like you ' re talking about accent . 
oh i see what you mean . 
and then hesitation . 
yeah . 
okay . 
and so then uh in terms of like words like uh and um i just wrote them . 
because i figured there ' s a limited number . 
and i keep them to a uh limited set . 
because it didn ' t matter if it was huh or um you know versus um . 
so i just always wrote it as u . m . . 
and uhhuh you know u . h . u . h . i . mean like a set of like five . 
okay . 
but in any case i didn ' t mark those . 
uhhuh . 
no . 
uhhuh is u . h . h . u . h . . 
uhuh is u . h . u . h . 
i ' d be happy with that . 
that ' d be fine . 
it ' d be good to have that in the in the conventions what ' s to be used . 
huh uh . 
i i did notice that there were some segments that had pauses on the beginning and end . 
we should probably mark areas that have no speakers as no speaker . 
yeah . 
that ' s a fine idea . 
then so question mark colon is fine for that . 
that ' s a fine idea . 
yeah . 
okay . 
well what ' s that mean ? 
just say silence . 
yeah . 
you mean 
no one ' s talking . 
oh . 
silence all around . 
yep . 
yep . 
so i had 
we have to mark those ? 
i 
don ' t they can ' t we just leave them unmarked ? 
well you see that ' s possible too . 
well i want to leave the marked 
i don ' t want them to be part of another utterance . 
okay . 
so you just you need to have the boundary at the start and the end . 
sure . 
uhhuh . 
now that ' s refinement that uh maybe it could be handled by part of the part of the script or something more . 
uh yeah . 
it seems like 
it seems like the uh the transcription problem would be very different if we had these automatic speaker detection turn placing things . 
because suddenly 
i mean i don ' t know . 
actually it sounds like there might be a problem putting it into the software if the software only handles two parallel channels . 
but assuming we can get around that somehow . 
uhhuh . 
well you were saying i think it can read 
it can read and write as many as you want . 
it ' s just that 
uhhuh . 
but what if you want to edit it ? 
right ? 
i mean the point is we ' re going to generate this transcript with five five tracks in it but with no words . 
someone ' s going to have to go in and type in the words . 
um 
and if there are five five people speaking at once 
right it ' s 
i didn ' t explain it well . 
if we use the the little the conventions that jane has established i have a script that will convert from that convention to their saved convention . 
oh yeah . 
yes . 
which allows five . 
right . 
and it can be edited after the fact . 
can ' t it also ? 
yes . 
but their but their format if you wanted to indicate the speakers right there instead of doing it through this indirect route then they a window comes up and it only allows you to enter two speakers . 
yeah . 
right . 
but you ' re saying that by the time you call it back in to from their saved format it opens up a window window with five speakers ? 
so 
but 
right . 
oh . 
that is sort of 
they didn ' t quite go the whole 
it ' s just user interface . 
so it ' s 
yeah they didn ' t go the whole route . 
did they ? 
the the the whole saved the saved format and the internal format all that stuff handles multiple speakers . 
they just 
it ' s just there ' s no user interface for specifying multiple any more than two . 
right . 
so your your script solves doesn ' t it solve all our problems . 
and that 
yep . 
because we ' re always going to want to go through this preprocessing . 
yep . 
uh assuming it works . 
yep . 
and that works nicely because this so quick to enter . 
so i wouldn ' t want to do it through the interface anyway adding which worry who the speaker was . 
yep . 
i see . 
right . 
good . 
and then uh let ' s see what else . 
oh yes . 
i i wanted to have 
so sometimes a i 
in terms of like the continuity of thought for transcriptions it ' s it isn ' t just words coming out . 
it ' s like there ' s some purpose for an utterance . 
and sometimes someone will do a backchannel in the middle of it . 
but you want to show that it ' s continued at a later point . 
so i have i have a convention of putting like a dash arrow just to indicate that this person ' s utterance continues . 
and then when it uh catches back up again then there ' s an arrow dash . 
and then you have the opposite direction to indicate continuation of ones own utterance versus 
um 
sometimes we had the situation which is you know which you which you get in conversations of someone continuing someone else ' s utterance . 
huh . 
and in that case i did a tilde arrow versus a arrow tilde to indicate that it was continuation . 
but it wasn ' t 
oh i guess i did equal arrow for the for the own for yourself things . 
uhhuh . 
because it ' s the speakers the same . 
and then tilde arrow if it was a different if a different speaker uh continuation . 
huh . 
oh . 
but just you know the arrows showing continuation of a thought . 
uhhuh . 
and then you could track whether it was the same speaker or not by knowing 
you know at the end of this unit you ' d know what happened later . 
and that was like this person continued . 
uhhuh . 
and you ' d be able to look for the continuation . 
but the only time that becomes ambiguous is if you have two speakers . 
like if you if you only have one person if you only have one thought that ' s continuing across a particular time boundary you just need one arrow at each end . 
and if it ' s picked up by a different speaker it ' s picked up by a different speaker . 
the time it becomes ambiguous if you have more than one speaker and that and they sort of swap . 
i guess if you have more than one thread going then you then you need to know whether they were swapped or not . 
uhhuh . 
uhhuh . 
uhhuh . 
how often does that happen do you think ? 
hopefully not very much . 
yeah i didn ' t use it very often . 
especially for meetings . 
it 
i mean if if you were just recording someone ' s day it would be impossible you know . 
if you were trying to do a remembrance agent . 
but i think for meetings it ' s probably all right . 
huh . 
but a lot of these issues i think that for uh from my point of view where i just want to do speech recognition and information retrieval it doesn ' t really matter . 
sure . 
i know . 
but other people have other interests . 
but it it does feel it does feel like it ' s really in there . 
so 
i you know i did this i did this transcription . 
and i marked that i marked it with ellipsis . 
because it seemed like there was a difference . 
it ' s something you wanted to indicate that it that i this was the end of the phrase . 
this was the end of that particular transcript . 
but it was continued later . 
and i picked up with an ellipsis . 
right . 
excellent . 
yeah . 
yeah . 
i didn ' t have the equal not equal thing . 
well that ' s you know i mean i that ' s why i didn ' t i didn ' t do it . 
i mean that ' s why i thought about it and and re ev 
yeah yeah . 
and it didn ' t do i didn ' t do it in ten times the the time . 
yeah . 
well so anyway are we interested then in writing tools to try to generate any of this stuff automatically ? 
is that something you want to do dan ? 
no . 
but it ' s something that i feel we definitely ought to do . 
no . 
i also wanted to ask you if you have a time estimate on the part that you transcribed . 
do you have a sense of how long 
yeah it took me half an hour to transcribe a minute . 
but i didn ' t have any i didn ' t even have a 
okay . 
i was trying to get transcriber to run but i couldn ' t . 
so i was doing it by typing into a text file and trying to fit . 
okay . 
it was horrible . 
okay . 
so thirty to one ' s what you got ? 
uhhuh . 
so that ' s new upper limit ? 
yeah . 
well i mean that ' s that ' s because you didn ' t have the segmentation help and all the other 
is it 
but i think for a first try that ' s about right . 
so so if we hired a if we hired a whole bunch of dan ' s 
that ' s right . 
yeah . 
it was actually it was quite it was a 
if we hire an infinite number of dan ' s 
and there ' s always a warm up thing of 
it ' d 
it 
are we going to run out of disk space by the way ? 
yeah . 
no . 
okay . 
good . 
okay . 
doesn ' t it beep in the other room when you ' re out of disk space ? 
so 
is there 
no . 
maybe we should consider also um starting to build up a web site around all of these things . 
web site . 
that ' s great ! 
i know . 
dan ' s sort of already started . 
we could have like business to business e . commerce as well . 
that ' s right . 
no but 
it would be interesting it would be interesting to see 
can we sell banner ads ? 
get get paid for click throughs ? 
yeah . 
what a good idea . 
that ' s how we could pay for the transcription . 
i want to introduce 
i i want to introduce the word snot - head into the conversation at this point . 
we can have 
you want to word that won ' t be recognized ? 
you see because uh because 
exactly . 
oh i don ' t think so . 
um 
no . 
the 
hey what about me ? 
what 
okay . 
you ' re the one who raised the issue . 
no . 
all right . 
see here ' s here ' s here ' s my thought behind it . 
which is that uh the the stuff that you ' ve been describing jane i one has to of course indicate um is very interesting . 
all right . 
and 
i ' d like to be able to to pore through you know the the types of conventions that you ' ve come up with and stuff like that . 
yeah yeah yeah . 
so i would like to see that kind of stuff on the web . 
okay . 
now the alternative to a web site would be to put it in doctor speech . 
yes . 
yes . 
because because what i have is a soft link to my transcription that i have on my account . 
either ' s fine . 
we 
but it doesn ' t matter . 
we can do it all . 
we can do it all . 
okay . 
we can write 
web site ' s nice . 
oh . 
yeah . 
then you have to you have to do an h . t . access . 
web site ' s what ? 
we could actually maybe we could use the t . c . l . plug in . 
oh man . 
ooo ! 
he ' s committed himself to something . 
ow . 
see he said the word t . c . l . and and that ' s 
but he does such a good job of it . 
he should be allowed to to you know do it . 
i know i know . 
i know . 
but that but i 
right . 
but i should be allowed to . 
but 
if you just did a crappy job nobody would want you to do it . 
i i shouldn ' t be allowed to by by my own by my according to my own priorities . 
all right . 
let ' s look at it anyway . 
so definitely we should we should have some kind of access to the data . 
yeah . 
and we have we have quite a disparate number of web and other sorts of documents on this project sort of spread around . 
i have several . 
and dan has a few . 
yes . 
uh . 
right . 
so we can add in links and stuff like that to other things . 
and 
nice . 
yep . 
well yeah . 
the 
well so then 
try try to consolidate . 
i mean who wants to do that though ? 
the other side is yeah . 
uh right . 
no one wants to do that . 
yeah . 
so 
right . 
that ' s the problem . 
why ? 
what what ' s what ' s the issue ? 
well we could put we could put sort of a disorganized sort of group gestalt . 
no one owns the project . 
no one what ? 
no one owns the project . 
yeah i own the project . 
but i don ' t want to do it . 
no one wants to own the project . 
right . 
well do but 
it ' s mine ! 
all mine ! 
well then you have to do the web site . 
but 
you know it ' s like it ' s that simple . 
wah hah hah hah hah hah . 
but but but what are you what are you talking about for web site hacking ? 
no . 
you ' re talking about writing h . t . m . l . right ? 
yeah . 
yeah i i ' m talking about putting together all the data in a form that that is legible and pleasant to read and up to date and et cetera et cetera et cetera . 
but is it against the law to actually use a tool to help your job go easier ? 
absolutely . 
it ' s it ' s absolutely against the law to use a tool . 
you 
i haven ' t found any tools that i like . 
it ' s just as easy to use to edit the raw h . t . m . l . as anything else . 
no kidding ? 
that ' s obviously not true . 
but you have 
it ' s obviously not true . 
no it ' s obviously true that he hasn ' t found any he likes . 
right . 
the question is what is what ' s he looked at . 
that ' s true . 
which one do you use jim ? 
i use something called trellix . 
oh that ' s right . 
i remember . 
yeah . 
and it 
which produces also site maps . 
it ' s very powerful . 
now i guess if i were if i were doing more powerful excuse me more complex web sites i might want to . 
but 
most of the web sites i do aren ' t that complex . 
well would this be to document it also for outside people or mainly for in house use ? 
but 
no i think 
i think both . 
i think mostly internal . 
mostly in house . 
that ' s right . 
okay . 
well yeah . 
but what does internal mean ? 
no both . 
i mean you ' re leaving . 
people at u . w . want to look at it . 
i mean it ' s it ' s internal until 
right . 
internal to the project . 
i see . 
we could do an h . t . access which would accommodate those things . 
i i i i 
okay . 
well 
send me links . 
and i 
send me pointers rather . 
and i ' ll put it together . 
i ' m not 
wonderful . 
okay . 
i ' m not sure how how important that distinction is . 
i don ' t think we should say oh it ' s internal . 
therefore we don ' t have to make it very good . 
i mean you can say oh oh it ' s internal . 
no . 
no . 
therefore we can put data in it that we don ' t we don ' t have to worry about releasing . 
but i think the point is to try and be coherent and make it a nice presentation . 
right . 
i agree . 
yeah it is true that is it benefits to 
because you ' re going to have to do the work sooner or later . 
that ' s right . 
yeah . 
i mean it ' s the early on . 
even if it ' s just writing things up . 
yep . 
you know ? 
it ' s a great idea . 
okay . 
um let ' s move on to electronics . 
uh . 
we we out of tape out of disk ? 
great . 
no . 
we ' re doing we ' re doing great . 
i i was looking for the actual box i plan to use . 
uh 
but i all i could i couldn ' t find it at the local store . 
but this is the the technology it ' s actually a little bit thinner than this . 
and it ' s two by two by one . 
and it would fit right under the right under the the the lip . 
yeah does everyone know about the lip on the table ? 
yeah . 
it ' s great . 
there ' s a lip in these tables . 
nice . 
and it i especially brought the bottom along to try and generate some frequencies that you may not already have recorded . 
clink ! 
let ' s see see what it does to the 
clink ! 
but this was the uh just just to review . 
and i also brought this along rather than the projector so we can put these on the table and sort of push them around . 
and and crinkle them and 
and that being a diagram . 
what ? 
what ? 
that that ' s the six tables that we ' re looking at . 
these six tables here with with little boxes sort of uh in the middle here . 
okay . 
i see . 
which would 
i mean the the boxes are pretty much out of the way anyway . 
i ' ll show you the the 
this is the table cross section . 
i don ' t know if people realize what they ' re looking at . 
you trying to screw up the the microphones ? 
yes . 
i mean 
he is . 
absolutely . 
well why not ? 
i mean because this is what ' s going to happen . 
you got plenty of data . 
i won ' t come to your next meeting . 
and and 
and so this is the box ' s 
get your paper off my p . d . a ! 
yeah . 
yeah . 
let let the record show that this is exhibit two b . . 
that ' s right . 
or not to be . 
yeah yeah . 
yeah . 
uh the box uh there ' s a half inch lip here . 
the box is an inch thick . 
so it hangs down a half an inch . 
and so the the two head set jacks would be in the front . 
and then the little l . e . d . to indicate that that box is live . 
the the important issue about the l . e . d . is the fact that we ' re talking about eight of these total which would be sixteen channels . 
and uh even though we have sixteen channels back at the capture they ' re not all going to be used for this . 
huh . 
so there ' d be a subset of them used for obviously just use the ones at this end for for this many . 
so 
excuse me . 
you ' d like a a way to tell whether your box is live so the l . e . d . wouldn ' t be on . 
right . 
all the lights . 
so if you ' re plugged in it doesn ' t work and the l . e . d . is off that ' s that ' s a tip off . 
that ' s good . 
and then the uh would wire the all of the cables in a in a bundle come through here and obviously collect these cables at the same time . 
uh so this this notion of putting down the p . z . m . ' s and taking them away would somehow have to be turned into leaving them on the table . 
or or 
right . 
well we want to do that definitely . 
right . 
right . 
so 
and so the you we just epoxy them down or something . 
big screw into the table . 
velcro . 
uh 
and even though there ' s eight cables they ' re not really very big around . 
so my model is to get a a piece of 
sleeve . 
yeah that that stuff that people put with the little you slip the wires into that ' s sort of shaped like that cross section . 
oh . 
yeah . 
okay not just sleeve them all ? 
i ' m i ' m i ' m going up and then i ' m going down . 
no . 
and leave them loose ? 
that looks like a semi circle . 
yeah . 
it ' s like a it ' s a sleeping policeman . 
sleeping 
speed bump ! 
whoo ! 
speed bump . 
yeah it ' s like a speed 
speed bump . 
a sleeping policeman . 
that ' s good . 
there we go . 
and they ' re they ' re actually extruded from plastic . 
cool . 
what is 
they sort of look like this . 
oh . 
what does that mean ? 
that ' s the that ' s british for speed bump . 
is it a speed bump ? 
so that the wires go through here . 
yeah . 
oh is that right ? 
wow ! 
i never heard that . 
yeah . 
uh . 
so 
that ' s really cruel . 
okay . 
so that 
so it would basically go on the diagonal here . 
it could go either way . 
so why do we have sixteen channels instead of like some fewer number ? 
yeah . 
i guess . 
uh because the 
how else are you going to distribute them around the tables ? 
because they ' re there . 
well okay . 
let me rephrase that . 
why two each ? 
oh because then you don ' t have to just have one each . 
so that if if you have two people sitting next to each other they can actually go into the same box . 
yeah . 
and to see this is really the way people sit on this table . 
okay . 
uhhuh . 
okay . 
uh 
dot dot dot . 
which means two at each station . 
well that that ' s the way people sit . 
that ' s how many chairs are in the room . 
yeah . 
yeah i ' m just saying that for the recording . 
all right . 
yeah . 
right . 
right . 
okay . 
and certainly you could do a thing where all sixteen were plugged in . 
uh if if you if you had nothing else . 
but then none of these . 
right . 
none of these and no p . z . m . ' s then . 
yeah . 
right . 
right . 
i agree . 
only if you had 
well it depends on this box right ? 
oh true enough . 
and actually at the my plan is to only bring eight wires out of this box . 
exactly . 
this this box 
oh i didn ' t understand . 
that being the wiring box . 
this box is a one off deal . 
oh i see . 
i see . 
uh 
and uh it ' s function is to to uh essentially a wire converter to go from these little blue wires to these black wires . 
plus supply power to the microphones . 
because the the the uh cheap head mounteds all require low voltage . 
so so you ' d imagine some sort of in some sort of patch panel on top to figure out what the mapping was between each of these two and each of those one or what ? 
well i 
huh . 
the simplest thing i could imagine which is really really simple is to quite literally that these things plug in . 
and there ' s a there ' s a plug on the end of each of these these uh eight cables . 
what 
okay . 
yeah . 
each of the blue wires . 
but there are only four . 
uhhuh . 
and there ' s only there ' s only four slots that are you know in in the first version or the version we ' re planning to to build . 
yeah . 
uhhuh . 
so that that was the whole issue with the l . e . d . 
yeah . 
that you plug it in the l . e . d . comes on and and and you ' re live . 
oh then it comes on . 
i see i see . 
okay . 
good . 
now the the the subtle issue here is that i i haven ' t really figured out a solution for this . 
so it ' ll have to be convention . 
what happens if somebody unplugs this because they plug in more of something else ? 
uhhuh . 
well the there ' s no clever way to let the up stream guys know that you ' re really not being powered . 
so 
there will be a certain amount of looking at cables has to be done if people uh rewire things . 
right . 
but 
yeah i mean we i had that last time . 
but uh there are actually that you know there ' s an extra there ' s a mix out on the radio receiver ? 
uhhuh . 
so there are actually six x . l . r . outs on the back of the radio receiver . 
and only five cables going in . 
i had the wrong five . 
so i ended up not recording one of the channels and recording the mix . 
how interesting . 
did you do any recognition on the mix mix out ? 
huh . 
no . 
wonder whether it works any 
but i subtracted the four that i did have from the mix and got a pretty good approximation of the . 
got the fifth ? 
you 
oh how great . 
cool ! 
yeah . 
and did it work ? 
is it is 
did it sound good ? 
it ' s not bad . 
it ' s not bad . 
yeah . 
ain ' t science wonderful ? 
wow . 
that ' s amazing . 
yeah . 
so 
so what ' s the schedule on these things ? 
wow . 
but you always 
uh 
well i was wrestling with with literally the number of connectors in the cable and the the uh powering system . 
and i i was going to do this very clever phantom power . 
and i decided a couple days ago not to do it . 
huh . 
so i ' m ready to build it . 
which is to say uh the neighborhood of a week to get the circuit board done . 
uhhuh . 
so i think the other thing i ' d like to do is do something about the set up . 
so that it ' s a little more presentable and organized . 
i agree . 
and i ' m i ' m just not sure what that is . 
i mean some sort of cabinet . 
well i can build a cabinet . 
the the difficulty for this kind of project is the intellectual capital to design the cabinet . 
uhhuh . 
in other words to figure out exactly what the right thing is . 
that cabinet can can go away . 
we can use that for for uh kindling or something . 
but if you can imagine what the right form factor is 
dan and i have sort of gone around on this and we were thinking about something that opened up in the top to allow access to the mixer for example . 
uhhuh . 
but there ' s these things sticking out of the mixer which are kind of a pain . 
so you end up with this thing that 
if you stuck the mixer up here and the top opened it ' d be it ' d be fine . 
you wouldn ' t necessarily 
well . 
you understand what i ' m 
the the you can you can start start sketching it out . 
yeah . 
yeah i understand . 
so 
and i can certainly build it out of oak . 
no problem . 
would it you know you know arbitrarily amount of 
i need a desk at home too all right ? 
is that going to be a better solution than just going out and buy one ? 
well the as we found out with the the thing that uh jeff bought a long time ago to hold our stereo system the stuff you buy is total crap . 
and i mean this is something you buy . 
uhhuh . 
and and 
and it ' s total crap . 
it ' s total crap . 
well it ' s useless for this function . 
works fine for holding a kleenex . 
but it 
right . 
kleenex and telephones . 
right . 
um 
so yeah i i guess it ' s just a question is that something you want to spend your time on . 
oh . 
i i ' m paid for . 
okay great . 
i have no problem . 
no but certainly one of the issues is is the uh is security . 
huh . 
i mean we ' ve been been been lax and lucky . 
uhhuh . 
yeah . 
lax . 
yep . 
really lucky with these things . 
but they ' re not ours . 
so 
the uh the flat panels . 
yeah . 
oh yeah . 
i ' m telling you i ' m just going to cart one of them away if they stay there much longer . 
wow . 
uh let the record show at uh at four thirty five adam janin says 
well yeah exactly . 
tempting . 
tempting . 
we ' ll know we ' ll know to come after . 
yeah . 
so um 
uh 
then the other question is do we want to try to do a user interface that ' s available out here . 
sorry ? 
user interface 
slipped almost slipped it by dan . 
a user interface . 
i mean do we want to try to get a monitor ? 
oh ! 
or just something . 
oh . 
sure . 
well of course we do . 
and how do we want to do that ? 
you mean like see see meter readings from while sitting here ? 
just so we see something . 
wow . 
how about use the thing that um aciri ' s doing ? 
yeah . 
which is to say just laptop with a wireless . 
yeah yeah . 
oh . 
sure . 
which we ' ll borrow from them when we need it . 
what ' s wrong with yours ? 
if we bought you a a 
oh applecard . 
sure . 
right . 
yeah you could use my machine . 
well 
what ? 
i have an i . ram machine i ' ve borrowed and we can use it . 
i or the 
no . 
i ' m i ' m i ' m serious . 
does does the wireless thing work on your 
wait isn ' t that an ethernet connection or is that a phone ? 
uh that ' s an ethernet connection . 
well . 
yeah no no i ' m i i i ain ' t joking here . 
it ' s going next door . 
we 
i ' m serious that that it it 
yeah . 
no no . 
absolutely that ' s the right way to do it . 
to have it uh just 
it ' s very convenient especially if dan happens to be sitting at that end of the table to not have to run down here and and look in the thing every so often . 
yeah . 
but just have the 
and given given that we ' ve got a wireless that we ' ve got a we got the field . 
it ' s right there . 
right . 
right ? 
the antenna ' s right there . 
yeah . 
right . 
right outside the 
yeah . 
i don ' t know . 
i mean we need obviously need to clear this with aciri . 
but uh 
how tough can that be ? 
there it you ' d all you need ' s web access isn ' t it ? 
we don ' t need x . access . 
in in theory . 
but i mean that ' s fine . 
that ' s that ' s what it does . 
okay . 
great . 
yeah . 
great . 
so 
um 
right so it ' s just a question of getting a laptop and a wireless modem . 
with a with a with a 
no . 
and he he had 
my my proposal is you have a laptop . 
no . 
you don ' t ? 
yeah . 
i do . 
yeah . 
yeah yeah . 
if if we bought you the thing would you mind using it with the the 
no . 
i would love to . 
but i ' m not sure if my laptop is compatible with the wave lan thing they ' re using . 
really ? 
to mac . 
your new one ? 
well apple has their own thing right ? 
he ' s 
i ' m sorry ? 
airport . 
apple has their own thing . 
and 
i thought it just came through a serial or an ethernet port . 
yeah . 
i think what 
i think you i think it just plugs in a p . c . card . 
so you could probably make it run with that . 
but 
the question is is there an apple driver . 
i 
yeah i ' m sure . 
i imagine there is . 
but anyway . 
but the two 
there are there are there are a bunch of machines at icsi that have those cards . 
and so i think if if it doesn ' t we should be able to find a machine that does that . 
i i mean i know that 
doesn ' t don ' t don ' t the important people have those little blue vaios that 
well uh that to me that ' s a whole nother that ' s a whole nother issue . 
huh . 
huh . 
yeah . 
the the idea of convincing them that we should use their network is fairly straight forward . 
yeah . 
yeah . 
the idea of being able to walk into their office and say oh can i borrow your machine for a while is is is a non starter . 
yeah . 
that i i don ' t think that ' s going to work . 
i see . 
so i mean either either we figure out how to use a machine somebody already in the group already owns and the idea is that if it ' s it perk you know it ' s an advantage not not a or else we we literally buy a machine exactly for that purpose . 
yeah . 
yeah yeah . 
absolutely . 
yeah . 
certainly it solves a lot of the problems with leaving a monitor out here all the time . 
i i i i ' m i ' m not a big fan of doing things to the room that make the room less attractive for other people . 
yeah . 
right . 
right ? 
which is part of the reason for getting all this stuff out of the way . 
yeah . 
and and a monitor sitting here all the time you know people are going to walk up to it and go how come i can ' t get you know pong on this or 
uhhuh . 
right . 
well 
i ' ve i ' ve borrowed the i . ram vaio sony thingy . 
right . 
yeah . 
and i don ' t think they ' re ever going to want it back . 
you ' re kidding ? 
well the next conference they will . 
so 
sure . 
yeah . 
but that does mean so we can use that as well . 
well uh the certainly you should give it a shot first see whether you can get compatible stuff . 
uhhuh . 
uh ask them what it costs . 
ask them if they have an extra one . 
who knows they might have an extra hardware 
i ' d trade them a flat panel display for it . 
yeah . 
good . 
what is the um projector supposed to be hooked up to ? 
uh the uh tsk 
it ' s going to be hooked up to all sorts of junk . 
there ' s going to be actually a a plug at the front that ' ll connect to people ' s laptops so you can walk in and plug it in . 
and it ' s going to be connected to the machine at the back . 
so we certainly could use that as as a constant reminder of what the v . u . meters are doing . 
huge v . u . meters . 
so people sitting here are going testing one two three . 
it 
but i mean that ' s another that ' s another possibility that you know solves 
yeah . 
yeah . 
that ' s an 
but but but i think the idea of having a control panel it ' s that ' s there in front of you is really cool . 
yeah . 
yeah yeah . 
uhhuh . 
i think and uh having having it on wireless is is the neatest way neatest way to do it . 
as long as you as as long as you ' re not tempted to sit there and keep fiddling with the volume controls going can you talk a bit louder . 
i had 
yeah . 
i had actually earlier asked if i could borrow one of the cards to do wireless stuff . 
yeah . 
and they said sure . 
whenever you want . 
so i think it won ' t be a problem . 
oh cool . 
and and it ' s a a p . c . m . c . i . a . card right ? 
okay . 
yep . 
p . c . card . 
so you can have a slot . 
p . c . card . 
right ? 
in your new machine . 
yeah yeah . 
is it with 
it ' s it really come down to the driver . 
i mean 
yeah . 
right ? 
it ' ll it ' ll work 
right i mean and if and if his doesn ' t work as i said we can use the p . c . 
it ' ll work the first time . 
i i trust steve jobs . 
good . 
um 
well that sounds like a good solution one way or the other . 
so 
so jim is going to be doing wiring and you ' re going to give some thought to cabinets ? 
uh yeah . 
we we need to figure out what we want . 
great . 
uh 
we ' d i think 
hey what are those green lights doing ? 
they ' re flashing ! 
uhoh ! 
uhoh ! 
does that it means it means it ' s going to explode . 
no . 
cut the red wire ! 
the red wire ! 
um 
when people talk it they go on and off . 
this 
so again washington wants to equip a system . 
our system we spent ten thousand dollars on equipment not including the p . c . 
however seven and a half thousand of that was the wireless mikes . 
uhhuh . 
uh 
using using these 
and it and the the five thousand for the wires . 
so if i ' m going to do 
no . 
it ' s a joke . 
yeah . 
i have to do 
that ' s true . 
but we haven ' t spent that right ? 
but once we once we ' ve done the intellectual part of these uh we can just knock them out right ? 
cheap . 
we can start we you can make a hundred of them or something . 
oh of the of the boards ? 
yeah yeah . 
sure . 
right . 
and then we could 
washington could have a system that didn ' t have any wireless but would had what ' s based on these . 
uhhuh . 
and it would cost 
peanuts . 
a p . c . and a peanuts . 
p . c . and two thousand dollars for the a . to d . stuff . 
yeah . 
and that ' s about because you wouldn ' t even need the mixer if you didn ' t have the 
right . 
oh the p . z . m . ' s . 
p . z . m . ' s cost a lot . 
but anyway you ' d save on the seven seven or eight thousand for the for the wireless system . 
so actually that might be attractive . 
right . 
okay . 
good . 
i can move my thumb now . 
that ' s a great idea . 
what ? 
it ' s nice it ' s nice to be thinking toward that . 
oh i thought like if we talked softer the disk lasts longer . 
well actually shorten 
yeah . 
there ' s a speech compression program that works great on things like this . 
because if the dynamic range is low it encodes it with fewer bits . 
and so most of the time no one ' s talking . 
so it shortens it dramatically . 
but if you talk quieter the dynamic range is lower and it will compress better . 
yeah . 
so 
oh . 
huh . 
it also helps if you talk in a monotone . 
probably . 
constant volume all the time . 
oh interesting . 
and shorter words . 
shorter words . 
now shorter words wouldn ' t would induce more dynamics . 
right ? 
you want to have 
yeah but if the words are more predictable . 
how about if you just go uh ? 
huh . 
uh . 
that ' s a long word . 
how do you spell that ? 
i don ' t know . 
okay . 
can you do one more round of digits ? 
are we done talking ? 
well it ' s a choice if we get a choice let ' s keep talking . 
sure . 
do we have more to talk about ? 
no . 
i ' m done . 
i ' m done . 
are you done ? 
i ' m done . 
i ' m done . 
yeah . 
dan isn ' t . 
but he ' s not going to say anything . 
but you you you there ' s a problem a structural problem with this though . 
you really need an incentive at the end if you ' re going to do digits again . 
like you know candy bars or something . 
or or or or a little uh you know toothbrushes like they give you at the dentist . 
i ' ll i ' ll remember to bring m . and m . ' s next time . 
huh . 
or both . 
or both . 
and we already got the crash out of the way . 
it did crash so i feel much better earlier . 
yeah . 
interesting . 
will you get the door ? 
huh . 
and 
okay 
okay so um 
you collected an agenda huh ? 
i did collect an agenda . 
so i ' m going to go first . 
mwa - ha - ha ! 
it shouldn ' t take too long . 
yeah . 
um so we ' re pretty much out of digits . 
we ' ve gone once through the set . 
um so the only thing i have to do 
no there ' s only ten . 
yeah that ' s right . 
so i i just have to go through them . 
well okay . 
and uh pick out the ones that have problems . 
and either correct them or have them reread . 
so we probably have like four or five more forms to be read to be once through the set . 
i ' ve also extracted out about an hour ' s worth . 
we have about two hours worth . 
i extracted out about an hour ' s worth . 
which are the digits with for which whose speaker have speaker forms . 
have filled out speaker forms . 
not everyone ' s filled out a speaker form . 
so i extracted one for speakers who have speaker forms . 
and for meetings in which the key file and the transcript files are parsable . 
some of the early key files it looks like were done by hand . 
and so they ' re not automatically parsable . 
and i have to go back and fix those . 
so what that means is we have about an hour of transcribed digits that we can play with . 
um 
so you think two you think two hours is the is the total that we have . 
liz 
yep . 
yeah . 
and you think uh 
i i didn ' t quite catch all these different things that are not quite right . 
but you think we ' ll be able to retrieve the other hour reasonably ? 
yes absolutely . 
okay . 
so it ' s just a question of a little hand editing of some files . 
and then waiting for more people to turn in their speaker forms . 
i have this web based speaker form . 
and i sent mail to everyone who hadn ' t filled out a speaker form . 
and they ' re slowly trickling in . 
so the relevance of the speaker form here 
it ' s for labeling the extracted audio files . 
oh okay . 
by speaker i . d . and microphone type . 
wasn ' t like whether they were giving us permission to use their digits or something . 
no i spoke with jane about that . 
and we sort of decided that it ' s probably not an issue that 
we edit out any of the errors anyway right ? 
yeah . 
so there are no errors in the digits . 
you ' ll always read the string correctly . 
so i can ' t imagine why anyone would care . 
so the other topic with digits is uh 
liz would like to elicit different prosodics . 
and so we tried last week with them written out in english . 
and it just didn ' t work at all . 
because no one grouped them together . 
so it just sounded like many many more lines instead of anything else . 
so in conversations with liz and uh jane we decided that if you wrote them out as numbers instead of words it would elicit more phone number social security number like readings . 
the problem with that is it becomes numbers instead of digits . 
when i look at this that first line is sixty one sixty two eighteen eighty six ten . 
um and so the question is does anyone care ? 
um i ' ve already spoken with liz and she feels that correct me if i ' m wrong that for her connected numbers is fine . 
uhhuh . 
as opposed to connected digits . 
um i think two hours is probably fine for a test set . 
but it may be a little short if we actually want to do training and adaptation and all that other stuff . 
yeah . 
um do um 
you want different prosodics . 
so if you always had the same groupings you wouldn ' t like that ? 
is that correct ? 
well we actually figured out a way to 
yeah the the 
the the groupings are randomly generated . 
no but i was asking if that was something you really cared about . 
because if it wasn ' t it seems to me if you made it really specifically telephone groupings that maybe people wouldn ' t uh go and do numbers so much . 
you know if if it ' s 
i think they may still do it . 
uh 
um 
maybe some but probably not so much . 
what about putting a hyphen between the numbers in the group ? 
and 
right ? 
so if you if if you have uh 
six dash one you mean ? 
if you go six six six uh dash uh two nine three one . 
i well okay i it might help 
i would like to get away from having only one specific grouping . 
that ' s what i was asking yeah . 
um so if that ' s your question . 
yeah . 
but i mean it seems to me that at least for us we can learn to read them as digits . 
if that ' s what people want . 
yeah . 
i i ' m 
yeah . 
don ' t think that ' d be that hard to read them as single digits . 
i agree . 
um 
and it seems like that might be better for you guys . 
since then you ' ll have just more digit data . 
right . 
and that ' s always a good thing . 
it ' s a little bit better for me too . 
yep . 
because the digits are easier to recognize . 
they ' re better trained than the numbers . 
right . 
so we could just uh put in the instructions read them as digits . 
right right read them as single digits . 
so sixty one is read as six one . 
uhhuh . 
and if people make a mistake we 
how about o . versus zero ? 
i mean the other thing is we could just bag it . 
because it ' s it ' s 
i ' m not worrying about it . 
i mean because we do have digits training data that we have from uh from o . g . i . 
i ' m sorry . 
digits numbers training that we have from o . g . i . 
we ' ve done lots and lots of studies with that . 
and um 
but it ' s nice to get it in this room with the 
yeah . 
i mean for it ' s 
no no i guess what i ' m saying is that 
just let them read it how they read it . 
to some extent maybe we could just read them have them read how how they read it . 
and it just means that we have to expand our our vocabulary out to stuff that we already have . 
right . 
well that ' s fine with me as long as it ' s just that i didn ' t want to cause the people who would have been collecting digits the other way to not have the digits . 
yeah . 
so 
we can go back to the other thing later . 
i mean we we we ' ve we can do this for awhile . 
okay . 
and then go back to digits for awhile . 
or um 
do i mean do you want do you want this do you need training data or adaptation data out of this ? 
okay . 
how much of this do you need ? 
with uh the 
it ' s actually unclear right now . 
i just thought well we ' re if we ' re collecting digits and adam had said we were running out of the t . i . forms i thought it ' d be nice to have them in groups . 
and probably all else being equal it ' d be better for me to just have single digits . 
since it ' s you know a recognizer ' s going to do better on those anyway . 
okay . 
um and it ' s more predictable . 
so we can know from the transcript what the person said and the transcriber in general . 
okay well if you 
but if they make mistakes it ' s no big deal . 
if the people say a hundred instead of one o . o . 
and also maybe we can just let them choose zero versus o . as they as they like . 
because even the same person sometimes says o . and sometimes says zero in different context . 
yeah . 
and that ' s sort of interesting . 
so i don ' t have a specific need . 
because if i did i ' d probably try to collect it you know without bothering this group . 
but if we can try it 
okay so so i can just add to the instructions to read it as digits . 
not as connected numbers . 
right and you can give an example . 
uhhuh . 
like you know six sixty one would be read as six one . 
right . 
and i think people will get it . 
uhhuh . 
and actually it ' s no more artificial than what we ' ve been doing with words . 
i ' m sure people can adapt to this . 
right right . 
read it single . 
it ' s just easier to read . 
the spaces already bias it toward being separated . 
right . 
and i know i ' m going to find this easier than words . 
oh yeah absolutely . 
cognitively it ' s much easier . 
i also had a hard hard time with the words . 
but then we went back and forth on that . 
yeah . 
okay so let ' s give that a try . 
okay and is the spacing all right or do you think there should be more space between digits and groups ? 
okay . 
and 
i mean what do other people think ? 
or is that all right ? 
because you guys are reading them . 
i think that it ' s fine . 
it it to me it looks like you ' ve got the the idea of grouping and you have the the idea of separation . 
okay . 
okay . 
and you know it ' s just a matter of the instructions that ' s all . 
great okay . 
well let ' s give it a try . 
and i think there are about ten different gouping patterns . 
let ' s try it . 
isn ' t that right liz ? 
right and you just they ' re randomly generated and randomly assigned to digits . 
that we did . 
i did 
so we have 
uhhuh . 
sorry . 
go ahead . 
i i was just going to say so we have in the vicinity of forty hours of of recordings now . 
and you ' re saying two hours uh is digits . 
so that ' s roughly the ratio then . 
something like twenty twenty to one . 
yep . 
which i guess makes makes sense . 
so if we did another forty hours of recordings then we could get another couple hours of this . 
right . 
um yeah like you say i think a couple hours for a for a for a test test set ' s okay . 
it ' d be nice to get you know more later . 
because we ' ll we might use use this up uh in some sense . 
uhhuh . 
but but uh 
right . 
yeah i also would like to argue for that . 
because it it seems to me that um there ' s a real strength in having the same test replicated in a whole bunch of times . 
and adding to that basic test bank . 
right . 
huh . 
because then you have you know more and more chances to get away from random errors . 
and i think um the other thing too is that right now we have sort of a stratified sample with reference to dialect groups . 
and it might be there might be an argument to be made for having uh for replicating all of the digits that we ' ve done . 
which were done by non native speakers . 
so that we have a core that totally replicates the original data set . 
which is totally american speakers . 
and then we have these stratified additional language groups overlapping certain aspects of the database . 
right . 
i think that uh trying to duplicate spending too much effort trying to duplicate the existing t . i . digits probably isn ' t too worthwhile . 
because the recording situation is so different . 
yeah . 
it ' s going to be very hard to be comparable . 
except that if you have the stimuli comparable then it says something about the the contribution of setting . 
no it ' s it ' s not the same . 
a little bit . 
and 
but the other differences are so major . 
okay . 
they ' re such major sources of variance that it ' s it ' s it ' s uh 
yeah i mean read versus not . 
what ' s an example of a of some of the other differences ? 
any other difference ? 
well individual human glottis is going to be different for each one . 
okay . 
you know it ' s just there ' s so many things . 
okay . 
it ' s it and and enunciation . 
well and not just that . 
i mean the uh the corpus itself . 
i mean we ' re collecting it in a read digit in a particular list . 
and i ' m sure that they ' re doing more specific stuff . 
i mean if i remember correctly it was like postman reading zipcodes and things like that . 
t . i . digits was ? 
i thought i thought it was read . 
i thought so . 
was it read ? 
yeah i think the reading zipcode stuff you ' re thinking of would be o . g . i . 
oh i may well be . 
yeah no t . i . digits was read in in read in the studio i believe . 
i haven ' t ever listened to t . i . digits . 
yeah . 
so i don ' t really know how it compares . 
yeah . 
but it but 
but but regardless it ' s going to it ' s hard to compare cross corpus . 
it ' s different people is the is the core thing . 
so 
and they ' re different circumstances with different recording environment and so forth . 
okay fine . 
so it ' s it ' s it ' s really pretty different . 
but i think the idea of using a set thing was just to give you some sort of framework . 
so that even though you couldn ' t do exact comparisons it wouldn ' t be valid scientifically at least it ' d give you some kind of uh frame of reference . 
uh you know it ' s not 
okay . 
hey liz what what do the groupings represent ? 
you said there ' s like ten different groupings . 
right just groupings in terms of number of groups in a line . 
and number of digits in a group . 
and the pattern of groupings . 
uhhuh . 
are the patterns like are they based on anything or 
um i i just roughly looked at what kinds of digit strings are out there . 
and they ' re usually grouped into either two three or four four digits at a time . 
oh . 
and they can have 
i mean actually things are getting longer and longer . 
in the old days you probably only had three sequences and telephone numbers were less and so forth . 
so there ' s between um 
well if you look at it there are between like three and five groups . 
and each one has between two and four groupings . 
and 
i purposely didn ' t want them to look like they were in any kind of pattern . 
huh . 
so 
and which group appears is picked randomly and what the numbers are are picked randomly . 
uhhuh . 
right . 
so unlike the previous one which i simply replicated t . i . digits this is generated randomly . 
huh oh okay . 
oh okay . 
but i think it ' d be great to be able to compare digits . 
whether it ' s these digits or t . i . digits to speakers um and compare that to their spontaneous speech . 
and then we do need you know a fair amount of of digit data . 
because you might be wearing a different microphone . 
and i mean so it ' s it ' s nice to have the digits you know replicated many times . 
uhhuh . 
especially for speakers that don ' t talk a lot . 
so um 
yeah . 
for adaptation . 
no i ' m serious . 
so we have a problem with acoustic adaptation . 
yeah . 
yeah all we have for some people is digits . 
yeah . 
and we ' re not using the digit data now . 
but you know 
oh you ' re not . 
not for adaptation nope . 
we ' re not we were running adaptation only on the data that we ran recognition on . 
and i ' d as soon as someone started to read transcript number that ' s read speech . 
and i thought well we ' re going to do better on that . 
oh i see . 
that ' s not fair to use . 
oh yeah that ' s true absolutely . 
but it might be fair to use the data for adaptation . 
okay . 
so 
so those speakers who are very quiet shy 
that would be interesting to see whether that helps . 
right . 
do you think that would help adapting on 
like adam ? 
yeah . 
yeah . 
yeah i have a real problem with that . 
well it i mean it ' s the same 
see the nice thing is we have that in the in the same meeting . 
right . 
yeah . 
and so you don ' t get 
same same acoustics . 
same microphone . 
same channel . 
yeah . 
right and so i still like the idea of having some kind of digit data . 
okay . 
good . 
yeah i mean for the for the um acoustic research 
for the signal processing farfield stuff i see it as as as the place that we start . 
but i mean it ' d be nice to have twenty hours of digits data . 
but but uh the truth is i ' m hoping that we we through the the stuff that that you guys have been doing as you continue that we get uh the best we can do on the spontaneous stuff uh uh nearfield . 
and then um we do a lot of the testing of the algorithms on the digits for the farfield . 
and at some point when we feel it ' s mature and we understand what ' s going on with it then we we have to move on to the spontaneous data with the farfield . 
so 
the only thing that we don ' t have 
great . 
i know this sounds weird . 
and maybe it ' s completely stupid . 
but we don ' t have any overlapping digits . 
yeah we talked about that a couple times . 
i know it ' s weird . 
but um 
overlapping digits . 
the the problem i see with trying to do overlapping digits is the cognitive load . 
all right everybody ' s laughing . 
okay . 
dueling digits . 
no it ' s it ' s not stupid . 
it ' s just i mean try to do it . 
i ' m just for the stuff that like dan ellis is going to try . 
i mean here let ' s try it . 
you know cross talk cancellation . 
let ' s try it . 
you read the last line i ' ll read the first line . 
okay . 
oh . 
wait oh it these are all the same forms . 
sixty one . 
okay so but 
so so you read the last line i ' ll read the first line . 
so you you plug your ears . 
no i ' ll 
oh i guess if you plug you ' re ears you could do it . 
but then you don ' t get the the same effects . 
yeah . 
well what i mean is actually not the overlaps that are well governed linguistically . 
but the actual fact that there is speech coming from two people . 
and the beam forming 
yeah . 
all the acoustic stuff that like dan ellis and and company want to do . 
oh i see . 
digits are nice and well behaved . 
i mean 
anyway it ' s just a thought . 
i guess we could try . 
we could try doing some . 
it it would go faster . 
parallel . 
it would take one around amount of 
it ' s the p . make of digit reading . 
well well okay well let ' s try it . 
that ' s right . 
i i i ' m i was sort of serious . 
but i really i mean i ' m i don ' t feel strongly enough that it ' s a good idea . 
see 
you do the last line i ' ll do the first line . 
so 
okay . 
that ' s not bad . 
no i can do it . 
and that prosody was great by the way . 
i couldn ' t understand a single thing you guys were saying . 
i think it was numbers . 
but i ' m not sure . 
it it sort of sounded like a duet or something . 
yeah . 
performance art . 
all right let ' s try three at once you you pick one in the middle . 
the aurora theater . 
okay . 
go . 
i ' m sorry . 
i ' m mean i think it ' s doable . 
the poor transcribers . 
i ' m just 
they ' re going to hate us . 
so we we could have a round like where you do two at a time . 
and then the next person picks up when the first guy ' s done or something . 
so pairwise . 
oh like a round . 
yeah like in a a 
like a 
yeah just pairwise . 
yeah . 
what do you call it ? 
a like 
a round . 
or 
row row row your boat . 
round . 
yeah . 
uhhuh . 
yeah . 
yeah like that . 
okay . 
it ' s going to require some coordination . 
then it would go like twice as fast or a third as fast . 
anyway it ' s just a thought . 
you have to have a similar pace . 
yeah . 
i ' m actually sort of serious if it would help people do that kind 
but the people who want to work on it we should talk to them . 
i don ' t think we ' re going to collect vast amounts of data that way . 
so 
huh . 
but i think having a little bit might at least be fun for somebody like dan to play around with . 
okay . 
i think maybe if we wanted to do that we would do it as a separate session . 
yeah . 
yeah . 
something like that . 
rather than doing it during a real meeting . 
and you know do two people at a time . 
then three people at a time and things like that . 
so 
can try it out . 
if we have nothing if we have no agenda we could do it some week . 
see see what dan thinks . 
yeah right . 
yeah yeah . 
okay . 
spend the whole time reading digits with different quantities . 
can can i have another another question about this ? 
i thought this was going to be fast . 
oh well . 
so um there are these digits . 
which are detached digits . 
but there are other words that contain the same general phoneme sequences . 
like wonderful has one in it . 
and and victor borge had a had a piece on this where he inflated the digits . 
well i wonder if there ' s um if there would be a value in having digits that are in essence embedded in real words to compare in terms of like the articulation of one in wonderful versus one as a digit being read . 
that ' s two bad . 
yeah . 
i ' m all four it . 
there you go . 
not after i eight though . 
uh they don ' t all work as well do they ? 
huh . 
what does nine work in ? 
uh 
uh 
nein ! 
you scream it . 
nein . 
oh in german . 
you have to be german . 
it ' s great for the germans . 
yeah . 
that ' s german yeah . 
oh oh . 
yeah . 
nein . 
that ' s right . 
yeah . 
oh . 
it only sounds good when you scream it though . 
so 
i think everybody ' s a little punchy here today . 
well i mean i just wanted to offer that as a possible task . 
yes . 
because you know if we were to each read his embedded numbers words in in sentences . 
because it ' s like an entire sketch he does . 
and i wouldn ' t take the inflated version . 
so he talks about the woman being two - derful . 
and 
and but you know if it were to be deflated just the normal word it would be like a little story that we could read . 
uhhuh . 
i don ' t know if it would be useful for comparison . 
but it ' s embedded numbers . 
well i don ' t know . 
i think for something like that we ' d be better off doing like uh timit . 
well i think the question is what the research is . 
so i mean i presume that the reason that you wanted to have these digits this way is because you wanted to actually do some research looking at the prosodic form here . 
huh . 
right yeah . 
yeah okay . 
so if somebody wanted to do that if they wanted to look at the the the difference of the uh phones in the digits in the context of a word versus uh the digits a a non digit word versus in digit word uh that would be a good thing to do . 
but i think someone would have to express interest in that . 
i see . 
i think to 
okay . 
i mean if you were interested in it then we could do it for instance . 
okay thank you . 
huh . 
okay are we done with digits ? 
um 
we have a . s . r . results from liz . 
transcript status from jane . 
and disk space and storage formats from don . 
does do we have any preference on which way we want to we want to go ? 
well i was actually going to skip the a . s . r . results part in favor of getting the transcription stuff talked about . 
uhhuh . 
since i think that ' s more important to moving forward . 
but i mean morgan has this paper copy . 
and if people have questions 
um it ' s pretty preliminary in terms of a . s . r . results . 
because we didn ' t do anything fancy . 
but i think just having the results there . 
and pointing out some main conclusions . 
like it ' s not the speaking style that differs . 
it ' s the fact that there ' s overlap that causes recognition errors . 
and then the fact that it ' s almost all insertion errors . 
which you would expect . 
but you might also think that in the overlapped regions you would get substitutions and so forth . 
um leads us to believe that doing a better segmentation like your channel based segmentation or some kind of uh echo cancellation to get basically back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on the on the close talking mikes . 
um why don ' t you if you have a hard copy why don ' t you email it to the list ? 
so these 
so that ' s about the summary . 
but this is morgan has this paper . 
yeah yeah . 
i mean he he 
yeah so it ' s the same thing ? 
oh it ' s in the paper . 
it it ' s that paper . 
it ' s the same thing i mailed to everybody that where it was . 
okay . 
yeah yeah . 
so we basically um did a lot of work on that . 
okay then it ' s already been mailed . 
yeah . 
and it ' s 
let ' s see 
i guess the other neat thing is it shows for sure that the lapel you know within speaker is bad . 
horrible ? 
and it ' s bad because it picks up the overlapping speech . 
so your your a . s . r . results were run on the channels synchronized . 
yes because that ' s all that had been transcribed at the time . 
okay . 
okay . 
okay . 
um 
but as we i mean i wanted to here more about the transcription . 
if we can get the channel asynchronous or the 
yeah . 
the closer 
that would be very interesting for us . 
because we 
so if 
yeah that ' s that ' s why i only used the part from . 
yeah . 
which we had uh about uh about the over all the channels . 
yeah . 
right . 
that ' s 
yeah sure . 
yeah . 
or mixed channel . 
rather mixed signal . 
yeah . 
so if there was a segment of speech this long 
because 
yeah . 
and someone said oh in the front in the middle . 
and oh and someone said oh the whole thing was passed to the recognizer . 
there were several speakers in it . 
yeah . 
that ' s right in fact i i pulled out a couple classic examples in case you want to use them in your talk of 
uhhuh . 
that ' s why there ' s so many insertion errors . 
chuck on the lapel . 
so chuck wore the lapel three out of four times . 
huh . 
i noticed that chuck was wearing the lapel a lot . 
um yeah . 
early on yeah . 
and i wore the lapel once . 
and for me the lapel was okay . 
i mean i still 
and i don ' t know why . 
i ' m 
but um 
for you it was 
probably how you wear it wore it i would guess . 
or who was next to me or something like that . 
yeah where you were sitting probably affected it . 
yeah . 
right but when chuck wore the lapel and morgan was talking there ' re a couple really long utterances . 
where chuck is saying a few things inside . 
and it ' s picking up all of morgan ' s words pretty well . 
and so the you know there ' re error rates 
because of insertion 
insertions aren ' t bounded . 
so with a one word utterance and ten insertions you know you got huge error rate . 
uhhuh . 
yeah . 
and that ' s that ' s where the problems come in . 
so this is sort of what we expected . 
but it ' s nice to be able to to show it . 
right . 
and also i just wanted to mention briefly that um uh andreas and i called up dan ellis who ' s still stuck in switzerland . 
and we were going to ask him if if there ' re you know what ' s out there in terms of echo cancellation and things like that . 
not that we were going to do it . 
but we wanted to know what would need to be done . 
and he said lots lots lots lots . 
and he we ' ve given him the data we have so far . 
so these sychronous cases where there are overlap . 
yep . 
and he ' s going to look into trying to run some things that are out there . 
and see how well it can do . 
because right now we ' re not able to actually report on recognition in a real paper . 
so 
like a eurospeech paper . 
because it would look sort of premature . 
so 
so the idea is that you would take this big hunk where somebody ' s only speaking a small amount in it . 
and then try to figure out where they ' re speaking based on the other 
right or who ' s at any point in time who ' s the foreground speaker . 
who ' s the background speaker . 
i thought we were just going to move the boundaries in . 
so yeah 
so 
yeah should it 
well that ' s with the hand stuff . 
so there ' s like 
but how would you do that automatically ? 
right . 
uh i ' ve actually done some experiments with cross correlation . 
well there ' s 
and it seems to work pretty well to to get rid of those those overlaps . 
uhhuh . 
i mean that ' s the sort of thing that you would do . 
yeah . 
yeah exactly so it ' s it ' s a 
so 
yeah . 
so why do you want to do echo cancellation ? 
um it would be techniques used from adaptive adaptive echo cancellation . 
which i don ' t know enough about to talk about . 
uhhuh . 
it just it just to to remove cross talk . 
um 
but 
yeah . 
yeah . 
right um and that would be similar to what you ' re also trying to do . 
but using um you know more than energy . 
i i don ' t know what exactly would go into it . 
yeah . 
yeah sure . 
so the idea is to basically run this on the whole meeting . 
so it would be 
and get the locations which gives you also the time boundaries of the individual 
okay . 
so do sort of what he ' s already what he ' s trying to do . 
right except that there are many techniques for the kinds of cues um that you can use to do that . 
okay i i see . 
yeah in another way . 
yeah . 
yeah . 
yeah . 
i see . 
yeah dave dave uh is um also going to be playing around with echo cancellation for the nearfield farfield stuff . 
so 
so we ' ll be 
and i guess espen . 
this is uh is he here too ? 
may also be working 
yeah . 
so it would just be 
that ' s really the next step . 
because we can ' t do too much you know on in terms of recognition results knowing that this is a big problem . 
uhhuh . 
um until we can do that kind of processing . 
and so once we have some some of yours . 
okay . 
yeah i ' m working on it . 
and we ' ll move on . 
i think this also ties into one of the things that jane is going to talk about too . 
um 
okay . 
uhhuh uhhuh . 
i also wanted to say i have done all this chopping up of digits . 
so i have some naming conventions that we should try to agree on . 
oh right . 
so let ' s do that off line . 
we don ' t need to do it during the meeting . 
yeah . 
right . 
okay . 
definitely 
uh and don should 
and and i have scripts that will extract it out from key files . 
and and do all the naming automatically . 
okay . 
so you don ' t have to do it by hand . 
all right . 
great . 
so that ' s it for the 
you ' ve compiled the list of uh speaker names . 
speakers and 
uhhuh . 
okay . 
not names . 
but i . d . ' s . 
yep . 
yeah names names in the names to i . d . ' s . 
so you 
okay . 
great . 
and it does all sorts of matches . 
because the way people filled out names is different on every single file . 
so it does a very fuzzy sort of match . 
right . 
cool . 
so at this point we can sort of finalize the naming and so forth . 
yep . 
and we ' re going to basically rewrite out these waveforms that we did . 
uhhuh . 
because as you notice in the paper your m . o . four in one meeting . 
and m . o . two in another meeting . 
and it ' s we just need to standardize the 
yeah . 
that was my fault . 
um 
no it ' s it ' s 
no i didn ' t notice that actually . 
um that ' s why those comments are are in there . 
yeah . 
yep . 
then disregard it then . 
so i now have a script that you can just say basically look up morgan . 
so 
right . 
yeah . 
okay . 
and it will give you his i . d . 
great great . 
okay . 
so 
terrific . 
um 
all right . 
do we 
don you had disk space and storage formats ? 
is that something we need to talk about at the meeting ? 
or should you just talk with chuck at some other time ? 
um i had some general questions just about the compression algorithms of shortening waveforms . 
and i don ' t know exactly who to ask . 
i thought that maybe you would be the the person to talk to . 
so is it a lossless compression when you compress 
uhhuh . 
so 
entropy coding . 
it just uses entropy coding ? 
so 
okay . 
so i mean i guess my question would be is 
i just got this new eighteen gig drive installed . 
um yeah . 
which is 
and i assume half of it is scratch and half of it is 
i ' m not exactly sure how they partitioned it . 
probably yeah . 
but um 
that ' s typical huh . 
yeah i don ' t know what ' s typical here . 
but um 
it ' s local though . 
so 
that doesn ' t matter . 
but 
you can access it from anywhere in icsi . 
okay . 
in fact this is an eighteen gig drive or is it a thirty six gig drive with eighteen 
all right . 
how do you do that ? 
n . 
eighteen . 
eighteen . 
it was a spare that dave had around . 
oh okay . 
slash n . slash machine name slash x . a . in all likelihood . 
oh i see . 
okay . 
all right i did know that . 
um so the the only question is how much of it 
the distinction between scratch and non scratch is whether it ' s backed up or not . 
uhhuh . 
right . 
so what you want to do is use the scratch for stuff that you can regenerate . 
okay . 
so 
the stuff that isn ' t backed up is not a big deal . 
because disks don ' t crash very frequently . 
right . 
as long as you can regenerate it . 
right . 
yeah it ' s 
i mean all of this stuff can be regenerated . 
it ' s just a question 
well the 
then put it all on scratch . 
because we ' re icsi is is bottlenecked by backup . 
yeah . 
uhhuh very good point . 
okay . 
well i ' d leave all the all the transcript stuff shouldn ' t should be backed up . 
so we want to put 
uhhuh . 
but all the waveform sound files should not be backed up . 
yeah i guess 
right . 
the ones that you write out . 
okay . 
so i mean i guess the other question was then should we shorten them downsample them or keep them in their original form ? 
um 
it just depends on your tools . 
i mean because it ' s not backed up and it ' s just on scratch if your tools can ' t take shortened format i would leave them expanded . 
right . 
so you don ' t have to unshorten them every single time you want to do anything . 
okay . 
we can downsample them . 
do you think that ' d be okay ? 
so 
yeah . 
to downsample them . 
yeah we get the same performance . 
okay . 
i mean the the front end on the s . r . i . recognizer just downsamples them on the fly . 
yeah i guess the only argument against downsampling is to preserve just the original files in case we want to experiment with different filtering techniques . 
so 
so that ' s 
i i i ' m sorry 
yeah if 
yeah i mean over all our data we we want to not downsample . 
you ' d you want to not 
okay . 
so we ' re what we ' re doing is we ' re writing out 
yeah . 
i mean this is just a question . 
we ' re writing out these individual segments that wherever there ' s a time boundary from thilo or or jane ' s transcribers you know we we chop it there . 
yeah . 
uhhuh . 
and the reason is so that we can feed it to the recognizer . 
uhhuh . 
and throw out ones that we ' re not using and so forth . 
yeah . 
and those are the ones that we ' re storing . 
yeah as i said since that ' s it ' s regeneratable what i would do is take downsample it . 
so 
yeah . 
and compress it however you ' re the s . r . i . recognizer wants to take it in . 
yeah . 
so we can ' t shorten them . 
but we can downsample them . 
right . 
yeah i mean 
yeah i ' m sorry . 
so 
as yeah as long as there is a a form that we can come from again that is not downsampled then 
yeah . 
oh yeah 
yeah those are going to be kept . 
yeah yeah . 
that that ' s why we need more disk space . 
uuu 
because we ' re basically duplicating the originals um 
yeah . 
then it ' s fine . 
right . 
but for for future research we ' ll be doing it with different microphone positions and so on . 
oh yeah . 
no we always have the original long ones . 
yep . 
right . 
we would like to 
yeah . 
so the s . r . i . front end won ' t take a uh an an a large audio file name and then a a list of segments to chop out from that large audio file ? 
they actually have to be chopped out already . 
um it ' s better if they ' re chopped out . 
and and it it will be 
uhhuh . 
yeah we could probably write something to do that . 
but it ' s actually convenient to have them chopped out . 
because you can run them you know in different orders . 
you you can actually move them around . 
and that ' s the whole point about the naming conventions . 
uh you can get rid 
is that you could run all the english speaking . 
yeah it ' s a lot faster . 
all the native speakers . 
right you can grab everything with the word the in it . 
and all the non native speakers . 
and all the men and all the women . 
and it ' s 
yeah . 
that ' s a lot quicker than actually trying to access the wavefile each time . 
find the time boundaries and 
so in principle yeah you could do that . 
i don ' t i don ' t think that ' s really right . 
but it ' s 
but it ' s um 
that ' s just not right man . 
these are long these are long 
the the point 
so so for example what if you wanted to run run all the native speakers ? 
you know 
this is an hour of speech . 
right so if if you did it that way you would have to generate a program that looks in the database somewhere . 
extracts out the language . 
finds the time marks for that particular one . 
do it that way . 
the way they ' re doing it you have that already extracted . 
and it ' s embedded in the file name . 
and so you know you just say 
yeah that ' s so that ' s part of it . 
so you just say you know asterisk e . asterisk dot wave and you get what you want . 
is 
right . 
and the other part is just that once they ' re written out it it is a lot faster to to process them . 
rather than doing seeks through the file . 
so 
otherwise you ' re just accessing 
this is all just temporary access . 
so i don ' t i think it ' s all just 
it ' s fine . 
you know . 
fine to do it however is convenient . 
right . 
i mean it just depends how big the file is . 
if the file sits in memory you can do extremely fast seeks . 
right . 
the other thing is that believe it or not i mean we have some 
but 
yeah and they don ' t . 
two gig . 
so we ' re also looking at these in waves like for the alignments and so forth . 
you can ' t load an hour of speech into x . waves . 
yeah . 
you need to have these small files . 
and in fact even for the transcriber program um 
yes you can . 
yeah you you can give waves a start and an end time . 
yeah if you try to load really long waveform into x . waves you ' ll be waiting there for 
and middle . 
no i i ' m not suggesting you load a long wave file . 
oh . 
i ' m just saying you give it a start and an end time . 
and it ' ll just go and pull out that section . 
i 
the transcribers didn ' t have any problem with that . 
did they jane ? 
what ' s in what respect ? 
loading the long 
they loaded they loaded the long long files into x . waves . 
no with the transcriber tool it ' s no problem . 
it takes a very long 
in the 
yeah just to load a transcription . 
uhhuh . 
right . 
it takes a very long time . 
takes a long time . 
but not for the wavefile . 
the wavefile is there immediately . 
uhhuh yeah . 
are you talking about transcriber or x . waves ? 
huh . 
yeah . 
oh i ' m talking about transcriber . 
actually you ' re talking about transcriber right ? 
yeah . 
it was also true of the digits task which was x . waves . 
because because we used x . waves to do the digits . 
yeah . 
and they were loading the full mixed files then . 
very quickly . 
and it didn ' t seem to be any problem . 
i agree . 
huh . 
well we we have a problem with that . 
you know time wise on a 
it ' s a lot slower to load in a long file . 
huh . 
seemed really fast . 
and also to check the file . 
so if you have a transcript um 
well regardless it ' s 
i mean it ' s 
yeah . 
i i think overall you could get everything to work by accessing the same waveform and trying to find two you know the begin and end times . 
um 
but i think it ' s more efficient if we have the storage space to have the small ones . 
and it ' s no problem right ? 
yeah it ' s 
because it ' s not backed up . 
yeah . 
it ' s it ' s just 
so we just 
if we don ' t have a spare disk sitting around we go out and we buy ourselves an eighty gigabyte drive . 
and make it all scratch space . 
you know it ' s not a big deal . 
you ' re right about the backup being a bottleneck . 
right . 
it ' s good to think towards scratch . 
yeah so these wouldn ' t be backed up the 
yeah . 
yep . 
right . 
so remind me afterward . 
and 
and i ' ll and we ' ll look at your disk and see where to put stuff . 
okay all right . 
i mean i could just do a d . u . on it right ? 
and just see which how much is on each . 
yep . 
so 
each partition . 
and you want to use either x . a . or scratch . 
okay . 
well x . question mark . 
anything starting with x . is scratch . 
okay . 
with two two digits . 
two digits right . 
x . a . x . b . x . c . 
so 
okay ? 
jane ? 
okay so i got a little printout here . 
so three on this side . 
three on this side . 
and i stapled them . 
okay . 
all right so first of all um there was a an interest in the transcription uh checking procedures . 
and and i can tell you first uh to go through the steps . 
although you ' ve probably seen them . 
um as you might imagine when you ' re dealing with um really a fair number of words and uh natural speech 
which means self repairs and all these other factors that there ' re lots of things to be um standardized and streamlined and checked on . 
and um so 
i did a bunch of checks . 
and the first thing i did was obviously a spell check . 
and at that point i discovered certain things . 
like um accommodate with one m . . 
that kind of thing . 
and then in addition to that i did an exhaustive listing of the forms in the data file . 
which included detecting things like faulty punctuation and things . 
i ' m i ' m sorry to interrupt . 
yeah ? 
you could could i just back up a little bit ? 
sure please . 
yeah please please . 
and 
yeah yeah yeah . 
so you ' re doing these so the whole process is that the transcribers get the conversation . 
and they do their pass over it . 
yes . 
and then when they ' re finished with it it comes to you . 
and you begin these these quality checks . 
that ' s right . 
exactly . 
i do these checks . 
uhhuh . 
okay . 
exactly . 
okay . 
yeah . 
thank you . 
and so uh i do a an exhaustive listing of the forms 
actually i will go through this in in order . 
so if if we could maybe wait and stick keep that for a second . 
because we ' re not ready for that . 
so on the fifth page seven down 
yeah yeah yeah yeah exactly exactly . 
all right so a spelling check first . 
then an exhaustive listing of the uh all the forms in the data with the punctuation attached . 
and at that point i pick up things like oh you know word followed by two commas . 
and and then another check involves uh being sure that every utterance has an identifiable speaker . 
and if not then that gets checked . 
then there ' s this issue of glossing so - called spoken forms . 
so there 
for the most part we ' re keeping it standard word level transcription . 
but there ' s 
and that ' s done with the assumption that pronunciation variants can be handled . 
so for things like and the fact that someone doesn ' t say the d . uh that ' s not important enough to capture in the transcription . 
because a a good pronunciation uh you know model would be able to handle that . 
however things like because where you ' re lacking an entire very prominent first syllable . 
and furthermore it ' s a form that ' s specific to spoken language . 
those are reasons for those reasons i i kept that separate . 
and used the convention of using c . u . z . for that form . 
however glossing it . 
so that it ' s possible with the script to plug in the full orthographic form for that one . 
and a couple of others . 
not many . 
so want to is another one . 
going uh going to is another one . 
with just the assumption again that this these are things which it ' s not really fair to consider expect that a pronunciation model to handle . 
and chuck you you indicated that because is is one of those that ' s handled in a different way also didn ' t you ? 
did i 
i don ' t remember . 
okay . 
so it might not have been it might not have been you . 
huh . 
but someone told me that in fact because is treated differently in um in this context . 
because of that reason that um it ' s a little bit farther than a pronunciation variant . 
okay so after that 
let ' s see . 
um 
so that was part of the spell check or was that that was after the spell check ? 
well so when i get the 
so the spell check picks up those words . 
because they ' re not in the dictionary . 
uhhuh . 
so it gets because and want to and that 
and then you gloss them ? 
yeah uhhuh . 
run it through 
i have a sed you know so i do sed script saying whenever you see going to you know convert it to going to you know gloss equals quote going to quote . 
you know . 
and with all these things being in curly brackets . 
so they ' re always distinctive . 
uhhuh . 
okay i also wrote a script which will um retrieve anything in curly brackets or anything which i ' ve classified as an acronym . 
and a pronounced acronym . 
and the way i tag pronounced acronyms is that i have underscores between the components . 
so if it ' s a . c . l . then it ' s a . underscore c . underscore l . . 
and the 
and so so your list here are these ones that actually occurred in the meetings ? 
yes uhhuh yeah . 
whew ! 
okay so now uh and 
we are acronym loaded . 
um can i ask a question about the glossing uh before we go on ? 
yeah . 
so for a word like because is it that it ' s always predictably because ? 
i mean is c . u . z . always meaning because ? 
yes but not the reverse . 
so sometimes people will say because in the meeting . 
and if if they actually said because then it ' s written as because with no 
because doesn ' t even figure into the equation . 
because 
but but in our meetings people don ' t say hey because how you doing . 
right right . 
except right there . 
yeah . 
yeah . 
um so i guess so from the point of view of 
that ' s a good point . 
the the only problem is that with for the recognition we we map it to because . 
and so if we know that c . u . z . 
well 
that ' s fine . 
well don has a script . 
but they have the gloss . 
yeah . 
but we don ' t 
you have the gloss form . 
so you always replace it . 
exactly . 
if that ' s how what you want to do . 
uhhuh . 
and don knows this . 
and he ' s he has a he has a script that 
yeah . 
i replace the because with because if it ' s glossed . 
right . 
but if it ' s 
okay . 
but then there are other glosses that we don ' t replace right ? 
and 
because 
yes and that ' s why there ' re different tags on the glosses . 
okay so then it ' s fine . 
on the different on the different types of comments . 
which we ' ll which we ' ll see in just a second . 
right . 
okay . 
so the pronounceable acronyms get underscores . 
the things in curly brackets are viewed as comments . 
there ' re comments of four types . 
so this is a good time to introduce that . 
the four types . 
and maybe we ' ll expand that . 
um 
but the but the comments are um of four types mainly right now . 
one of them is um the gloss type we just mentioned . 
can 
another type is um 
so are we done with acronyms ? 
because i had a question on what what this meant . 
i ' m still doing the overview . 
i haven ' t actually gotten here yet . 
oh i ' m sorry . 
okay so gloss is things like replacing the full form with the um more abbreviated one to the left . 
uh then you have if it ' s uh there ' re a couple different types of elements that can happen that aren ' t really properly words . 
and some of them are laughs and breathes . 
so we have uh that ' s prepended with a a tag of v . o . c . 
whew . 
and the non vocal ones are like door - slams and tappings . 
and that ' s prepended with a non - vocalization . 
so then it just an ending curly brace there ? 
or is there something else in there ? 
oh yeah so this would 
let ' s just take one example . 
a comment basically . 
oh oh oh . 
and then the non - vocalization would be something like a door slam . 
they always end . 
so it ' s like they ' re paired curly brackets . 
and then the third type right now uh is things that fall in the category of comments about what ' s happening . 
so it could be something like you know referring to so - and - so . 
talking about such and such . 
uh you know looking at so - and - so . 
so on the 
on the middle so in the first case that gloss applies to the word to the left . 
yeah . 
yeah and this gets substituted here . 
but in the middle two it ' s not applying to anything right ? 
they ' re impulsive . 
huh uh . 
okay . 
no they ' re events . 
they ' re actually they have the status of events . 
okay . 
well the qual can be the qual is applying to the left . 
right i just meant the middle two ones . 
yep . 
yeah . 
well and actually um it is true that with respect to laugh there ' s another one . 
which is while laughing . 
while laughing . 
and that is uh an argument could be made for this turning that into a qualitative statement . 
because it ' s talking about the thing that preceded it . 
but at present we haven ' t been um uh coding the exact scope of laughing you know . 
and so to have while laughing you know that it happened somewhere in there . 
which could well mean that it occurred separately and following . 
or you know including some of the utterances to the left . 
haven ' t been awfully precise about that . 
but i have here 
now we ' re about to get to the to this now . 
i have frequencies . 
so you ' ll see how often these different things occur . 
but um uh the very front page deals with this uh final uh uh aspect of the standardization . 
which has to do with the spoken forms like uhhuh and uhhuh and ha and uhuh and all these different types . 
and um uh someone pointed out to me . 
this might have been chuck about um about how a recognizer if it ' s looking for uhhuh with three m . ' s and it ' s transcribed with two m . ' s that it might uh that it might increase the error rate . 
which is which would really be a shame . 
because um i i personally would not be able to make a claim that those are dramatically different items . 
so right now i ' ve standardized across all the existing data with these spoken forms . 
oh good . 
i i should say 
so it ' s a small list . 
all existing data except thirty minutes which got found today . 
so i ' m going to i ' m going to i ' m going to check 
that that ' s known as found data . 
yeah yeah . 
actually yeah . 
i got it was stored in a place i didn ' t expect . 
it ' s like the zapruder film . 
so and and um 
we uh reconstructed how that happened . 
i want to work with lost data . 
yeah it ' s much easier . 
and this is this ' ll be great . 
so i ' ll i ' ll be able to get through that tonight . 
and then well actually later today probably . 
huh . 
and so then we ' ll have everything following these conventions . 
but you notice it ' s really rather a small set of these kinds of things . 
yeah . 
and i made it so that these are um with a couple exceptions but things that you wouldn ' t find in the spell checker . 
so that they ' ll show up really easily . 
and um 
jane can i ask you a question ? 
what ' s that very last one correspond to ? 
sure . 
i don ' t even know how to pronounce that . 
well yeah now that that only occurs once . 
yeah . 
and i ' m thinking of changing that . 
right . 
i haven ' t listened to it . 
uh is that like someone ' s like burning or some such thing ? 
so i don ' t know . 
i haven ' t heard it actually . 
like their hair ' s on fire . 
i i need to listen to that one . 
uh ! 
actually we we gave this to our pronunciation person . 
it ' s the castle of uh . 
uh it looks like that . 
she ' s like i don ' t know what that is either . 
so 
did she hear the did she actually hear it ? 
no we just gave her a list of words that you know weren ' t in our dictionary . 
because i haven ' t heard it . 
and so of course it picked up stuff like this . 
and she just didn ' t listen . 
so she didn ' t know . 
we just we ' re waiting on that just to do the alignments . 
yeah . 
yeah i ' m curious to hear what it is . 
but i didn ' t know want to change it to something else until i knew . 
maybe it ' s argh . 
right . 
well sss you know 
but that ' s not really like 
hhh . 
yeah . 
no one really says argh you know . 
right no one 
well you just did . 
it ' s not 
well 
yeah . 
there ' s another there ' s another word error . 
except for now . 
that ' s right . 
yes that ' s right . 
we ' re going to have a big problem when we talk about that . 
cha - ching ! 
uh . 
we ' re going to never recognize this meeting . 
okay . 
in monty python you say argh a lot . 
oh yeah ? 
so 
well or if you ' re a c . programmer . 
huh . 
yeah that ' s right . 
yeah . 
you say arg c . and arg v . all the time . 
that ' s right . 
yeah . 
that ' s true . 
but it has a different prosody . 
yeah . 
arg . 
it does . 
arg arg - max arg - min . 
uhhuh . 
yeah . 
uh ! 
uh 
so jane what ' s the 
maybe he died while dictating . 
so 
i have one question about the the e . h . versus like the a . h . and the u . h . 
that ' s partly a nonnative - native thing . 
but i have found e . h . in native speakers too . 
okay . 
but it ' s mostly non native . 
okay . 
h . 
that ' s uh versus uh ? 
uh . 
uh . 
uh yeah right . 
because there were were some speakers that did definite uh ' s . 
uhhuh . 
but right now we 
they were the canadians right ? 
canadians yeah yeah yeah . 
that ' s right . 
so it it ' s actually probably good for us to know the difference between the real uh and the one that ' s just like uh or transcribed ah . 
exactly . 
because in like in switchboard you would see all of these forms . 
but they all were like uh . 
you mean just the single letter a as in the particle ? 
the transcription or 
no no i mean like the the u . h . 
article . 
u . h . 
oh . 
or the u . h . e . h . a . h . were all the same . 
and then we have this additional non native version of uh like eeh . 
all the e . h . s . i ' ve seen have been like that . 
they ' ve been like uh 
like that have has been transcribed to e . h . 
uhhuh that ' s right . 
and sometimes it ' s stronger . 
like eeh which is like closer to e . h . 
huh . 
right . 
but 
yeah . 
i ' m just these poor transcribers they ' re going to hate this meeting . 
i know . 
we should go off line . 
well we ' re not doing we ' re not doing length . 
quick thilo do a do a filled pause for us . 
yeah that ' s right . 
ooo no . 
but you ' re a native german speaker . 
so it ' s not a not a issue for 
yeah . 
it ' s only 
them canadians . 
yeah . 
no only if you don ' t have lax vowels i guess . 
right ? 
so it ' s like japanese and spanish . 
oh . 
this makes sense . 
yeah i i think you ' ve 
uhhuh yeah . 
and 
uhhuh . 
oh i see . 
that makes sense . 
i didn ' t get that . 
okay . 
yeah and so you know i mean i have there are some um americans who who are using this uh too . 
and i haven ' t listened to it systematically . 
maybe with some of them uh they ' d end up being uh ' s . 
but uh my spot checking has made me think that we do have uh in also um american data represented here . 
but 
any case that ' s the this is reduced down from really quite a a much longer list . 
yeah this is great . 
and this is 
uhhuh . 
yeah it ' s good . 
this is really really helpful . 
yeah . 
functionally pretty you know also 
it was fascinating i was listening to some of these uh i guess two nights ago . 
and it ' s just hilarious to to to do a search for the uhhuh ' s . 
and you get uhhuh . 
and everybody ' s doing it . 
and just listen to them . 
yeah . 
just i wanted to say i think it would be fun to make a montage of it . 
because there ' s a uhhuh . 
uhhuh . 
uhhuh . 
performance art . 
just extract them all . 
right . 
it ' s really it ' s really fun to listen to . 
morgan can make a song out of it . 
all these different vocal tracts you know . 
but it ' s it ' s the same item . 
it ' s very interesting . 
okay . 
uh then the acronyms . 
and the ones in parentheses are ones which the transcriber wasn ' t sure of . 
and i haven ' t been able to listen to to to clarify . 
oh i see . 
but you can see that the parenthesis convention makes it very easy to find them . 
because it ' s the only place where where they ' re used . 
how about question mark ? 
the question marks yeah . 
question mark is punctuation . 
what are those ? 
so it they said that . 
oh . 
uhhuh . 
um d . c . 
so they so it ' s p . l . p . 
uh . 
exactly . 
exactly . 
yeah so the only 
well and i do have a stress marker here . 
sometimes the contrastive stress is showing up . 
and um 
i ' m sorry i i got lost here . 
what ' s the difference between the parenthesized acronym and the non - parenthesized ? 
the parenthesized is something that the transcriber thought was a . n . n . but wasn ' t entirely sure . 
so i ' d need to go back or someone needs to go back and say you know yes or no . 
uh . 
right . 
and then get rid of the parentheses . 
but the parentheses are used only in that context in the transcripts of of noticing that there ' s something uncertain . 
yeah p . make is 
yeah i mean because they they have no idea . 
that ' s a good one . 
that ' s correct . 
right . 
if you hear c . t . p . d . i . mean they do pretty well . 
yeah . 
uhhuh . 
but it ' s 
i i don ' t recognize a lot of these . 
you know how are how are they going to know ? 
i know . 
i 
i i was saying that i think a lot of them are the networks meeting . 
yeah . 
i think that ' s true . 
maybe . 
yeah absolutely . 
yeah . 
n . s . a . 
i see a few . 
a lot of these are are coming from them . 
i listened to some of that . 
although i see i see plenty of uh 
yeah we don ' t have that many acronyms comparatively in this meeting . 
yeah . 
yeah i agree . 
it ' s not so bad . 
right . 
and robustness has a fair amount . 
but the n . s . a . group is just very very many . 
yeah . 
huh . 
the recognizer it is funny . 
kept getting p . t . a . for p . d . a . 
this is close . 
yeah . 
yeah that ' s pretty close . 
right . 
and the p . t . a . was in these uh topics about children . 
that ' s not bad . 
yeah . 
so anyway 
that ' s interesting . 
is the p . p . t . a . working . 
right and sometimes i mean you see a couple of these that are actually okay ' s . 
so it ' s it ' s may be that they got to the point where i mean it was low enough understandable 
understandability that they weren ' t entirely sure the person said okay . 
you know so it isn ' t really necessarily a an undecipherable acronym . 
but just needs to be double checked . 
there ' s a lot of okay ' s . 
now we get to the comments . 
the number to the left is the number of incidences ? 
this 
count . 
number of times out of the entire database . 
yep . 
uhhuh . 
except for that last thirty minutes i haven ' t checked yet . 
so c . t . s . is really big here . 
yeah i wonder what it is . 
yeah . 
yeah . 
so what is the difference between papers rustling and rustling papers ? 
i . p . 
i know what i . p . is . 
i ' d have to listen . 
i i agree . 
i i ' d like to standardize these down farther . 
but um uh 
uh to me that sounds equivalent . 
yeah . 
but i i ' m a little hesitant to to collapse across categories unless i actually listen to them . 
seems so . 
okay . 
oh i ' m sure we ' ve said x . m . l . more than five times . 
well then at least now . 
six now yeah . 
now it ' s at least six times yeah . 
yeah . 
six . 
okay well 
the self - referential aspect of these these 
i ' m 
yes it ' s very bad . 
yeah . 
well this is exactly how people will prove that these meetings do differ because we ' re recording right ? 
yes . 
normally you don ' t go around saying now you ' ve said it six times . 
yeah that ' s right . 
now you ' ve 
but did you notice that there were seven hundred and eighty five instances of okay ? 
and that ' s just without the without punctuation . 
yep . 
no i didn ' t . 
seven hundred eighty five instances . 
yeah . 
yeah . 
and that ' s an underestimate . 
extra forty one if it ' s questioned . 
because they ' re 
where ' s that ? 
so 
yep . 
on the page two of acronyms . 
yeah . 
is this after like did you do some uh replacements for all the different form of okay to this ? 
seven hundred eighty . 
yeah . 
of okay yes . 
okay . 
uhhuh . 
so that ' s the single existing convention for okay . 
wait a minute . 
so now we ' re up to seven hundred and eighty eight . 
yeah that ' s 
although what ' s there ' s one with a slash after it . 
that ' s kind of disturbing . 
yeah . 
that ' s that ' s i looked for that one . 
yeah we ' ll have to look at it you know . 
yeah . 
anyway 
i actually explicitly looked for that one . 
uhhuh . 
and i think that um 
i i ' m not exactly sure about that . 
was that somewhere where they were going to say new speaker or something ? 
no i looked for that . 
but that doesn ' t actually exist . 
and it may be 
i don ' t i can ' t explain that . 
that ' s all right . 
i ' m just pointing that out . 
it ' s the only 
there ' s 
it ' s the only pattern that has a slash after it . 
well there ' s not . 
and i think it ' s it ' s an epiphenomenon . 
so i ' ll just i was just looking at the bottom of page three there . 
is that to be or not to be ? 
yeah . 
oh that ' s cute . 
there ' s no tilde in front of it . 
so 
that ' s funny . 
yeah . 
okay . 
okay anyways sorry . 
there is one 
try to stay on topic adam . 
well no that ' s that ' s legitimate . 
so now uh comments you can see they ' re listed again . 
same deal with exhaustive listing of everything found in everything except for these final thirty minutes . 
okay so um on some of these quals 
yeah . 
are they really quals ? 
or are they glosses ? 
so like there ' s a qual t . c . l . 
t . c . l . 
where do you see that ? 
uh 
oh oh . 
the reason is because it was said tickle . 
what ' s a qual ? 
oh i see i see . 
huh . 
so it ' s not gloss . 
okay i see . 
yep . 
it wasn ' t said t . c . l . 
shouldn ' t it be qual t . i . c . k . l . e . or something ? 
of course . 
like it ' s not 
on the in the actual script in the actual transcript i i 
so this this happens in the very first one . 
uhhuh . 
i actually wrote it as tickle . 
okay . 
because we they didn ' t say t . c . l . they said tickle . 
yeah . 
right . 
and then following that is qual t . c . l . 
oh i see . 
i i forget . 
okay . 
what ' s qual ? 
qualifier . 
it ' s just comment about what they said . 
comment . 
yeah . 
comment or contextual comment . 
it ' s not something you want to replace with . 
so they didn ' t mean tickle as in elmo . 
but 
yeah . 
tickle . 
they meant tickle as in 
yeah . 
huh . 
right . 
but at some point i mean we probably 
we ' ll probably add it to the language model . 
but we should add it to the 
no to the pronunciation model . 
yeah . 
what did i say ? 
language uh 
to the language model model . 
well both . 
we can go on add it to both dictionary and language model . 
oh oh 
add what liz ? 
yeah . 
it ' s in the language model . 
yeah but so it ' s the pronunciation model that has to have a pronunciation of tickle . 
well tickle was pronounced tickle . 
right ? 
what are you saying ? 
it ' s pronounced the same it ' s pronounced the same as the verb . 
tickle is pronounced tickle ? 
i ' m sorry . 
so i think it ' s the language model that makes it different . 
oh sorry . 
what i meant is that there should be a pronunciation tickle for t . c . l . as a word . 
oh i see . 
and that word in the in you know it stays in the language model wherever it was . 
yeah . 
uhhuh . 
right . 
right . 
yeah you never would put tickle in the language model in that form . 
right . 
yeah . 
right . 
right . 
there ' s actually a bunch of cases like this with people ' s names and 
so how there ' d be a problem for doing the language modeling then with our transcripts the way they are . 
yes . 
yeah . 
yeah so there ' s a few cases like that where the um the word needs to be spelled out in in a consistent way as it would appear in the language . 
but there ' s not very many of these . 
tcl ' s one of them . 
and and you ' ll you ' ll have to do it sychronously . 
um 
yeah . 
right so so whoever ' s creating the new models will have to also go through the transcripts and change them synchronously . 
it ' s just disturbing . 
right . 
right . 
we have this there is this thing i was going to talk to you about at some point about you know what do we do with the dictionary as we ' re updating the dictionary ? 
huh . 
these changes have to be consistent with what ' s in the like spelling people ' s names and so forth . 
if we make a spelling correction to their name 
like someone had deborah tannen ' s name misspelled . 
and since we know who that is you know we could correct it . 
you can correct it . 
but 
yeah . 
but we need to make sure we have the 
if it doesn ' t get corrected we have to have a pronunciation as a misspelled word in the dictionary . 
things like that . 
uhhuh . 
these are so funny to read . 
well of course now the the tannen the spelling change 
so 
uh that ' s what gets i i picked those up in the frequency check . 
right right . 
so if there ' s things that get corrected before we get them it ' s it ' s not an issue . 
but if there ' s things that um we change later then we always have to keep our the dictionary up to date . 
uhhuh . 
and then yeah in the case of tickle i guess we would just have a you know word t . c . l . which 
uhhuh . 
you add it to the dictionary . 
which normally would be an acronym . 
you know t . c . l . 
right . 
but just has another pronunciation . 
yep . 
icsi is is one of those that sometimes people pronounce and sometimes they say i . c . s . i . 
uhhuh . 
so those that are are listed in the acronyms i actually know . 
oh yeah . 
they were said as letters . 
the others um those really do need to be listened to . 
because i haven ' t been able to go to all the icsi things . 
right exactly . 
and and until they ' ve been listened to they stay as i . c . s . i . 
uhhuh . 
right . 
don and i were just noticing . 
love this one over on page three . 
vocal vocal gesture mimicking sound of screwing something into head to hold mike in place . 
that ' s great . 
it ' s this rrre - rrre - rrre . 
it was me . 
it was . 
in fact it was . 
yeah . 
a lot of these are me . 
he he he said he said get 
the the beep is said with a high high pitch and lengthening . 
to head . 
yeah that ' s it . 
that was the i was imitating uh beeping out . 
beep . 
perfect . 
oh there is something spelled out b . e . e . e . e . e . e . p . 
yeah . 
yeah that ' s it . 
um 
that ' s it . 
yeah that ' s that ' s been changed . 
yeah . 
in the old 
thank you . 
because he was saying how many e . ' s do i have to allow for . 
you need a lot of 
what i meant was beep . 
you need a lot of qualification adam . 
that ' s been changed . 
i guess so . 
so exactly that ' s where the lengthening comment came in . 
anyway 
right thanks . 
subtext . 
brought it down . 
yeah . 
so they ' re vocalization 
right . 
and those of course get get picked up in the frequency check . 
glosses . 
because you see beep . 
right . 
and you know i mean it gets kicked out in the spelling . 
right . 
and it also gets kicked out in the uh frequency listing . 
right . 
i have the there ' re various things like breathe versus breath versus inhale and hhh . 
you know i don ' t know . 
i i think they don ' t have any implications for anything else . 
so it ' s like i ' m tempted to leave them for now . 
and it ' s easy enough to find them when they ' re in curly brackets . 
we can always get an exhaustive listing of these things and find them and change them . 
yeah . 
sings finale type song . 
yeah . 
yeah that was in the first meeting . 
that ' s that ' s good . 
um 
yeah but i don ' t actually remember what it was . 
but that was eric did that . 
yeah . 
yeah . 
so on 
tah - dah . 
i don ' t know . 
i think maybe something like that . 
something like that ? 
maybe yeah . 
well that ' d qualify . 
on the glosses for numbers 
yeah . 
it seems like there are lots of different ways it ' s being done . 
okay . 
interesting question . 
there ' s a 
yes . 
okay now first of all 
ooo - ooo ! 
very important . 
ooo - ooo . 
uh chuck chuck led to a refinement here . 
which is to add nums if these are parts of the read numbers . 
now you already know that i had uh in places where they hadn ' t transcribed numbers i put numbers in place of any kind of numbers . 
but there are places where they 
um it this convention came later . 
and at the very first digits task in some transcripts they actually transcribed numbers . 
and um 
chuck pointed out that this is read speech . 
and it ' s nice to have the option of ignoring it for certain other uh uh things . 
and that ' s why there ' s this other tag here which occurs a hundred and five or three hundred and five times right now . 
which is just well nums by itself . 
nums . 
yeah . 
which means this is part of the numbers task . 
i may change it to digits . 
i mean with the sed command you can really just change it however you want . 
because it ' s systematically encoded you know ? 
yep . 
have to think about what ' s the best for for the overall purposes . 
but in any case um numbers and nums are a part of this digits task thing . 
um now then i have these numbers that have quotation marks around them . 
um i didn ' t want to put them in as gloss comments . 
because then you get the substitution . 
and actually um the reason i did it this way was because i initially started out with the other version . 
you have the numbers and you have the full form and the parentheses . 
however sometimes people stumble over these numbers they ' re saying . 
so you say seventy eight point two or whatever . 
and there ' s no way of capturing that if you ' re putting the numbers off to the side . 
you can ' t have the seven and 
so what ' s to the left of these ? 
the left is 
so example the very first one 
it would be spelled out in words point five . 
uhhuh . 
okay that ' s what i was asking . 
right . 
only it ' s spelled out in words . 
so this is also spelled out in in words . 
point f . i . v . e . yeah . 
point five . 
good . 
and then in here nums . 
so it ' s not going to be mistaken as a gloss . 
it comes out as nums quote dot five . 
okay now the other example is in the glosses right there 
thank you . 
gloss one one one dash one three zero . 
right . 
well now 
what what ' s to the left of that ? 
in that case it ' s people saying things like one one one dash so - and - so . 
or they ' re saying uh two i mean zero whatever . 
okay . 
and in that case it ' s part of the numbers task . 
and it ' s not going to be included in the read digits anyway . 
so i in the uh 
so there will be a nums tag on those lines ? 
there is . 
yeah . 
yeah . 
i ' ve added that all now too . 
good . 
there ' s a numbers tag 
wait . 
i ' m sorry i ' m i didn ' t follow that last thing . 
so so gloss in the same line that would have gloss quote one one one dash one thirty you ' d have a gloss at the end of the line saying uh curly bracket nums curly bracket . 
right . 
so if you if you did a uh a grep minus v . nums . 
oh so you could do grep minus v . nums . 
so that ' s the 
and you get rid of anything that was read . 
yeah . 
so there wouldn ' t be something like 
okay . 
if somebody said something like boy i ' m really tired okay and then started reading that would be on a separate line . 
yes . 
okay great . 
because i was doing the grep minus v . quick and dirty . 
and looked like that was working okay . 
uhhuh . 
but 
good . 
great . 
yep . 
now why do we what ' s the reason for having like the point five have the nums on it ? 
is that just like when they ' re talking about their data or something ? 
this is more because 
or 
yeah . 
oh these are all these the nums point this all where they ' re saying point something or other . 
these are all like inside the spontaneous 
and the other thing too is for readability of the transcript . 
i mean if you ' re trying to follow this while you ' re reading it it ' s really hard to read you know 
uh so in the data column five has you know one point five compared to seventy nine point six . 
it ' s like when you see the words it ' s really hard to follow the argument . 
and this is just really a a way of someone who would handle the data in a more discourse y way to be able to follow what ' s being said . 
oh okay . 
label it . 
i see . 
so this is where chuck ' s um overall architecture comes in . 
where we ' re going to have a master file of the channelized data . 
um there will be scripts that are written to convert it into these these main two uses . 
and some scripts will take it down into a a take it to a format that ' s usable for the recognizer . 
uh other scripts will take it to a form that ' s usable for the for linguistics and discourse analysis . 
and um the implication that that i have is that the master copy will stay unchanged . 
these will just be things that are generated . 
right . 
and 
okay . 
by using scripts . 
master copies of superset . 
when things change then the the script will change . 
but the but there won ' t be stored copies of in different versions of things . 
good . 
so i guess i ' d have one request here . 
which is just um maybe to make it more robust . 
that the tag whatever you would choose for this type of nums where it ' s inside the spontaneous speech is different than the tag that you use for the read speech . 
right . 
right that would argue for changing the other ones to be digits or something . 
um that way if we make a mistake parsing or something we don ' t see the point five . 
or or it ' s not there then we 
uhhuh . 
just and actually for things like seven eighths or 
people do fractions too i guess . 
you maybe you want one overall tag for sort of that would be similar to that . 
except 
or 
as long as they ' re as they ' re different strings that we that ' ll make our sort of processing more robust . 
well 
because we really will get rid of everything that has the nums string in it . 
i suppose what you could do is just make sure that you get rid of everything that has curly brace nums curly brace . 
well 
exactly . 
exactly . 
i mean that would be the 
that was that was my motivation . 
yeah . 
and these can be changed like i said . 
you know i mean as i said i was considering changing it to digits . 
and it just you know it ' s just a matter of deciding on whatever it is and being sure the scripts know . 
right . 
it would probably be safer if you ' re willing to have a separate tag . 
just because um then we know for sure . 
and we can also do counts on them without having to do the processing . 
but you ' re right . 
we could do it this way . 
it it should work . 
um 
yeah and it makes it i guess the thing about 
but it ' s probably not hard for a person to tell the difference . 
because one ' s in the context of a you know a transcribed word string . 
yeah . 
right . 
the other thing is you can get really so minute with these things . 
and 
so 
and increase the size of the files and the and decrease the readability to such an extent by simply something like percent . 
now i i could have adopted a similar convention for percent . 
but somehow percent is not so hard you know ? 
huh . 
it ' s just when you have these points and you ' re trying to figure out where the decimal places are . 
and we could always add it later . 
percent ' s easy to detect . 
point however is is uh a word that has a couple different meanings . 
and you ' ll find both of those in one of these meetings . 
where he ' s saying well the first point i want to make is so - and - so . 
and he goes through four points . 
and also has all these decimals . 
so liz what does the recognizer do 
so 
uh 
huh . 
what does the s . r . i . recognizer output for things like that ? 
seven point five . 
does it output the word 
seven point five . 
right . 
well the numbers . 
the word seven . 
the number seven . 
the word . 
the word seven okay . 
yeah . 
yeah . 
so i ' d so i ' d like i ' d like to talk about point five . 
and and actually you know the language 
it ' s the same point actually . 
yeah . 
the the you know the word to and the word going to and to go to 
those are two different to ' s . 
and so there ' s no distinction there . 
uhhuh . 
it ' s just just the word point has 
yeah every word has only one yeah one version 
even if even if it ' s 
actually even like the word read and read . 
those are two different words . 
they ' re spelled the same way right ? 
uhhuh . 
and they ' re still going to be transcribed as r . e . a . d . 
right . 
uhhuh . 
so 
yeah i i like the idea of having this in there . 
i just i was a little bit worried that um the tag for removing the read speech . 
because what if we have like read letters ? 
or i don ' t know . 
we might want to just a separate tag that says it ' s read . 
like read something . 
like read . 
yeah basically . 
uhhuh . 
but other than that it sounds great . 
yeah . 
okay . 
are we done ? 
well i wanted to say also regarding the channelized data . 
oh i guess we ' re not done . 
that um thilo requested um that we get some segments done by hand to reduce the size of the time bins . 
yeah . 
like was chuck was mentioning earlier . 
that um that um if you if you said oh and it was in part of a really long complex overlapping segment that the same start and end times would be held for that one . 
well 
as for the longer utterances . 
we did that for one meeting right ? 
and 
so you have that data don ' t you ? 
yeah that ' s the training data . 
and he requested that there be uh similar uh samples done for five minute stretches involving a variety of speakers and overlapping sections . 
he gave me he did the very nice he he did some shopping through the data . 
yeah . 
and found segments that would be useful . 
and at this point all four of the ones that he specified have been done . 
in addition the i ' ve i have the transcribers expanding the amount that they ' re doing actually . 
oh great . 
so right now um i know that as of today we got an extra fifteen minutes of that type . 
and i ' m having them expand the realm on either side of these places where they ' ve already started . 
oh great . 
okay . 
but if if you know and i and he ' s going to give me some more sections that that he thinks would be useful for this purpose . 
yeah . 
yeah . 
because it ' s true . 
i mean if we could do the the more fine grained tuning of this uh using an algorithm that would be so much more efficient . 
and um 
so this is going to be useful to expand this . 
so i i thought we we we perhaps we should try to to start with those channelized versions . 
just to just to try it . 
give it give one transcriber the the channelized version of of my speech - nonspeech detection . 
and look if if that ' s helpful for them . 
or just let them try if if that ' s better . 
or if they if they can 
you mean to start from scratch in a brand new transcript . 
yeah yeah . 
yeah . 
that ' d be excellent . 
yeah that ' d be really great . 
as it stands we ' re still in the phase of sort of um cleaning up the existing data . 
getting things uh in more tightly time uh aligned . 
i also want to tell um i also wanted to raise the issue that okay so there ' s this idea we ' re going to have this master copy of the transcript . 
it ' s going to be modified by scripts into these two different functions . 
and actually the master 
two or more . 
two or more different functions . 
two two or more . 
and that the master is going to be the channelized version . 
right . 
so right now we ' ve taken this initial one it was a single channel basically the way it was input . 
and now uh thanks to the advances made in the interface we can from now on use the channelized part . 
and um any changes that are made get made in the channelized version kind of thing . 
but i wanted to get all the finished all the checks . 
yeah so that has implications for your script . 
yeah . 
so uh have those the the ten hours that have been transcribed already have those been channelized ? 
yes they have . 
and i know i ' ve seen i ' ve seen they ' ve been channelized . 
all ten hours ? 
except for the missing thirty minutes . 
but 
great . 
have they uh have they been has the time have the time markings been adjusted uh on a per channel 
uh for for a total of like twenty 
for a total of 
let ' s see four times 
total of about an thirty minutes . 
that ' s that ' s been the case . 
so 
and plus the training whatever you have . 
i guess i mean i don ' t know if we should talk about this now or not . 
but 
well it ' s just we ' re missing tea . 
yeah i know . 
so 
no but i mean my question is like should i wait until all of those are processed and channelized ? 
like the time markings are adjusted before i do all the processing . 
and we start like branching off into the into the our layer of uh transcripts . 
well you know the problem the problem is that some some of the adjustments that they ' re making are to bring are to combine bins that were time bins which were previously separate . 
and the reason they do that is sometimes there ' s a word that ' s cut off . 
right . 
and so it ' s true that it ' s likely to be adjusted in the way that the words are more complete . 
and 
okay . 
so i it ' s going to be a more reliable thing . 
no i know i know that adjusting those things are going to is going to make it better . 
and i ' m not sure 
yeah . 
i mean i ' m sure about that . 
but do you have like a time frame when you can expect like all of it to be done ? 
or when you expect them to finish it or 
well partly it depends on how um how effective it will be to apply an algorithm . 
because this takes time . 
yeah . 
you know it takes a couple hours to do uh ten minutes . 
yeah . 
yeah i don ' t doubt it . 
um so 
so right now the what you ' re doing is you ' re taking the uh the original version . 
and you ' re sort of channelizing yourself right ? 
yeah i ' m doing it myself . 
i mean if the time markings aren ' t different across channels . 
like the channelized version really doesn ' t have any more information . 
uhhuh . 
so i was just i mean originally i had done before like the channelized versions were coming out . 
right . 
right . 
um 
and so it ' s a question of like what 
so i i i think probably the way it ' ll go is that you know when we make this first general version and then start working on the script that script that will be you know primarily come from what you ' ve done um we ' ll need to work on a channelized version of those originals . 
uhhuh . 
uhhuh . 
uhhuh . 
and so it should be pretty much identical to what you have . 
yep . 
except for the one that they ' ve already tightened the boundaries on . 
uhhuh . 
right . 
um 
yeah i mean 
so 
yeah . 
uh and then probably what will happen is as the transcribers finish tightening more and more you know that original version will get updated . 
and then we ' ll rerun the script and produce better uh versions . 
okay . 
but the i guess the the effect for you guys because you ' re pulling out the little wave forms into separate ones that would mean these boundaries are constantly changing . 
you ' d have to constantly rerun that . 
i know . 
so maybe 
right . 
but that that ' s not hard . 
but that 
uhhuh . 
no . 
i think the harder part is making sure that the the transcription 
okay . 
so if you merge two things then you know that it ' s the sum of the transcripts . 
but if you split inside something you don ' t where the word which words moved . 
uhhuh . 
uhhuh . 
and that ' s that ' s where it becomes a little bit uh having to rerun the processing . 
uhhuh . 
the cutting of the waveforms is pretty trivial . 
yeah . 
i mean as long as it can all be done automatically i mean then that ' s not a concern . 
you know if i just have to run three scripts to extract it all and let it run on my computer for an hour and a half or however long it takes to parse and create all the reference file that ' s not a problem . 
right . 
uhhuh . 
yeah . 
uhhuh . 
uhhuh . 
um 
so yeah . 
as long as we ' re at that point . 
and i know exactly like what the steps will work what ' s going on in the editing process . 
yeah . 
so 
okay . 
so that ' s i mean i could there were other checks that i did . 
but it ' s i think that we ' ve unless you think there ' s anything else i think that i ' ve covered it . 
yeah . 
i can ' t think of any of the other ones . 
okay . 
great . 
okay . 
oop ! 
man ! 
okay . 
well we ' re we ' re so ahead of the game now . 
because we ' ve got built in downsampling now . 
we have what what do we have ? 
we ' ve got built in downsampling . 
and so it ' s only recording sixteen kilohertz data . 
and we ' ve got 
wait a second . 
we ' re not we ' re not recording the empty channels . 
the ones that aren ' t filled out are the ones you want to hand out . 
what about the ones that we didn ' t record ? 
no i was looking for the ones 
i threw the ones out that we already recorded . 
but we didn ' t record . 
oh okay . 
okay . 
well then fine . 
fine . 
then it doesn ' t matter . 
well done . 
see if we care . 
does it ? 
well done . 
okay . 
you ' re probably wondering why i brought you all here today . 
right . 
but before before we 
before that . 
right so the first task is to read some digits . 
before that 
yeah . 
so i ' ll go ahead and start . 
and this is adam on mike number two . 
so if you could just fill out the form . 
and then later on we ' ll read it with pauses between . 
good . 
and we ' re session two . 
do you want to read next ? 
shall i 
or 
i ' d like to hear one 
let her fill it out and go ahead and read . 
yeah i ' d like to hear one more . 
uh 
okay . 
um this is eric on mike one . 
the wireless lapel . 
channel zero . 
um 
could i hear you next ? 
okay . 
so basically they ' re kind of like sentences but with numbers instead of words . 
okay . 
so i ' m i ' m on uh number four with the microphone around my neck . 
and i will read these . 
so you want to pause briefly between each one . 
so that the person transcribing can tell where one ends and one begins . 
okay . 
and 
so a short sentence between each line . 
it really sounds like sentences . 
your intonation sounds like somewhat like sentence intonation . 
well you can intone it however you want . 
imagine that you ' re reading a number phone number to someone . 
okay . 
yeah ? 
yep . 
um 
okay . 
okay good . 
thanks . 
great . 
so we ' ll probably do another one at the end of the meeting . 
just to get some more digits . 
right . 
and uh 
okay . 
thank you . 
if i were to be dictating a phone number i would have done that more slowly . 
but uh which would have been easier for the of course for the machine . 
but was that an okay pace ? 
sure . 
it ' s kind of weird . 
yeah . 
it ' s fine . 
that was great what you did . 
um 
okay . 
just as long as it ' s with you know uh within the constraints . 
what what ' s your mike number jane ? 
number four . 
oh sorry . 
dan doesn ' t remember what sex he is ? 
yeah because i figure no one ' s going to be able to figure it out . 
from the from my name . 
that ' s true it ' s it ' s really difficult . 
so 
yeah . 
and the voice . 
just no way . 
well don ' t you 
i i wrote a scanner program that scans these forms in . 
oh right right right . 
anyway so why did i call you all here ? 
yes . 
um what i ' d like to talk about is um the transcription . 
oh you did . 
so as part of this um project we need to transcribe these meetings . 
um to do training and test and so on . 
and uh so we need word transcripts and uh speaker change identification . 
so speaker i d . 
and uh so i ' d sort of like to know who ' s going to do that . 
hi jane . 
and uh what tools to use . 
what other resources you might need . 
and also what we 
things like just the data format and how we ' re going to do it . 
so i ' m just curious how how how exactly you got roped into this . 
i mean 
oh . 
um because my name was was mentioned when i wasn ' t around . 
but i ' m most happy . 
okay . 
oh really ? 
good . 
because morgan said he asked you . 
oh uh he did . 
and and i approved . 
uhhuh . 
but i think that i was uh proposed before i was asked . 
and that doesn ' t matter . 
because i think there was probably an uh an indication that that i was interested in advance . 
oh . 
yeah that would be that would be my fault . 
and in which case i thank you . 
right . 
yeah . 
uh right . 
and so one of the first questions is do you need help . 
okay . 
well hang on . 
oh . 
that ' s not the first question . 
well well i guess . 
okay . 
do you so do you 
what are what are we talking about ? 
that you ' re going to you ' re going to do transcriptions ? 
you ' re going to listen to these things and 
i ' m going to provide i ' m going to be 
once i ' m given the data i will provide word level transcripts with uh indication of speakers . 
okay . 
and um 
i guess speaker change in any case . 
so speaker i d . 
and words . 
okay so you ' re going to do the actual transcription yourself ? 
yeah . 
okay . 
and do you have a clear i mean is that 
do you sort of 
are you going to have to make up what you do ? 
or do you have a very clear idea of what you ' re going to do ? 
so i mean is it is it is this is it like something you ' ve done before ? 
well . 
or 
i ' ve transcribed a lot . 
yeah . 
but um you know the i mean there are always ways of doing things more efficiently or more uh in a more technically sophisticated way . 
and 
yeah . 
do you have to speak true english sentences when you do this ? 
yeah . 
because people are going to be listening to it afterwards . 
and saying oh listen to her . 
she couldn ' t even speak true english sentences . 
she can ' t speak . 
it ' s terrible . 
okay so um 
oh you ' re meant you ' re meant to speak naturally . 
you ' re meant to say oh i didn ' t realize we were being recorded . 
uh right . 
yeah . 
no one told me that . 
this microphone what ' s this doing around my neck ? 
uh that ' s 
i i was saying before we don ' t really have to worry about people being surprised by it . 
it ' s just it ' s just jewelry . 
okay so um typically what i you know i in uh what i ' ve done before is i have a uh tape recorder with a reverse button . 
yeah . 
and you just you know if it ' s word level you know you do a a i just hit the the rewind button every couple of words . 
play . 
and type what i know . 
yeah . 
and then and then at the end do a breeze through to be sure that everything ' s correct . 
yeah . 
however they do have software these days which with a digitized uh record you can have control over replay through some sort of an interface . 
yeah . 
um i ' ve never used one of those . 
i know it would be an a wonderful idea . 
it ' s just i haven ' t transcribed in in awhile . 
the problem is the nice thing about transcribers is they have foot pedals . 
i mean 
right . 
foot pedals i ' ve used transcribing machines . 
that ' s fine . 
um but i frankly didn ' t find it any more use to me than my hand held taperecorder . 
oh . 
i see . 
however if we have a transcribing machine i would accept it . 
the other thing is you know having getting hold of a transcriber . 
i think that cogsci has one . 
uhhuh . 
yeah . 
and i could probably borrow one . 
well one 
i i i actually have one . 
you have one yourself ? 
well sarah has one . 
oh i see . 
because she does a lot of transcribing of interviews . 
oh super . 
but the crazy thing is we ' d have to convert the we ' d have to dump the audio files onto cassette to use it . 
the other thing is is that we might be 
oh . 
oh i see . 
okay . 
i mean given that we ' ve already got them digitally it would be 
you know it ' s quite tempting to use some kind of uh software thing . 
oh okay . 
but but then there ' s the question of the ergonomic interface that 
i 
oh i actually have some foot pedals for the p c . 
well that ' s what i was going to say is that adam has foot pedals that we could probably try and rig something up to . 
okay . 
oh that ' d be super . 
what do they connect to ? 
uh keyboard . 
and they generate keystrokes . 
oh that ' s totally cool . 
now how how do you how do you decide which keystrokes they generate ? 
um there ' s a little program that downloads into it . 
um 
huh . 
this is great . 
and this is windows ? 
but the program probably only runs in windows . 
although i bet we could program it once . 
uhhuh . 
and and then put it on another machine and it would work . 
except for the fact that we would have to unplug it and and change it 
i haven ' t used them . 
does it lose the memory once you ' ve unpowered it ? 
i don ' t know . 
i don ' t think it does . 
so hang on . 
you have you have these foot pedals but you you ' re not using them . 
i ' m not using them anymore . 
i used to use them . 
so they ' re currently set up for shift control and alt . 
yeah . 
but i i don ' t use them . 
they ' re not even plugged in . 
wow ! 
that ' s so cool . 
okay 
this sounds wonderful . 
and so uh if that would help uh i ' m certainly willing to donate them . 
well 
i ' m i ' m open to 
the the well the uh the part that ' s not wonderful is someone has to write the software . 
right . 
yeah that ' s true . 
and it it is a p c connection . 
well you know 
so it would have to go on a p c somewhere . 
yeah . 
now we ' re at a pilot phase right now . 
uhhuh . 
and what i was told is that beginning 
you know that the the pilot data would be something like half hour of uh or you know half hour to forty minutes of running text . 
and so for the pilot thing you know of course this would be useful . 
right this is the pilot data . 
and i i i ' m i ' m assuming that i would not be uh you know uh uh transcribing all of it . 
yeah yeah you are generating it . 
well that that was part of the question . 
is that if for if we ' re doing this regularly 
right . 
imagine we ' re doing a couple of hours a week of transcripts . 
yeah . 
um of recording . 
uh i wouldn ' t expect you to do it all . 
no . 
no no . 
so the question is do you know of resources that we could use ? 
so are there grad students or undergrads or just commercial services ? 
yes . 
uhhuh yeah okay so now i ' ve i ' ve been involved with some of that at at cogsci . 
um so susan susan ervin tripp who you know um would typically and i ' ve done this too supervise undergrads to do this kind of thing . 
huh . 
and they you know you can give them like 
if you give them a little bit of instruction and and make it interesting for them they can do it as a two ninety eight or 
or not two ninety eight what is it one whatever undergraduate research credit . 
because what you do is you can you know build it into some sort of a 
uhhuh . 
oh really ? 
so we only have to give them credits . 
we don ' t have to give them money ? 
well uh you have to be sure you give them compensation for you know of some of some sort . 
oh you do have to pay them . 
awesome . 
what i mean is it ' s not necessarily monetary . 
but if they feel like they ' re getting something out of it sometimes you can do it that way . 
uhhuh . 
uhhuh . 
and otherwise as part of a grant you can you can do it . 
some sort of minimal wage . 
yeah . 
well we we need to we need to find out how much that will cost so i can pass that on to morgan . 
yeah . 
because right now we have almost no money . 
yeah . 
okay . 
so so the cheaper we can do it the better . 
well 
okay well you also want to get quality . 
i mean someone ' s going to have to pass through either a higher level person will have to pass through or you have to be sure you get good quality to begin with . 
yeah absolutely . 
uhhuh . 
right . 
but um yeah that ' s quite you know we ' ve that ' s been done . 
i can ask susan ervin tripp what she would recommend on that . 
yeah . 
she ' s really she ' s done of the people that i know she ' s the one who ' s supervised the most of those things locally . 
uhhuh . 
what ' s her name ? 
uh uh doctor susan ervin tripp . 
okay . 
faculty member in psychology recently retired . 
uhhuh . 
so 
and very well known in discourse analysis . 
oh okay . 
so the i mean what i ' m hearing is that the problem of starting off with some recordings and trying to get word transcripts is kind of i mean it ' s not a it ' s not an unfamiliar problem . 
so that 
oh it ' s very common . 
so that i mean that basically there are standard solutions and we should just adopt adopt them . 
yeah . 
and it ' s going to cost however much it ' s going to cost . 
i mean there ' s we ' re we ' re probably not going to have a lot of flexibility in bringing down the cost . 
because probably the low cost solution ' s already been established . 
and so that ' s just whatever it is . 
uhhuh . 
that ' s how we ' ll do it . 
see what i mean ? 
i think there ' s always this question of the trade off between uh paying more for the first pass and then and then editing less later . 
uhhuh . 
uhhuh . 
or paying less the first pass and editing more later . 
so 
yeah . 
well whatever they people who have had to do this 
i mean the only thing is i wonder if our requirements are different from um i mean there ' s than than what ' s been done in the past . 
than discourse analyzers . 
because maybe we have different requirements in terms of time you know how much time aligned detail we need and uh how much detail in terms of people . 
oh but that ' s a 
uhhuh . 
okay . 
i i don ' t know how much i don ' t think we do need any time aligned detail . 
i think we just have basically one text file which runs from beginning to end . 
but 
well if in terms of transcripts sure . 
but in terms of speaker change it might be nice to get the actual time . 
sure . 
but not if it costs more . 
right . 
well okay so what happened with switchboard was at least i mean the output was that they had speaker turns . 
and they um analyzed it in terms of you know this is where this speaker change came in . 
and of course that gets really difficult when you ' re talking about 
i mean this is some of the stuff that you were talking about in uh your lunch talk . 
uhhuh . 
is that is that you know you get backchannels and stuff like that that that you know disrupt the um the segment you know the segmentation . 
right . 
yeah . 
right i mean the it ' s sort of it ' s a little in some sense it ' s a little bit easier with it with switchboard . 
because the telephone is so actually people are less flexible in what they do . 
in this kind of situation where we ' ve got nonverbal channels then there ' s a lot of overlap . 
and there ' s just that it ' s not a very good model . 
right . 
oh in terms of data format what are we going to do about that ? 
i mean you have the s t m format where you have you know every every utterance is is a single speaker . 
i mean is that the right way to do it ? 
or 
well every utterance is a single speaker . 
right ? 
it ' s just that utterances can overlap . 
i mean 
is that the right way to do it ? 
i think so . 
okay . 
i think i think i mean i think when i ' m when 
like so eric made a made a sentence and that should be like one utterance . 
and then i had a couple of backchannels in there . 
and they should be just overlapping things that 
i don ' t think that we should break eric ' s sentences for those i think . 
okay so that means that for each utterance we ' ll need the time marks . 
right . 
the start and end of each utterance . 
yeah . 
so so 
well we ' ll have to go in from somewhere . 
but we can ' t necessarily i mean we we may be able to get the transcriber to give them to us if we give them software . 
but we may not . 
in which case we ' ll have to get them some other way . 
like with forced alignment later . 
i mean you know all this can be done . 
uhhuh . 
so we maybe we should look at the um the tools that mississippi state has . 
yeah . 
because i i i know that they published um annotation tools . 
you know for their 
well x waves have some as well . 
but they ' re pretty low level . 
they ' re designed for um for phoneme level . 
yeah . 
phoneme phoneme phoneme transcriptions . 
yeah . 
i should ' ve 
although they actually have a nice tool for that could be used for speaker change marking . 
there ' s a there are there ' s a whole bunch of tools . 
there ' s a some web page where they have a list of like ten of them or something . 
yes . 
are you speaking about mississippi state per se ? 
okay . 
or are 
no no no there ' s some i mean i just there are there are a lot of a lot of these things . 
yeah . 
actually i wanted to mention there are two projects which are international huge projects focused on this kind of thing actually . 
one of them ' s mate . 
one of them ' s eagles . 
and um and both of them have 
oh eagles . 
yeah that ' s the european one . 
yeah . 
you know i i know you know about the big book . 
yeah . 
i think you got it as a prize or something . 
huh . 
yeah . 
got a surprise . 
and um and they have you know a lot of 
and mate is a project which is being run out of denmark . 
and um they have a lot uh big uh 
you know they ' re trying to set up a a work bench or something or other . 
and they have a whole bunch of tools that are associated with them . 
uhhuh . 
so i mean there are things that in terms of like the time alignment issue 
uhhuh . 
i mean you guys are more expert on that i mean than i am . 
but i want to say that i know for a fact i keep running across these . 
and those would be my first two choices of looking at eagles and mate . 
and i have the documentation downstairs . 
okay . 
i didn ' t think to bring it . 
have you looked at it already ? 
oh i have . 
but i wasn ' t interested in that particular issue . 
uhhuh . 
is this 
so we ' re talking now once you have words you know how do you time align it . 
and that ' s 
oh so these are particularly for time alignment ? 
well these are uh tools 
so mate and eagles are both within the so called uh language engineering branch . 
and um so they ' re intended for this kind of a computer science application type of approach . 
yeah . 
these are not discourse types of tools . 
right . 
so they 
right are they just for time alignment or are they for transcription as well ? 
can i be excused ? 
and i ' ll go down and get my stuff . 
because um i i do think 
you don ' t 
just take the thing with you . 
it ' s wireless . 
are you serious ? 
i mean it won ' t 
well i don ' t know what will happen . 
but you may as well . 
i but but 
what uh i mean can you spare like a minute or two of a 
sure sure sure . 
sure . 
sure . 
okay . 
and i go get my books and i ' ll be right back . 
i didn ' t think of bringing this . 
do i need this ? 
i need my keys . 
okay . 
my uh my 
oops ! 
i need my card key . 
we can hear all your conversations along the way . 
yeah so be just 
i ' ll try not to say so oh dear boy that ' s itching there . 
yeah don ' t talk to yourself too much . 
yeah . 
so 
yeah . 
that ' s true . 
you can leave it behind as well if you want . 
so for the digits for the 
i i assume that these are projects where they do the whole thing . 
right ? 
right . 
so they probably will have tools to address the actual the the the transcriber support . 
oops ! 
and then automated alignment of what the transcribers give you . 
which is you know exactly the problem we have 
uhhuh . 
right but we can do automated alignment . 
that ' s not a problem . 
okay . 
right . 
i think . 
right . 
but then again we don ' t have to do it . 
well i ' m not sure if we can do automated alignment or not . 
and 
i mean especially in with speaker change in a meeting like this where we ' re overlapping so much . 
i 
i don ' t think we ' re going to have a a prayer . 
oh sure we are . 
we ' ve got individual microphones . 
well to get to get the to get the actual transcript i think we ' ll do okay . 
because of because of the separate channels . 
oh that ' s true . 
right . 
we could just do it through these . 
yeah . 
right . 
i hadn ' t even thought about that . 
sure . 
um in terms of data formats uh what i did for the digits stuff was just to hand rolled my own that looks like this form . 
you know it ' s just uh something that ' s easy to parse in perl . 
um probably for the full one we ' ll want to do something like s t m . 
i mean some format that our tools already work with . 
yeah . 
well 
yes . 
although that might presumably we ' ll have one we ' ll have several formats that you can interconvert between . 
right . 
yeah presumably . 
when we want to do recognition we ' ll do s t m . 
but if we ' re rather than rather than designing our own format we ' ll just take whatever comes out of the tools that we can find to use i think . 
yeah i guess that ' s true . 
yeah . 
i i i ' ve got no idea what that ' ll look like . 
right . 
but 
well i know that i know that um the mississippi state tools at least what the produce does not come out in s t m format . 
on our speaker phones . 
right . 
they they basically give 
um they subdivide into wave files . 
and then they give for each they give a one oh you know a wave file that indicates where the start and stop times are . 
uhhuh . 
and then um and then give the uh whatever the sentence information . 
yeah . 
but i mean it as you said it was easy to convert back and forth between um that file and s t m format . 
in fact what i did is i took the mississippi state data and just made s t m files out of it . 
uhhuh . 
okay . 
good . 
okay mate mark up framework . 
okay . 
right . 
specification of uh coding workbench . 
uhhuh . 
that ' s one thing . 
and then back in here 
oh no ! 
it has the word x m l in it . 
oh good . 
it must be it must be fundable then . 
k c m file formats . 
oh looks like looks like uh work packages . 
this is the 
must be a european project . 
yeah . 
oh yeah . 
yeah it is european . 
both of these are european . 
but they have you know american contributions and stuff . 
oh so they ' re using the alembic workbench from mitre . 
alembic ? 
i guess . 
yeah . 
is that free ? 
i don ' t know . 
well but you see they have a whole bunch of things . 
what they ' re doing is trying to bring together . 
and they rate things . 
i wasn ' t focused on that . 
so i didn ' t 
let me show 
have you seen this one dan ? 
no . 
and i ' ll try to get one for you too . 
oh you ' ve got one . 
what are you looking at here ? 
he ' s got the mark up framework . 
oh yeah . 
different coding schemes . 
but it doesn ' t have enough pictures . 
so i think it will require too much reading to understand whether this is anything that we can easily use . 
okay . 
oh ! 
this is 
i see . 
they ' re reviewing and 
what they ' re doing is they ' re comparing all these existing things that have been submitted . 
and and it includes this one includes the t e i . 
i see . 
and uh 
so it ' s it ' s um pretty broad based . 
t e i is 
these things do seem to be . 
mitre . 
that ' s the text encoding initiative . 
oh . 
that ' s a way of markup . 
so you know but focus on tools to do this stuff . 
um i do have a file also in addition to those things . 
but 
it ' ll take me just a second here . 
well i guess x m l makes some amount of sense . 
i ' m not actually familiar with it . 
but it seems to be the sort of thing that this would be good for . 
but 
well yeah . 
i mean if you start with a a basic transcription and a good filter you can 
uhhuh . 
i mean that ' s sort of my feeling about it . 
that you should be you should be able to translate between an x m l and non x m l version . 
because most at least you know with a focus on discourse mostly . 
right . 
oh i wanted to 
this this approach here this is uli heid from stuttgart . 
is um a query language for research in phonetics where he wants to build in tobi tags . 
and so you can determine 
um i wanted to mention this to you . 
i was going to come by and ask you about this . 
uhhuh . 
do you know about the stuttgart um people ? 
because he ' s saying if you represent 
i don ' t think so . 
he says that uh in german selbst is used in two different ways . 
so you have it either means uh himself or it means even . 
and you can tell the difference in terms of uh intonation . 
uhhuh . 
so they have the recordings such that they can locate things uh with by searching for part of speech and also intonational tags . 
huh . 
uhhuh . 
anyway that ' s that . 
because the transcriber ' s put in intonational tags ? 
this is true . 
this is true . 
which of course is another issue . 
or maybe not . 
exactly so . 
and then i have one more thing i need to find . 
well . 
but that kind of thing i think we would probably want to extract automatically . 
and then i ' ll be 
i mean this is the this is a conversation that we should have with liz . 
yeah . 
yes . 
oh okay . 
right . 
i think . 
because she ' s going to be she ' s going to be the one who ' s the most concerned about this kind of thing . 
okay . 
and so she may have some ideas on on that particular issue . 
uhhuh . 
right but it ' s i think for the initial task just getting the word transcripts and speaker change is highest on my list . 
yeah . 
i i 
yeah . 
well that ' s what morgan mentioned to me too . 
so 
i mean if in terms of the the type . 
yeah . 
but you asked me about uh tools and things . 
and um there ' s this one . 
yeah . 
um this is called transcriber . 
um binary distribution for for uh linux and solaris and s g i and windows . 
uhhuh . 
uhhuh . 
transcriber is a tool for assisting creation of speech corpora . 
who ' s it from ? 
right . 
it allows to manually segment label and transcribe speech signals . 
and 
is it the french one ? 
uh let ' s see . 
where did i get this ? 
i got this from u penn . 
u penn . 
i think that i ' ve heard of this one . 
but 
it was the one that steve renals mentioned . 
it is possible . 
it could be french . 
i can ' t really tell . 
well i think that uh 
can i see that ? 
it sounds like you ' re at least a little familiar with these tools jane . 
so are do you feel comfortable just picking one ? 
um because 
i ' ve never used any of them . 
okay . 
and so um i think it would be something that we should work uh together with in terms of uh seeing how this 
sure . 
right . 
here ' s another thing i got . 
oh so this would this is probably what the l d c uses . 
i mean they do a lot of transcription at the l d c . 
okay . 
i could ask my contacts at the l d c what what it is they actually use . 
oh ! 
i mean i know i mean i ' ve got i ' ve got contacts up there . 
good idea . 
great idea . 
signed language is interesting . 
so 
excellent idea . 
so 
automatic annotation of prosody in verbmobil . 
can i see ? 
yeah . 
this is the other think that um this is part of eagles . 
but um 
but here again it ' s focusing on representation rather than the tools to do this . 
why do i feel like i ' m whispering ? 
well so how should we proceed on picking a tool ? 
jane do you want to pick a few ? 
and we ' ll download them and try them out . 
is that the right thing to do ? 
oh ! 
i think that would be lovely . 
now so are we talking about the stage of uh simply the word stage ? 
or are you talking about tools that would allow the time alignment as well ? 
no we ' re not going to do time alignment . 
no . 
well well we are going to do time alignment . 
okay . 
but we ' ll probably do it ourselves . 
right ? 
so we ' re not we ' re not concerned about getting getting about buying and or bringing in tools . 
right . 
we ' re very good at time alignments . 
we ' re not very good . 
okay . 
but we ' re proud of ourselves . 
right . 
okay . 
we ' re very proud of our time alignment . 
absolutely . 
yeah . 
okay . 
right and so but in terms of what the transcriber needs to do they ' re not going to have to do time alignment . 
good . 
oh good okay . 
except maybe for word speaker change . 
fine . 
but 
right . 
i mean it ' s not a bad 
oh look ! 
it uses snack ! 
um 
uses what ? 
it uses snack . 
that ' s a t c l audio thing that i had some involvement with . 
okay then we ' ll have to use it . 
oh cool . 
very cool . 
no no question . 
yeah . 
if i have to use it . 
i ' m sure i ' m sure it ' s a t c l based thing . 
i ' m sure it ' s just wonderful . 
cool . 
cool . 
yes t transcriber was developed with the scripting language t c l t k and c extensions . 
yeah . 
it relies on the snack sound extension which allows support for most common audio formats . 
cool . 
boy the recognition on what you just mumbled is going to be really horrible . 
yeah . 
it ' s the french one . 
oh cool . 
yeah . 
okay . 
there . 
there you go . 
i mean no i i 
i i love it when they 
but i ' ve never downloaded it . 
someone mentioned it to me . 
and that ' s probably why they mentioned it to me . 
because they thought i would be excited because it ' s t c l based . 
did you see this one ? 
did you see this one here ? 
oh deliverable d three point one . 
oh yeah . 
okay so so it ' s called transcriber you said ? 
okay . 
gacks . 
transcriber . 
whoa ! 
so it ' s very i mean it ' s interesting that one of the coordinators on that is mark liberman from the l d c . 
uhhuh . 
yeah . 
which means that i don ' t know what coordinator means in in terms of that . 
i mean 
well i think 
what what is what is what is this web page from ? 
well i apparently 
you know i roam around on on topics like this . 
sure . 
and i think i got this off the u penn . 
and it does in fact cite a french site . 
so um they have some sort of an arrangement . 
well i just wrote down the french site . 
i see . 
and i will check it and try to download it . 
right . 
and uh see what it looks like . 
good . 
you you can access it through um through the uh whatever 
i can ' t remember which aspect of of u penn i was following . 
right . 
but it must have been the l d c . 
i i i bet you anything . 
yeah . 
yeah they have a 
i vaguely recall that they have a pages uh tools page somewhere . 
uhhuh . 
okay . 
with like lists and lists and lists of uh various and assorted tools . 
okay . 
yes . 
well there ' s they have a special project as i ' m remembering . 
and um usually it doesn ' t deal with much that has to do with discourse . 
uhhuh . 
but they uh they show up in resources . 
so um we ' ll start with transcriber . 
and if it looks like that ' s not going to do what we need we ' ll move on to the mississippi state . 
and if it doesn ' t look like that ' s going to work we ' ll look at something else . 
i like that very much . 
and and i like the idea of also doing one that ' s tied in with these larger corpus projects . 
okay . 
so that you know the fact that yeah it ' s u penn and all that . 
uhhuh . 
huh . 
yeah . 
yeah . 
right . 
also i wanted to mention just in passing that uh another thing that we ' re going to want to start collecting is queries for the meetings . 
so if over the next couple of days you find yourself wondering what we talked about in the meeting write down the sort of query you ' d like to make . 
oh good idea . 
do you understand what i mean ? 
it ' s like the p d a thing . 
uhhuh . 
so imagine that we had meeting recorder all done and you had one . 
what might you do with it ? 
so 
if they occur to you . 
so like did the french system use tcl . 
right . 
that ' s a good one . 
actually what i would have come up with was what was the web address of that thing . 
send so if you could just email me them . 
which we didn ' t 
yeah except we didn ' t record . 
we didn ' t record that . 
so 
right . 
it ' s w w w dot e t c a dot f r . 
that ' s a fine question . 
if anyone wants to know . 
wow ! 
but you could get it through the u penn 
slash slash capital c t a slash 
slash lots of other stuff yeah . 
yeah . 
yeah . 
so this thing this uh deliverable d three point one of the mate project is a review of a lot of different tools . 
right . 
yes . 
yeah there you go . 
exactly . 
they ' re actually they seem to be more 
the the main focus of the tools is you ' ve already got a transcription but you ' re trying to tag the different turns transcriptions with uh discourse roles . 
and things like that . 
i see . 
but i mean a lot them are tools that will also do transcription as well . 
and i could be wrong . 
well my my impression 
i i i really thought of these resources in the context of you you asking about time aligning the 
you know what would you need to indicate . 
right . 
and were there tools for that . 
because um i suspect that would be uh pretty time intensive . 
i also wanted to say in terms of like you know if there are discussions about intonation contours i do have a certain amount of background in that . 
and i really would be i ' d like to be involved in that . 
right . 
no right i didn ' t mean to imply that that we that that we shouldn ' t discuss this now . 
yeah . 
but i ' m i ' m just saying that 
oh not right now . 
but i mean in the future . 
right . 
so at this meeting with liz i you know i mean 
i i do i ' d like to i like that stuff . 
sure sure . 
so when is she showing up ? 
well i mean they ' re coming in april . 
april . 
okay . 
right . 
but um 
you know we we may or may not talk before then on that . 
uhhuh . 
um i i think we won ' t probably talk until we have more data . 
i would think . 
right ? 
right since we have almost none right now let ' s 
yeah . 
we need to move forward from there . 
but uh yeah i guess it ' s okay . 
and then uh there ' s also just the general question of will it handle multiple channels or should we just 
dan and i spoke about this briefly . 
do we want to try to combine channels somehow to make the transcriber ' s job easier ? 
i was listening to some of it . 
and uh 
like if you just listen to the far p z m the person sitting at this end of the table you can hardly hear at all . 
on on the transcript . 
so there may be 
it may be worthwhile to at least try a little bit to combine the channels . 
right . 
i uh the stuff i did i combined pairs of these into stereo pairs . 
listened to them in stereo . 
huh . 
and i was very impressed by how well you could hear separate speakers . 
neat . 
but i haven ' t i haven ' t done very extensive tests . 
oh so that would be interesting as well to do that . 
oh ! 
yeah because you ' d get you get 
you get a certain amount of spatial information . 
right . 
it ' s not it ' s not consistent . 
but it ' s gives you some noise . 
wow ! 
well i bet if you used this one the two most separated p z m ' s 
well maybe maybe not . 
yeah yeah . 
you ' d get get wide coverage . 
well you would you would sound like you ' d have like in this big big head . 
big ears . 
right . 
right . 
but i mean but you would you would you know you ' d get good you ' d get good pick up at both ends of the table . 
right . 
so 
right . 
right . 
okay . 
do we have anything else to talk about with transcribes ? 
well what is what is the goal ? 
again ? 
we ' re going to end up with some i mean ultimately we ' re going to end up with transcriptions of these meetings . 
and we ' ll run a train a neural net . 
and create a recognizer . 
and do information retrieval . 
what ? 
and then then then we ' ll be done ? 
and 
huh ? 
well that ' s my interest . 
i mean other people have different interests . 
um 
so 
that ' s what i want . 
of course there are different kinds of 
so we ' re going to actually train a recognizer based on these uh far field mikes . 
right . 
because what we that ' s the problem we ' re trying to solve . 
right . 
okay . 
we need a lot of i mean 
well what the so the reason we ' re doing near field as well is if that doesn ' t work we want to we want some something that will work . 
well and also the near field will allow us to do the time alignment accurately . 
right . 
right . 
um 
so these are near near field ? 
uhhuh . 
yeah . 
there 
okay . 
yeah . 
close mikes . 
i mean i 
yeah i feel like that what we ' re actually going to do with these data is very unclear to me . 
why ? 
well because i don ' t think that ' s a that ' s not going to work . 
right ? 
okay we ' re going to get horrible performance on that . 
the question is is it will it work well enough to do information retrieval . 
uhhuh . 
so will the application the meeting recorder application work ? 
yeah . 
so is part of the research is um is fifty percent accuracy enough to do useful information retrieval . 
well part 
it might be . 
well we know the answer to that but unfortunately will we get fifty percent accuracy . 
that ' s right . 
well but you know we have to try . 
yeah . 
we we we could simply not do the project . 
but i think that ' s a bad solution . 
we also need to do this in terms of smartkom . 
i mean we ' re collecting this as to build general english acoustic models . 
that can be that they can say okay here ' s the vocabulary . 
and here ' s the you know here are the pronunciations and go to it . 
and are they specifically far field mikes ? 
yeah . 
yeah . 
oh i didn ' t know that . 
okay . 
you know if if we were to add in addition and i ' m offering this um to the word level also the uh so stressed words within utterances . 
yeah . 
i do think that that would help the information retrieval . 
well i mean that would be tremendously useful information . 
okay . 
assuming that we actually pursue it . 
but um we ' ve got a huge problem . 
because if we if we want train a recognizer we need tens of hours of labelled data . 
oh good point . 
and um it ' s just uh it ' s very frightening . 
yep . 
do you think 
so are are you familiar with this the the marsec project ? 
uhuh . 
um so i ' ll put this over here . 
because he seems to be the chairman . 
um 
who eric ? 
oh he ' s not ? 
no . 
he has he has the open piece of paper . 
well 
uhhuh . 
so open notebook . 
he 
yeah . 
well he can 
well dan ' s got an open notebook too . 
discuss discuss among yourselves . 
outrageous ! 
laying out his folders . 
i have one . 
but i ' ve carefully covered it so that it doesn ' t 
right . 
so this is a project that um has time aligned spoken data . 
which is um i see it as sort of in between um these fields . 
because a lot of the time when people do rich um intonational and and stress oriented transcription they don ' t have the digital record at the same time . 
and the don ' t have it time aligned . 
uhhuh . 
i don ' t know how large this is actually . 
but i just was sort of thinking that um i ' m i ' m 
and it ' s british . 
uhhuh . 
and you know 
well i think to some extent with things like the stress and the other prosodic things . 
so 
uhhuh . 
and tighter time alignments that we can do . 
i think we should probably do those . 
but only once we have a consumer of that data . 
uhhuh . 
okay . 
you know so right now we have a consumer of the word transcripts and the speaker change . 
uhhuh . 
me . 
i want those things to work . 
and so i would like to get that done as quickly as possible . 
uhhuh . 
and so if if liz or someone else wants to do some work on uh prosody and on stress and so on then we can go back to the data and generate the uh the transcripts that we need . 
i ' m 
uhhuh . 
okay . 
one thing about that is that is that um in the process of of doing the word level it really is just as easy to put the stress in at that point . 
even for an undergrad ? 
simply the stressed 
oh oh ! 
well see in my pilot stuff 
so in the half hour or so that i ' m doing i ' d just as soon put it in . 
because i do think that you ' d find that those would be words 
uhhuh . 
okay . 
i mean you know of course rosaria ' s pursuing this this area . 
uhhuh . 
but i really do think from everything that i ' ve run across that um you you should get gain in terms of the uh uh what you were saying . 
the information retrieval aspects from that . 
right . 
and i wouldn ' t be too surprised . 
i mean it ' s it ' s like uh 
i mean i don ' t know how how reliable lea is . 
but if this idea of islands of of um for whatever they are . 
islands of reliability or whatever it is . 
accuracy ? 
the stressed stressed words . 
certainty . 
islands of certainty . 
is that it ? 
okay . 
yeah . 
i mean 
are you certain ? 
lea ? 
no . 
the claim that uh words that get stressed are easier to recognize . 
i see . 
so i mean i i think it there ' s be sort of a benefit with very minimal input . 
yeah . 
because when you listen to a sentence you can tell if it ' s contrastive stress . 
you say oh that word was stressed . 
and why the heck not put it in at the word level ? 
so so i mean the part that i ' m doing i ' m really happy to supply that without any 
because it it ' s just it ' s there . 
uhhuh . 
okay if you think it won ' t slow you down at all . 
it ' s not it doesn ' t take any thinking . 
yeah . 
i ' m not going to talk about you know uh trying grade them in any kind of careful way . 
but just indicate if if there ' s a prominent word to indicate it . 
sure . 
yeah that ' s great . 
all caps . 
no well presumably there ' s a an annotation standard for prefix characters or something like that . 
whatever . 
whatever . 
people 
that ' s what they ' re using here . 
yeah people do different different ways . 
okay . 
a and so just as long as it ' s systematic in my view you can always filter it into some other format . 
yeah exactly . 
exactly . 
exactly . 
anything else ? 
well so um 
what is the plan ? 
we ' re going to 
i mean how many how many how many meetings ? 
i ' m going to go download transcriber . 
and jane and i will look at it . 
what about our recording schedule ? 
oh ! 
how many meetings are we going to record ? 
um 
which ones are we going to transcribe ? 
um 
do we 
well i think the answer is we need to record as many as we can . 
okay . 
right i don ' t see any reason not to try to record a meeting or two a week . 
absolutely . 
um 
i mean more if we can . 
and uh so i want to um i want to start by in the next couple weeks just doing the speech group . 
until we get to the point where we ' re fairly comfortable with the hardware and the software and everything works . 
yeah . 
and then i think i ' ll 
also uh jerry volunteered to have his group do a few . 
so i ' ll uh try to get those as well . 
how many of these do you have ? 
okay . 
these near mikes . 
five . 
we have five of the wireless . 
oh okay . 
okay . 
and then we were going to be getting a bunch of wired ones as well . 
i mean notice that 
well . 
your you you stood up and walked around . 
none of the rest of us have . 
and so we could have wired mikes and i wouldn ' t be a big deal . 
oh . 
oh i see . 
for bigger meetings . 
okay . 
i see . 
so 
interesting . 
very interesting . 
wow ! 
i ' m just really impressed by this . 
um yeah . 
it really makes you feel like you ' re doing real work . 
when you get all this hardware . 
well this is i mean compared to the way people normally do like discourse stuff . 
you know it ' s like you got your 
i mean they ' ve gotten away from reel to reel tapes . 
uhhuh . 
but 
and they do have dat recorders . 
i mean you do have that . 
uhhuh . 
but i mean this is just wonderful the uh added level of yeah compactness in the channels . 
if we can do anything with it yeah . 
yep . 
i do find myself whispering . 
i mean i suspect my normal 
why ? 
i don ' t know why . 
i had noticed that you were talking quietly . 
it ' s bizarre . 
and i was actually going to ask you . 
yeah this is not really my normal pattern . 
i was going to ask you to speak up . 
but i didn ' t want you to feel self conscious . 
i think the problem is that i ' m afraid that i ' m talking into someone ' s ear . 
oh . 
i really do . 
so it ' s so it ' s like 
and i realize now that you have volume uh control . 
but uh 
yeah . 
i don ' t feel like you ' re speaking unnaturally quietly . 
oh good . 
i mean i feel like it ' s all quite normal . 
okay . 
good . 
well i hear what you ' re saying . 
i ' m glad . 
yeah . 
good . 
eric ' s really got it easy because he ' s got the lapel mike which is so unobtrusive . 
that ' s great . 
i asked if somebody else wanted the lapel mike . 
somebody else can take it next time . 
i ' ve been trying to rotate it through . 
so dan will get it next time . 
are these more expensive or less expensive than this kind ? 
they ' re much more expensive . 
okay . 
i i which i don ' t understand . 
but there it is . 
it would be like the television effect or something maybe . 
right it ' s because they make people feel like television stars . 
do you feel like a television star ? 
so you can charge more for it . 
that ' s probably why i thought he was the chairman . 
yeah that ' s it . 
that must be it . 
that that makes sense . 
that ' s it . 
right ? 
because he ' s not heavily encumbered with this . 
yeah . 
right . 
you should have run it under your sweater though . 
right . 
yes . 
okay . 
well i don ' t mind . 
oh we should read some more numbers then . 
are we are we are we there ? 
oh good . 
yeah . 
are we at that point ? 
i think we ' re there . 
good . 
how much space do we have left ? 
good . 
more space than you can 
uh 
we ' ve got two hours of space now . 
he he he changed the downsampling . 
oh really . 
yeah . 
so 
so is keith showing up ? 
he ' s talking with george right now . 
uh is he going to get a rip uh rip himself away from from that ? 
what ? 
he ' ll probably come later . 
he ' s 
probably not is my guess . 
oh then it ' s just going to be the five of us ? 
well he he was very affirmative in his way of saying he will be here at four . 
yeah . 
but you know that was before he knew about that george lecture probably . 
right . 
this this is not it ' s not bad for the project if keith is talking to george . 
okay so my suggestion is we just 
forge ahead . 
forge ahead yeah . 
cool . 
are you in charge ? 
sure . 
um 
well i sort of had informal talks with most of you . 
so eva just reported she ' s really happy about the c . b . t . ' s being in the same order in the x . m . l . 
as in the um java declaration format . 
yeah . 
the 
so you don ' t have to do too much in the style sheet transversion . 
uh yeah . 
yeah so 
the uh java the embedded bayes wants to take input uh uh a bayes - net in in some java notation . 
and eva is using the xalan style sheet processor to convert the x . m . l . that ' s output by the java bayes for the into the uh e . bayes input . 
huh . 
actually maybe i could try like emailing the guy . 
and see if he has something already . 
sure . 
huh . 
that ' d be weird that he has both the java bayes and the embedded bayes in 
yeah . 
but that ' s some sort of conversion program ? 
yeah . 
and put them into different formats . 
oh 
yep he could do that too . 
i think you should demand things from him . 
he charges so much right ? 
yeah . 
no i think it ' s a good idea that you may as well ask sure . 
yeah . 
and um well pretty pretty much on on the top of my list i would have asked keith how the where is x . hand parse is standing . 
um but we ' ll skip that . 
uh there ' s good news from johno . 
the generation templates are done . 
so the trees for 
the x . m . l . trees for the for the for the synthesizer are written . 
so i just need to do the uh write a new set of tree combining rules . 
but i think those will be pretty similar to the old ones . 
so 
just going to be you know 
oh . 
you were going to send me a note about hiring 
yes . 
i didn ' t finish the sentence . 
but he understood it . 
i know what he ' s talking about . 
okay . 
but nancy doesn ' t . 
hiring somebody . 
the guy . 
okay so natural language generation produces not a just a surface string that is fed into a text to speech but a surface string with a syntax tree that ' s fed into a concept to speech . 
no . 
yeah . 
uhhuh . 
now and this concept to speech module has certain rules on how if you get the following syntactic structure how to map this onto prosodic rules . 
better . 
uhhuh . 
sure . 
uhhuh . 
and fey has foolheartedly agreed to rewrite uh the german uh syntax - to - prosody rules . 
i didn ' t know she spoke german . 
no she doesn ' t . 
oh okay . 
but she speaks english . 
oh rewrite the german ones into english . 
into english . 
okay got it . 
and um therefore the 
uh 
if it ' s okay that we give her a couple of more hours per week then she ' ll do that . 
okay got it . 
what language is that written 
is that that scheme thing that you showed me ? 
yeah . 
that ' s the lisp type scheme . 
she knows how to program in scheme . 
i hope . 
no i . 
my guess is i i asked for a commented version of that file . 
if we get that then it ' s doable . 
even without getting into it even though the scheme uh stuff is really well documented in the festival . 
well i guess if you ' re not used to functional programming scheme can be completely incomprehensible . 
because there ' s no 
like there ' s lots of unnamed functions . 
syntax . 
yeah . 
and 
you know . 
uhhuh . 
anyway it we ' ll sort this out . 
um 
but anyway send me the note . 
and then i ' ll check with uh morgan on the money . 
i i don ' t anticipate any problem . 
but we have to ask . 
oh so this was you know on the generation thing 
um 
if she ' s really going to do that then we should be able to get prosody as well . 
so it ' ll say it ' s nonsense with perfect intonation . 
are we going to can we change the voice of the of the thing ? 
because right now the voice sounds like a murderer . 
yep we we have to change the voice . 
which one ? 
the the little smarticus . 
smarticus sounds like a murderer . 
oh . 
that ' s good to know . 
i have your reservations . 
but i will not give them to you unless you come into my lair . 
it is uh we have the choice between the uh usual festival voices . 
which i already told the smartkom people we aren ' t going to use because they ' re really bad . 
festival ? 
it ' s the name of some program . 
the the synthesizer . 
oh oh got it okay . 
but um 
you know the usual party voices . 
yeah i know . 
that doesn ' t sound exactly right either . 
o . g . i . has uh crafted a couple of diphone type voices that are really nice . 
and we ' re going to use that . 
we can still um agree on a gender if we want . 
so we still have male or female . 
i think 
well let ' s just pick whatever sounds best . 
huh ? 
whatever sounds best . 
uh 
does o . g . i . stand for original german institute ? 
unfortunately probably male voices a bit more research on . 
so 
oregon . 
oregon graduate institute . 
try oregon . 
oh . 
oregon graduate 
uh . 
it turns out there ' s the longstanding links with these guys in the speech group . 
huh ! 
very long . 
huh ! 
huh . 
in fact there ' s this guy who ' s basically got a joint appointment . 
hynek hermansky . 
spends a fair amount of time here . 
anyway 
leave it . 
won ' t be a problem . 
okay . 
and it ' s probably also absolutely uninteresting for all of you to um learn that as of twenty minutes ago david and i per accident uh managed to get the whole smartkom system running on the uh icsi linux machines with the icsi n . t . machines . 
thereby increasing the number of running smartkom systems in this house from one on my laptop to three . 
huh that ' s good . 
how was this by accident ? 
yeah i know . 
that ' s the part i didn ' t understand . 
um i suggested to try something that was really kind of . 
even though against better knowledge shouldn ' t have worked . 
but it worked . 
huh ! 
intuition . 
maybe maybe maybe a bit for the a . i . intuition thing . 
will it work again ? 
yeah . 
or 
yeah . 
okay . 
and um we ' ll never found out why . 
it ' s just like why why the generation the presentation manager is now working . 
huh ! 
which 
this is something you you get used to as a programmer right ? 
you know and it ' s cool it works out that way . 
so the the people at saarbruecken and i decided not to touch it ever again . 
yeah that would work . 
okay . 
um i was going to ask you where something is . 
and what we know about that . 
where 
where the where is construction is . 
okay . 
where is x . ? 
what what thing is this ? 
okay . 
oh ! 
but by uh we can ask uh did you get to read all four hundred words . 
was it okay ? 
i did . 
was it 
i i i was looking at it . 
yeah . 
it doesn ' t follow logically . 
it doesn ' t the first paragraph doesn ' t seem to have any link to the second paragraph . 
and so on . 
huh . 
that 
yeah . 
yeah . 
you know yeah it 
each paragraph is good though . 
i 
yeah well it ' s fine . 
it was written by committee . 
anyway 
um 
but the meeting looks like it ' s it ' s going to be good . 
so 
yeah . 
i think it ' s uh 
yeah i didn ' t know about it until robert told me like 
yeah i i i ran across it in i don ' t even know where . 
you know some just some weird place . 
and uh yeah i ' m surprised i didn ' t know about it . 
yeah well yeah i was like why didn ' t dan tell me . 
since we know all the invited speakers . 
right or 
right . 
anyway . 
so but anyway 
yeah . 
so i i did see that . 
oh yeah before we get started on this 
so i also had a nice email correspondence with daphne kohler who said yes indeed she would love to work with us on the um you know using these structured belief nets and stuff . 
but starting in august . 
that she ' s also got a new student working on this and that we should get in touch with them again in august . 
and then we ' ll figure out a way for you uh you to get seriously connected with um their group . 
so 
that ' s uh looks pretty good . 
and um 
yeah i ' ll say it now . 
so um 
and it looks to me like we ' re now at a good point to do something start working on something really hard . 
we ' ve been so far working on things that are easy . 
oh ! 
uh which is mental spaces and uh and or 
huh ! 
it ' s hard . 
huh ? 
yeah it ' s hard . 
it ' s a hard puzzle . 
yeah . 
yeah . 
but the other part of it is the way they connect to these uh probabilistic relational models . 
so there ' s all the problems that the linguists know about about mental spaces and the cognitive linguists know about . 
but then there ' s this problem of the belief net people have only done a moderately good job of dealing with temporal belief nets . 
uh which they call dynamic 
they incorrectly call dynamic belief nets . 
huh . 
so there ' s a term dynamic belief net doesn ' t mean that . 
it means time slices . 
and srini used those and people use them . 
uh but 
one of the things i would like to do over the next uh month it may take more is to understand to what extent we can not only figure out the constructions for them for multiple worlds 
and 
uh sort of what the formalism will look like and where the slots and fillers will be but also what that would translate into in terms of belief net and the inferences . 
so the story is that if you have these probabilistic relational models they ' re set up in principle so that you can make new instances . 
and instances connect to each other and all that sort of stuff . 
so it should be feasible to set them up in such a way that if you ' ve got the past tense and the present tense and each of those is a separate uh belief structure that they do their inferences with just the couplings that are appropriate . 
but that ' s that ' s as far as i can tell it ' s it ' s putting together two real hard problems . 
one is the linguistic part of what are the couplings . 
and and when you have a certain uh construction that implies certain couplings and other couplings . 
you know between let ' s say between the past and the present . 
or any other one of these things . 
and then we have this inference problem of exactly technically how does the belief net work . 
if it ' s got um let ' s say one in in you know different tenses . 
or my beliefs and your beliefs . 
or any of these other ones of of multiple models . 
so um 
you know in the long run we need to solve both of those . 
and my suggestion is that we start digging into them both uh in a way that you know 
hopefully turns out to be consistent . 
so that the 
um 
and sometimes it ' s actually easier to solve two hard problems than one . 
yeah . 
because they constrain each other . 
i mean if you ' ve got huge huge range of possible choices 
um 
we ' ll see . 
but anyway so that ' s um 
oh yeah like uh i solved the the problem of um we were talking about how do you 
various issues of how come a plural noun gets to quote count as a noun phrase . 
you know occur as an argument of a higher construction but a bare singular stem doesn ' t get to act that way . 
right . 
um 
and it would take a really long time to explain it now . 
but i ' m about to write it up this evening . 
i solved that at the same time as how do we keep adjectives from floating to the left of determiners and how do we keep all of that from floating outside the noun phrase to get something like i the kicked dog . 
um 
that ' s great . 
did it did it at once . 
so maybe maybe it ' ll be a similar thing . 
yeah . 
cool . 
no i know i i think that is going to be sort of the key to this to the big project of the summer of of getting the constructions right . 
is that people do manage to do this . 
so there probably are some uh relatively clean rules . 
they ' re just not context free trees . 
right . 
and if we if the formalism is is good then we should be able to have you know sort of moderate scale thing . 
and that by the way is is keith what i encouraged george to be talking with you about . 
not the formalism yet . 
uhhuh . 
but the phenomena . 
yeah . 
the 
and 
oh another thing 
um 
there was this uh thing that nancy agreed to in a in a weak moment this morning that . 
huh . 
i was really strong . 
huh . 
huh . 
uh sorry in a in a friendly moment . 
same thing . 
anyway uh that we were that we ' re going to try to get a uh first cut at the revised formalism by the end of next week . 
okay . 
all right . 
probably skipping the mental spaces part . 
seems 
right i do . 
uh just trying to write up essentially what what you guys have worked out so that everybody has something to look at . 
we ' ve talked about it but only the innermost inner group currently uh 
uhhuh . 
knows . 
knows uh 
okay . 
yeah and and not even all of them really do . 
yeah . 
but like 
right . 
there ' s the group as a whole knows . 
but no individual member 
well that that yeah there ' s one of the advantages of a document right ? 
yeah . 
is is that it actually transfers from head to head . 
right . 
so anyway . 
okay . 
so um 
uh communication . 
huh ? 
communication . 
communication documentation and stuff . 
huh . 
anyway so uh with a little luck 
uh let ' s let ' s have that as a goal anyway . 
and 
so uh what was the date there ? 
monday ? 
or 
no no no . 
it ' s a friday . 
no uh we ' re talking about a week end of next week . 
but uh but but the two of us will probably talk to you at well before 
end of next week . 
i thought you said beginning of 
i mean 
yeah . 
anyway let ' s talk separately about how 
yeah i have a busy weekend . 
but after that yeah . 
gung ho . 
okay yeah so so sometime next week . 
great . 
now if it turns out that that effort leads us into some big hole that ' s fine . 
uhhuh . 
okay . 
you know if you say we ' re we ' re dump dump dump . 
there ' s a really hard problem . 
we haven ' t solved yet . 
that that ' s just fine . 
okay . 
uhhuh . 
but at at least sort of try and work out what the state of the art is right now . 
right if to the extent that we have it let ' s write it . 
okay . 
and to the extent we don ' t let ' s find out what we need to do . 
okay . 
so uh 
can we is it worth thinking of an example out of our tourism thing domain that involves a a a decent mental space shift or setting up ? 
i think it is . 
but uh but i interrupted before keith got to tell us what happened with where is the powder tower or whatever . 
right . 
well uh what was supposed to happen ? 
i ' ve sort of been actually caught up in some other ones . 
so um you know i don ' t have a write up of or i haven ' t elaborated on the ideas that we were already talking about . 
huh yeah i think i think we already came to the conclusion that we have two alternative paths that we two alternative ways of representing it . 
which were 
one is sort of a has a 
um 
it ' s gone . 
um 
the question of whether the polysemy is sort of like in the construction or pragmatic . 
one of them was 
right . 
or comes 
right . 
is resolved later . 
yeah . 
i think it has to be the the second case . 
yeah . 
um so did you is it clear what we ' re talking about here ? 
i agree . 
uh 
the question is whether the construction is semantic or like ambiguous between asking for location and asking for path . 
it ' s 
so you might be yeah and asking for directions . 
um 
should we have a a a 
or or whether the construction semantically uh is clearly only asking for location . 
uh 
but pragmatically that ' s construed as meaning tell me how to get there . 
uhhuh . 
so assume these are two uh nodes we can observe in the bayes - net . 
yep . 
yeah . 
right . 
so these are either true or false . 
and it ' s also just true or false . 
if we encounter a phrase such as where is x . should that set this to true and this to true ? 
and the bayes - net figures out which under the situation in general is more likely . 
um or should it just activate this have this be false ? 
and the bayes - net figures out whether this actually now means 
uh that ' s a 
okay so that ' s a that ' s a separate issue . 
slightly different . 
okay . 
so i i i i agree with you that um it ' s a disaster to try to make separate constructions for every uh pragmatic reading . 
uhhuh . 
although there are some that will need to be there . 
good . 
uhhuh . 
right . 
right . 
i mean there ' s some that 
or have every construction list all the possible pragmatic implications of the same one . 
you can ' t do that either . 
yeah . 
right . 
yeah . 
but you know um almost certainly can you pass the salt is a construction worth noting that there is this this this this uh 
yeah . 
request . 
uhhuh yeah . 
very yeah . 
so right this one is maybe in the gray area . 
is it is it like that or is it just sort of obvious from world knowledge that no one you wouldn ' t want to know the location without wanting to know how to get there or whatever ? 
huh . 
yeah . 
one 
or in some cases it ' s it ' s quite definitely . 
yeah . 
so that you just know want to know where it is . 
yeah . 
well the question is basically is this conventional or conversational implicature . 
exactly yeah . 
might be yeah . 
and i guess see the more important thing at this stage is that we should be able to know how we would handle it in 
in the short run it ' s more important to know how we would treat technically what we would do if we decided a . and what we would do if we decided b . than it is to decide a . or b . right now . 
right . 
okay right . 
right . 
which one it is . 
which of that is yeah okay . 
huh . 
because there will be other examples that are one way or the other right . 
we know for sure that we have to be able to do both . 
yeah . 
so i guess in the short run let ' s let ' s be real clear on what the two alternatives would be . 
okay . 
and then we had another idea floating around um which we wanted to uh get your input on . 
and that concerns the 
but the nice thing is we would have a person that would like to work on it . 
and that ' s irina gurevich from e . m . l . who is going to be visiting us uh the week before uh august . 
and a little bit into august . 
and she would like to apply the ontology that is um being crafted at e . m . l . 
that ' s not the one i sent you . 
the one i sent you was from g . m . d . out of a european crumpet . 
it was terrible . 
agreed . 
um and one of the one of the those ideas was 
so 
back to the old johno observation that if if you have a dialogue history and it said the word admission fee was uh mentioned um it ' s more likely that the person actually wants to enter than just take a picture of it . 
from the outside . 
now what could imagine to you know have a list for each construction of things that one should look up in the discourse history yeah . 
that ' s the really stupid way . 
then there is the really clever way that was suggested by keith . 
and then there is the uh middle way that i ' m suggesting . 
and that is you you get x . which is whatever . 
the castle . 
the ontology will tell us that castles have opening hours . 
that they have admission fees . 
they have whatever . 
and then this is we go via a thesaurus . 
and look up certain linguistic surface structures that are related to these concepts . 
and feed those through the dialogue history . 
and check dynamically 
for each entity we look it up check whether any of these were mentioned and then activate the corresponding nodes on the discourse side . 
but keith suggested that a a much cleaner way would be is you know to keep track of the discourse in such a way that you if you know that something like that has been mentioned before this just continues to add up 
you know in in a 
so if someone mentions admission fees that activates an enter schema which sticks around for a little while in your in the representation of what ' s being talked about . 
and then when someone asks where is x . you ' ve already got the the enter schema activated . 
uhhuh . 
kind of a priming 
and you ' re able to to conclude on it . 
yeah . 
priming a spreading activation . 
right . 
yeah . 
yeah so that ' s certainly more realistic . 
i i mean psychologically . 
right . 
now technically 
yeah . 
um 
well uh is it doesn ' t it seem like if you just managed the dialogue history with a a thread that you know kept track of of the activity of 
i mean because it would the the thread would know what nodes like needed to be activated . 
so it could just keep track of how long it ' s been since something ' s been mentioned and automatically load it in . 
yeah . 
you could do that . 
um 
but here ' s here ' s a way 
in in the bayes - net you could you could think about it this way that if um at the time admissions fee was mentioned you could increase the probability that someone wanted to enter . 
turn prior on . 
yeah that ' s what i i wasn ' t i was i wasn ' t thinking in terms of enter schemas . 
i was just 
fair enough okay . 
but but in terms of the the current implementation 
right . 
so that 
um 
it would already be higher in the context . 
that the the the conditional probability that someone 
so at the time you mentioned it 
this is this is essentially the bayes - net equivalent of the spreading activation . 
uhhuh . 
yeah . 
it ' s in some ways it ' s not as good . 
but it ' s the implementation we got . 
yeah sure . 
we don ' t have a connectionist implementation . 
no i mean 
now now my guess is that it ' s not a question of time but it is a question of whether another intervening object has been mentioned . 
yeah relevance . 
yeah . 
i mean we could look at 
yeah . 
this is 
of course the other thing we we do is is we have this data coming . 
yeah . 
which probably will blow all our theories . 
but but skipping that 
yeah right . 
so so but my guess is what what ' ll probably will happen here ' s a here ' s a proposed design is that there ' re certain constructions which uh for our purposes do change the probabilities of eva decisions and various other kinds . 
and 
that the uh standard way that that these contexts work is sort of stack like or whatever . 
but that ' s sort of the most recent thing . 
and so it could be that when another uh tourist entity gets mentioned you 
renew . 
essentially you know re i essentially re - initialize the state . 
huh . 
yeah . 
uhhuh . 
and of course if we had a fancier one with multiple worlds you could have uh you could keep track of what someone was uh saying about this and that . 
you know i want to go in the morning . 
yeah . 
i want to 
here ' s my plan for today . 
here ' s my plan for tomorrow . 
yeah or yeah in the morning morning i ' m planning to go shopping . 
hypothetically . 
in the afternoon to the powder tower . 
yeah . 
uh so i ' m talking about shopping . 
and then you say uh you know well um what ' s it cost or something . 
uhhuh . 
or 
anyway . 
so one could well imagine 
but not yet . 
yeah . 
but i do think that the it ' ll turn out that it ' s going to be depend pretty much on whether there ' s been an override . 
yeah i mean if if you ask how much does a train ride and and cinema around the vineyards cost and then somebody tells you it ' s sixty dollars and then you say okay how much is uh i would like to visit the whatever something completely different then i go to you know point reyes . 
yeah . 
it it ' s not more likely that you want to enter anything . 
but it ' s as a matter of fact a complete rejection of entering by doing that . 
right . 
right . 
right . 
yeah . 
so when you have admission fee and it changes something it ' s only for that particular it ' s relational right ? 
it ' s only for that particular object . 
yeah i 
yeah . 
well and and and the simple idea is that it ' s it ' s only for for the current uh tourist entity of interest . 
yeah . 
yeah . 
right . 
yeah but that ' s 
i mean this this function 
so has the current object been mentioned in in with a question about concerning its 
no no it ' s it it goes the other it goes in the other direction . 
is 
when when the this is mentioned the uh probability of of let ' s say entering changes . 
of that object . 
changes . 
for but 
right . 
you could just uh just basically it it observes an uh it sets the a node for entered or true or something . 
yeah . 
yeah . 
now uh but i think robert ' s right that to determine that okay you may well want to go through a thesaurus . 
discourse enter . 
and and 
so if the issue is if so now this construction has been matched and you say okay does this actually have any implications for our decisions then there ' s another piece of code that presumably does that computation . 
so sort of forward chaining in a way rather than backward . 
yeah yeah . 
okay . 
but but what ' s robert ' s saying is is 
and i think he ' s right is you don ' t want to try to build into the construction itself all the synonyms and all you know all the 
uh 
maybe . 
i ' ll have to think about that . 
huh . 
i don ' t know . 
i mean it i can i can think of arguments in either direction on that . 
but somehow you want to do it . 
uhhuh . 
well it ' s just another sort of construction side is how to get at the possible inferences we can draw from the discourse history . 
or changing of the probabilities and or . 
guess it ' s like i the other thing is whether you have a user model that has you know whatever a current plan whatever plans that had been discussed . 
and 
i don ' t know . 
i mean 
what uh what ' s the argument for putting it in the construction ? 
is it just that the synonym selection is better or 
oh well the the the argument is that you ' re going to have the 
if you ' ve recognized the word 
you ' ve recognized the word which means you have a lexical construction for it . 
so you could just as well tag the lexical construction with the fact that it ' s a uh you know thirty percent increase in probability of entering . 
you so you could you could you could invert invert the whole thing so you you tag that information on to the lexicon . 
huh . 
oh i see . 
since you had to recognize it anyway . 
that that ' s the argument in the other direction . 
at at 
yeah and this is 
even though uh the lexical construction itself out out of context uh won ' t do it . 
i mean you have to keep track whether the person says . 
but but i ' m not interested in the opening times . 
yeah . 
is sort of more a v . type . 
yeah there ' s yeah there ' s that as well . 
yep . 
huh . 
so 
but we ' ll 
uh we have time to 
this is a just a sidetrack . 
but uh 
i think it ' s also something that people have not done before is um sort of abuse an ontology for these kinds of uh inferences on 
whether anything relevant to the current something has been uh has crept up in the dialogue history already or not . 
and um 
i have the uh if we wanted to have that function in the dialogue dialogue module of smartkom i have the written consent of jan to put it in there . 
good . 
okay well this this is highly relevant to someone ' s thesis . 
yes . 
um that ' s uh i ' m i ' m keeping on good terms with jan . 
you ' ve noticed that . 
yeah . 
okay . 
so the point is it ' s very likely that robert ' s thesis is going to be along these lines . 
and the local rules are if it ' s your thesis you get to decide how it ' s done . 
oh 
okay so if you know if this is seriously if this becomes part of your thesis you can say hey we ' re going to do it this way that ' s the way it ' s done . 
huh . 
yay it ' s not me ! 
it ' s always me when it ' s someone ' s thesis . 
no no no ! 
no no we ' ve got a lot we ' ve got a lot of theses going . 
there ' s a few of us around now . 
yay ! 
i know it is . 
yeah . 
right . 
well let ' s let ' s talk after friday the twenty ninth . 
then we ' ll see how 
right so he ' s got a he ' s got a meeting in germany with his thesis advisor . 
yeah he said he ' s going to finish his thesis by then . 
oh yeah . 
yeah . 
i should try to finish it by then yeah . 
oh right . 
so 
um 
yeah so i think in fact that ' s the other thing . 
uh this is this is speaking of hard problems this is a very good time um to start trying to make explicit where construal comes in . 
and you know where where the construction per se ends and where construal comes in . 
uhhuh . 
uhhuh . 
because this is clearly part of 
yeah we ' ve we ' ve done quite a bit of that . 
huh ? 
yeah . 
we ' ve been doing quite a bit of that . 
yeah . 
well i said but that ' s part of what the 
we have many jobs for you robert . 
yeah well he ' s going to need this . 
the conclusion . 
yeah it seems to always land in your category . 
yeah . 
right so right so thing that ' s part of why we want the formalism . 
you ' re lucky . 
is is because it is going to have implicit in it 
yeah . 
was i in the room ? 
no you weren ' t there on purpose . 
like 
made it much easier to make these decisions . 
obviously . 
uh 
yeah . 
right well i that ' s tentative . 
they aren ' t decisions . 
yeah right right right . 
they ' re they ' re just proposals . 
no they ' re decisions . 
yes excuse me . 
okay . 
yeah that that ' s the point is is 
yeah . 
constraints . 
let ' s call them constraints around which one has to 
yeah . 
yeah anyway but so that ' s that ' s 
actually 
yeah there ' s a problem with that word too though . 
yeah but it the decisions i made had to do with my thesis . 
yeah . 
so consequently don ' t i get to decide then that it ' s robert ' s job ? 
no . 
uh 
anyhow . 
well i ' ll just pick a piece of the problem and then just push the hard stuff into the center and say it ' s robert ' s . 
i ' ve always been completely in favor of consensus decisions . 
like 
so we ' ll we ' ll find a way . 
right . 
i can 
well we we we will . 
but um 
i haven ' t okay . 
not 
it it might even be interesting then to say that i should be forced to um sort of pull some of the ideas that have been floating in my head out of the uh out of the top hat . 
yes . 
and um 
always good . 
right . 
that metaphor is not going anywhere you know . 
yeah . 
no absolutely . 
so uh you had you know you you had done one draft . 
yes and um it ' s none of that is basically still around . 
and another draft 
i didn ' t get 
but it ' s 
okay . 
that ' s normal . 
oh i guess it ' s good i didn ' t read it . 
i this is i ' m shocked . 
this is the first time i ' ve seen a thesis proposal change . 
right anyway uh so 
really ? 
but yeah a second that would be great . 
so uh a i mean you ' re going to need it anyway . 
huh . 
yeah and i would like to discuss it . 
and 
and you know get you guys ' s input . 
right . 
and make it sort of bomb proof . 
yep . 
bomb proof . 
good . 
oh oh okay . 
bulletproof . 
that ' s the word i was looking for . 
both proof . 
either way . 
both . 
right . 
uh 
good luck really . 
so that so this i mean so this is the point is we we ' re going to have to cycle through this . 
but the draft of the proposal on the constructions is is going to tell us a lot about what we think needs to be done by construal . 
yeah . 
and um we ought to be doing it . 
okay . 
yeah we need we need some then we need to make some dates . 
um 
meeting regular meeting time for the summer . 
we really haven ' t found one . 
we did thursdays one for a while . 
i just talked to ami . 
it ' s a coincidence that he can ' t do couldn ' t do it today here . 
usually he can . 
usually he has no real constraints . 
so 
and the n . t . l . meeting moved to wednesday . 
because of of uh 
yeah it was just an exception . 
yeah you weren ' t here . 
but but but uh and so if that ' s okay with you . 
you would 
it ' s is it staying basically at the wednesday noon ? 
yeah it was 
okay it was off this week . 
yeah i always thought it was staying . 
yeah . 
right . 
yeah i thought it was just this week that we were changing it . 
huh yeah . 
okay . 
and um how do we feel about doing it wednesdays ? 
because it seems to me that this is sort of a time where when we have things to discuss with other people there . 
they seem to be tons of people around . 
the only disadvantage is that it may interfere with other . 
or 
subgroup meetings . 
you know other other 
no you uh people in this group connecting with with . 
those people who happen to be around . 
those people who who might not be around so much . 
uh i don ' t care . 
uh you know i have no fixed 
to tell you the truth i ' d i ' d i ' d would like to avoid more than one i . c . s . i . meeting per day if possible . 
okay . 
but i mean i don ' t know . 
whatever . 
no that ' s fine . 
i mean that 
the i ' d like to have them all in one day . 
so package them up and then 
yeah i can understand that . 
well 
people people differ in their tastes in this matter . 
yeah . 
i i ' m neutral . 
yeah . 
yeah i ' m always here anyway . 
it ' s okay that 
so 
yeah that ' s me too . 
it doesn ' t matter . 
i ' m basically i ' m here . 
so 
well if one sort of thing is this room is taken at after three thirty pretty much every day . 
by the data collection . 
oh . 
so we have subjects anyway except for this week we have subjects in here . 
that ' s why it was one . 
oh . 
okay . 
so we just knew 
so did you just say that ami can ' t make one o ' clock ? 
no he can . 
oh okay . 
oh . 
so let ' s say thursday one . 
but for next week this is a bit late . 
so i would suggest that we need to to talk 
oh oh 
okay . 
okay about the the 
could we do thursday at one thirty ? 
would that that be horrible ? 
no . 
yes . 
oh really ? 
because uh this room is again taken at two thirty by morgan . 
oh okay okay you didn ' t tell me that . 
okay that ' s fine . 
and the meeting recorder meeting meeting meeting recording on meeting meetings . 
okay okay okay okay yeah . 
so 
interesting . 
uh yeah . 
so you ' re proposing that we meet tuesday . 
how about that ? 
i i could 
next week . 
well we ' re meeting tuesday . 
i mean we usually meet tuesday or like linguists um at two . 
would it 
that ' s right . 
so 
and the 
do you want to meet again here 
i mean 
is the speech - gen meeting still at on tuesdays ? 
well actually we did scrap our monday time just because bhaskara couldn ' t come monday . 
hhh maybe i do need a palm pilot . 
so there ' s nothing ' s impeding monday anymore either . 
that doesn ' t apply to a 
get a fresh start . 
although i thought you wanted to go camping on monday uh take off mondays a lot so you could go camping . 
yeah that ' s another thing yeah . 
but um i mean there are also usually then holidays anyways . 
i mean like sometimes it works out that way . 
usually ? 
so huh . 
well i mean the linguists ' meeting happens to be at two . 
but i think that ' s i mean 
that should be relatively flexible 
pretty flexible i think . 
yeah there ' s just sort of the two to four of us . 
so 
the multiple meetings . 
right ? 
yeah . 
yeah . 
so 
right . 
and you know of course nancy and i are just sort of always talking anyway and sometimes we do it in that room . 
yeah . 
so you know i mean 
okay so forget about the the camping thing . 
so let ' s uh any other problems 
but i suggested monday . 
if that ' s a problem for me then i shouldn ' t suggest it . 
ha ha ha . 
okay . 
so 
um all of the proposed times sound fine with me . 
same here . 
monday ? 
okay i mean what i think robert ' s saying is that 
earlier in the week . 
earlier we 
at least for next week there ' s a lot of stuff we want to get done . 
uhhuh yeah . 
so why don ' t we plan to meet monday ? 
huh . 
and we ' ll see if we want to meet any more than that . 
okay . 
okay . 
what time ? 
at one two three ? 
one two three ? 
three ' s too late . 
two thirty ? 
oh i yeah i actually two is the earliest i can meet on monday . 
okay two . 
here i ' m blissfully agreeing to things and realizing that i actually do have some stuff scheduled on monday . 
sure sounds great . 
uh so that ' s the eighteenth . 
you guys will still remind me right ? 
no way . 
you ' ll come and take all the the the good headphones first and then remind me . 
why do you 
yeah exactly . 
and 
sorry two p . m . 
why do i have this unless i ' m going to write ? 
do i get to see uh your formalism before that ? 
fine . 
yes . 
uh would you like to ? 
uhhuh . 
i i would like i would sort of get a get a notion of what what you guys have in store for me . 
okay i was actually going to work on it for tomorrow like this this weekend . 
yeah . 
well you know maybe maybe we can put this is part of what we can do monday if we want . 
yeah 
okay . 
all right . 
okay . 
i mean i i i 
is some some version . 
yeah so there was like you know in my head the goal to have like an intermediate version like everything i know . 
uhhuh . 
and then i would talk to you and figure out everything you know that you know see if they ' re consistent . 
yeah . 
okay . 
why don ' t maybe you and i should meet sort of more or less first thing monday morning and then we can work on this . 
yes yeah . 
that ' s fine with me . 
okay . 
so 
i might i might um 
you said you ' re busy over until the weekend right ? 
yeah sort of through the weekend . 
because kate has a photography show . 
that ' s fine so we might continue our email thing . 
yeah . 
and that might be fine too . 
so maybe i ' ll send you some . 
um if you have time after this i ' ll show you the noun phrase thing . 
okay that would be cool . 
so 
okay and we ' ll you want to 
so the idea is on monday at two we ' ll we ' ll see an intermediate version of the formalism for the constructions . 
yeah . 
so that ' s okay for you 
and do an online merging with my construal ideas . 
sure sure . 
okay . 
all right . 
so it won ' t be like a semi formal presentation of my proposal . 
that ' s okay . 
it ' ll be more like towards finalizing that proposal . 
okay that ' s fine . 
okay . 
because then you ' ll find out more of what we ' re making you do . 
yep and then 
yeah . 
huh huh . 
yikes . 
oy deadlines . 
we ' ll make a presentation of your of your proposal . 
perfect can you also write it up ? 
it ' s like this is what we ' re doing . 
and the complement is robert . 
i ' ll i ' ll send you 
i ' ll i ' ll send you a style file right ? 
okay . 
you just 
i already sent you my my bib file . 
so 
okay . 
and um 
sounds good . 
someday we also have to we should probably talk about the other side of the where is x . construction . 
which is the issue of um how do you simulate questions ? 
what does the simspec look like for a question ? 
yeah . 
uhhuh . 
because it ' s a little different . 
yeah . 
yeah now we 
we had to we had an idea for this which seemed like it would probably work . 
great okay . 
yeah simspec may need we may need to rename that . 
i yeah i 
yeah . 
okay so let ' s think of a name for for whatever the this intermediate structure is . 
oh we talked about semspec for semantic specification . 
huh . 
and that seems 
um 
it ' s more general . 
you know so it ' s a minimal change . 
only have to change one vowel . 
that ' s great . 
yeah just 
all the old like graphs . 
right . 
just change the just like mark out the 
cool . 
right a little 
you know that ' s what text substitution uh macros are for . 
yeah it ' s good for you . 
yeah . 
anyway uh so let ' s let ' s for the moment call it that until we think of something better . 
okay . 
and yeah we absolutely need to find 
part of what was missing were markings of all sorts that weren ' t in there . 
including the questions . 
we didn ' t we never did figure out how we were going to do emphasis in in uh the semspec . 
uhhuh . 
yeah . 
yeah we ' ve talked a little bit about that too . 
which 
uh uh it ' s hard for me to figure out with sort of our general linguistic issues how they map onto this particular one . 
but 
yeah . 
okay yeah understood . 
but that ' s part of the formalism . 
is got to be uh how things like that get marked . 
uhhuh . 
do you have data like the the you have preliminary data ? 
because i know you know we ' ve been using this one easy sentence . 
and i ' m sure you guys have uh maybe you are the one who ' ve been looking at the rest of it . 
um 
it ' d it ' d be useful for me if we want to have it a little bit more data oriented . 
to tell you the truth what i ' ve been looking at has not been the data so far . 
yeah . 
uhhuh uhhuh . 
and i have not gotten them out of the way yet . 
uhhuh . 
surprise . 
so um 
yeah . 
so i have not really approached a lot of the data . 
but i mean obviously like these the the question one . 
since we have this idea about the indefinite pronoun thing and all that you know i can try and um run with that . 
you know try and do some of the sentence constructions now . 
okay do you want to run the indefinite pronoun idea past jerry ? 
it would make sense . 
okay . 
oh yeah the basic idea is that 
um uh you know 
uh let ' s see if i can formulate this . 
so mary fixed the car with a wrench . 
yeah . 
so you perform the mental sum . 
and then you know who fixed the car with a wrench . 
you basically are told to to do this . 
in the in analogously to the way you would do someone fixed the car with a wrench . 
and then you hand it back to your hippocampus . 
and find out what that you know . 
means . 
means . 
and then come up with that so who that someone was . 
the w . h . question has this as sort of extra thing which says and when you ' re done tell me who fills that slot or you know . 
uhhuh . 
so um 
and you know this is sort of a nice way to do it . 
the idea of sort of saying that you treat from the simulation point of view or whatever you treat uh w . h . constructions similarly to uh indefinite pronouns . 
like someone fixed the car . 
because lots of languages um have w . h . questions with an indefinite pronoun in situ or whatever . 
use actually the same one . 
and you just get intonation to tell you that it ' s a question . 
all right which is 
so it makes sense . 
um 
skolemization . 
huh ? 
in in logic it ' s it ' s it ' s huh . 
huh . 
right let ' s put a skolem skolem constant in . 
yeah . 
what ? 
yeah . 
sure . 
yeah right . 
okay . 
that ' s not that ' s not saying it ' s bad . 
it ' s just that 
right right no of course . 
huh . 
that that the logicians have have uh 
that ' s right . 
come up with this . 
it makes sense from that point of view too which is actually better . 
so yeah um 
anyway but just that kind of thing . 
and we ' ll figure out exactly how to write that up and so on . 
but 
good . 
uh no all the focus stuff . 
we sort of just dropped that . 
because it was too weird . 
and we didn ' t even know like what we were talking about exactly . 
what the object of study was . 
um huh . 
so 
yeah well if if i mean part of of what the exercise is by the end of next week is to say what are the things that we just don ' t have answers for yet . 
yeah . 
that ' s fine . 
yep . 
i mean 
uhhuh . 
well if you if you do want to discuss focus background and then get me into that . 
because i mean i i scientifically worked on that for for almost two years . 
yeah . 
okay then certainly we will . 
yeah you should definitely um be on on that 
good . 
maybe maybe by after monday we ' ll you can see what things we are and aren ' t 
yeah we should figure out what our questions are for example to ask you . 
yeah yeah . 
so 
okay . 
okay . 
hans . 
has i haven ' t seen hans boas . 
he ' s been around . 
yeah . 
okay so has he been been involved with this ? 
just maybe not today . 
or 
uh with us ? 
yeah . 
yeah . 
yeah . 
i would say that that those discussions have been primarily um keith and keith and me . 
but um 
like in the meeting i mean he sort of i like the last meeting we had i think we were all very much part of it . 
yeah . 
but um 
sometimes hans has been sort of coming in there as sort of like a devil ' s advocate type role or something . 
but different 
yeah . 
like this make you know i ' m going to pretend i ' m a linguist who has nothing to do with this . 
this makes no sense . 
and he ' ll just go off on parts of it which definitely need fixing . 
right . 
but aren ' t where we ' re at right now . 
like like what you call certain things . 
so it ' s 
which we decided long ago we don ' t care that much right now . 
yeah . 
right . 
okay . 
but in a sense it ' s good to know that he of all people 
you know like maybe a lot of people would have much stronger reactions . 
so you know he ' s like a relatively friendly linguist . 
yeah . 
and yet a word like constraint causes a lot of problems . 
yeah . 
and so right so 
okay this is consistent with um the role i had suggested that he he play . 
uh . 
uhhuh . 
okay which was that one of the things i would like to see happen is a paper that was tentatively called towards a formal cognitive semantics . 
which was addressed to these linguists uh who haven ' t been following this stuff at all . 
yeah . 
so it could be that he ' s actually at some level thinking about how am i going to communicate this story . 
yeah . 
yeah . 
so internally we should just do whatever works . 
yeah . 
because it ' s hard enough . 
yeah . 
but if he if he turns is is really going to turn around and help to write this version that does connect with as many as possible of the other linguists in the world um then then it becomes important to use terminology that doesn ' t make it hard . 
uhhuh . 
uhhuh . 
yeah . 
yeah . 
uhhuh sure . 
i mean it ' s going to be plenty hard for for people to understand it as it is . 
but you don ' t want to make it worse . 
yeah . 
yeah . 
so 
no right i mean that role is is uh indispensable . 
but that ' s not where sort of our heads were at in these meetings . 
right . 
yeah yeah no that ' s fine . 
it was a little strange . 
i just wanted to 
i have to catch up with him and i wanted to get a feeling for that okay . 
yeah . 
uhhuh . 
so i don ' t know what his take will be on these meetings exactly you know . 
okay good . 
because sometimes he sort of sounds like we ' re talking a bunch of goobledy - gook from his point of view . 
i think it ' s good when we ' re 
when we ' re into data and looking at the some specific linguistic phenomenon in in english or in german in particular whatever that ' s great . 
yeah . 
uhhuh . 
and ben and and hans are if if anything more you know they have more to say than let ' s say i would about some of these things . 
right . 
but when it ' s like well how do we capture these things you know i think it ' s definitely been keith and i who have you know who have worried more about the 
well that ' s good that ' s i think that should be the the core group . 
uhhuh . 
which is fine . 
yeah . 
uhhuh . 
and um 
that ' s you know i think very close to the maximum number of people working together that can get something done . 
yeah . 
yes . 
yeah we actually have i think we have been making progress . 
and its sort of surprising . 
yeah . 
i i i i definitely get that impression yeah . 
you know like 
that ' s great . 
yep . 
yeah . 
so anyone else would like uh ruin the balance of 
anyway . 
well but well but then then we have to come back to the bigger group . 
right . 
yeah . 
yeah great and then we ' re we ' re going to 
because of this other big thing we haven ' t talked about is actually implementing this stuff . 
so that i guess the three of us are going to connect tomorrow about that . 
yeah we could talk tomorrow . 
i was just going to say though that for instance there was you know out of a meeting with johno came the suggestion that oh could it be that the meaning constraints really aren ' t used for selection . 
which has sort of been implicit in the parsing strategy we talked about . 
right . 
in which case we we can just say that they ' re the effects or the bindings . 
which uh so far in terms of like putting up all the constraints as you know pushing them into type constraints the when i ' ve you know then proposed it to linguists who haven ' t yet given me you know we haven ' t yet thought of a reason that that wouldn ' t work . 
right as long as we allow our type constraints to be reasonably complex . 
well it 
so anyway to be to talk about later . 
yeah it has to in the sense that you ' re going to use them 
it ' s you know it ' s sort of a um generate and test kind of thing . 
uhhuh uhhuh . 
and if you over generate then you ' ll have to do more . 
i mean if there are some constraints that you hold back and don ' t use uh in your initial matching then you ' ll match some things . 
uhhuh uhhuh . 
i mean i i i don ' t think there ' s any way that it could completely fail . 
it it could be that uh you wind up 
i mean 
the original bad idea of purely context free grammars died because there were just vastly too many parses . 
you know exponentially many parses . 
and so the concern might be that not that it would totally fail but that 
uhhuh . 
uhhuh . 
that it would still generate too many right ? 
it would still 
so by just having even bringing semantics in for matching just in the form of semantic types right ? 
like conceptually these have to be construed as this this and this might still give us quite a few possibilities . 
yeah . 
we don ' t know . 
that you know and and it certainly helps a lot . 
but yeah . 
i mean let ' s put it that way . 
no question yeah . 
so 
and i think it ' s a it ' s a perfectly fine place to start . 
you know and say let ' s see how far we can go this way . 
uhhuh uhhuh . 
and uh 
well it definitely makes the problem easier . 
i ' m i ' m in favor of that . 
uh because i think i think it ' s as you know i think it ' s real hard and if if we 
right . 
so friday ? 
monday ? 
yeah . 
monday . 
yeah . 
so okay that ' s tuesday . 
yeah . 
yeah . 
like that ' s the conclusion okay . 
so your dance card is completely filled now ? 
uhhuh . 
shoot . 
yeah and i have nothing to do this weekend but work . 
why don ' t 
no that ' s not really true 
but like 
bummer . 
what about what about d . d . r ? 
it ' s almost true . 
oh i don ' t have it this weekend . 
so tsk don ' t have to worry about that . 
huh . 
d . d . r . he asked ? 
speaking of dance . 
dance dance revolution . 
i can ' t believe i ' m 
it ' s a it ' s like a game but it ' s for like dancing . 
hard to it ' s like karaoke but for dancing . 
and they tell you what 
it ' s amazing . 
it ' s so much fun . 
yeah it ' s so good . 
my friend has a home version and he brought it over . 
and we are so into it . 
it ' s so amazing . 
well you know of it ? 
it ' s one of your hobbies ? 
it ' s great exercise i must say . 
i can ' t wait to hear this . 
uhhuh . 
oh definitely they have like places instead of like yeah instead of karaoke bars now that have like d . d . r . 
like 
yeah yeah i didn ' t until i started hanging out with this friend who ' s like oh well i can bring over the d . d . r . if you want . 
oh oh dance dance revolution okay . 
he actually brought a clone called stepping selection . 
but it ' s just as good . 
so 
so 
thanks very much for coming . 
okay . 
so um 
let ' s see . 
so um as you know the meeting today is to um benefit from your involvement in the data . 
all the things that that you ' ve been exposed to in these many months . 
and um i just i just put down some ideas . 
you ' ve seen some of this in the email that i sent out earlier . 
and um 
huh . 
none of these these are not obligatory topics . 
but they ' re just things that i thought might be useful to discuss . 
just as a way of organizing the discussion . 
but if there are other topics you ' d like to discuss that ' d be great too . 
all right . 
so um 
it struck me that um you know we could start out with some sort of general thing about um things that you found easier or more difficult with respect to transcribing or checking or using the interface or uh dealing with the time bins or any aspect of that type . 
and then maybe talk about specifics specifics of the data . 
and then maybe talk about um aspects of the conventions . 
and then the technical set up regarding the um auditory image and the interface . 
okay . 
so 
maybe we could just um start with issues of the the up there at the top of 
what what did you find easiest or more most difficult about transcribing the data ? 
okay . 
yeah . 
one thing that i remember being really difficult at the beginning and it got easier as we went along was um acronyms and technical terms . 
um because there are so many . 
uhhuh . 
and it ' s a field that i ' m not really very 
i don ' t know . 
i don ' t know very much about this kind of stuff . 
computers and speech recognition . 
i ' ve never taken classes on it or anything . 
so i found that really hard . 
and i remember transcribing and having a bunch of 
you know every five words there ' d be something i ' d put in parentheses because i didn ' t know what it was . 
so 
parentheses meaning uncertainty . 
yeah . 
yeah . 
uhhuh . 
but it ' s definitely gotten easier because the same things keep getting repeated . 
uhhuh . 
once you learn what it is and you can say okay i know what they meant by that . 
or i know how to spell that now . 
or something like that . 
and the cast of characters that you put up on the web was helpful . 
is 
yeah . 
also . 
yeah . 
okay . 
good . 
it ' s sort of like a foreign language isn ' t it ? 
it ' s basically you have these specialized terms for things that i didn ' t know needed specialized terms . 
yeah . 
yeah . 
especially when describing like the set up in this room also and the different types of mikes . 
yeah . 
i don ' t know . 
uhhuh . 
and it ' s hard to tell when people are talking relatively quickly . 
they just glide over some of the letters . 
they don ' t fully pronounce them . 
so you can ' t really tell even if you listen to it ten times what it is . 
uhhuh . 
huh . 
uhhuh . 
yeah . 
i usually put most of the acronyms in parentheses . 
because i think it ' s sort of safe . 
because people can people can say their acronyms really fast . 
uhhuh . 
and i figure that even if i think i know exactly what letters they said it ' s probably best to put them in parentheses . 
because i probably don ' t . 
that ' s not a bad strategy . 
i mean it ' s it ' s true that i i always check the parentheses at the last stage . 
and those are pretty easy to clear in terms of when they ' re in context . 
uhhuh . 
right . 
huh . 
not a bad strategy . 
uhhuh . 
yeah . 
some of them just occurred over and over the again . 
so like p d a like that got got easy . 
yes . 
uhhuh . 
there there was a a bunch of them that uh 
i suspect in context 
they just kept getting repeated often and often . 
you know over and over . 
so 
uhhuh . 
yeah . 
just got better . 
and also when you have the the juxtaposition of p d a and p z m then you know you in context you can tell which one it ' s is probably likely to be the one that you had . 
but 
uhhuh . 
yeah . 
even though i still don ' t know what they are . 
i mean i assume they ' re microphones of some sort . 
but that ' s all . 
well these here are the p z m ' s . 
that right there . 
oh . 
oh . 
is anybody wearing one of those awful quote crown microphones that people used to be 
no . 
uh you ' ve heard the crown of pain . 
yeah . 
no he was telling us uh before the meeting that um that they ' re not in circulation right now . 
that they ' re they were unpopular . 
i liked them . 
huh . 
and adam liked them . 
oh oh okay . 
i thought the quality was good . 
huh . 
just curious . 
what 
yeah what did he say 
he said some more things about that . 
but i was i was working on something else . 
about the microphone ? 
uhhuh . 
i can ' t remember . 
i mean he ' s 
he he said that they were designed for a specific sized head ? 
uh yeah . 
yeah that ' s right . 
right ? 
yeah . 
and so if if your head happened to be that size then you were fine . 
that ' s right . 
oh . 
and if it was bigger then it was like torture . 
oh . 
right . 
yeah . 
or i don ' t know . 
it ' s 
i don ' t know . 
i liked them . 
and there ' s the actually there ' s the picture of the of the crown adjustment on the wall right there . 
huh . 
so it sort of hooks over your ears from the back . 
right . 
oh yeah . 
oh okay . 
yeah good 
oh it doesn ' t look so bad . 
but i guess it depends really . 
okay . 
so now what about accents ? 
do you have uh did you find any 
they ' re tough sometimes . 
uhhuh . 
yeah . 
sometimes the german accents can get a little bit daunting . 
i mean 
um 
i forget who it was that i was transcribing . 
but it was tough to figure out what he was saying uh at any given point in time . 
and i would i would just listen to it over and over and over again going oh my god my head ' s going to explode . 
like not really understanding 
yeah . 
you know ? 
and so 
i was getting a little frustrated . 
because i would put a lot of things into parentheses . 
and then go back over it . 
and go back over it again . 
and still 
you know ? 
i i like to try to clear as much up as i possibly can . 
and i i just felt like you know with the german accents just for me personally those were probably the toughest to get around . 
uhhuh . 
um they weren ' t impossible . 
but just like they the they took the most time too . 
i mean i would take maybe twice as long on a a given channel with a speaker who has a german accent than somebody who ' s you know a native english speaker . 
uhhuh . 
huh huh . 
or even asian . 
like uh speaks an asian language . 
i found that easier . 
uh 
you know . 
uh somebody who speaks like chinese or something . 
what ' s 
you ' ve studied some languages . 
uhhuh . 
which which ones do you are you studying ? 
it ' s more of a romance direction ? 
or 
um yeah . 
well i studied i mean i studied old english for a while . 
uhhuh . 
um 
and then i ' ve worked with larry hyman on like some of the bantu languages . 
um 
uhhuh . 
and you know i ' m also working with ian maddieson . 
and he ' s been doing work on the uh like also some african languages . 
so i ' ve like learned a little bit . 
uhhuh . 
so it ' s not really you ' re not really exposed to german very much . 
no . 
i mean i sing in german . 
uh interesting . 
interesting . 
but 
i mean i can i can pronounce it . 
huh . 
but i don ' t know any . 
okay . 
that ' s interesting . 
huh huh . 
uhhuh . 
i can do i can pronounce a lot of languages and not actually speak them . 
yeah . 
because of singing . 
yeah . 
huh . 
huh . 
for me i found the spanish speakers to be the hardest . 
and the german speakers i found a little bit easier . 
yeah . 
and i thought maybe that was because i had i took german for a semester and i ' ve had exposure to german . 
oh . 
um because i had a lot of friends who were really into germany and german language . 
and 
but 
and i found that i could 
if they were pronouncing something in a certain way i could say oh well that ' s just the german way of pronouncing this . 
and then i figured out what they were saying . 
uhhuh . 
um but with the spanish speakers it was 
i ' ve never taken spanish . 
and even though i ' ve taken french and i speak french fairly well um i found the spanish to be much harder . 
and maybe also because the level of fluency for the spanish speakers was a little bit less than the level of fluency of the german speakers that are here . 
oh . 
if you ' re talking about who i think you ' re talking about . 
i think . 
are you talking about 
um 
there was a couple of different spanish speakers . 
can we give names ? 
can 
yeah . 
we we probably shouldn ' t right ? 
is that 
it ' s a good question . 
um 
and i can ' t really answer that . 
okay . 
well there ' s one in particular who i find the hardest to transcribe of all . 
and it ' s she ' s spanish . 
oh . 
so 
oh yeah . 
okay . 
and um 
and i ' ve taken lots 
i ' m fluent in spanish . 
and so 
um when i when i correct it i can i can tell that the person who um transcribed it before me probably didn ' t speak spanish . 
because i can catch a lot of things . 
like like no that ' s not what she said . 
i can tell she ' s pronouncing pronouncing it the way that if you read it from a you know a spanish speaker ' s mind that you would you know pronounce it the way that you would pronounce it in spanish . 
but the same time uh i can ' t get most of it . 
because i 
huh that ' s really interesting . 
oh that ' s fascinating . 
huh . 
i find it one of one of the hardest ones to transcribe . 
well what you can see is that it ' s it ' s her lack of of english fluency that ' s being 
yeah . 
oh okay . 
i think so . 
yeah . 
yeah that ' s that ' s really interesting . 
i do find that the german tends to be easier for me than than the others . 
uhhuh . 
uhhuh . 
because of my exposure and interest in german . 
uhhuh . 
yeah . 
but um 
right . 
maybe i haven ' t transcribed this spanish woman . 
i don ' t know if i have . 
i suspect you haven ' t . 
because this was uh earlier on that we had a lot of 
uhhuh . 
actually she she was in the middle phase i would say . 
we had another spanish speaker who was earlier who was also difficult . 
huh . 
uhhuh . 
yeah . 
uhhuh . 
yeah he was hard . 
yeah . 
but that ' s really interesting . 
he got easier though . 
because he started like he would say certain words over and over . 
yeah . 
and 
and you got to know his pronunciation of them . 
yeah . 
so when he said sign yah and it sounds like sign he was saying signal . 
i remember yeah . 
yes yes yes yes . 
uhhuh . 
yeah i remember that . 
and so i would transcribe it as signal . 
exactly . 
huh . 
oh wow ! 
and and uh the way he said mixed was really strange too . 
uh 
miss ed . 
meexe meese mees uh or something . 
miss ed or 
yeah . 
uhhuh . 
huh . 
right . 
yeah . 
which was you know you could predict it . 
he 
i mean if you knew looked back at it . 
uhhuh . 
that ' s kind of cool . 
especially because also in the beginning meetings i mean he ' d say something and no one in the meeting would understand . 
they 
and then everyone would say what was that again . 
oh uh 
and then they ' d pronounce it in english . 
yeah . 
and so i could figure out what it was . 
yeah . 
that way . 
yeah . 
interesting . 
yeah . 
okay . 
yeah i mean he was never like 
it was never up to like a native speaker . 
but like that it got a little easier . 
um 
like his english fluency got better ? 
i remember in the beginning you had and you were just sort of like you were beating your head against the wall . 
oh i went crazy . 
but i it but it got better it got better . 
i i would skip doing that portion for as long as i could . 
yeah i know yeah i remember . 
because i just couldn ' t deal with it . 
yeah . 
and 
yeah i had the same experience . 
yeah . 
sometimes 
and actually 
sometimes when people lack a certain level of fluency you can ask them themselves what did you say there . 
and they can ' t tell you . 
and they won ' t know . 
i think it ' s it ' s sort of a general variability when it ' s not when you ' re learning a language and you haven ' t gotten to a certain level . 
huh . 
uhhuh . 
oh . 
huh . 
uhhuh . 
uhhuh . 
uhhuh . 
yeah . 
yeah . 
i also wonder if if it ' s partly that spanish has different pronunciations in different regions . 
i mean do you think that um that uh maybe 
i mean being 
i mean not that i would know that . 
huh . 
but i just wondered if 
um 
you know she was from probably continental spain versus you know other spanish . 
i wonder if that would have a a contributing factor . 
i don ' t know . 
oh like the region ? 
i have no idea about spain . 
yeah . 
but i know that in france for example parisian french is much easier for me to understand . 
because i learned it . 
versus france in like marseilles or in the south or in like the like the villages in the south . 
sure . 
right . 
it ' s really hard to understand . 
uhhuh . 
menton . 
or in quebec . 
that ' s right . 
right ? 
in canada it ' d be 
yeah . 
right . 
it ' s different . 
much different . 
a lot of the pronunciations are different . 
yeah . 
yeah . 
yeah . 
and in my case with with uh german i a certain region that i do well in . 
and then get farther away from that region . 
yeah . 
yeah . 
and i notice it ' s more and more difficult . 
uhhuh . 
there ' s another language that ' s spoken in spain too that ' s um 
yeah . 
what am i thinking of ? 
castillian ? 
castillian . 
yeah . 
and uh 
and 
um 
isn ' t it catalan ? 
catalan . 
yeah . 
uhhuh . 
so maybe i mean depending on where she is like maybe 
but she was also very low volume . 
and um and didn ' t say a lot . 
yeah . 
uhhuh . 
i mean i i i i totally agree . 
this was a a difficult person to to understand . 
yeah . 
yeah . 
well the last one i did she actually said a lot . 
yeah . 
but 
and it was kind of it was very hard to transcribe . 
you 
it was i just think that um her fluency in english wasn ' t um wasn ' t very very high up there . 
so it was really difficult . 
yeah . 
but i mean i did find that knowing spanish helped me a lot . 
i can imagine that . 
i could tell that a lot of things that the other transcriber had put in parentheses i was like i can see how you how you couldn ' t understand that . 
huh . 
yeah . 
uhhuh . 
but i i i think i know what she ' s doing . 
yeah yeah yeah . 
i mean i think i know the mistake she ' s making . 
and 
uhhuh . 
that ' s really good . 
yeah yeah . 
yeah . 
because that ' s definitely something that i wouldn ' t have be able to do . 
yeah . 
yeah i couldn ' t do it in spanish . 
i ' ve i found myself doing that somewhat in in german . 
yeah . 
german . 
in german . 
yeah . 
uhhuh . 
there were problems even with um english speakers though . 
i mean not in their level of fluency obviously . 
uhhuh . 
but in 
uhhuh . 
some people tend to mumble . 
uhhuh . 
huh . 
yeah . 
that ' s right . 
and 
and it ' s hard to catch what it is . 
is because it goes by really quickly . 
and you can ' t really tell . 
uhhuh . 
and 
or they ' re laughing when they ' re talking . 
that too . 
or they ' re 
uhhuh . 
uhhuh . 
that too . 
yeah . 
or just 
i don ' t know . 
and some people tend to get interrupted more . 
i know that ' s not something that the person themselves can control . 
yeah . 
but 
huh . 
if when people talk over one another like constantly like there ' s this whole barrage of voices coming from everywhere . 
um 
uhhuh . 
it ' s like oh my god . 
what ' s going on right now . 
especially when they ' re when you were using the the mikes that weren ' t headmounted mikes . 
it ' s kind of 
oh . 
yeah . 
and there was input from other people on the same channel as the person who was talking . 
yeah . 
yeah . 
and that was really hard to deal with . 
we had lapels for 
and then sometimes people would wear these around their necks . 
huh . 
which would mean really basically uh a problem that you ' re saying of getting input from others . 
uhhuh . 
oh yeah . 
huh . 
right . 
and also um it varying when they change their head position . 
uhhuh . 
yeah . 
yeah . 
right . 
but 
a big 
i i think the transcriptions improved immensely . 
like exponentially . 
um after it was able to sort of isolate a single person onto a single channel . 
yeah . 
oh excellent . 
absolutely . 
um 
oh good to know . 
yeah . 
oh there ' s no question . 
yeah . 
oh yeah . 
um 
so that was you ' re talking about early on the change into channeltrans . 
yeah . 
yeah . 
you guys didn ' t have one channel per person before ? 
uhhuh . 
no . 
no it was one like one ribbon for everybody . 
no . 
oh wow . 
euh . 
and you had to kind of 
you could switch signals . 
like you could listen to a different one . 
uhhuh . 
but you couldn ' t really 
well could you ? 
did we didn ' t do that very much . 
you couldn ' t visually isolate it ? 
what ? 
you couldn ' t visually do it . 
no . 
huh . 
euh . 
no . 
and 
yeah . 
and you had to mark interruptions by a slash . 
uhhuh . 
that ' s right . 
right ? 
and it was very hard to be precise about it . 
um 
overlaps . 
and it was very hard to tell . 
i had so much trouble at the very beginning trying to figure out who was who . 
huh . 
yeah . 
because there ' s so many men and so few women . 
huh . 
the women were easy to figure out who was who . 
and then the men all their voices sounded the same . 
except i think there was one british english speaker . 
and that was easy . 
but 
wow that ' s difficult . 
uh yeah . 
you know what ? 
there might be a gender thing there though too . 
yeah . 
because i think i think as women it might be easier to differentiate 
well there were fewer women too . 
but i i wonder if a man transcribing all the guys would have had 
yeah . 
an easier time ? 
like if you had transcribed it you would have had an easier time differentiating them . 
uhhuh . 
i don ' t know why that would be true . 
that ' s interesting . 
that ' s possible . 
but 
that ' s possible . 
you wonder if there ' d be like a gender difference there ? 
i don ' t know . 
i ' m thinking about it as like a psychologist i suppose . 
i don ' t know . 
it ' s possible . 
anyway . 
well it ' s 
huh . 
oh yeah . 
yeah that ' s possible . 
huh . 
yeah . 
i was just going to say something . 
i was going to say that 
i mean it ' s easier for people to mimic like the timbre of somebody ' s voice if it ' s the same if uh that person ' s voice is the same . 
if that person is the same sex as you so maybe like implicitly people pay attention more closely to uh speakers of the same sex . 
uhhuh . 
huh ? 
i don ' t know . 
i don ' t know if that ' s actually true . 
but i ' m just throwing that out there . 
huh . 
it ' s interesting . 
huh . 
i don ' t know . 
huh . 
kind of an interesting research project . 
yeah . 
it seems like it ' s it ' s related to this production idea . 
how you you internalize what you ' re externalizing in a way . 
but 
yeah . 
yeah . 
yeah but it definitely got much better when that change happened . 
oh yeah . 
it was so it it became much easier . 
uhhuh . 
um 
you know . 
in the 
you ' ve also gone through 
they ' ve been here since the beginning . 
you ' ve also gone through the use the introduction of the pre segmentation and that kind of thing . 
oh yeah . 
right . 
so initially they had to actually mark all the time bins themselves as well . 
wow . 
oh . 
oh wow . 
right . 
that took a 
which wasn ' t as hard . 
yeah . 
i mean it took time . 
no it just took time yeah . 
it took time . 
yeah . 
uhhuh . 
huh . 
um i find that i have to adjust the time bins a lot anyway . 
uhhuh . 
me too . 
me too . 
yeah yeah . 
yeah . 
um 
i always adjust the time bins . 
yeah . 
um not for the end of the utterance but for the beginning . 
yeah . 
sometimes the beginning the person started to say something . 
yeah . 
i see . 
really ? 
it ' s a very slight difference . 
and then the time bin starts . 
uhhuh . 
yeah that happens a lot . 
yeah right . 
huh . 
right . 
um so you have to just move it back a little bit . 
and and i think you mentioned at some point that you wanted a little pad of time anyway . 
uhhuh . 
it doesn ' t hurt to have a pad . 
it ' s it ' s nicer to have a pad than not . 
yeah . 
then to have it be cut off . 
but don ' t have to be really yeah don ' t doesn ' t have to be 
yeah . 
don ' t have it just start . 
yeah . 
i always wonder about the um time bins . 
i thought 
um so . 
i mean i usually ended adjusting them a little bit . 
yeah . 
i mean 
definitely when something ' s cut off at the beginning or the end . 
but also sometimes there ' s just like huge pads of you know air before and or after um that i don ' t really feel is necessary for that segment . 
uhhuh . 
and i usually um you know shrink it a bit . 
huh . 
shrink in them or whatever . 
uhhuh . 
yeah . 
nice . 
and make it a little bit 
seems like i always have to cut off pads at the end . 
nice . 
i don ' t have so much problem at the beginning . 
but 
of breath or of uh nothing ? 
no of just nothing . 
just nothing . 
yeah . 
huh yeah . 
yeah . 
yeah there ' s nothing going on . 
at the beginning it seems to happen when um voicing occurs later . 
yeah . 
yeah . 
you know like 
with fricatives a lot . 
yeah with fricatives and with like uh 
huh . 
i mean like it doesn ' t happen with uh like buh so much . 
because you ' ve got the pre voicing before the consonant actually begins . 
although i found one in actually i was just working right before this meeting one where someone said great . 
and 
the the g it was pronounced as a k . 
so it was unvoiced . 
and then part of the r was cut off in the beginning . 
oh . 
and then 
you it sounded like great . 
if you just listened to that time bin it still sounded like great . 
uhhuh . 
but if you listened to right before it you could hear a little the the k or whatever and a little bit of the r . 
uhhuh . 
so 
i don ' t know . 
that ' s kind of interesting . 
usually it ' s not 
usually that doesn ' t happen . 
but this time it did . 
so for the non linguists what ' s a fricative ? 
i 
uh 
oh . 
uh it ' s like fff sss . 
or sss . 
or 
yeah . 
oh okay . 
or thh . 
shh . 
it ' s a sound that 
it ' s like the noisy uh um like airflow ones where you ' ve got like a a stoppage in your mouth . 
like uh like your tongue 
but it ' s not completely blocking the airflow . 
oh i see . 
yeah . 
and you can sort of you can sort of keep it going a little bit . 
right . 
oh i see . 
oh okay . 
unlike like a tuh or a kuh that just stops . 
yeah . 
yeah . 
right . 
got it . 
sorry . 
have you 
i guess i ' m the only non linguist . 
well i ' m i ' m sort of a hybrid . 
so i i you know i i appreciate having them do this . 
uhhuh . 
oh right . 
yeah oh you 
yeah . 
yeah . 
so um in did you have you run into places 
i ' ve run into a couple where actually the word was totally different when you adjusted the time bin . 
have you had that happen ? 
huh yeah . 
oh yeah . 
yeah . 
that ' s fascinating . 
yeah . 
i like that . 
yeah . 
oh it ' s really a kick . 
i think that ' s fun . 
yeah . 
and it sometimes changes the entire utterance too . 
oh it does . 
yeah . 
yeah . 
completely . 
yeah . 
i i don ' t remember the words exactly . 
it ' s a shame . 
there was one that was a whole sentence was broken up in the middle and there was a little like millisecond of break in the middle . 
and 
if you connected it all together it completely changed what was right before it and what was right after it . 
it was written as something else . 
and then it became a word together from what was before and after . 
and then with this little tiny millisecond pause . 
so i guess i don ' t know i mean i guess when we talk in between different segments of the word maybe there ' s pauses somehow . 
i guess 
huh . 
or the you can 
we stop voicing sometimes . 
yeah . 
or something like that . 
it ' s probably like inaudible for us . 
but 
and maybe the pause was just so short that it made up a pause . 
i don ' t is it that doesn ' t make any sense . 
but 
there are some times when there have been words that they just pause right in the middle of . 
uhhuh . 
you ' re 
it ' s 
on purpose though . 
or not . 
well 
it i ' m sure sometimes on purpose . 
but sometimes it ' d just be saying something and especially people who have really elongation in their style . 
uhhuh . 
and they say that ' s really fascinating . 
uhhuh . 
it ' s not a great example . 
but you know 
uhhuh . 
and 
yeah . 
uh there ' s 
it ' s it ' s funny how um 
it ' s funny to me that something like that you just change one little boundary and suddenly the whole meaning changes . 
and i ' ve run across that also . 
uhhuh . 
uhhuh . 
yeah . 
yeah that is true . 
huh would you want um uh a transcription of something like that ? 
of a big pause in between in the middle of a word . 
or just leave it as fascinating ? 
what i ' ve done i ' ve 
it ' s very rare i mean when i ' ve run across it . 
uhhuh . 
and you know maybe there are times i haven ' t detected it . 
and i ' m not you know i haven ' t looked at everything . 
i ' ve looked at i ' ve probably looked at uh at least eighty percent of the data . 
you know all the way through every meeting for about eighty percent of the stuff that i ' ve cleared so far . 
oh ! 
and um 
it you guys are getting so good that it ' s like i ' m i i i can get through them faster and i ' m getting to the point where i maybe don ' t have to go through them all the way . 
you know ? 
uhhuh . 
so it ' s like it ' s just we ' ve gotten to a level it ' s just really great of um of of precision that um it takes a lot of a load off of me . 
huh . 
and um 
and so i ' m not going to be checking them all i don ' t think in the for throughout the whole rest of the project . 
but um 
certainly have spot checking . 
but um hhh those that i have found that way to me i think the most sensible way to handle it from my perspective was to treat it as a pronunciation situation . 
uhhuh . 
so just do a you know a mark then fascinating and then put p r n and uh interrupted by a pause or you know some kind of other gloss like that you know . 
uhhuh . 
uhhuh . 
p r n . 
how it was really pronounced . 
uhhuh . 
uhhuh . 
right . 
huh oh right . 
uhhuh . 
you know p r dot dot fascinating whatever it is . 
i always get confused with the pronunciation convention . 
sorry what was this ? 
i get confused with pronunciation like when there ' s a strange pronunciation that i want to mark . 
okay . 
because i think 
in the beginning did we do the strange pronunciation and then write p r n and what it really was meant to be ? 
and now we ' re doing the normal word and then inside the brackets what it sounded like ? 
right . 
we did a switch right ? 
or not . 
i don ' t know if it ' s just me that ' s confused or if it was 
well i ' ve 
uhhuh . 
i it it never occurred to me but now that you ' re mentioning it yeah yeah possibly . 
there was an adjustment . 
and i and i ' ve switched them all all the way at this point so that 
okay . 
okay . 
so the convention as it stands now is write the word as it is normally conventionally spelled in english with the little apostrophe or whatever you call it . 
yeah . 
yep . 
uhhuh that ' s right . 
and then p r n . 
and then in the brackets what it 
how it ' s pronounced . 
uhhuh . 
so you know okay is a very easy example . 
uhhuh . 
a person says huh kay . 
uhhuh . 
then 
oh . 
it ' s okay with a a little hatch . 
and then p r n and then huh kay or whatever it is in quotes . 
oh right . 
okay . 
oh right . 
i think nelson ' s the only one who uh 
oh morgan . 
you guys call him morgan . 
yeah yeah . 
he ' s the only one who ever did that i think . 
huh kay . 
he does it a lot . 
huh kay . 
i 
he does it a 
okay . 
yeah . 
yeah . 
and some people just say kay . 
um 
yeah . 
kay . 
yeah that ' s true . 
yeah that ' s right . 
yeah . 
and of course you know i mean there ' s also this other reduction that that we ' ve done in terms of like not capturing every time a person says and versus nnn versus you know nd whatever . 
uhhuh . 
all the different ways of reducing and . 
that ' s true . 
because you can assume that the speech recognition um uh pronunciation models will handle a certain amount of reductions of these types . 
and the same thing for um well the the versus the . 
that there are those known variants and 
uhhuh . 
uhhuh . 
or a versus a . 
exactly . 
uhhuh . 
uhhuh . 
and that they should be able to handle themselves . 
and and that we assume also that for discourse purposes those distinctions are not really the focus right now . 
and those distinctions could be added later if needed . 
but it ' s unlikely that they would be . 
and it ' s so time consuming . 
uhhuh . 
so we ' ve made these these simplifying assumptions with that . 
and so then you begin to think well what about okay . 
i mean maybe huh kay is an appropriate variant for okay . 
and it wouldn ' t be necessary to mark those either . 
so it ' s it ' s definitely there ' s a uh choice of how far you go with that and whether kay is is enough of a variant . 
uhhuh . 
huh . 
you know it ' s this is a case where um i appreciate it when people mark those kinds of things . 
but i i sort of figure that that that ' s not as far away from okay as huh kay is . 
so it ' s not quite so 
uhhuh . 
huh . 
but i don ' t change it back if it ' s there . 
uhhuh . 
i think with like some of them like you know with uh the difference between the and the you can you can distinguished very uh definitively like what context they ' re going to be used in . 
you know ? 
yes . 
uhhuh . 
uhhuh . 
like um like you would say the apple . 
because it ' s the plus then the next word starts with a vowel . 
uhhuh . 
or the cat because it ' s next word starts with a 
yeah . 
there ' s a study done on when people say uh and when people say um . 
yeah i ' m sure it ' s 
also there ' s in contextual variation . 
oh really ? 
and it ' s predictable apparently . 
huh . 
uhhuh . 
i haven ' t read the 
i was trying to figure that out myself a couple times . 
it ' s really interesting . 
but something like 
and i couldn ' t get anything . 
yeah . 
yeah . 
uhhuh . 
interesting . 
i kept looking at all the uh ' s and um ' s and i was like oh this would be hard to do . 
yeah . 
oh that ' s interesting . 
you know what ' s on that sort of similar topic i just thought of something that ' s been hard for me sometimes is you can have a pronunciation of of the word a as a . 
huh ? 
yeah . 
and then you can have uh like a pause or whatever as uh . 
uhhuh . 
and sometimes it ' s hard to tell what the person meant . 
are did they mean uh like they ' re pausing ? 
huh yeah . 
or did they mean a like a person ? 
yeah . 
yeah . 
i ' ve run into that . 
really ? 
yeah . 
yeah . 
yeah . 
right . 
huh ? 
once in a while . 
and 
i don ' t usually get 
you can kind of tell from the context . 
but sometimes it ' s hard . 
yes . 
right . 
yeah . 
yeah that came up a couple of times . 
yeah i 
yeah . 
huh . 
yeah . 
i agree . 
and and when i when i ' m totally in doubt if there ' s a case where it really could be either and i could flip a coin i ' ll choose the one that would make syntactically the most sense . 
uhhuh . 
uhhuh . 
uhhuh . 
give them the benefit of the doubt that they ' re being fluent about it . 
uhhuh . 
uhhuh . 
sometimes i ' ll put in like a bracket like uh you know the orthographic a slash u h like if i ' m really confused . 
like you can ' t tell . 
uhhuh . 
uhhuh . 
yeah . 
kind of go well there ' s two . 
so here . 
uhhuh . 
it must be really rare though . 
i haven ' t run across that often . 
is it rare ? 
huh huh . 
a few times . 
a few . 
it ' s really 
yeah . 
okay . 
it ' s rare . 
relatively rare . 
i don ' t think i ever have . 
yeah . 
yeah . 
i mean i can only think of like two or three occasions where i sat and thought about it for a while . 
huh . 
other times just you figure you look at it and what ' s the context . 
yeah . 
it ' s okay . 
i don ' t know . 
right . 
okay well let ' s see now . 
there ' s another another 
what i i want to ask you at some point it just occurred to me i ' d like to ask you the following question maybe you can have this in the back of your minds something like um you know what sorts of hypothesis your hypothesis about the you know trying to find the distributional explanations for some of these things . 
huh ? 
right . 
what kind of uh hypotheses have has this caused you 
uh i mean don ' t want to have you give away a paper topic that you want to explore . 
but 
you know if there ' s interesting uh hypotheses that the that have been suggested to you by looking at the data . 
that kind of thing maybe uh at some point . 
so 
hnh . 
and oh and i also want to say that um i ' d like to meet again also next week . 
uhhuh . 
um and i don ' t know if this is a good time frame . 
uh maybe it ' d be good to have it an hour later . 
or i don ' t know i mean could do anything . 
this is fine . 
this time is fine for me . 
about 
yeah this is a good time for me . 
good time for you ? 
it should be . 
okay . 
um i know i have something in the morning which i don ' t normally have . 
i don ' t remember off the top of my head when it ends . 
um i ' ll let you know if it ' s it ' ll be a problem . 
but it should be okay . 
okay . 
two thirty should be late enough . 
so 
okay . 
excellent . 
because we could probably move it one hour later . 
in 
i mean i think unless 
i was just going to say maybe fifteen minutes later would help me a little bit . 
just because i have a class up at dwinelle just before this . 
oh i see . 
that ' s why i was a little late today . 
wow ! 
you did really well . 
because 
yeah . 
thanks . 
well i took the bus for part of the way . 
uhhuh . 
oh did you ? 
okay okay . 
but um that might help me just a little bit . 
because then it i you know i ' m going to going to be hobbling a little slowly . 
then you don ' t have to rush . 
would anybody be constrained by having it be a full half hour later ? 
hnh nn . 
no . 
no . 
okay . 
and the final question 
no . 
except we ' ll miss treat time . 
oh ! 
tea ! 
oh that ' s right . 
oh i thought she said mistreat time . 
oh no ! 
maybe we could have like a like a half hour then take a little break . 
yeah . 
mistreat oh ! 
yeah . 
then come back and finish the 
well that ' s that ' s some good motivation to not start a half hour later . 
you know what we could do ? 
yeah you know that ' s that ' s that ' s an interesting 
we could just ask the someone like the front desk person or lila to like set aside a little bit for us . 
that ' s so funny . 
little bit of treats . 
hey they would . 
oh that ' s true . 
uhhuh . 
yeah they would . 
yeah . 
that ' s that ' s not a bad solution . 
uhhuh . 
it ' s not going to be birthday cake . 
so 
yeah so we ' ll survive . 
yeah . 
yeah that ' s right . 
this is very important . 
it ' s already done . 
it ' s good to good to have these things all scheduled . 
okay . 
so um 
oh . 
uh uh then i was going to ask you what about an hour later ? 
i mean if we had those things an hour later . 
like would people 
this is fine with me . 
okay . 
that ' s fine too . 
yeah . 
okay good . 
huh . 
yeah that ' s fine . 
all right so i ' ll i ' ll settle on that . 
yeah . 
okay now i wanted to say you ' ve been through a couple of different uh improvements in the methods the pre segmentation . 
there was another another improvement in that 
well let ' s ask if it was an improvement from your standpoint . 
uh the tigerfish um approach . 
so 
uh moving from having the first transcription done by an external service and then you correcting that versus doing the initial transcription yourselves . 
how have you 
oh . 
and so i think you yeah i think you did you 
i don ' t think i have ever done one from an external 
has there already been 
i have . 
i i feel like they ' ve all been done probably by another transcriber here . 
you talking about the i b m ones ? 
yeah i b m or if if it was dash t f . 
that ' s the tigerfish . 
right . 
right . 
yeah . 
oh yeah yeah . 
oh yeah then i guess i have . 
maybe the one i ' m working on now . 
i could tell you something that i thought . 
uhhuh . 
so 
they have different definitely a different style right ? 
do they end all them all in dots ? 
yeah . 
like dot dot . 
there ' s a lot of that . 
yes . 
yeah . 
they used to . 
uhhuh . 
and they and they capitalize like every single first 
i really 
yeah . 
and they put 
um not parentheses . 
what ' s it called ? 
punctuation after brackets . 
yeah . 
that ' s right too . 
yep . 
oh okay . 
yeah then i ' m doing that right now . 
right . 
oh right . 
uhhuh . 
yeah . 
laugh period . 
yeah . 
yeah . 
something like that right ? 
right . 
yeah . 
which makes no sense to me . 
no it doesn ' t to me either . 
like that ' s not a syntactic part of that sentence . 
yeah . 
if 
but 
no . 
exactly . 
exactly . 
i ' m glad you 
yeah . 
yeah exactly . 
well they ' re not linguists . 
if 
uhhuh . 
so 
no . 
if i could be completely frank i really didn ' t like the i b m ones . 
yeah . 
oh good to know . 
yeah 
i didn ' t either . 
oh that ' s helpful . 
i found them to be just 
i just i i ended up basically redoing them . 
okay . 
huh . 
um like from start to finish . 
i don ' t know if i did one . 
so when i was checking them like it would take me basically as long as it would have taken me to just to transcribe it by myself . 
wow . 
huh . 
huh . 
wow ! 
i think it was a little bit faster than just transcribing it . 
wow . 
okay . 
yeah . 
but i definitely saw a lot of 
i ' m really picky . 
there was a lot of errors that are not in the tigerfish ones . 
uhhuh . 
yeah tigerfish are better . 
yeah . 
and they just have better intuitions or i don ' t know what but about what ' s said . 
which are what are the two differences ? 
i ' m not sure . 
i ' m not sure if you had an i b m one . 
so this was earlier on . 
so do i have a tigerfish one right now ? 
huh . 
if it says t f . 
if it says t f . 
you probably do . 
uhhuh . 
okay . 
yeah . 
the ones that say i b m are like they actually say i b m . 
so i don ' t think i ' ve ever 
the i b m ones were the ones that came in huge huge paragraphs huh ? 
yes . 
yeah and we had to split them up . 
see i never got one of those . 
yeah and you have to parse them all down . 
right . 
yeah yeah yeah yeah . 
okay . 
yeah . 
uhhuh yeah i didn ' t ever get one of those . 
so you didn ' t get one . 
oh interesting . 
no i ' m glad i didn ' t . 
okay . 
i didn ' t get one either . 
i think those show up in tigerfish too . 
because i think i ' ve had a couple of tigerfish where i ' ve had to break them up . 
where they have 
yeah but they ' re not like 
they ' re not 
yeah i can remember i used to see 
they ' re not huge huge though . 
a couple were . 
really ? 
yeah . 
oh . 
and i had to sort of break them down . 
oh . 
do they get them um 
i don ' t know . 
is 
they don ' t have like an interface right ? 
they just 
no . 
in neither case . 
and i ' m and i ' m thinking i ' m thinking you ' re causing me to think back over what the differences were in the what they got . 
yeah . 
and i b m didn ' t 
yeah . 
they just have they just have it segmented . 
yeah . 
you can tell because sometimes they have it so wrong . 
and it ' s like well if you had just listened to what was before . 
yeah . 
yeah . 
but they don ' t have that option . 
yeah but they don ' t have that . 
yeah i figured that they didn ' t . 
right . 
yeah . 
right . 
there ' s also some iffiness about how if 
we ' re not sure really how tigerfish does it . 
you know the methodology . 
how do they do this ? 
huh . 
because sometimes you ' ll have the the same word 
and i ' ve seen this like within 
well within a single turn it ' ll be spelled in three different ways . 
and it ' s like you know is this the same person who ' s kind of forgetful . 
huh . 
uhhuh . 
or is it that they have several people doing it together ? 
you know maybe it ' s parallel . 
right . 
right . 
maybe they ' re all doing it in parallel . 
and one falls behind and the other one . 
yeah . 
oh that ' s interesting . 
but who knows ? 
and they don ' t 
one person doesn ' t listen to all the channels of one meeting . 
right ? 
so they can ' t get clues from the other channels ? 
well you know the the way they ' re listening to it is they they get a they get 
or can they ? 
i don ' t know . 
uhhuh . 
it ' s linearized . 
so if you picture what we have on the screen . 
um you know there ' s this block and it goes over 
i ' m doing it from my perspective . 
you have this block . 
and it goes over to here and stops . 
and this person starts to talk . 
and he goes over to here . 
uhhuh . 
and then you have an overlap over here . 
and so what they would get is this block from the first guy . 
this block from the second guy . 
and then the top of the overlap . 
and then the second guy in the overlap . 
oh . 
oh wow . 
huh . 
and then it would move on . 
huh . 
so it ' s sort of like this you know you go this way as much as you can . 
then you cycle through there . 
and then you go up to this next level . 
so they hear all the channels at once like you guys were saying you first did ? 
and 
oh okay . 
um 
let ' s see . 
they hear them 
oh . 
uh they hear them separately in two chunks . 
but then sometimes they get confused about who the foreground speaker is because they ' re not being told who the foreground speaker is . 
uhhuh . 
you know . 
and especially you can see if you have like four speakers it be you can maybe find a way of doing that . 
but with nine speakers 
eee yeah . 
so what they get is they get a beep that tells them when there ' s something that they think that the pre segmenter thought there should be transcribed in there . 
uhhuh . 
uhhuh . 
huh . 
and so they ' ll get 
and it ' s numbered so that we end up with the same number of of transcribed slots . 
as there are slots in the pre segmentation . 
exactly . 
uhhuh . 
because the first time when we didn ' t have them numbered we ended up with a couple extra segments that were transcribed . 
and it was hard to patch the whole thing back together . 
uhhuh . 
huh . 
because when it comes back to our end um it ' s just this long string of things that they ' ve uh partitioned according to the tape that they were given . 
uhhuh . 
because they don ' t they actually don ' t have digital interface either . 
so it ' s it ' s audiotape . 
oh wow . 
oh wow . 
huh ? 
oh . 
huh wow . 
and they type it on . 
makes it really hard . 
and then then it comes back to us . 
wow . 
and adam and thilo have a program they put it back together into our interface format . 
and then we can use it . 
uhhuh . 
but 
um 
um there are cases where you ' ll get a segment and it ' s someone else ' s utterance . 
and that ' s because that was overlapping with someone else and this is the weaker speaker of the two . 
uhhuh . 
and you ' ll have like two totally parallel renditions of the same thing . 
yeah . 
because it ' s just 
right . 
so what they get is like is they get something like beep one . 
and then then they get beep two beep three . 
chuck wooters does the numbers . 
and um it cycles through . 
wow . 
oh so they don ' t 
do they know the names of the speakers ? 
no . 
oh okay . 
and they don ' t know which channel is supposed to be together . 
because 
okay . 
huh . 
because sometimes there ' d just be interesting things where there ' d be a misunderstanding about like 
like 
morgan would be speaking but it ' d be on your channel . 
and it ' d be like this is clearly not a woman speaking . 
yes . 
exactly . 
huh . 
yeah . 
yeah that ' s quite right . 
it ' s like how could they do that . 
and that ' s why . 
it ' s like well now it ' s it seems more reasonable that they ' d make a mistake like that if they had no idea . 
uhhuh . 
exactly right . 
okay . 
yeah . 
huh . 
god it must take them a really long time to do these . 
huh . 
yeah . 
um 
they ' re very fast . 
that ' s amazing . 
is 
yeah . 
it sounds so hard . 
yeah . 
it it turns out that they ' re really much faster than the other approaches we ' ve used . 
and we don ' t know exactly how they do it . 
uhhuh . 
and i think that that ' s by intention that not just me who thinks that it ' s that proprietarily it ' s a very competitive business . 
uhhuh . 
and they probably don ' t want to uh say too much about it . 
huh . 
huh . 
right . 
leak their secrets ? 
yeah . 
yeah . 
but they ' re very fast . 
it ' s uh 
well i 
i definitely prefer not doing the transcript . 
i mean i liked transcribing because i felt like i was much closer to the data . 
yeah . 
and i had a lot more ideas like you were saying hypotheses of what ' s going on . 
huh . 
and 
uhhuh . 
huh . 
but it took a really long time and i ' d get frustrated with it . 
and i think that i would lose my 
yeah . 
i don ' t know . 
i would not be as thorough . 
not be as careful . 
i kind of miss it . 
excellent . 
uhhuh . 
i liked 
you miss 
yeah . 
oh i see . 
i liked transcribing . 
i kind of did too . 
yeah i liked transcribing . 
oh interesting . 
uhhuh . 
i you know i feel i feel like it was um more personal . 
i was 
it was more personal . 
you know the this is sort of just you know correcting other 
yeah . 
i feel like i ' m just sort of like correcting a test or something now . 
uhhuh . 
you know ? 
that somebody ' s already done . 
oh how interesting . 
and 
but i mean it ' s still it ' s still cool . 
yeah . 
yeah . 
but um 
yeah i did i did like actually doing the transcribing a little bit more . 
you don ' t tend to notice as much i don ' t think at checking as you do transcribing . 
because it ' s already there . 
so you don ' t have to pay as much attention . 
that ' s true . 
yeah . 
yeah . 
okay . 
yeah . 
and when you ' re when you ' re um just checking you ' re you ' re usually just looking for certain things that you know are going to come up . 
huh . 
and i usually assume that um the words are mostly right . 
although i you know i go through and i look and make sure all the words are right . 
but usually it ' s like punctuation and capitalization and other things that i ' m end up changing . 
and time bin corrections and things . 
and time bins . 
yeah . 
yeah . 
yeah . 
i guess i ' m such a perfectionist that i sort of combine the two when i ' m checking . 
like i act as though i ' m transcribing it . 
huh . 
really ? 
and so 
yeah i really do . 
like i ' m i tend to take a little longer maybe than other people doing checking . 
but like i i ' m like ultra careful . 
uhhuh . 
i that ' s just how i am . 
but like i 
i think i really like think of it in terms of re transcribing it almost . 
yeah . 
and i only you know 
huh . 
so 
like i i change time bins a lot . 
and i like will change what people write like for whatever words they write a lot . 
uhhuh . 
right . 
uhhuh . 
like 
so i guess i don ' t see too much of a difference . 
but that ' s just because it ' s me . 
uhhuh . 
like i think i like checking more for that reason . 
because then it ' s sort of it ' s like it ' s a it ' s a little helpful . 
uhhuh . 
it ' s like kind of you know somebody ' s helping me a little bit . 
but i ' m actually doing the work anyway . 
uhhuh . 
right . 
is kind of how i see it . 
huh . 
huh . 
huh . 
yeah . 
one thing that ' s annoying i think with checking is that a lot of times in the meetings you tend to have one or two people who talk a lot and the rest of the people just sit there until it ' s their turn to give their little report or whatever . 
uhhuh . 
huh . 
right . 
and yet you have to check the channels for if they did backchannels or if they did other things that you need to encode that weren ' t on the pre segmenter . 
but sometimes it ' s not visually easy . 
yeah . 
and so 
i ' m 
sometime i debate with myself whether it ' s really worth it to sit there and listen to the whole thing or risk missing a little bit and doing it visually . 
uhhuh . 
it ' s hard to decide sometimes . 
and this is when you crank up the visual . 
uhhuh . 
i mean you ' ve still got the maximum 
yeah . 
uhhuh . 
yeah . 
yeah okay . 
yeah . 
well sometimes when you crank up the visual all it gives you is the background speakers . 
yeah . 
and 
yeah . 
yeah it ' s true . 
yeah . 
that ' s the thing . 
it ' s true . 
that ' s the thing that makes it harder sometimes . 
yeah . 
it ' s just a big mess . 
or if they ' re breathing loudly . 
so 
yeah . 
yeah . 
yeah . 
yeah that ' s right . 
well it ' s a judgment call . 
and you can also say well you know if the backchannels were so so low on volume that they weren ' t visually obvious then you can say well it ' s reasonable not to worry about them . 
yeah . 
yeah . 
the i mean 
but also if they have it all pre segmented and they can only hear the segments they often miss what ' s in between . 
because they didn ' t even have the option of listening to what ' s in between . 
you mean the transcribers ? 
right . 
yeah . 
uhhuh . 
yeah . 
so and you know the the segmenter usually misses little things like uhhuh and yeah . 
yeah that ' s right that ' s quite right . 
and 
yeah that ' s right . 
and even bigger things . 
yeah . 
sometimes the segmenter will 
i mean you ' ve said things that weren ' t caught on the pre segmenter . 
like whispers kind of . 
yeah . 
uhhuh . 
just like oh that ' s interesting . 
okay . 
or something like that . 
well like little sighs . 
or like inbreaths . 
like as though you ' re going to start speaking . 
yeah . 
you ' re about to speak . 
which i feel is important . 
uh 
yes . 
i agree . 
huh . 
because it means that somebody ' s about to interject something . 
but then they decide for whatever reason that they ' re not going to . 
but then they don ' t . 
uhhuh . 
yeah . 
and oftentimes i find that the segmenter will miss those kind of things . 
those kind of vocal cues . 
and sometimes even laughs . 
yeah breath laughs especially . 
oh yeah . 
yeah . 
uhhuh . 
uhhuh . 
oh yeah . 
huh . 
i usually take out 
um i usually don ' t put in any of the breaths unless they ' re laughs . 
i usually don ' t transcribe the the inbreaths or things like that . 
i don ' t either . 
but i mean i don ' t take them out if they ' re already there . 
you know . 
i don ' t 
yeah it ' s it ' s good to 
if it sounds like a yawn 
i ' ve transcribed yawns . 
uhhuh . 
yeah . 
uhhuh . 
yeah . 
um 
you can hear there ' s like . 
you know ? 
it like something like that . 
yeah . 
yeah . 
uhhuh . 
it well it ' s communicative . 
uh 
yeah . 
uhhuh . 
yeah . 
or when it ' s a laugh . 
yeah . 
i mean often in the tigerfish there ' d it would say breath . 
but it it it actually seemed more like a laugh . 
yeah . 
it ' s really a laugh . 
it ' s a laugh yeah . 
but it ' s a laugh . 
it ' s actually a breath laugh . 
yeah . 
and you can 
um 
because everyone ' s laughing . 
someone has just said something funny . 
uhhuh . 
and everyone ' s like uh ha ha ha ha . 
and everyone else is laughing . 
and then the other person is like ha ha . 
right . 
yeah . 
but it ' s not a actual laugh . 
right . 
but like 
it ' s it ' s not a very committed laugh . 
i don ' t know how you do it . 
right . 
right . 
but it ' s still a laugh . 
you know ? 
it ' s no like . 
yeah it ' s like . 
yeah . 
yeah i guess i ' ll laugh because everyone else is laughing . 
but yeah . 
have you noticed that 
i ' ve noticed that tigerfish uses cough a lot where it isn ' t really a cough . 
it should be clear throat or something . 
you notice that ? 
yeah . 
yeah yeah . 
oh yeah . 
huh . 
oh yeah . 
uhhuh . 
yeah i i just fix that . 
uhhuh . 
uhhuh . 
yeah . 
i ' d fix that too . 
yeah . 
do you find 
you ' ve 
this has caused me to wonder . 
so in tigerfish ones do you find that where they ' ve where they have like dot dot ' s because it ' s segments they didn ' t hear that that you add 
you probably do add things in those places where it ' s where nothing is transcribed really because they didn ' t even hear it . 
uhhuh . 
you mean in between the segments that they did transcribe ? 
yeah . 
oh yeah . 
yeah . 
that ' s where you tend to find 
uhhuh . 
interesting . 
oh interesting . 
yeah you find little lost lost words in the middle . 
yeah . 
yeah . 
huh . 
huh . 
it ' s it depends on the person . 
i mean some people don ' t tend to do aren ' t that involved in the meeting or something . 
and they don ' t tend to say as much . 
huh . 
uhhuh . 
um backchannels or whatever . 
and some people 
i mean 
i remember transcribing one person . 
all they did was clear their throat and breathe . 
yeah . 
and then read digits . 
and then it was like the end of the meeting . 
yo . 
i think i know who you ' re talking about . 
but 
so 
but then some people tend to 
there ' s one guy in particular who does that . 
it ' s really cute actually . 
uhhuh . 
uh 
uhhuh . 
but then there are some people who are even if they ' re not actually speaking you can tell they ' re more involved or interested or something . 
yeah . 
because they ' re always uhhuh oh yeah really uhhuh um reacting yeah . 
reacting . 
uhhuh . 
yeah . 
it just occurred to me 
this is a a different kind of question . 
but i 
from having listened to all these people 
is kind of abnormal to be listening to them as if you ' re they ' re talking into your ear really . 
uhhuh . 
you know it ' s this really unusual acoustic circumstances . 
huh . 
right . 
uhhuh . 
um 
i sort of end up feeling like i know these people better than i really do . 
and it ' s like you go out to tea and there they are . 
yeah . 
and oh you were so funny in that meeting . 
and it it has this sort of unusual dynamic . 
because you know i i ' m privy to information which really by all rights i shouldn ' t be . 
huh . 
except of course they they agreed . 
yeah . 
they signed . 
they were there . 
they agreed . 
uhhuh . 
right . 
huh . 
yeah . 
but but it but it ' s sort of an unusual relationship to say 
you know you know 
if you ' re in the meeting yourself then you of course you ' d have access to all this information and all your inferences about you know whether they ' re funny or not funny or whatever . 
i remember from the very beginning i would go to tea and start recognizing voices . 
but it 
oh that ' d be interesting . 
and like turn around and be like wait that person doesn ' t look anything like i imagined them . 
yeah . 
yep . 
uhhuh . 
yeah yeah . 
yes . 
uh 
you know who i kept wanting to meet was bhaskara . 
nnn . 
he ' s he ' s on campus . 
i found this out . 
is he really ? 
yeah yeah yeah yeah . 
he has such a nice voice . 
i really like his voice . 
yeah . 
nice guy . 
nice guy . 
so i kept wanting to meet him . 
and then john told me that he ' s not around anymore . 
oh but he is . 
huh . 
or something . 
i went on i actually went on a hike with him two weeks three weeks ago . 
so 
neat . 
oh cool . 
just curious . 
yeah . 
yeah yeah yeah . 
nice guy . 
i just wanted to know what liz looked like . 
uhhuh . 
i ' ve never gotten to see her . 
nn huh . 
oh she ' s here . 
i haven ' t seen most of them . 
i haven ' t either . 
she ' s got a nice voice . 
i know she ' s here . 
i know she ' s a big part of the institute right ? 
so 
yeah i ' m sure you ' ve seen her . 
um 
uh but 
i must have . 
i just don ' t know who you know what she looks like . 
yeah . 
um 
yeah i think she ' s got a nice voice . 
uhhuh . 
but anyway . 
yeah . 
she always tends to get interrupted . 
huh . 
it ' s okay if we say nice things about these people . 
yeah . 
right ? 
yeah yeah that ' s no problem . 
i also find that some of the 
you know if someone sits there and and 
it there ' s this one who doesn ' t say much . 
but she just is always pleasant . 
you know ? 
and it ' s kind of a smiling voice and she laughs . 
yes . 
and 
i i think i know who you ' re talking about . 
what a difference . 
yeah . 
i mean it ' s like 
actually it ' s 
um she ' s she ' s just so pleasant . 
and and you know adds a lot just by virtue of that . 
yeah . 
you know can people will talk on all these technical things . 
but she ' ll she ' ll say something technical and then laugh . 
and 
it ' s it ' s very interesting the ambience that you can get through these these little things . 
yeah . 
it ' s really makes it a lot nicer to transcribe . 
because there can be a lot of heated discussions about these very technical issues . 
yeah . 
uhhuh . 
and people will have their opinions . 
and you know 
and then you can 
it ' s really nice to have a little bit of humor . 
a little bit of break away from that . 
uhhuh . 
huh . 
because it ' s hard to sit there and see like but don ' t you see you ' re being rude to this person you ' re cutting off this person . 
i know . 
and it ' s not nice . 
i started like kind of making mental friends . 
uhhuh . 
i ' m just like i really like that person . 
you know what . 
i ' m going to be his or her friend . 
i agree with you . 
and then 
i agree . 
yeah . 
it ' s it ' s really interesting also . 
huh . 
it ' s a persona . 
you get this 
huh . 
yeah . 
there ' s definitely a sense of persona . 
you definitely get an image of 
uh especially if you can relate it to what the person or what you assume the person is uh interested in academically . 
yeah . 
yeah . 
yeah . 
yeah . 
it ' s really 
some of that computer stuff i just 
oh my god . 
i ' ll just sit there like going oh fff . 
it ' s going right over my head . 
yeah . 
yeah . 
i just i start zoning out sometimes . 
like i don ' t mean to . 
but i ' m just kind of going i don ' t know what any of these acronyms are . 
yeah . 
and no idea what you ' re talking about . 
and there was a whole set of meetings that are like that . 
uhhuh . 
that ' s right . 
it wasn ' t there ? 
yeah . 
yeah . 
those were really hard . 
oh yeah . 
and they ' re writing stuff on boards and stuff that we can ' t see . 
really hard . 
yeah . 
and it ' s hard . 
and so we don ' t know what they ' re referring to . 
right . 
yeah all you hear is the squeaky pen . 
and so 
yeah . 
and you ' re like oh no . 
right . 
something something ' s going on that i don ' t know . 
yeah they ' re referring to this or that and the other thing . 
and you ' re just going no . 
yeah . 
i don ' t understand . 
no . 
yeah it ' s difficult . 
yeah you guys talked about doing a videotape . 
yes . 
um it ' s mainly a matter of two things . 
sort of 
first is the storage it ' d be so huge that uh you ' d want to be sure that it was of interest to someone . 
that it would be worthwhile doing . 
uhhuh . 
and that ' s the other thing that we don ' t have . 
someone currently doing the video thing . 
it would really be interesting . 
yeah . 
because i know it was mentioned . 
uhhuh . 
also having a meeting where you all wore blindfolds . 
yeah . 
oh ? 
really ? 
it was liz ' s idea . 
wasn ' t it ? 
that was liz ' s idea . 
yeah . 
what would be the point of that ? 
oh well it ' s a question of feedback and being able to give feedback . 
oh . 
oh wow . 
i think that would be really interesting . 
oh i see . 
that would be interesting . 
so you have to do it vocally as opposed to visually ? 
like you can ' t use gesture . 
yeah . 
exactly . 
oh . 
uh . 
yeah . 
wow . 
and you know i mean that was the meeting where um you know the the partitions wouldn ' t work . 
another possibility is partitions wouldn ' t work . 
because then it would cut off the p z m ' s from having the indirect . 
right . 
huh . 
so it ' s like you have these unusual configuration problems that that you wouldn ' t normally have . 
right . 
yeah blindfolds . 
you know and someone else said well maybe you could just turn the light out . 
there you go . 
that ' d be kind of creepy . 
but then someone else said no . 
cute . 
because there are these special lights that have to stay on all the time . 
oh . 
oh . 
oh . 
for the fire code or whatever it is . 
oh wow . 
oh . 
but then 
i would just be so worried that someone would cheat . 
you know ? 
it ' s sort of like a prisoners ' prisoners ' dilemnas game where you know everyone ' s wearing their blindfold but someone could just cheat and look see what ' s see what ' s going on . 
that ' s right . 
are you raising your hand ? 
yeah . 
totally . 
you know someone just leaves . 
you know . 
gets coffee . 
right right right . 
comes back . 
and no one knows . 
gets bored . 
yeah . 
i mean there are other things we could expand on and with in terms of the methodology . 
it ' s nice to have a core set of data though . 
and they ' ve actually done some they ' ve had some good results in terms of the digits . 
which they do in terms of having a a nice broad set of speakers doing the same thing meeting after meeting after meeting . 
uhhuh . 
huh . 
so um 
that ' s good . 
i ' m wondering 
um 
so we still technically 
uh you know i mean what should we do in terms of tea ? 
technically 
uhhuh . 
if we could hang on for fifteen more minutes and have tea ? 
yeah . 
that ' s okay . 
and then continue with this this next next week ? 
yeah sure . 
uhhuh . 
okay . 
oh yeah . 
it ' s okay . 
that ' d be great . 
okay . 
so um 
let ' s see . 
i had something that i could bring up . 
yes . 
um 
as far as ideas about looking at the data and getting ideas about whatever you said hypotheses about how to figure it out . 
yes . 
yeah . 
one thing that i i ' m you probably don ' t remember this that i was really interested in is the use of so and the use of or . 
because the way people use it in these meetings i found was 
i don ' t know if it was it if it ' s different than other people . 
i don ' t know if it ' s a computer speech thing . 
i mean computer people speech thing . 
but um 
huh . 
people tend to end utterances quite often with so or or and trailing off . 
oh yes . 
uhhuh . 
huh . 
a couple people in particular do that . 
yeah . 
uhhuh . 
yeah . 
uhhuh . 
that ' s right . 
and i found that really interesting . 
and i was curious to to figure out when that happened . 
if it happened in certain occasions and whatever . 
and i never really got around to it . 
but 
do you people 
uhhuh . 
i mean does everyone agree with that 
i mean i i share her intuition that ' s it ' s it is sort of unusual to have so used as a final uh part of a person ' s turn . 
oh yeah . 
i mean it ' s 
it didn ' t sound 
huh . 
uhhuh . 
i mean it doesn ' t sound like bizarre enough that i don ' t understand . 
uhhuh . 
but i don ' t think it ' s something that happens in just everyday speech really . 
i don ' t 
i don ' t 
no i don ' t agree necessarily . 
really ? 
i was wondering 
i do it . 
really ? 
yeah . 
i trail off with so . 
huh ? 
um 
i don ' t necessarily do it as often as the one speaker i ' m thinking of . 
um 
but i do do that because 
i think partly because i want to make sure that people know that my my thought my utterance is finished . 
yeah . 
right . 
but that it ' s not necessarily final . 
like that you ' re flexible ? 
like you can 
right . 
or you can build on it . 
right . 
or expound on it . 
uhhuh . 
i think it ' s sort of a like you guys can take from here . 
you know ? 
somebody somebody build on my thought . 
yeah . 
yeah . 
it ' s are you people also do it with but . 
it ' s kind of like a shrug . 
yeah but it tends to happen 
it ' s like a it ' s like a 
you know ? 
i mean so tends to happen when the person brings up a new idea that kind of goes against what the other people is saying . 
so 
or at least that ' s what i found . 
what do you mean ? 
like if someone in a meeting is talking about a certain thing and someone kind of interrupts or doesn ' t necessarily interrupt and says something either a new topic or a different take on the same topic will tend to use will trail off with so . 
oh . 
oh oh oh yeah okay . 
huh . 
uhhuh . 
uh like 
so you can see you might be wrong . 
but i don ' t want to actually say that . 
yes that ' s possible . 
yeah . 
uhhuh . 
kind of . 
yeah yeah . 
yeah . 
huh ? 
yeah . 
interesting . 
yeah . 
and or tends to be used with questions more than so . 
yeah . 
huh . 
that ' s true . 
but . 
i thought that was really interesting . 
or 
i ' ve heard you say so in that sort of sense . 
like uh um so in other words blah blah blah blah . 
uhhuh . 
like a sort of an 
of course 
uh uh 
but that ' s not really an example of this . 
because they don ' t just say so . 
right . 
nnn . 
but 
that ' s true . 
is that right ? 
ending with so . 
i mean i just want to be sure . 
or i maybe i ' m misunderstanding what you were 
when you end with so . 
when you end the utterance . 
when 
when you say something 
oh just just ending with so . 
yeah . 
right . 
and you say so . 
yeah . 
okay . 
yeah . 
i i could get all those extra signatures . 
it 
but i don ' t know . 
so . 
yeah . 
right . 
yeah to me it ' s like a vocal shrug . 
it ' s 
yeah . 
that ' s a very nice characterization . 
uhhuh . 
interesting . 
i ' d definitely like to look more at that if i can . 
but 
that ' s cool . 
huh huh . 
i think people end in but a lot too . 
and i feel that that means that they want somebody else to take it up . 
uhhuh . 
or somebody just sort of like you know take it from here . 
oh yeah . 
uhhuh . 
so you know blah blah blah blah blah . 
but . 
but i ' m not really sure . 
once again a 
so you can you could finish my thought . 
yeah so 
is it a shrug ? 
would you say it ' s another shrug ? 
um 
or 
it ' s a different kind of shrug though . 
i feel like it i feel like it sort of um asks for somebody else to uh put input in now . 
okay . 
yeah . 
i could see that . 
i think it shows less of confident like less confidence in what they just said . 
uhhuh . 
okay . 
or giving permission ? 
yeah . 
okay . 
yeah . 
in a way . 
same with i don ' t know . 
yeah . 
you can also end an utterance with uh blah blah blah . 
but i don ' t know . 
huh . 
yeah . 
like that . 
uhhuh . 
yeah . 
like i feel like maybe that ' s similar to but . 
yeah . 
uhhuh . 
more similar than to so i think . 
yeah that ' s interesting . 
to so . 
yeah . 
i think so too . 
huh ? 
huh ? 
interesting . 
what about um the way people treat when they give a joke ? 
i mean and and they ' re like they laugh . 
and then after the laugh they say uh . 
i mean 
if you 
so it ' s like ha ha ha . 
uh . 
i mean 
do you have you run across this ? 
yeah . 
yeah . 
huh . 
and it ' s like to me i i think i ' ve heard comedians do that . 
there ' s there ' s something there about 
you know you you make a joke . 
and then you have an uh in there somehow . 
which i don ' t really understand the function of . 
maybe it ' s like saying like this is funny . 
do you 
but maybe it shouldn ' t be funny . 
or this is funny . 
but maybe it ' s funny for some sort of perverse reason . 
or maybe it ' s just a link to get back to the conversation or something . 
huh . 
like to connect it with what is going on elsewhere . 
huh . 
well . 
so the one i ' m thinking of is like if like ha ha . 
uh you say you would say like um . 
uh like 
okay . 
so he ' s laughing . 
ha ha . 
and then he ' d go uh . 
oh like kind of kind of laughing with it . 
and 
yeah . 
kind of . 
in a way . 
yeah . 
yeah . 
kind of like uh . 
you know ? 
yeah . 
and to me that ' s more of like the maybe this shouldn ' t be funny . 
but it is . 
maybe this is funny because it ' s kind of disgusting or perverse in some way . 
huh . 
huh . 
yeah . 
it ' s possible . 
now what i ' m thinking 
i didn ' t have the extra the extra um what do you say nuances in the uh which you just which you just did . 
wi 
oh okay . 
however the context fits . 
i mean that ' s an interesting take on it i think . 
huh . 
it ' s possible . 
it ' s possible . 
so you meant just sort of like a just a normal uh ? 
it ' s just a normal uh . 
uhhuh . 
yeah . 
but it ' s stuck in 
maybe it ' s a little louder than usual . 
it ' s not any of the extra um you know glottal thing . 
huh . 
meaning let ' s keep going ? 
maybe it means that . 
well 
but it just seems like it ' s more prominent than 
you know it really is like a placeholder of some sort . 
uh . 
like 
which i think is self reflexive in in the sort of brings focus back onto the jokemaker . 
that ' s 
yeah . 
maybe if maybe it ' s when people don ' t laugh enough or something . 
but 
yeah . 
yeah that ' s possible . 
i don ' t know . 
yeah like let ' s come back to the original subject . 
okay . 
and i will take it from there . 
oh it could be . 
yes that ' s possible . 
maybe . 
it ' s possible . 
because i ' ve heard um morgan do that . 
exactly who i was thinking of actually . 
yeah . 
he does that a lot . 
uhhuh . 
yeah exactly . 
yeah . 
for obvious reasons probably . 
if that ' s the way he uses it . 
that ' s true . 
that would the 
and he does continue after that . 
but it ' s just you know to say uh you to say uh while you ' re laughing it ' s just to me it ' s an interesting category . 
right . 
i think it may almost have to do with like okay . 
i told a joke . 
now everyone ' s laughing . 
and now it ' s common courtesy i ' ll sort of tell everyone to stop laughing . 
you know . 
so you don ' t offend me about how good my joke was . 
you know . 
it ' s almost like okay . 
uh . 
okay . 
my joke ' s over . 
you know you can stop laughing now . 
right . 
that ' s possible . 
huh . 
giving them permission to 
yeah . 
you know . 
because it ' s like how do you you know how much do you laugh after someone ' s joke ? 
huh ? 
i don ' t know about permission . 
yeah . 
yeah yeah yeah . 
to tell them how much you enjoyed it . 
be polite or whatever . 
or 
yeah . 
or how long do you wait after the joke 
to keep going with the meeting . 
to 
right . 
yeah . 
very interesting . 
interesting . 
because sometimes you can get on digressions that just last for like minutes at a time . 
right . 
yes . 
and people are just hysterical . 
and they ' re like what were we talking about . 
i don ' t know . 
yeah . 
that ' s that ' s 
huh okay . 
it ' s hard when people get really really like into their laughing and start talking at the same time . 
yeah . 
it ' s hard to figure out what they ' re what they ' re talking about . 
and also they don ' t tend to talk very 
there ' s a lot of disfluencies when they ' re laughing and talking . 
yeah . 
definitely . 
huh . 
it ' s hard to 
sometimes they make me laugh so hard . 
because they ' ll just be talking about something technical . 
yeah . 
and i ' ll be so bored . 
and then suddenly they ' ll say something that they only just sort of chuckle at . 
and then i laugh at for the next like twenty minutes . 
because i think it ' s so funny . 
like one time everybody was doing the um digits . 
and they were all doing it at the same time . 
and they started off kind of shaky . 
oh right . 
they were like oh do we want to do this at the same time . 
you know that ' s you know let ' s not all start laughing . 
and then they all did it at the same time . 
and one person ended up at the very end doing the digits . 
and everybody had finished . 
yeah ! 
and he had like two more lines to go . 
go 
and when he ended somebody turned to him and went you lose . 
oh 
and i just kept laughing and laughing and laughing . 
johno keeps making comments about the transcribers . 
yes . 
yeah . 
it ' s the funniest thing . 
yes . 
he he ' ll like 
what does he say ? 
he ' s very funny . 
say he ' ll say like mean things about the transcribers . 
he ' ll be like 
why ? 
oh but i don ' t mean the transcribers we have here of course . 
oh . 
like well sometimes he ' ll do that . 
yeah . 
but sometimes he doesn ' t . 
and sometimes he ' ll just be like uh you know um here transcribers . 
try transcribing this . 
yeah . 
yeah like when they do random sounds that you have no idea 
like thanks . 
he ' s very funny . 
right . 
yeah . 
i i started laughing with something he said the other day . 
it was it was the beginning of a meeting . 
and it hadn ' t gotten far into it . 
and 
and he ' s he ' s doing this one of these mock fights with nancy . 
which he does . 
have you run across these mock fights ? 
uhhuh . 
and he he says um something like 
uh 
i and he ' s they they have this nice mutual condescending joking thing going on . 
and he says well i could explain this to you . 
i have a better laugh than you do . 
the transcribers told me so . 
and it went on a little longer . 
but it ' s it ' s like this really 
yeah . 
and then at one point she you know at another meeting she she was not sure which channel she was on . 
and he said well i think you ' re on channel so - and - so . 
and then she said well no . 
shouldn ' t it be channel so - and - so . 
and he says well no . 
it should be channel so - and - so . 
and then it turned out it was channel so - and - so . 
which he said . 
and and she said he he said i bested you again nancy . 
and she said yes . 
that ' s my recollection of all of our meetings together . 
oh my god ! 
oh no . 
they have this really nice 
you know it ' s really 
those sorts of things it ' s true . 
you know it ' s like it really does liven things up to have the uh the nice interrelationships . 
yeah . 
uhhuh . 
yeah . 
huh . 
i think 
i i found that ' s a nice aspect of a lot of these meetings . 
the uh the uh uh little periods of humor like that . 
yeah . 
all right . 
well so do we would would we could do digits if we so desired . 
if if we wanted to do that . 
woo hoo ! 
uh the digits task . 
let ' s do simultaneous digits . 
no let ' s let ' s not . 
let ' s do simultaneous digits . 
we 
can somebody explain to me why you do digits ? 
no no let ' s not . 
no you don ' t ? 
i still don ' t really know . 
okay the idea is that you have then um you have ground truth . 
you know exactly what they ' re supposed to have said . 
and then of course sometimes we go through and actually um people do double check that they read them correctly and all . 
huh . 
huh . 
yeah . 
so that we ' re sure . 
as you ' ve done . 
i remember i did that a little bit . 
yeah i did that once too . 
yeah . 
and yeah you must have too . 
yeah yeah . 
and you did also ? 
we we are meant to be transcribing if they ' re just left in the the curly brackets ? 
kind of early on . 
no . 
because it ' s it ' s it should be able to be taken care of efficiently with this interface . 
i mean if the tigerfish people do it then you know leave it . 
yeah they do write the numbers in . 
the 
yeah . 
that ' s fine . 
yeah i ' ve been just leaving it . 
and sometimes they don ' t . 
yeah . 
yeah . 
oh i ' ve been writing the numbers just because i wasn ' t sure what to do . 
sometimes they don ' t . 
well if you do that ' s that ' s all right as well . 
oh really ? 
you don ' t have to ? 
you don ' t have to . 
oh okay . 
huh . 
because uh we ' re we have the assumption that we ' ll take care of it this in this other way . 
but in any case the idea is that you have ground truth . 
oh . 
you know exactly what the person should have said . 
and you check to be sure . 
and usually there aren ' t many errors uh when they were checked . 
um and then you have this multiplicity of voices uh reading these things . 
and you can do really good speech recognition that way . 
so they have some papers out that they ' ve done this . 
it ' s really it ' s been very fruitful in terms of the analyses . 
huh . 
huh . 
it ' s nice to have you know a standard . 
uh you know it ' s like uh psychological approach also that you like to have some standard stimulus here . 
uhhuh . 
oh yeah . 
and then you can 
no i totally agree . 
yeah . 
uhhuh . 
i i agree . 
i think it ' s a nice it ' s a nice design feature . 
where ' s the little things that ' s supposed to say transcript l dash blah blah blah ? 
oh it ' s at the top . 
yes you run across that . 
let ' s see . 
i guess it would be 
it ' s up there . 
it ' s right here . 
oh i see . 
yeah i looked for that too . 
uhhuh . 
up there at the top . 
uh oh . 
okay . 
okay . 
so i have a question . 
yeah . 
because now i ' m looking at this and i realize i don ' t know the answer . 
is 
um 
sometimes when people are reading zero they say o . 
yeah . 
yes . 
yeah . 
and sometimes they say zero . 
uhhuh . 
but 
and i thought that there must be an indication here . 
used to be . 
that ' s what i thought too . 
used to be . 
oh . 
huh . 
that read o or read zero . 
oh . 
this they changed them . 
initially it was words all spelled out . 
uhhuh . 
so o n e . 
oh . 
huh . 
oh my ! 
yes . 
oh wow . 
yeah . 
and that was like a stroop test in some ways . 
it took a lot of 
when i was doing those i had to really concentrate . 
yeah . 
it was like one seven . 
you know it was like you really had to let ' s see the words and the numbers . 
yeah you ' re not used to seeing the numbers like that . 
and 
yeah . 
and then you ' d have an o h periodically . 
and um they were initially spelled out that way . 
huh . 
huh . 
one or the other . 
i see . 
so that ' s why . 
but we converted them to this format . 
and then the idea 
i mean you could conceivably put an o h or a zero for the o s and still have this benefit . 
but i think that the idea is that people can choose what they think is most natural for them to say in those those locations . 
right . 
and you know maybe there ' d be 
uhhuh . 
so it ' s optional ? 
huh . 
you can say one or the other ? 
yes . 
uhhuh . 
okay . 
huh . 
so um 
oh can i ask also ? 
sure . 
um it says it looks like the groupings are important . 
but some of the transcripts i ' ve seen they don ' t have any commas or breaks . 
it ' s just a string of numbers . 
so we should be adding the breaks if 
yes . 
well see uh also this has been a a change in the procedure that used to be that they were like uh one long string . 
oh okay . 
different sized strings . 
but to have them broken up like this it ' s it ' s been about uh maybe half a year that that this or maybe maybe seven months i don ' t know maybe longer that they ' ve gotten actually broken up within the line . 
huh . 
so the idea is to pause when you see that . 
but in the transcriptions i mean we don ' t have to deal with that . 
because when the other interface deals with it then they break it up or whatever . 
no . 
that ' s right . 
break it up more finely . 
yeah . 
but if you can clearly hear pauses and there ' ve not been transcribed we should be adding the commas or not ? 
though the one i ' m working on now is like that . 
well 
i would say don ' t worry about that . 
because um this is 
okay . 
again you know it it ' d be nice to get the words right . 
but um 
the uh the interface that these guys used uh allows you to set the time boundaries really accurately . 
uhhuh . 
so it ' s not so important . 
it ' s more important to focus on the words . 
because there we don ' t know the ground truth . 
uhhuh . 
so 
okay so 
are we going to do them together then ? 
or no ? 
well i don ' t know . 
how do you feel ? 
yeah i don ' t care . 
i mean 
what we could do is we could do it together one week . 
whatever . 
and then separate the next . 
or something like that . 
sure . 
to give the variety . 
sure . 
whatever . 
we 
sure . 
why don ' t we do them together this time ? 
just because in the interest of time to get you out in time . 
okay . 
okay . 
okay . 
okay . 
so um 
we just start out we and you you say transcript l whatever it is . 
and then launch into the numbers . 
and then pause between the the gaps . 
sure . 
and then 
i guess you ' re supposed to treat 
pause after each line ? 
yeah . 
you well you ' re supposed to treat each line as kind of like a little sentence . 
what do they say ? 
okay . 
each line into smaller groups . 
please read each string as if you were giving it to someone over the telephone using the groupings indicated . 
huh . 
uhhuh . 
pause briefly between lines . 
yes . 
right . 
there you go . 
okay . 
okay . 
so here we go . 
okay . 
all right . 
ready . 
set . 
go . 
ugh ! 
so i didn ' t send out agenda items . 
because until five minutes ago we only had one agenda item . 
and now we have two . 
so and uh 
okay . 
so just to repeat the thing that we said last week 
it was there ' s this suggestion of alternating weeks on more uh automatic speech recognition related or not . 
right . 
was that sort of the division ? 
so which week are we in ? 
well we haven ' t really started . 
but i thought we more we more or less did meeting recorder stuff last week . 
so i thought we could do uh 
i thought we had a thing about speech recognition last week too . 
but i figure also if they ' re short agenda items we could also do a little bit of each . 
yeah . 
yeah . 
so 
i seem to be having difficulty getting this adjusted . 
here we go . 
okay . 
so uh as most of you should know i did send out the consent form thingies . 
and uh 
so far no one has made any ach any comments on them . 
so no no one has bleeped out anything . 
um yeah 
so 
i don ' t expect anyone to . 
but . 
so what follows 
at some point you go around and get people to sign something ? 
no . 
we had spoken about this before . 
and we had decided that they have they only needed to sign once . 
yeah but i ' ve forgotten . 
and the agreement that they already signed simply said that we would give them an opportunity . 
so as long as we do that we ' re covered . 
and how long of an opportunity did you tell them ? 
uh july fifteenth . 
july fifteenth . 
oh so they have plenty of time . 
yep . 
and 
given that it ' s that long 
um um 
why was that date chosen ? 
you just felt you wanted to 
jane told me july fifteenth . 
so that ' s what i set it . 
oh okay . 
oh i just meant that that was the release date that you had on the data . 
oh i i didn ' t understand that there was something specific . 
i uh 
i thought 
you you had 
i don ' t 
i had heard july fifteenth . 
so that ' s what i put . 
no the only the only mention i recall about that was just that july fifteenth or so is when this meeting starts . 
uhhuh . 
so 
that ' s right . 
that ' s why . 
oh i see . 
you said you wanted it to be available then . 
okay . 
right . 
i didn ' t mean it to be the hard deadline . 
it ' s fine with me if it is . 
or we 
but i thought it might be good to remind people two weeks prior to that . 
in case uh you know by the way this is your last 
right . 
uh yeah 
we probably should have talked about it . 
because because if we want to be able to give it to people july fifteenth 
if somebody ' s going to come back and say okay i don ' t want this and this and this used uh clearly we need some time to respond to that . 
right ? 
yeah as i said we i just got one date . 
damn ! 
yeah . 
and that ' s the one i used . 
so but i can send a follow up . 
yeah . 
i mean it ' s almost all us . 
i mean the people who are in the this meeting was uh these the meetings that in are in set one . 
was my was my response okay ? 
that ' s right . 
i just wrote you replied to the email saying they ' re all fine . 
right i mean that ' s fine . 
okay good . 
i we don ' t my understanding of what we had agreed upon when we had spoken about this months ago was that uh we don ' t actually need a reply . 
that makes it easy . 
we just need to tell them that they can do it if they want . 
okay . 
i just didn ' t remember . 
but 
and so no reply is no changes . 
and he ' s got it so that the default thing you see when you look at the page is okay . 
okay . 
so that ' s very clear . 
all the way down the page okay . 
and they have two options . 
they can change it to one of them is censor and the other one is incorrect . 
is it is your word is incorrect ? 
right . 
which means also we get feedback on if um there ' s something that they that needs to be adjusted . 
because i mean these are very highly technical things . 
i mean it ' s an added uh level of checking on the accuracy of the transcription as i see it . 
but in any case people can agree to things that are wrong . 
well 
so 
yeah the reason i did that it was just so that people would not censor not ask to have stuff removed because it was transcribed incorrectly . 
and the reason i liked it was because 
as opposed to uh 
was because it um it gives them the option of uh being able to correct it . 
right . 
approve it and correct it . 
and um 
so you have it nicely set up so they email you . 
and uh 
when they submit the form it gets processed and emailed to me . 
uhhuh uhhuh . 
so 
and i wanted to say the meetings that are involved in that set are robustness and meeting recorder . 
the german ones will be ready for next week . 
those are three three of those . 
a different set of people . 
and we can impose 
the german ones ? 
uh well 
yeah those uh 
n s a . 
okay i spoke loosely . 
the the german french sorry the german dutch and spanish ones . 
spanish 
yeah . 
uhhuh . 
oh those are the n s a meetings ? 
those are 
the non native 
yeah uhhuh . 
oh oh okay . 
german dutch swiss and spanish . 
the all non native 
that ' s that ' s that ' s 
uhhuh . 
uhhuh . 
okay i ' d i 
yeah it ' s the other group . 
it was the network network services group . 
okay . 
uhhuh . 
yeah . 
yeah exactly yeah . 
i didn ' t mean to isolate them . 
otherwise known as the german dutch and spanish . 
yeah sorry . 
uhhuh . 
it was it was not the best characterization . 
but what what i meant to say was that it ' s the other group that ' s not no no overlap with our present members . 
and then maybe it ' d be good to set an explicit deadline . 
something like a week before that . 
uh july fifteenth date . 
or two weeks before . 
i mean i would suggest we discuss 
i mean if we ' re going to have a policy on it 
that we discuss the length of time that we want to give people . 
uhhuh . 
so that we have a uniform thing . 
so that ' s a month . 
which is fine . 
twelve hours . 
well the only thing i said in the email is that the data is going to be released on the fifteenth . 
i mean it seems 
i didn ' t give any other deadline . 
uhhuh . 
so my feeling is if someone after the fifteenth says wow i suddenly found something we ' ll delete it from our record . 
we just won ' t delete it from whatever ' s already been released . 
huh that ' s a little bit difficult . 
what else can we do ? 
yeah . 
if someone says hey look i found something in this meeting and it ' s libelous and i want it removed what can we do ? 
we have to remove it . 
well that ' s true . 
i i agree with that part . 
but i think that it would it uh we need to have uh a a a message to them very clearly that beyond this date you can ' t make additional changes . 
i mean 
um 
i i i i think that somebody might request something . 
even though we say that . 
but i think it ' s good to at least start some place like that . 
so if we agreed okay how long is a reasonable amount of time for people to have ? 
uhhuh good . 
if we say two weeks or if we say a month 
i think we should just say that 
say that you know as um per the the the uh page you signed you have the ability to look over this stuff and so forth . 
and uh because we these uh 
i would i would imagine some sort of generic thing that would say because we uh will continually be making these things available to other researchers uh this can ' t be open ended . 
and so uh uh please give us back your response within this you know within this amount of time whatever time we agree upon . 
well did you read the email and look at the pages i sent ? 
did i ? 
no i haven ' t yet . 
no okay well why don ' t you do that ? 
no just 
and then make comments on what you want me to change . 
no no i ' m not saying that you should change anything . 
i ' m what i ' m what i ' m i ' m trying to spark a discussion hopefully among people who have read it . 
so that that you can you can uh decide on something . 
uhhuh . 
so i ' m not telling you what to decide . 
uhhuh . 
i ' m just saying you should decide something . 
i already did decide something . 
okay . 
and then 
and that ' s what ' s in the email . 
yeah yeah okay so 
and if you disagree with it why don ' t you read it and give me comments on it ? 
yeah . 
well 
i i think that there ' s one missing line . 
well the one thing that i did read and that you just repeated to me was that you gave the specific date of july fifteenth . 
uhhuh . 
and you also just said that the reason you said that was because someone said it to you . 
right . 
so what i ' m telling you is that what you should do is come up with a length of time that you guys think is enough . 
and you should use that rather than this date that you just got from somewhere . 
that ' s all i ' m saying . 
okay . 
okay . 
i i have one question . 
this is in the summer period . 
and presumably people may be out of town . 
but we can make the assumption can ' t we that um they will be receiving email uh most of the month . 
right ? 
because if someone 
it well it well you ' re right sometimes somebody will be away . 
and uh you know there ' s uh for any length of time that you uh choose there is some person sometime who will not end up reading it . 
okay . 
that ' s it ' s you know just a certain risk to take . 
so maybe when 
am i on by the way ? 
i don ' t know . 
oh . 
you should be . 
hello hello ? 
you should be channel b . 
oh okay all right so the 
um 
maybe we should say in 
you know when the whole thing starts when they sign the agreement that 
you know specify exactly uh what you know how how they will be contacted . 
and they can you know they can be asked to give a phone number and an email address or both . 
and um then 
we did that i i believe . 
right . 
so and then you know say very clearly that if they don ' t if we don ' t hear from them you know as morgan suggested by a certain time or after a certain period after we contact them that is implicitly giving their agreement . 
yeah . 
well they ' ve already signed a form . 
right . 
and the form says 
and nobody nobody really reads it anyway . 
so 
and the and the form was approved by human subjects . 
says that . 
right . 
well if that ' s if that ' s already if 
uh the 
so uh that ' s going to be a little hard to modify . 
well the form well the form doesn ' t say if uh you know if you don ' t respond by x number of days or x number of weeks 
i see . 
uh 
oh okay . 
so what does it say about the the the process of of uh the review process ? 
it doesn ' t have a time limit . 
that you ' ll be provided access to the transcripts . 
oh okay . 
and then uh allowed to remove things that you ' d like to remove before it goes to the general uh larger audience . 
huh . 
right . 
oh . 
here . 
you can read what you already signed . 
there you go . 
i guess when i read it um 
okay . 
i ' m not as diligent as chuck . 
but i had the feeling i should probably respond . 
and tell adam like i got this and i will do it by this date . 
and if you don ' t hear from me by then you know in other words responding to your email once right away saying as soon as you get this could you please respond . 
right . 
and then if you if the person thinks they ' ll need more time because they ' re out of town or whatever they can tell you at that point . 
because 
oh i just i didn ' t want to do that . 
because i don ' t want to have a discussion with every person if i can avoid it . 
well it ' s 
so what i wanted to do was just send it out . 
and say on the fifteenth the data is released . 
uhhuh . 
if you want to do something about it do something about it . 
but that ' s it . 
i i kind of like this . 
well 
okay so we ' re assuming that 
yeah . 
well that ' s that would be great if 
but you should probably have a legal person look at this . 
and make sure it ' s okay . 
because if you if you uh do this and you then there ' s a dispute later and uh some you know someone who understands these matters concludes that they didn ' t have uh you know enough opportunity to actually exercise their their right 
or they they might never have gotten the email . 
because although they signed this they don ' t know by which date to expect your email . 
and so someone whose machine is down or whatever 
i mean we have no 
uhhuh . 
internally we know that people are there . 
well okay let me let me reverse this . 
but we have no confirmation that they got the mail . 
so let ' s say someone i send this out . 
and someone doesn ' t respond . 
do we delete every meeting that they were in ? 
i don ' t think so . 
well then 
no . 
it we ' re hoping that doesn ' t happen . 
but that ' s why there ' s such a thing as registered mail . 
that will happen . 
or 
that will happen . 
that will absolutely happen . 
right . 
because people don ' t read their email . 
or they ' ll read and say i don ' t care about that . 
i ' m not going to delete anything . 
and they just won ' t reply to it . 
maybe uh do we have mailing addresses for these people ? 
no . 
no . 
we have what they put on the speaker form . 
oh . 
which was just generic contact information . 
most 
but the ones that we ' re dealing with now are all local . 
well then 
except the ones who 
i mean we we ' re totally in contact with all the ones in those two groups . 
huh . 
okay . 
so maybe uh i you know that ' s not that many people . 
and if i if uh 
there is an advantage to having them admit . 
and if i can help with with processing that i will . 
it ' s it ' s there is an advantage to having them be on record as having received the mail and indicating 
yeah i mean i thought we had discussed this like a year ago . 
yes we did . 
and so it seems like this is a little odd for it to be coming up yet again . 
you ' re right . 
well i you know but sometimes 
well we we haven ' t experienced it before . 
so 
that ' s right . 
right ? 
so 
you ' ll either wonder at the beginning or you ' ll wonder at the end . 
need to get it right . 
i mean there ' s no way to get around 
it ' s pretty much the same amount of work . 
except for an additional email just saying they got the email . 
yeah . 
and maybe it ' s better legally to wonder before 
you know a little bit earlier than 
well 
it ' s much easier to explain this way . 
okay well why don ' t you talk 
to have it on record . 
morgan can you talk to our lawyer about it ? 
and find out what the status is on this . 
because i don ' t want to do something that we don ' t need to . 
yeah but huh 
because 
what i ' m telling you people won ' t respond to the email . 
no matter what you do there ' re going to be people who you ' re going to have to make a lot of effort to get in contact with . 
i mean it ' s 
huh . 
well then we make the effort . 
and do we want to spend that effort ? 
it ' s kind of like signing up for a mailing list . 
we make the effort . 
they have opt in and opt out . 
and there are two different ways . 
i mean and either way works . 
probably i mean . 
except i really think in this case 
i i ' m i agree with liz that we need to be in the clear . 
and not have to after the fact say oh but i assumed 
and oh i ' m sorry that your email address was just accumulating mail without notifying you . 
if this is a purely administrative task we can actually have administration do it . 
you know . 
oh excellent . 
but the thing is that you know i i i think without going through a whole expensive thing with our lawyers from my previous conversations with them my my sense very much is that we would want something on record as indicating that they actually were aware of this . 
yes . 
well we had talked about this before . 
and i thought that we had even gone by the lawyers asking about that . 
uhhuh . 
and they said you have to they ' ve already signed away the with that form . 
that they ' ve already signed once . 
i don ' t remember that this issue of the time period allowed for response was ever covered . 
yeah . 
okay . 
yeah we never really talked about that . 
or the date at which they would be receiving the email from you . 
yeah . 
or or how they would indicate 
they probably forgot all about it . 
we certainly didn ' t talk uh about with them at all about uh the manner of them being made the uh uh materials available . 
yeah . 
we do it like with these 
that was something that was sort of just within our implementation . 
we can use it we can use a a ploy . 
okay . 
like they use to um 
you know that when they serve like 
uh uh uh uh 
you know like dead beat dads . 
they they they make it look like they won something in the lottery . 
and then they open the envelope . 
and that 
and they ' re served . 
right ? 
because and then the the the the thing is served . 
so you just make it you know oh you won . 
you know go to this web site . 
and you ' ve uh you ' re 
that ' s why you never open these things that come in the mail . 
that one . 
yeah . 
well it ' s just we ' ve gone from one extreme to the other where at one point a few months ago morgan was you were saying let ' s not do anything . 
right no i it might 
well it doesn ' t matter . 
it it might well be the case 
and now we ' re 
it might 
we ' re saying we have to follow up each person and get a signature . 
right . 
i mean what are we going to doing here ? 
it might well be the case that that this is perfectly you know this is enough to give us a basis to just uh assume their consent if they don ' t reply . 
well 
uhhuh . 
but i ' m not you know me not being a lawyer i wouldn ' t just want to do that without having the the expert uh opinion on that . 
and how many people 
then i think we had better find out . 
altogether we ' ve got twenty people these people are people who read their email almost all the time . 
so that we can find a 
yeah . 
let me look at this again . 
right . 
i i really don ' t see that it ' s a problem . 
i i think that it ' s a common courtesy to ask them uh to expect for them to uh be able to have us try to contact them . 
for for 
just in case they hadn ' t gotten their email . 
i think they ' d appreciate it . 
yeah my adam my my view before was about the nature of what was of the presentation . 
uhhuh . 
of of how my my 
the things that we ' re questioning were along the lines of how easy 
uh 
how how much implication would there be that it ' s likely you ' re going to be changing something as opposed to 
uhhuh . 
that was the kind of dispute i was making before . 
uhhuh . 
i remember that . 
but um the attorneys i uh i can guarantee you the attorneys will always come back with 
and we have to decide how stringent we want to be in these things . 
but they will always come back with saying that um you need to you want to have some paper trail or which includes electronic trail that they have uh in fact okay ' d it . 
uhhuh . 
so um 
i think that if you if we send the email as you have . 
and if there ' s half the people say who don ' t respond at all by you know some period of time we can just make a list of these people . 
and hand it to uh 
you know just give it to me . 
and i ' ll hand it to administrative staff or whatever . 
right . 
and they ' ll just call them up and say you know have you 
is is this okay and would you please mail you know mail adam that it is if if it you know is or not . 
so you know we can we can do that . 
the other thing that there ' s a psychological effect that at least for most people that if they ' ve responded to your email saying yes i will do it or yes i got your email they ' re more likely to actually do it later than to just ignore it . 
uhhuh . 
and of course we don ' t want them to bleep things out . 
but it it ' s a little bit better if we ' re getting the their uh final response once they ' ve answered you once than if they never answer you ' d at at all . 
that ' s how these mailing houses work . 
so i mean it ' s not completely lost work . 
because it might benefit us in terms of getting responses . 
uhhuh . 
you know an official okay from somebody is better than no answer even if they responded that they got your email . 
and they ' re probably more likely to do that once they ' ve responded that they got the email . 
i also think they ' d just simply appreciate it . 
i think it ' s a good a good way of of fostering goodwill among our subjects . 
well our participants . 
i think the main thing is i mean what lawyers do is they always look at worst cases . 
sending lots of spam . 
so they so so that ' s what they ' re paid to do . 
yep . 
and so it is certainly possible that uh somebody ' s server would be down or something . 
and they wouldn ' t actually hear from us . 
and then they find this thing is in there . 
and we ' ve already distributed it to someone . 
so what it says in there in fact is that they will be given an opportunity to blah blah blah . 
uhhuh . 
but if in fact if we sent them something or we thought we sent them something but they didn ' t actually receive it for some reason um then we haven ' t given them that . 
well so how far do we have to go ? 
do we need to get someone ' s signature ? 
or is email enough ? 
do we have to have it notarized ? 
email is enough . 
i mean 
okay . 
yeah . 
i mean i ' ve been through this 
i mean i ' m not a lawyer . 
but i ' ve been through these things a things like this a few times with lawyers now . 
uhhuh . 
so i i i ' m pretty comfortable with that . 
do you track um when people log in ? 
to look at the 
uh if they submit the form i get it . 
uhhuh . 
if they don ' t submit the form it goes in the general web log . 
but that ' s not sufficient . 
huh 
right ? 
because if someone just visits the web site that doesn ' t imply anything in particular . 
except that you know they got the mail . 
uhhuh that ' s right . 
right . 
i i could get you on the notify list if you want me to . 
i ' m already on it . 
for that directory ? 
uhhuh . 
okay great . 
so again hopefully um this shouldn ' t be quite as odious a problem either way . 
uh in any of the extremes we ' ve talked about . 
because uh we ' re talking a pretty small number of people . 
for this set i ' m not worried . 
because we basically know everyone on it . 
uhhuh . 
huh 
uhhuh . 
you know they ' re all more or less here . 
or it ' s it ' s eric and dan and so on . 
but for some of the others you ' re talking about visitors who are gone from icsi whose email addresses may or may not work . 
uhhuh . 
uhhuh . 
oh . 
and 
so what are we going to do when we run into someone that we can ' t get in touch with ? 
i don ' t think uh they ' re so recent these visitors . 
i and and i they ' re also so 
uhhuh . 
uhhuh . 
they ' re prominent enough that they ' re easy to find through 
i i mean i i i ' ll be able to if you have any trouble finding them i really think i could find them . 
other methods ? 
okay . 
yeah because it what it what it really does promise here is that we will ask their permission . 
um and i think you know if you go into a room and close the door and and ask their permission and they ' re not there it doesn ' t seem that 
that ' s the intent of uh meaning here . 
so 
well the the question is just whether how active it has to be . 
i mean because they they filled out a contact information . 
and that ' s where i ' m sending the information . 
right . 
and so far everyone has done email . 
there isn ' t anyone who did uh any other contact method . 
well the way icsi goes people uh who uh were here ten years ago still have have forwards to other accounts and so on . 
yeah . 
so it ' s unusual that that they uh 
so my original impression was that that was sufficient . 
that if they give us contact information and that contact information isn ' t accurate that we fulfilled our burden . 
yeah . 
then they just come back . 
all my files were still here . 
same as us . 
i just 
so if we get to a boundary case like that then maybe i will call the attorney about it . 
yeah . 
okay . 
but you know hopefully we won ' t need to . 
i i just don ' t think we will . 
all right . 
for all the reasons that we ' ve discussed . 
so we ' ll we ' ll see if we do or not . 
yep and we ' ll see how many people respond to that email . 
yeah . 
so far two people have . 
yeah i think very few people will . 
so 
and and and you know people people see long emails about things that they don ' t think is going to be high priority they typically uh don ' t don ' t read it or half read it . 
right . 
because people are swamped . 
but 
and actually 
um i i didn ' t anticipate this . 
so i that ' s why i didn ' t give this comment . 
and it i this discussion has made me think it might be nice to have a follow up email within the next couple of days saying by the way you know we want to hear back from you by x date . 
and please 
and then add what liz said . 
please uh respond to please indicate you received this mail . 
uh or well maybe even additionally uh um 
even if you ' ve decided you have no changes you ' d like to make if you could tell us that . 
respond to the email yep . 
uhhuh . 
right that would that would definitely work on me . 
yeah . 
it is the first time through the cycle . 
you know it makes you feel like 
um 
if you were going to if you ' re predicting that you might not answer you have a chance now to say that . 
whereas i i mean i would be much more likely myself 
and the other 
given all my email to respond at that point saying you know what i ' m probably not going to get to it or whatever . 
rather than just having seen the email thinking i might get to it . 
and never really uh pushing myself to actually do it until it ' s too late . 
yeah i was 
i was thinking that it also lets them know that they don ' t have to go to the page to accept this . 
right right that ' s true . 
right . 
i mean i i 
yeah . 
so that way they could they can see from that email that if they just write back and say i got it no changes they ' re off the hook . 
yeah . 
they don ' t have to go to the web page . 
and 
i mean the other thing i ' ve learned from dealing with dealing with people sending in reviews and so forth uh is um if you say you ' ve got three months to do this review um people do it you know two and seven eighths months from now . 
yeah that ' s true . 
right . 
if you say you ' ve got three weeks to do this review they do do it you know two and seven eighths weeks from now they do the review . 
and um so 
if we make it a little less time i don ' t think it ' ll be that much 
well and also if we want it ready by the fifteenth that means we better give them deadline of the first . 
if we have any prayer of actually getting everyone to respond in time . 
there ' s the responding part . 
and there ' s also what if 
uh i mean i hope this doesn ' t happen . 
what if there are a bunch of deletions that have to get put in and changes ? 
right . 
then we actually have to deal with that . 
uhhuh some lead time . 
if we want it to 
ugh ! 
disk space . 
oh my god ! 
by the way has has jeremy signed the form ? 
i hadn ' t thought about that . 
okay . 
that for every meeting 
any meeting which has any bleeps in it we need yet another copy of . 
oh . 
just that channel ? 
can ' t you just do that channel ? 
oh no we have to do 
no of course not . 
you need all the channels . 
yeah you have to do all of them . 
oh . 
do you have to do the other close talking ? 
as well as all of these . 
yeah . 
wow . 
yes absolutely there ' s a lot of cross talk . 
you have to do all you could just do it in that time period though . 
well 
but i guess it ' s a pain . 
well but you have to copy the whole file . 
yeah . 
right ? 
because we ' re going to be releasing the whole file . 
yeah you ' re right . 
well i you know i think at a certain point that copy that has the deletions will become the master copy . 
yeah it ' s just i hate deleting any data . 
so i i don ' t want i really would rather make a copy of it rather than bleep it out . 
are you are you bleeping it by adding ? 
and then 
overlapping . 
so it ' s it ' s exactly a censor bleep . 
so what i really think is bleep 
i understand . 
and then i want to 
but is is it summing signals ? 
or do you delete the old one and put the new one in ? 
i delete the old one put the new one in . 
oh okay . 
there ' s nothing left of the original signal . 
because 
oh because if you were summing you could 
no but anyway 
yeah it would be quite easy to get it back again . 
and then i was going to say also that they don ' t have to stay on the system as you know . 
yeah . 
then someday we can sell the unedited versions . 
because because the the ones 
say again ? 
once it ' s been successfully bleeped can ' t you rely on the 
or we ' ll tell people the frequency of the beep . 
encrypt it . 
you can hide it yeah . 
and then they could subtract the beep out . 
oh yeah . 
can ' t you rely on the archiving to preserve the older version ? 
right exactly i see . 
it wouldn ' t be that hard to hide it . 
yeah that ' s true yeah yep that ' s true . 
see this is good . 
i wanted to create some side conversations in these meetings . 
yeah you could encrypt it . 
okay . 
you can use spread spectrum . 
you know with a with a two hundred bit thousand bit uh 
uhhuh . 
so 
hide it . 
here we go . 
yeah yeah . 
yeah there you go . 
because we don ' t have enough asides . 
i have an idea . 
you reverse the signal . 
so it it lets people say what they said backwards . 
there you go . 
backwards . 
then you have like subliminal uh messages . 
but 
you ' ve seen the this the speech recognition system that reversed very short segments ? 
yeah . 
like 
did you read that paper ? 
no . 
it wouldn ' t work . 
the speech recognizer still works . 
yeah and if you do it backward then 
yeah . 
that ' s because they use forward backward . 
h good old h m m . 
forward but backward that ' s right . 
no it ' s backward forward . 
good point . 
a point . 
uh well i ' m sorry if i sound a little peeved about this whole thing . 
it ' s just we ' ve had meeting after meeting after meeting on this . 
and it seems like we ' ve never gotten it resolved . 
well but we never also we ' ve also never done it . 
huh . 
uh 
so 
yeah . 
this is the first cycle . 
if it makes 
there ' re bound to be some glitches the first time through . 
and uh and i ' m sorry responding without uh having much knowledge . 
but the thing is uh i am like one of these people who gets a gazillion mails . 
and and stuff comes in as 
well and that ' s exactly why i did it the way i did it . 
which is the default is if you do nothing we ' re going to release it . 
because you know i have my stack of emails of to to be done . 
yeah . 
that you know fifty or sixty long . 
and the ones at the top i ' m never going to get to . 
right . 
and uh so so 
move them to the bottom . 
yeah right . 
so so the only thing we ' re missing is is some way to respond to easily to say uh okay go ahead or something . 
so this is going to mean 
just re mail them to yourself and then they ' re at the bottom . 
yeah . 
yeah . 
yeah that ' s actually definitely a good point . 
yeah . 
the email doesn ' t specify that you can just reply to the email as as opposed to going to the form . 
in 
uhhuh . 
right . 
and 
and it also doesn ' t give a a specific i didn ' t think of it . 
i think it ' s a good idea an explicit time by which this will be considered definite . 
yeah release . 
and and it has to be a time earlier than that endpoint . 
yeah it ' s converging . 
this um i ' ve seen this recently . 
yeah that ' s right . 
uh i got email . 
and it if i use a mime capable mail reader it actually says you know click on this button to confirm receipt of the of the mail . 
huh . 
oh that ' s interesting . 
so 
you you can 
a lot of mailers support return receipt . 
it ' s like certified mail . 
could do that . 
right . 
but it doesn ' t confirm that they ' ve read it . 
no no no this is different . 
this is not so i i know you can tell you know the uh mail delivery agent to to confirm that the mail was delivered to your mailbox . 
huh . 
right . 
but but no this was different . 
in the mail there was a 
oh just a button . 
uh there was a button that when you clicked on it it would send uh you know a actual acknowledgement to the sender that you had actually looked at the mail . 
oh yeah . 
yeah yeah we could do that . 
but i hate that . 
but it but it only works for you know mime capable . 
you know if you use netscape or something like that for your 
yeah . 
you might as well just respond to the mail . 
and 
and we actually need a third thing . 
right . 
i mean 
it ' s not that you ' ve looked at it . 
it ' s that you ' ve looked at it and and and agree with one of the possible actions . 
no no you can do that . 
right ? 
you know you can put this button anywhere you want . 
oh ? 
and you can put it the bottom of the message and say here by you know by clicking on this i i agree uh you know i acknowledge 
oh i see . 
that my first born children are yours . 
and 
yeah . 
yeah . 
quick question . 
are um 
well i could put a u r l in there without any difficulty . 
and even pretty simple mime readers can do that . 
but why shouldn ' t they just email back ? 
so 
yeah reply . 
yeah . 
i don ' t see there ' s a problem . 
right . 
it ' s very nice . 
yeah . 
i i like the high - tech aspect of it . 
no no no i actually don ' t . 
but i think 
i appreciate it . 
i ' m just saying that . 
well i because i use a text mail reader . 
if but i ' m 
don ' t you use v i ? 
for your 
yeah . 
wow that ' s that ' s my guy . 
all right . 
you you read email in v i ? 
yeah . 
so i 
i like v i . 
there ' s these logos that you can put at the bottom of your web page like powered by v i . 
yeah . 
wow ! 
anyway quick question . 
you could put wed bugs in the email . 
i see . 
how 
yeah . 
like there were three meetings this time or 
or how many ? 
six . 
six . 
but of different people . 
so i guess if you ' re in both these types of meetings you ' d have a lot . 
but how 
i mean it also depends on how many 
like if we release this time it ' s a fairly small number of meetings . 
but what if we release like twenty five meetings to people ? 
well what my expectation is is that we ' ll send out one of these emails every time a meeting has been checked and is ready . 
in 
i don ' t know . 
oh oh okay . 
so that was my intention . 
so this time was just the first chunk okay . 
it ' s just 
yeah . 
that we just happened to have a bunch all at once . 
well that ' s a good idea . 
i mean maybe 
is that the way it ' s going to be you think jane ? 
i agree with you . 
it ' s we could do it uh i could i ' d be happy with either way . 
batch wise 
what i was thinking 
uh so this one 
that was exactly right . 
that we had a uh uh 
i i had wanted to get the entire set of twelve hours ready . 
don ' t have it . 
but uh this was the biggest clump i could do by a time where i thought it was reasonable . 
uhhuh . 
people would be able to check it and still have it ready by then . 
my um i was thinking that with the n s a meetings i ' d like there are three of them . 
and they ' re uh i i will have them done by monday . 
uh unfortunately the time is later . 
and i don ' t know how that ' s going to work out . 
but i thought it ' d be good to have that released as a clump too . 
because then you know they ' re they they have a it ' s in a category . 
it ' s not quite so distracting to them is what i was thinking . 
and it ' s all in one 
but after that when we ' re caught up a bit on this process then um i could imagine sending them out periodically as they become available . 
okay . 
i could do it either way . 
i mean it ' s a question of how distracting it is to the people who have to do the checking . 
we heard anything from i b m ? 
at all . 
uh let ' s see . 
we 
yeah right . 
so we got the transcript back from that one meeting . 
everything seemed fine . 
adam had a script that will put everything back together and there was well there was one small problem but it was a simple thing to fix . 
and then um we uh i sent him a pointer to three more . 
and so he ' s off and working on those . 
yeah now we haven ' t actually had anyone go through that meeting to see whether the transcript is correct . 
and to see how much was missed and all that sort of stuff . 
that ' s on my list . 
so at some point we need to do that . 
yeah . 
well that ' s on my list . 
yeah it ' s going to have to go through our regular process . 
i mean the one thing i noticed is it did miss a lot of backchannels . 
there are a fair number of yeahs and uhhuh that it ' s just that aren ' t in there . 
so 
huh . 
but i think yeah like you said i mean that ' s that ' s going to be our standard 
that ' s what the transcribers are going to be spending most of their time doing i would imagine . 
uhhuh . 
uhhuh uhhuh . 
once once we 
yes absolutely yeah . 
one question about the backchannels . 
it ' s going to 
do you suppose that was because they weren ' t caught by the pre segmenter ? 
yes absolutely absolutely . 
oh interesting . 
oh interesting okay . 
yeah they ' re they ' re not in the segmented . 
it ' s not that the i b m people didn ' t do it . 
okay . 
okay . 
just they didn ' t get marked . 
okay so maybe when the detector for that gets better or something 
i i 
there ' s another issue which is this 
we ' ve been uh contacted by university of washington now of course to um 
we sent them the transcripts that correspond to those six meetings . 
and they ' re downloading the audio files . 
so they ' ll be doing that . 
chuck ' s chuck ' s uh put that in . 
uhhuh yeah i pointed them to the set that andreas put uh on the web . 
so if they want to compare directly with his results they can . 
and um then once uh 
we can also point them at the um uh the original meetings . 
and they can grab those too with s c p . 
wait so you put the reference files 
no no they they wanted the audio . 
or the 
jane sent them the uh transcripts . 
no i mean of the transcripts . 
um 
well we can talk about it off line . 
there ' s another meeting in here what at four ? 
uhhuh . 
right ? 
yeah so we have to finish by three forty five . 
so does does does u w want to do this want to use this data for recognition or for something else ? 
uh for recognition . 
oh . 
i think they ' re doing 
didn ' t they want to do language modeling on you know recognition compatible transcripts ? 
oh i see . 
yeah . 
or 
this is to show you uh some of the things that turn up during the checking procedure . 
so this is from one of the n s a meetings . 
and uh if you ' re familiar with the diff format the arrow to the left is what it was . 
and the arrow to the right is what it was changed to . 
so 
and now the first one . 
okay so then we started a weekly meeting . 
the last time uh and the transcriber thought little too much . 
but uh 
really um it was we learned too much . 
which makes more sense syntactically as well . 
and these the parentheses were from 
then 
oh this that ' s the convention for indicating uncertain . 
uncertains . 
so the transcriber was right . 
you know she was uncertain about that . 
okay . 
so she ' s right to be uncertain . 
oh okay . 
and it ' s also a a good indication of the of that . 
the next one this was about uh claudia . 
and she ' d been really busy with stuff such as waivers . 
uh okay . 
um next one . 
um this was an interesting one . 
so the original was so that ' s not so claudia ' s not the bad master here . 
and then he laughs . 
web master . 
but it really web master . 
oh uhoh . 
and then you see another type of uncertainty which is you know they just didn ' t know what to make out of that . 
so instead of split upon unknown it ' s split in principle . 
yep . 
jane these are from i b m ? 
spit upon ? 
the top lines . 
no no these are these are our local transcriptions of the n s a meetings . 
no these are ours . 
oh . 
the transcribers transcriber ' s version versus the checked version . 
oh i see . 
my my checked version after i go through it . 
okay . 
um then you get down here . 
um 
sometimes some speakers will insert foreign language terms . 
that ' s the next example . 
the next one . 
the uh version beyond this is 
so instead of saying or 
especially those words also and oder and some other ones . 
those sneak in . 
um the next one 
discourse markers . 
that ' s cool . 
discourse markers . 
sorry what ? 
discourse markers ? 
discourse markers . 
sure sure sure sure . 
yeah yeah . 
and it ' s and it makes sense . 
because it ' s like below this it ' s a little subliminal there . 
yeah . 
yeah yeah . 
um okay the next one . 
uh this is a term . 
the problem with terminology . 
description with the transcriber has x as an advance . 
but really it ' s q s in advance . 
i mean i i ' ve benefited from some of these uh cross group meetings . 
okay then you got 
um uh 
instead of from something or other cards it ' s for multicast . 
and instead of ann system related it ' s end system related . 
this was changed to an acronym initially . 
and it shouldn ' t have been . 
and then you can see here g p s was misinterpreted . 
it ' s just totally 
this is this is a lot of jargon . 
um and the final one 
the transcriber had in the core network itself 
or the exit unknown . 
not the internet unknown . 
and it it comes through as in the core network itself of the access provider . 
not the internet backbone core . 
now this is a lot of terminology . 
huh . 
and they ' re generally extremely good 
but you know in this this area it really does pay to um to double check . 
and i ' m hoping that when the checked versions are run through the recognizer that you ' ll see substantial improvements in performance . 
because the you know there ' re a lot of these in there . 
yeah so how often 
yeah but i bet i bet they ' re acoustically challenging parts anyway though . 
huh . 
no actually no . 
oh really ? 
huh uh . 
uh it ' s 
oh so it ' s just jargon . 
it ' s jargon yeah . 
i mean this is because you know you don ' t realize in daily life how much you have top down influences in what you ' re hearing . 
well but 
but but 
and it ' s it ' s jargon coupled with a foreign accent . 
but we don ' t i mean our language model right now doesn ' t know about these words anyhow . 
so 
you know until you actually get a decent language model adam ' s right . 
yeah . 
it probably won ' t do any better . 
you probably won ' t notice a difference . 
but it ' s i mean it ' s definitely good that these are fixed . 
i mean obviously . 
yeah . 
well also from the standpoint of getting people ' s approval . 
because if someone sees a page full of uh um barely decipherable you know sentences and then is asked to approve of it or not it ' s uh uh 
did i say that ? 
yeah . 
yeah that would be a shame if people said well i don ' t approve it because the it ' s not what i said . 
okay . 
well that ' s exactly why i put the extra option in 
yeah . 
exactly that ' s why we discussed that . 
is that i was afraid people would say let ' s censor that because it ' s wrong . 
yeah . 
and i don ' t want them to do that . 
yeah . 
and then i also the final thing i have for transcription is that i made a purchase of some other headphones . 
because of the problem of low gain in the originals . 
and and they very much they much prefer the new ones . 
and actually i i mean i i think that there will be fewer things to correct because of the the choice . 
we ' d originally chosen uh very expensive headsets . 
yeah . 
ugh ! 
but um they ' re just not as good as these um in this with this respect to this particular task . 
well return the old ones . 
it ' s probably impedance matching problems . 
but 
i don ' t know exactly . 
but we chose them because that ' s what ' s been used here by prominent projects in transcription . 
could be . 
uhhuh . 
so it we had every reason to think they would work . 
so you have spare headsets ? 
sorry what ? 
you have spare headsets ? 
they ' re just earphones . 
they ' re not headsets . 
they ' re not microphones . 
no no i mean just earphones . 
right . 
um 
because i uh i could use one on my workstation . 
just to 
because sometimes i have to listen to audio files . 
and i don ' t have to go borrow it from someone . 
and 
we have actually i have 
well the thing is that if we have four people come to work for a day i was i was hanging on to the others for uh for spares . 
oh okay . 
sure no problem . 
no but you ' d if you yeah we should get it . 
but i can tell you what i recommend . 
but if you need it just get it . 
i just 
come on . 
right . 
yeah if you need it . 
yeah . 
yeah . 
yeah i still i still need to get a pair too . 
it ' d just have to be a a separate order an added order . 
they ' re they ' re they ' re they ' re pretty inexpensive . 
yeah that 
we should order a uh two or three or four actually . 
i ' m using one of these . 
yeah . 
yeah . 
i think i have a pair that i brought from home . 
we have 
but it ' s just for music listening . 
no just just just just buy them . 
and it ' s not 
just get the model number . 
nnn yeah . 
and 
just buy them . 
where do you buy these from ? 
yeah . 
cambridge soundworks just down the street . 
like 
you just go and 
oh . 
yeah they always have them in stock . 
yeah . 
anyway . 
that ' d be a good idea . 
uh could you email out the brand ? 
yeah . 
oh sure yeah okay . 
because i think sounds like people are interested . 
yeah . 
so 
definitely . 
yeah . 
it ' s made a difference in in how easy 
yeah . 
i realized something i should talk about . 
so what ' s the other thing on the agenda actually ? 
uh the only one was don wanted to uh talk about disk space yet again . 
yeah . 
it ' s short . 
i mean if you want to go we can just throw it in at the end . 
no no why don ' t you why don ' t you go ahead ? 
since it ' s short . 
um well uh 
oh i thought you meant the disk space . 
the disk space was short . 
yeah we know disk space is short . 
yeah that ' s what i thought too . 
that ' s a great ambiguity . 
yeah . 
it ' s one of these 
it ' s it ' s social . 
it ' s 
and uh discourse level . 
yeah . 
and 
yeah it ' s great . 
sorry . 
yeah . 
double double 
yeah it was really 
see if i had that little scratch pad i would have made an x there . 
thank you thank you . 
uh well we ' ll give you one then . 
yeah . 
um so um 
without thinking about it when i offered up my hard drive last week 
oh no ! 
it was while i was out of town . 
um this is always a suspect phrase . 
but um no i uh i realized that we ' re going to be doing a lot of experiments um for this uh paper we ' re writing . 
so we ' re probably going to need a lot more . 
we ' re probably going to need that disk space that we had on that eighteen gig hard drive . 
but um we also have someone else coming in that ' s going to help us out with some stuff . 
so 
we ' ve just ordered a hundred gigabytes . 
i think we need like another eighteen gig disk to be safe . 
okay we just need to 
well we ' re getting three thirty thirty sixes . 
so 
okay . 
right ? 
that are going into the main file server . 
okay . 
markham ' s ordering and they should be coming in soon . 
well so so 
so 
soon ? 
yeah i mean i guess the thing is is all i need is to hang it off like the person who ' s coming in sonali ' s computer . 
oh so so you mean the the internal the disks on the machines that we just got ? 
whew ! 
or we can move them . 
no . 
or extra disk ? 
these are going to go onto abbott . 
new disks . 
onto abbott . 
so are we going to move the stuff off of my hard drive onto that when those come in ? 
the file server . 
oh oh okay . 
on 
yeah . 
once they come in sure . 
uh 
okay that ' s fine . 
do when when is this planned for roughly ? 
they should be i i imagine next week or something . 
okay . 
okay . 
if you ' re if you ' re desperate i have some space on my drive . 
so 
i think if i ' m 
but i i vacillate between no space free and a few gig free . 
yeah . 
yeah i think i can find something if i ' m desperate . 
so 
and um in the meantime i ' ll just hold out . 
okay . 
that was the only thing i wanted to bring up . 
it should be soon . 
we we should 
okay . 
so there ' s another hundred gig . 
so 
all right great . 
uhhuh . 
okay . 
that ' s it . 
it ' s great to be able to do it . 
good . 
just say oh yeah a hundred gig . 
yeah . 
yeah . 
no big deal . 
a hundred gig here . 
a hundred gig there . 
well each meeting is like a gig or something . 
it ' s eventually real disk space . 
yeah . 
so it ' s really 
yeah . 
um yeah i was just going to comment that i ' m going to uh be on the phone with mari tomorrow late afternoon . 
oh yeah . 
we ' re supposed to get together and talk about uh where we are on things . 
uh there ' s this meeting coming up . 
uh and there ' s also an annual report now . 
i never actually 
i i was asking about this . 
i don ' t really quite understand this . 
she was she was referring to it as 
i think this actually didn ' t just come from her . 
but this is what uh darpa had asked for . 
um she ' s referring to it as the annual report for the fiscal year . 
but of course the fiscal year starts in october . 
so i don ' t quite understand why we do an annual report that we ' re writing in july . 
she ' s either really late or really early . 
huh . 
or she ' s getting a good early start . 
uh i think basically it ' s none of those . 
it ' s that the meeting is in july . 
so they so darpa just said do an annual report . 
so 
so 
so anyway i ' ll be putting together stuff . 
i ' ll do it uh you know as much as i can without bothering people . 
just by looking at at papers and status reports . 
huh . 
i mean the status reports you do are very helpful . 
uh so i can grab stuff there . 
and if uh if i have some questions i ' ll 
when we remember to fill them out . 
yeah if people could do it as soon as as you can if you haven ' t done one recently . 
uh uh 
but you know i ' m i ' m sure before it ' s all done i ' ll end up bugging people for for more clarification about stuff . 
um but um 
i don ' t know . 
i guess i guess i know pretty much what people have been doing . 
we have these meetings and and there ' s the status reports . 
uh but um um 
yeah so that wasn ' t a long one just to tell you that and if something hasn ' t uh 
i ' ll be talking to her late tomorrow afternoon . 
and if something hasn ' t been in a status report and you think it ' s important thing to mention on this kind of thing uh uh just pop me a one liner . 
and and and i ' ll i ' ll have it in front of me for the phone conversation . 
okay . 
uh . 
i guess uh you ' re still pecking away at the demos and all that probably . 
yep . 
and don is going to be helping out with that . 
oh that ' s right . 
so 
okay . 
did you want to talk about that this afternoon ? 
um 
not here but later today . 
we should probably talk off line about when we ' re going to talk off line . 
okay okay . 
okay . 
yeah i might want to get updated about it in about a week . 
because um i ' m actually going to have a a few days off the following week . 
after the after the picnic . 
so 
oh okay . 
that ' s all i had . 
so we were going to do sort of status of speech transcription . 
automatic transcription . 
but we ' re kind of running late . 
so 
how long does it take you to save the data ? 
fifteen minutes . 
yeah . 
so 
if you want to do a quick 
yeah . 
ten minute . 
guess we should stop like twenty of at the latest . 
uh 
we we have another meeting coming in that they want to record . 
so 
and there ' s the digits to do . 
so maybe maybe maybe 
yeah well we can skip the digits . 
we could . 
five minute report or something . 
it ' s up to you . 
i don ' t 
whatever you want . 
yeah yeah . 
well i would love to hear about it . 
what do you have to say ? 
i ' m interested . 
especially since 
so 
yeah well i ' m going to be on the phone tomorrow . 
so this is just a good example of the sort of thing i ' d like to hear about . 
wait why is everybody looking at me ? 
sorry . 
i don ' t know . 
because he looked at you . 
what ? 
and says you ' re sketching . 
uh i ' m not sure what you were referring to . 
i i i i ' m not actually i ' m not sure what 
are we supposed to have done something ? 
no we were just talking before about alternating the subject of the meeting . 
oh . 
alternating . 
uhhuh . 
and this week we were going to try to do automatic transcription status . 
i wasn ' t here last week . 
oh ! 
sorry . 
oh . 
we did that last week . 
but we sort of failed . 
right ? 
hhh . 
no . 
i thought we did . 
did we ? 
yeah we did . 
okay . 
okay so now now we have the schedule . 
so next week we ' ll do automatic transcription status . 
plus anything that ' s real timely . 
okay . 
oh . okay . 
okay . 
okay whew ! 
whew ! 
good update . 
that was 
dodged that bullet . 
yeah nicely done liz . 
a woman of few words . 
but but lots of prosody . 
okay okay . 
uh i mean we we really haven ' t done anything . 
excuse me ? 
sorry . 
well since last week . 
yeah we ' re 
i mean the the next thing on our agenda is to go back and look at the um the automatic alignments . 
because uh i got some 
i i i learned from thilo what data we can use as a benchmark to see how well we ' re doing on automatic alignments of the background speech . 
or of the foreground speech with background speech . 
so 
yeah . 
but we haven ' t actually 
and then uh i guess the new data that don will start to process 
the um 
when he can get these 
you know before we were working with these segments that were all synchronous . 
and that caused a lot of problems . 
huh . 
oh right right . 
because you have timed at on either side . 
uhhuh . 
and so that ' s sort of a 
stage two of trying the same kinds of alignments with the tighter boundaries with them is really the next step . 
right . 
we did get our um 
i ' ll be interested . 
i guess good news . 
we got our abstract accepted for this conference . 
um workshop . 
isca workshop in um uh new jersey . 
and we sent in a very poor abstract . 
but they 
very poor . 
very quick . 
um 
but we ' re hoping to have a paper for that as well . 
which should be an interesting 
when ' s it due ? 
the paper isn ' t due until august . 
the abstracts were already due . 
so it ' s that kind of workshop . 
uhhuh . 
but i mean the good news is that that will have sort of the european experts in prosody . 
sort of a different crowd . 
and i think we ' re the only people working on prosody in meetings so far . 
so that should be interesting . 
what ' s the name of the meeting ? 
uh it ' s isca workshop on prosody in speech recognition and understanding or something like that . 
it ' s called prosody to 
uhhuh . 
some generic 
good . 
uh so it ' s focused on using prosody in automatic systems . 
and there ' s a um a web page for it . 
you going to uh eurospeech ? 
yeah . 
yeah . 
i don ' t have a paper . 
but i ' d kind of like to go . 
if i could . 
is that all right ? 
we ' ll discuss it . 
okay i guess that ' s no . 
my my my car my car needs a good wash by the way . 
okay well that hey if that ' s what it takes that ' s fine with me . 
um 
i ' ll pick up your dry cleaning too . 
should we do digits ? 
yeah . 
uh 
okay we ' re on . 
so i think this is going to be a pretty short meeting because i have four agenda items . 
three of them were requested by jane who is not going to be at the meeting today . 
tsk . 
so the uh first was transcription status . 
does anyone besides jane know what the transcription status is ? 
um sort of i do peripherally . 
um well first of all with i b m i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them a week or week and a half ago . 
is that english ? 
that ' s our system . 
ugh ! 
and that it ' s gone out to the transcribers . 
and hopefully next week we ' ll have the transcription back from that . 
um jane seems to be um moving right along on the transcriptions from the icsi side . 
can i have a pen ? 
she ' s assigned i think probably five or six more meetings . 
yeah i think we ' re up to m r thirteen or something . 
yeah so um i guess she ' s hired some new transcribers . 
huh . 
and 
which meetings is she transcribing ? 
speaking 
um well we ' ve we ' ve run out of e d us because a certain number of them are um sort of awaiting to go to i b m . 
okay . 
for i b m yeah . 
okay . 
huh . 
and the rest are in process being transcribed uh here . 
so we ' re doing some in parallel . 
so does she have transcribers right now who are basically sitting idle because there ' s no data back from i b m ? 
yep . 
no . 
oh no no . 
no no . 
no . 
no ? 
we ' re not waiting on them . 
we haven ' t done that process . 
so they ' re doing the full transcription process . 
oh . 
oh okay . 
yeah . 
so they ' re just doing their own thing until 
because i i need to ask jane whether it ' s it would be okay for her um some of her people to transcribe uh some of the initial data we got from the smartkom data collection which is these short like five or seven minute sessions . 
we ' re doing it in parallel yeah . 
okay . 
yep . 
um and we want it you know we need 
the again we we have a similar uh logistic set up where we are supposed to send the data to munich . 
and get it transcribed and get it back . 
right . 
but to get going we would like some of the data transcribed right away so we can get started . 
yep sounds familiar . 
and so um i wanted to ask jane if if uh you know maybe one of their transcribers could could do 
i mean since these are very short that should really be uh 
uhhuh . 
um it ' s 
there ' s only two channels . 
so it ' s only 
yeah . 
it ' s only two 
yeah . 
as the synthesis doesn ' t have to be transcribed i think . 
right 
so 
yeah . 
so so it ' s basically one channel to transcribe . 
and it ' s 
one session is only uh like seven 
so that should have many fewer 
and it ' s also not uh a bunch of interruptions with people and all that . 
right . 
and some of it is read speech so we could give them the the thing that they ' re reading . 
right ? 
so 
yeah . 
and they just may 
make sure it ' s right ? 
and so um 
yep . 
um i guess since she ' s 
i was going to ask her but since she ' s not around i maybe i ' ll 
yeah well it certainly seems 
uh if if that ' s okay with you to to you know get that stuff uh to ask her for that then i ' ll do that . 
yeah . 
yeah if we ' re held up on this other stuff a little bit in order to encompass that that ' s okay because i i um i mean i still have high hopes that the that the i b m pipeline will work out for us so it ' s 
yeah . 
okay yeah . 
yeah . 
alrighty . 
oh yeah and also related to the transcription stuff . 
so i ' ve been trying to keep a web page uh up to date showing what the current status is of the of all the things we ' ve collected . 
and what stage each meeting is in in terms of whether it ' s 
can you mail that out to the list ? 
uhhuh yeah i will . 
i 
that ' s the thing that i sent out just to foo people saying can you update these pages . 
and so that ' s where i ' m putting it but i ' ll 
oh okay okay . 
i ' ll send it out to the list telling people to look at it . 
yeah i haven ' t done that . 
so i have lots of stuff to add that ' s just in my own directory . 
yeah . 
i ' ll try to get to that . 
okay . 
so jane also wanted to talk about participant approval but i don ' t really think there ' s much to talk about . 
i ' m just going to do it . 
and uh if anyone objects too much then they can do it instead . 
you are going to 
i ' m going to send out to the participants uh with links to web pages which contain the transcripts and allow them to suggest edits . 
and then bleep them out . 
okay . 
for the ones that we have . 
um 
so but it ' s just transcripts not the not the audio ? 
nope they ' ll have access to the audio also . 
okay yeah yep . 
uh 
i mean that ' s my intention . 
yeah . 
because the transcripts might not be right . 
so 
yeah . 
so you want people to be able to listen to them . 
so um the audio that they ' re going to have access to will that be the uncompressed version ? 
or will you have scripts that like uncompress the various pieces and 
oh that ' s a good point . 
that ' s a good point . 
yeah it ' s it ' s probably going to have to be the uncompressed versions because uh uh it takes too long to do random access decompression . 
huh . 
yeah i was just wondering because we ' re uh running out of the un backed up disk space on 
well that was the other point . 
oh was that another one ? 
yep that ' s another agenda item . 
okay . 
i ' ll wait . 
so uh 
but that is a good point so we ' ll get to that too . 
um darpa demo status not much to say . 
the back end stuff is working out fine . 
it ' s more or less ready to go . 
i ' ve added some stuff that uh indexes by the meeting type m r e d u et cetera . 
and also by the user i d . 
so that the front end can then do filtering based on that as well . 
uh the back end is uh going more slowly as i i think i said before just because i ' m not much of a tcl t . k . programmer . 
and uh dave gelbart says he ' s a little too busy . 
so i think don and i are going to work on that and and you and i can just talk about it off line more . 
right . 
but uh the back end was pretty smooth . 
oh . 
so i think we ' ll have something . 
it may not be as as pretty as we might like but we ' ll have something . 
i wondered when we would reach dave ' s saturation point . 
he ' s sort of been been volunteering for everything . 
and and uh 
yeah . 
uhhuh . 
okay ! 
finally said he was too busy . 
i guess we reached it . 
yeah he he actually he volunteered but then he then he retracted it . 
so 
oh well . 
um 
and also um i was just showing andreas i got um an x waves kind of display . 
and i don ' t know how much more we can do with it . 
with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom . 
oh cool . 
so right now it ' s just an x waves . 
and then you have three windows . 
but i don ' t know it looked pretty nice . 
and i ' m sure it think it has potential for a little something . 
for a demo ? 
yeah for a demo . 
yeah sounds good . 
so 
okay so again the issue is for july the issue ' s going to be what can we fit into a windows machine uh and so on . 
oh . 
but 
okay . 
so it might just be slides . 
yeah okay . 
well we ' ll see um 
well yeah . 
i ' ve been putting together uh transcriber things for windows . 
so 
and i installed it on dave gelbart ' s p c and it worked just fine . 
so hopefully that will work . 
really ? 
so is that 
because there ' s some people um 
it would be cool if we could uh get that to work uh at at s r i . 
yeah . 
because the um 
yep . 
we have we have more windows machines to run the 
well transcriber is tcl t . k . very generic with snack . 
yeah . 
so basically anything you can get snack to run on it will work . 
right . 
yeah . 
yeah . 
but but the problem is the version transcriber works with the snack version is one point six whatever . 
and that ' s not anymore supported . 
it ' s not on on the web page anymore . 
but i just wrote an email to to the author of to the snack author . 
and he sent me to one point six whatever library . 
and so it works . 
well i thought it was packaged with transcriber . 
yeah . 
but then you can ' t add our patches . 
and then the the new version is is totally different . 
oh . 
and in yeah in terms of of the source code . 
you you can ' t find the tcl files anymore . 
uh . 
it ' s some whatever wrapped thing . 
huh . 
and you can ' t you can ' t access that . 
so you have to install first install tcl then install snack . 
and then install the transcriber thing . 
and then do the patches . 
patch . 
i i wonder if if we should contribute our changes back to the authors so that they maintain those changes along 
ugh ! 
yeah . 
yeah . 
we have . 
we have ? 
yeah it ' s just hasn ' t made it into the release yet . 
oh . 
oh okay . 
so did you um put the uh the n t version out on the uh meeting recorder page or 
no i haven ' t done that yet . 
i ' m 
oh nope . 
but i definitely will do that . 
so can some of the stuff that don ' s talking about somehow fit into this ? 
uh mean you just have a set of numbers that are associated with the 
yeah . 
yeah it ' s basically ascii files or binary files whatever representation . 
so 
just three different 
it ' s a waveform and just a stylized pitch vector basically so it ' s 
i mean we could do it in i mean you could do it in a number of different places i ' m sure . 
so so well 
but but it would be cool if the transcriber interface had like another window for the you know maybe above the waveform where it would show some arbitrary valued function that is that is you know time time synchronous with the waveform . 
yep . 
yeah . 
yeah that ' d be very cool . 
yes . 
it ' d be easy enough to add that . 
again it ' s it ' s it ' s more tcl t . k . programming . 
yeah . 
so someone who ' s familiar with tcl t . k . has to do it . 
right . 
right . 
but uh it wouldn ' t be hard to do . 
but it would almost be like having another waveform displayed . 
uhhuh . 
yep . 
yep . 
right . 
yeah . 
yeah maybe we could look into that . 
yeah . 
but it it seems to me that i 
and 
it doesn ' t seem like having that real time is that necessary . 
so it seems to me you could do images . 
um what do you mean by real time ? 
do you mean like 
like being able to scroll through it and stuff for the demo . 
okay . 
is that what you mean ? 
yeah yeah . 
yeah . 
it just seems to me 
it would be cool to see it . 
it would be cool like to see to hear it and see it . 
and to hear it . 
yeah . 
and see the pitch contours also . 
yeah . 
yeah . 
sure but i don ' t think i you can do all that just statically in powerpoint . 
i think it would lose 
yeah i mean 
just record the audio clip and show an image and i think that ' s 
right right . 
i just thought if you meant slides i thought you meant like just like um view graphs or something . 
you know 
yeah . 
so uh 
no we ' re talking about on the computer . 
right . 
and and um i think when we were talking about this before we had this little demo meeting . 
we sort of set up a range of different degrees of liveness that you could have . 
and the more live the better but uh given the crunch of time we may have to retreat from it to some extent . 
so i think for a lot of reasons i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it . 
uhhuh . 
so it ' d be a good thing to get in there . 
but 
um anyway just looking for ways that we could actually show what you ' re doing uh in to people . 
uhhuh . 
because a lot of this stuff particularly for communicator uh certainly a significant chunk of the things that we waved our arms about originally had had to do with prosodics . 
it ' d be nice to show that we can actually get them and see them . 
uhhuh . 
huh . 
and the last item on the agenda is disk issues yet again . 
so we ' re doing okay on backed up . 
we ' re we ' re only about thirty per cent on the second disk . 
so uh we have a little bit of time before that becomes critical . 
but we are like ninety five per cent ninety eight per cent on the scratch disks for the expanded meetings . 
yeah . 
and my original intention was like we would just delete them as we needed more space . 
but unfortunately we ' re in the position where we have to deal with all the meeting data all at once in a lot of different ways . 
yeah . 
oh there ' s a lot of transcribers too . 
yeah there ' re a lot of transcribers . 
yeah . 
so all of those need to be expanded . 
uhhuh . 
and then people are doing chunking and i want to do uh uh uh the permission forms . 
right . 
so i want those to be live so there ' s a lot of data that has to be around . 
um and jane was going to talk to uh dave johnson about it . 
one of the things i was thinking is we we just got these hundred 
all right excuse me . 
ten uh sparc blade sun blades . 
did they come in ? 
sun blades . 
yeah . 
yeah . 
they came in the other day . 
they came in but they ' re not set up yet . 
oh . 
and so it seems to me we could hang scratch disk on those because they ' ll be in the machine room . 
they ' ll be on the fast connection to the rest of the machines . 
and if we just need un backed up space we could just hang disks off them . 
well is there 
why not just hang them off of abbott ? 
is there a 
yeah . 
because there ' s no more room in the disk racks on abbott . 
uh . 
uh i see . 
weren ' t we going to get 
well maybe it should get another rack . 
but you still need to store the disks somehow . 
well but the sun blades have spare drive bays . 
so 
you can put two 
just put them in . 
oh you mean you put them inside the pizza boxes for the 
internal . 
sure . 
yeah . 
yeah . 
oh . 
because the sun uh these sun blades take commodity hard drives . 
so you can just go out and buy a p c hard drive and stick it in . 
huh . 
but if abbott is going to be our disk server it it file server it seems like we would want to get it uh a second disk rack or something . 
plus we ' re talking about buying a second uh file server . 
well i mean there are lots of long term solutions . 
what i ' m looking for is where do we expand the next meeting ? 
yep . 
i see oh i see . 
well for the next meeting you might be out of luck with those ten . 
mightn ' t you ? 
uh you know dave johnson is gone for like ten days . 
oh i didn ' t know he had left already . 
uh well tonight . 
oh oh well . 
you mean he won ' t set up the 
huh . 
how much space do you need for these ? 
i don ' t know . 
i don ' t know what his schedule is . 
you we need about a gig per meeting . 
i ' m just saying he ' s gone . 
i i 
yep . 
i have um i have an eighteen gig drive hanging off of my computer . 
all right ! 
so 
what ' s your computer ' s name ? 
uh samosa . 
you had an eighteen gigabyte drive . 
yeah i had . 
well it ' s about i think there ' s about twelve gig left . 
so it and you have an x drives installed ? 
yeah . 
okay . 
so i didn ' t realize it was so critical . 
and you ' re you ' re offering 
i mean i ' m not doing anything on it right now until i get new meetings to or that are new transcriptions coming in i really can ' t do anything . 
okay . 
i i i just gave thilo some about ten gigs the last ten gigs of space that there was on on uh abbott . 
um not that i can ' t do anything i 
uh and uh 
so but that but 
which one was that ? 
x g ? 
x g . 
x g . 
okay . 
yeah . 
x g ? 
that ' s also where we store the the uh hub five training set waveforms . 
oops . 
no . 
right ? 
but that won ' t be getting any bigger . 
i don ' t think that ' s on x g . 
will it ? 
right . 
on x g is only carmen and and stephane ' s disk . 
it ' s 
but i ' ve also been storing i ' ve been storing the feature files there . 
yeah . 
and i guess i can start deleting some because we now know what the best features are . 
well 
and we won ' t be using the old ones anymore . 
yeah i i don ' t think it was on x g . 
i have a lot of space though . 
uh oh thats x . a . oh that ' s x 
isn ' t that x h ? 
i 
i have a lot of space and it ' s not it ' s 
not not for long . 
there ' s very little uh 
yeah . 
not for long . 
but i mean it ' s not going 
maybe i ' m 
oh no i ' m sorry . 
it ' s not being used often at all . 
but i ' m using x h h too . 
yeah it ' s probably probably only about four gig is on x on your x drive . 
so 
oh okay . 
but we ' ll definitely take it up if you 
i 
i think you ' re right . 
i think it ' s about four or five gig . 
it ' s x h and d 
because i have four meetings on there . 
the 
i ' m also using d g . 
i got that confused . 
three or four meetings . 
okay k . 
great . 
so 
we need 
okay so that will get us through the next couple days . 
we need another gigaquad . 
yep . 
at least . 
there should i there should just be a i should have a button . 
just press press each meeting saying we need more disk space this week . 
the more disk space button ? 
yep . 
skip the rest of the conversation . 
well we ' ve collected so far something like uh sixty five meetings . 
and it ' s about a gig uncompressed . 
and and how much does each meeting take ? 
it ' s it ' s a little bit more as i usually don ' t do not uncompress the all of the p z m and the p d a things . 
is a little more ? 
right yeah so if you uncompressed everything it ' s even more . 
so 
it ' s 
yeah . 
one point five or something . 
uh compressed how much are they ? 
like 
half a gig . 
about half ? 
for all of them . 
yeah . 
yeah . 
yep . 
so we ' re definitely are storing you know all of those . 
so there ' s what ? 
thirty some gig of just meetings so far ? 
so so so maybe there ' s a hundred gig or something . 
or 
uhhuh . 
i mean because we we have the uncompressed around also . 
right . 
yeah . 
so it ' s like 
right . 
well we we haven ' t uncompressed all the meetings . 
but 
i would like to . 
yeah . 
well i mean it ' s they really are cheap . 
i mean it ' s just a question of figuring out where they should be and hanging them . 
right . 
yep . 
but but uh we could you know if you want to get four disks get four disks . 
i mean it ' s it ' s small i mean these things are just a few hundred dollars . 
yeah . 
well i sent that message out to i guess you and dave asking for if we could get some disk . 
yeah . 
i i sent this out a a day ago . 
and put it where ? 
right . 
but and dave didn ' t respond so i i don ' t know how the whole process works . 
i mean does he just go out and get them and if it ' s okay and 
yep . 
so i was assuming he was going to take over that . 
but he ' s probably too busy given that he ' s leaving . 
yeah i think you need a direct conversation with him . 
and just say an just ask him that you know what should you do . 
and in my answer back was are you sure you just want one . 
so i mean i think that what you want to do is plan ahead a little bit and figure well here ' s what we figure on doing for the next few months . 
yeah . 
i know what they want . 
the sysadmins would prefer to have one external drive per machine . 
yeah . 
so they don ' t want to stack up external drives . 
um and then they want everything else in the machine room . 
right . 
so the question is where are you going to hang them ? 
uhhuh . 
i don ' t know what the space situation is in the machine room . 
right . 
so 
right . 
so this is a question that ' s pretty hard to solve without talking to dave . 
the 
i think part of the reason why dave can ' t get the the new machines up is because he doesn ' t have room in the machine room right now . 
because it 
one 
huh . 
yep . 
one one one thing to to um to do when you need to conserve space is 
so he has to re arrange a bunch of stuff . 
i bet there are still some old uh like nine gig disks uh around . 
and you can probably consolidate them onto larger disks . 
and and you know recover the space . 
yep . 
yeah . 
no . 
i think dave dave knows all these things of course . 
right . 
and so he always has a lot of plans of things that he ' s going to do to make things better in many ways and runs out of time . 
uhhuh . 
but i i know that generally their first priority has been for backed up disk . 
and so i think what he ' s been concentrating on is uh the back the back up system rather than on new disk . 
huh . 
huh . 
so 
well . 
so 
which 
but this this is a very specific question for me . 
basically we can easily get one to four disks . 
i mean you just go out and get four and we ' ve got the money for it . 
it ' s no big deal . 
uh but the question is where they go ? 
and i don ' t think we can solve that here . 
maybe we can put some disks in the in that back room there . 
you just have to ask him . 
yeah really . 
attach to 
popcorn . 
to the machine that collects the data . 
yeah . 
so then you could at least temporarily store stuff there . 
the only 
huh . 
yeah it ' s just it ' s not on the net so it ' s a little awkward . 
what do you mean it ' s not on the net ? 
it ' s not 
it ' s not bad . 
it ' s behind lots of fire walls that don ' t allow any services through except s s h . 
oh because it ' s because it ' s an aciri machine ? 
yep . 
oh oh oh . 
yeah . 
and also on the list is to get it into the normal icsi net . 
but who knows when that will happen ? 
that might be a good short term solution though . 
but that can ' t be that hard . 
i mean 
no the the problem with that apparently is that they don ' t currently have a wire running to that back room that goes anywhere near one of the icsi routers . 
oh 
so they actually have to run a wire somewhere . 
yeah . 
yeah again you know any one of these things is certainly not a big deal . 
if there was a person dedicated to doing it they would happen pretty easily but it ' s it ' s everybody everybody has a has 
but dave has to do all of them . 
well all of us have long lists of different things we ' re doing . 
but at any rate i think that there ' s a there ' s a longer term thing and there ' s immediate need . 
and i think we need a a conversation with 
uh maybe maybe after after tea or something you and i can go down and and talk to him about it . 
just say you know what should we do right now . 
how long is david going to be gone ? 
uh eleven days or something . 
oh my ! 
yeah . 
basically tomorrow and all of the week after . 
and that ' s all i have . 
um 
let ' s see . 
the only thing other thing i was going to add was that um uh i talked briefly to mari . 
and uh we had both been busy with other things so we haven ' t really connected that much since the last meeting we had here . 
but we agreed that we would have a telephone meeting the friday after next . 
and i i i wanted to make it um after the next one of these meetings . 
so something that we want to do next meeting is is uh to put together um a kind of reasonable list for ourselves of what is it um that we ' ve done . 
i mean just sort of bulletize i mean i can i can dream up text but this is basically going to lead to the annual report . 
so um if 
uhhuh . 
this is the fifteenth ? 
um that would 
so just a week from tomorrow ? 
yeah . 
okay . 
yeah . 
so uh we can 
this 
is this got to be in the morning ? 
so that ' s an 
um 
or 
because you know i fridays i have to leave uh like around uh two . 
so if it could be before that would be be 
no no but i i i don ' t need other folks for the meeting . 
i can do it . 
oh okay all right . 
all i ' m saying is that on 
oh i ' m sorry i misunderstood . 
i thought you are 
yeah . 
so what i meant was on the this meeting if i something i i i ' m making a major thing in the agenda is i want to help in getting together a list of what it is that we ' ve done so i can tell her . 
okay . 
all right . 
uhhuh . 
okay . 
i think i have a pretty good idea . 
but but um 
uh and then the next day uh late in the day i ' ll be having that that discussion with her . 
huh . 
um so 
um uh one thing i mean we in past meetings we had um also you know various variously talked about the um work that uh was happening sort of on the on the recognition side . 
um but isn ' t necessarily related to meetings uh specifically . 
uhhuh . 
so um and i wondered whether we should maybe have um a separate meeting . 
and between you know whoever ' s interested in that . 
because i feel that uh there ' s plenty of stuff to talk about . 
but it would be sort of um maybe the wrong place to do it in this meeting if uh 
think so ? 
well it ' s that it ' s just going to be very boring for people who are not you know sort of really interested in the details of the recognition system . 
i ' m interested . 
me too . 
well okay so how many how many people here would not be interested in uh in a meeting about recognition ? 
jane may not be . 
jane i think . 
well i know well jane 
yep . 
well you mean in a separate meeting or talking about it in this 
no . 
if we talked about it in this meeting . 
he ' s wondering how much overlap there will be . 
okay . 
yeah so you ' re 
so 
so 
uh uh 
liz and jane probably . 
okay so we ' re going to have a guy ' s meeting . 
good thing liz isn ' t here . 
real 
uh if you want to put it that way . 
watch a ball game ? 
yeah real real real men real men do decoding or something like that . 
don ' t listen to this liz . 
right . 
uh 
i mean it ' s sort of i mean when when the talk is about data collection stuff sometimes i ' ve you know i i ' m bored . 
yeah . 
the nod off ? 
so it ' s i i can sympathize with them not wanting to to to be uh you know if i you know this could 
it ' s because you have a 
so you need a better developed feminine side . 
heh ! 
i ' m not sure i want to 
there ' s probably going to be a lot of bleeps in this meeting . 
yeah i would i would guess . 
uh um 
yeah . 
and 
i think it must be uh nearing the end of the week . 
um yeah . 
i you know i i ' ve heard some comments about like this . 
that could be . 
uhhuh . 
i mean the 
um 
and we don ' t have to do it every week . 
could we 
we could do it every other week or so . 
right i was 
you know or whenever we feel like we 
why don ' t we alternate this meeting every other week ? 
or just alternate the focus . 
that ' s what i mean . 
yeah so on even weeks have basic on data . 
yeah . 
we could do that yeah . 
yeah . 
i i personally i ' d i ' m not in favor of more meetings . 
um because uh 
right . 
you know 
i am . 
oh 
but i i don ' t i mean a lot of times lately it seems like we don ' t really have enough for a full meeting on meeting recorder . 
right . 
so if we did that 
well except that we keep going for our full time . 
yep . 
well because we get into these other topics . 
yeah . 
we feel we feel obligated to collect more data . 
yeah . 
so if we could alternate the focus of the meeting 
i don ' t . 
let ' s read digits and go . 
why don ' t we just start with that ? 
and then if we find you know we ' re just not getting enough done there ' s all these topics not coming up then we can expand into another meeting . 
umm okay . 
uhhuh . 
but i i think that ' s a great idea . 
uh so uh um let ' s chat about it with liz and jane when we get a chance see what they think and 
uhhuh . 
yeah that would be good . 
i mean andreas and i have various talks in the halls . 
and there ' s lots of things you know details and stuff that would i think people would be interested in . 
uhhuh . 
and i ' d you know where do we go from here kind of things and 
so it would be good . 
yeah and you ' re you ' re attending the uh the front end meeting as well as the others so you have you have probably one of the best 
you and i i guess are the main ones who sort of see the bridge between the two . 
bridge . 
uhhuh . 
we are doing recognition in both of them . 
so 
uhhuh . 
right . 
uh 
so um 
okay . 
so so we could talk a little bit about that now if if there ' s some time . 
no no that would be for next week . 
um i so the latest result was that um 
um yot i tested the uh the sort of final version of the p l p configuration um on development test data for for this year ' s hub five test set . 
uhhuh . 
and the recognition performance was exactly and i mean exactly up to the you know the first decimal same as with the uh mel cepstra front end . 
huh . 
for both females and males ? 
yes . 
oh ! 
uh well there was a little bit of a 
overall . 
they they were the males i think were slightly better and the females were slightly worse but nothing really . 
uhhuh . 
i mean definitely not significant . 
uhhuh . 
uhhuh . 
and then the really nice thing was that if if we combine the two systems we get a one and a half per cent improvement . 
wow . 
so 
just with rover ? 
with n best rover which is like our new and improved version of rover . 
uhhuh . 
which actually uses the whole n best list from both systems to uh combine that . 
so except i mean the only key difference between the two really is the kind of smoothing at the end which is the auto regressive versus the cepstral truncation . 
yeah . 
okay . 
and the 
but a per cent and a half . 
that ' s 
yeah it ' s pretty impressive . 
and and so uh after i told the my uh colleagues at s r i about that you know now they definitely want to you know uh have a 
next time we have an evaluation they want to do uh you know basically at least the system combination . 
um and you know why not ? 
sure why not ? 
uh so 
we clearly got to add a few more features though . 
uh what do you mean ? 
more features in the sense of front end features or in the sense of just bells and whistles ? 
no uh front end features . 
you know we did p l p and mel cepstra . 
let ' s you know try rasta and m s g and 
oh i mean 
yeah . 
well 
right . 
so we 
yeah . 
that ' s the the the 
there ' s one thing uh i mean you don ' t want to overdo it because every front end 
you know if you you know you basically multiply your effort by n where n is a number of different systems . 
oh . 
uhhuh . 
and um 
so so one one compromise would be to only to have the everything up to the point where you generate lattices be basically one system . 
and then after that you rescore your lattices with the multiple systems . 
and combine the results and that ' s a fairly painless um thing . 
huh . 
do you think we ' d still get the one and a half uh 
so 
i i think so . 
yeah . 
maybe a little less because at that point the error rates are lower . 
and so if 
uhhuh . 
you know maybe it ' s only one per cent or something but that would still be worthwhile doing . 
so 
um you know just wanted to let you know that that ' s working out very nicely . 
cool . 
and then we had some results on digits uh with um 
we we 
so this was uh really really sort of just to get dave going with his um experiments . 
uhhuh . 
and so uh 
but as a result um you know we were sort of wondering why is the hub five system doing so well on the digits . 
and the reason is basically there ' s a whole bunch of read speech data in the hub five training set . 
right . 
right . 
including digits i gather yeah . 
and you 
and 
not all of 
no it ' s actually digits is only a maybe a fifth of it . 
the rest is is read is read timit data and uh atis data and wall street journal and stuff like that . 
a fifth of it is how much ? 
right . 
but a a fifth is how much ? 
a fifth would be maybe uh two hours something . 
yeah so i mean that ' s actually not that different from the amount of training that there was . 
right . 
but it definitely helps to have the other read data in there . 
so 
because we ' re doing 
oh yeah ? 
you know the error rate is half of what you do if you train only on uh timit uh not timit uh t i digits . 
uhhuh . 
which is only what ? 
two hours something ? 
right . 
i don ' t know . 
so uh more read speech data definitely helps . 
and you can leave out all the conversational data with no performance penalty . 
that ' s 
yeah that was the interesting thing . 
that was 
because because uh it was apparent if you put in a bunch more data it would be better . 
right right . 
but but uh 
right . 
well is there even more read speech data around ? 
oh yeah . 
so we only for the hub five training we ' re only using uh a fairly small subset of the macrophone data base . 
uhhuh . 
um so you could beef that up and probably do even better . 
i could also put in uh focus condition zero from hub four from broadcast news which is mostly prepared speech . 
uhhuh . 
it ' s not exactly read speech but it ' s pretty darn close . 
yeah . 
yeah . 
right . 
well i mean that ' s plenty of read speech data . 
i mean wall street journal uh take one example . 
yeah . 
that ' s right . 
but um 
so you know that might be useful for the people who train the the digit recognizers to to use uh something other than t i digits . 
yeah . 
well they been using timit . 
okay . 
that 
uh they they uh they experimented for a while with a bunch of different data bases with french and spanish and so forth because they ' re multi lingual tests . 
uhhuh . 
and and uh um and actually the best results they got were uh using timit . 
huh . 
uh but uh which so that ' s what they ' re they ' re using now . 
huh . 
but but yeah certainly if we um 
if we knew what the structure of what we ' re doing there was . 
i mean there ' s still a bunch of messing around with different kinds of uh noise robustness algorithms . 
uhhuh . 
uhhuh . 
so we don ' t know exactly which combination we ' re going to be going with . 
once we know then the trainable parts of it it ' d be great to run lots of lots of stuff through . 
uhhuh . 
right . 
well that was that . 
and then i guess chuck and i had some discussions about how to proceed with the tandem uh system . 
and you want to you want to see where that stands ? 
well i ' m 
yeah so andreas uh brought over the uh alignments that the s r i system uses . 
and so i ' m in the process of um converting those alignments into uh label files that we can use to train uh a new net with . 
and uh so then i ' ll train the net . 
and 
and one side effect of that would be that it ' s um that the phone set would change . 
right . 
so the m l p would be trained on i think only forty six or forty eight 
eight . 
forty eight phones . 
uhhuh . 
uh which is smaller than the um than the phone set that that we ' ve been using so far . 
yeah . 
and that that that will probably help actually . 
so it ' s a little different . 
because um the fewer dimensions uh the less trouble probably with the as far as just the um um 
just 
you know we want to try things like deltas on the tandem features . 
and so you have to multiply everything by two or three . 
and so you know fewer dimensions in the phone set would be actually helpful just from a logistics point of view . 
sure . 
although we i mean it ' s not that many fewer and and and we take a k l t anyway so we could 
right . 
exactly . 
so so that was the other thing . 
yeah . 
and then we wanted to just limit it to maybe uh something on the same order of dimensions as we use in a standard um front end . 
so that would mean just doing the top i don ' t know ten or twelve or something of the k l t dimensions . 
yeah and i think and we again check we should check with stephane . 
my impression was that when we did that before that had very little uh he didn ' t lose very much . 
right . 
by just taking the top whatever ? 
yep . 
yeah . 
yeah . 
but then 
and then something 
once we have the new m l p trained up uh one thing i wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know those features . 
uh and uh retrain m l p and also the you know the dictionary that we use for the hub five system . 
and the and the base starting off with the base of the alignments that you got from from a pretty decent system . 
exactly . 
right . 
yeah . 
so that would basically give us a um more hopefully a a better system . 
yeah . 
um because you know compared to what eric did a while ago where he trained up i think a system based on broadcast news . 
and then uh retraining it on switchboard . 
or uh and 
yeah . 
but he i think he he didn ' t he probably didn ' t use all the training data that was available . 
and his dictionary probably wasn ' t as tuned to um conversational speech as as the as ours is . 
so 
that ' s that ' s certainly one thing yeah . 
and the dictionary made a huge difference . 
uh yeah . 
uh we we made some improvements to the dictionary ' s uh to the dictionary about two years ago . 
which resulted in a uh something like a four per cent absolute error rate reduction on switchboard . 
which 
well the other thing is dipping deep into history and into uh our resource management days when we were collaborating with s r i before . 
uhhuh . 
huh . 
uhhuh . 
uh it was i think it is was a really key uh starting point for us that we actually got our alignment . 
when we were working together we got our initial alignments from decipher uh at the time . 
uhhuh . 
yeah . 
uh and later we got away from it because because once we had decent systems going then it was it was typically better to use our own systems . 
yeah . 
uhhuh . 
because they were consistent . 
but but certainly to start off when we were trying to recover from our initial hundred and forty per cent error uh rate . 
uh but that was a that was a good good good way to start . 
yeah . 
okay . 
and we ' re not quite that bad with our our switchboard systems but it was they certainly aren ' t as good as s r i ' s . 
yeah . 
so 
what is the performance on the best switchboard system that we ' ve done ? 
right . 
roughly ? 
well the hybrid system we never got better than about fifty per cent error . 
and uh it was 
i think there ' s just a whole lot of things that uh no one ever had time for . 
we never did really fix up the dictionary . 
uh we always had a list of a half dozen things that we were going to do . 
and and a lot of them were pretty simple and we never did . 
yeah . 
huh . 
but that 
uh we never did never did any adaptation . 
even that that number 
right . 
uh we never did any 
and and that number i think was on switchboard one data . 
right ? 
where the error rate now is in the twenties . 
yeah . 
so um 
yeah . 
so we were 
that ' s yet 
yeah . 
we were probably at least a factor or two off . 
right . 
yeah . 
so it would be so it would be good to sort of uh 
yeah . 
just at least to give us an idea of how well the hybrid system would do . 
yeah . 
but i think again it ' s 
yeah . 
it ' s the it ' s the conversational speech bit . 
because our our broadcast news system is actually pretty good . 
uhhuh . 
he knows . 
right . 
and the other thing that that would help us to evaluate is to see how well the m l p is trained up . 
right ? 
because it ' s a pretty good um indicator of that . 
uhhuh . 
so it ' s sort of a sanity check of the m l p outputs before we go ahead and train up the uh you know use them as a basis for the tandem system . 
uhhuh . 
yeah . 
it ' ll still probably be worse . 
i mean it ' s it ' d be context independent and so on . 
no . 
sure . 
should we should we bother with um using the net before doing uh embedded training ? 
not 
but 
but 
i mean should should we even use that ? 
oh oh that ' s a good question . 
or should i just go straight to 
yeah we we weren ' t sure whether it ' s worth to just use the alignments um from the s r i recognizer . 
or whether to actually go through one or more iterations of embedded training where you realign . 
try it . 
you run it . 
keep keep both versions . 
see which one ' s better . 
uh yeah . 
i mean i think i agree with 
i mean basically you would then you proceed with the embedded training . 
uhhuh . 
uhhuh . 
it ' s going to take you a while to train at this net anyway . 
right . 
and while it ' s training you may as well test the one you have and see how it did . 
okay . 
huh . 
all right . 
i could make arguments either way . 
but but so i 
you know it ' s 
well but 
sort of given up guessing . 
but in your experience i mean uh have you seen big improvements in on some tasks with embedded training ? 
or was it sort of smallish uh improvements that you got ? 
uh well it depended on the task . 
i mean i think in this one i would sort of expect it to be important . 
right . 
because we ' re coming from uh alignments that were achieved with an extremely different system . 
that are from another 
right . 
right . 
although i mean we ' ve done it with when we were combining with the cambridge recurrent neural net embedded training made it worse . 
uh 
which i ' ve never figured out . 
right . 
but i mean 
i think it ' s a bug . 
so you you started training with outputs from a with alignments that were generated by the cambridge uh system ? 
yep . 
and then 
uh uh 
yeah . 
yeah . 
well that might probably just 
huh . 
that was probably because your initial system i mean your system was worse than cambridge ' s . 
and you um 
was it ? 
i don ' t think it was . 
no . 
they were they were comparable . 
it wasn ' t ? 
no . 
really ? 
they were very close . 
yeah . 
that ' s weird . 
excuse me ? 
that ' s that ' s weird . 
no i mean it ' s weird that it did 
oh ! 
that ' s what i said . 
i ' m sorry . 
it ' s 
it ' s weird that it got worse . 
that ' s ambiguous . 
um no . 
uh we ' ve i mean and with the numbers o g i numbers task we ' ve seen a number of times people doing embedded trainings and things not getting better . 
oh actually it ' s not that weird . 
because we have seen 
we have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better . 
yeah . 
it just 
yeah . 
but i but i would i would suspect that something that that had um a very different um feature set for instance . 
i mean they were using pretty similar feature sets to us . 
yep . 
i i would expect that something that had a different feature set would would uh benefit from . 
uhhuh . 
what about uh hidden unit size on this ? 
oh wait a minute . 
and the other thing uh 
oh . 
sorry . 
it was the other thing is that what was in common to the cambridge system and our system is they both were training posteriors . 
right . 
so i mean uh that ' s another pretty big difference . 
uh yeah . 
that ' s another big difference . 
and uh one at least 
back at 
you mean with soft targets ? 
or 
sorry i ' m 
i missed 
what what ' s the key issue here ? 
oh that uh both the cambridge system and our system were were training posteriors . 
and if we ' re we ' re coming from alignments coming from the s r i system it ' s a likelihood based system . 
so so that ' s another difference . 
yeah . 
i mean you know there ' s different front end different different uh um training criterion . 
uh i would think that in that an embedded uh embedded uh training would have at least a good shot of improving it some more . 
uhhuh . 
but we don ' t know . 
okay . 
you going to say something ? 
yeah . 
i was wondering uh you know what size net i should 
anybody have any intuitions or suggestions ? 
uh how much training data ? 
well i was going to start off with the small train set . 
and how how many hours is that ? 
that ' s why i was 
i i ' m not sure how much that is . 
uh i think that has about 
well you ' d would be gender dependent training . 
right ? 
gender dependent yeah . 
so so i think it ' s uh that ' s about huh something like thirty hours . 
thirty hours ? 
thirty hours per gender . 
i ' m not sure what this ' ll mean . 
in the small training set ? 
hello ? 
i i think so . 
i ' ll 
excuse me ? 
it ' s definitely less than a hundred . 
you know it ' s more like like thirty forty hours . 
all right . 
something like that . 
wrong number . 
they called to tell us that ? 
yeah . 
yeah . 
um so uh after run 
i mean i didn ' t want to do too big . 
right . 
just 
so 
at least a couple thousand hidden units . 
i mean 
uhhuh . 
it ' s it ' s the thing i ' ll i ' ll think about it a little more . 
but it it ' d be toss up between two thousand and four thousand . 
huh . 
you definitely wouldn ' t want the eight thousand . 
it ' s it ' s more than 
and a thousand is too small ? 
oh let me think about it . 
but i think that that uh at some point there ' s diminishing returns . 
uhhuh . 
i mean it doesn ' t actually get worse typically . 
uhhuh . 
but it but but there is diminishing returns . 
and you ' re doubling the amount of time . 
remember you ' ll have a smaller output layer so there ' s going to be fewer parameters there . 
but not by a lot . 
not by much . 
and then 
fifty fifty four to forty eight ? 
vast majority is from the input unit . 
okay . 
yeah . 
yeah . 
yeah . 
it ' ll have a very tiny effect . 
right because you used the context windows . 
and so the input to hidden is much much larger . 
yeah . 
oh i see . 
i see . 
yeah of course . 
yeah . 
yeah . 
it ' s negligible okay . 
yeah so it ' s it ' d be way way less than ten per cent of the difference . 
uhhuh . 
uh there ' s uh 
how how big 
let ' s see . 
what am i trying to think of ? 
the the net that that we did use already uh was eight thousand hidden units . 
and that ' s the one that eric trained up . 
right . 
and that was trained up on uh like a hundred and forty hours of of speech . 
was that gender dependent or independent ? 
gender dependent . 
oh . 
so that would be like trained on sixty or seventy hours . 
uhhuh . 
so uh 
yeah definitely not the one thousand uh two thousand 
i mean the four thousand will be better . 
and the two thousand will be almost will be faster and almost as good . 
it ' ll be faster . 
yeah . 
so 
maybe i ' ll start off with two thousand just to see . 
uhhuh . 
yeah . 
okay . 
okay . 
yeah thirty hours is like a hundred and ten thousand uh seconds . 
uh so that ' s like eleven eleven million frames . 
and a two thousand hidden unit net is uh i guess about seven eight hundred thousand parameters . 
so that ' s probably that ' s probably fine . 
i mean a four thousand is well within the range that you could benefit from . 
but the two thousand would be faster . 
so 
right . 
i actually have to go . 
so 
all right . 
uncle bernie ' s rule is ten to one . 
bernie woodrow ' s rule of 
yeah . 
uncle bernie 
yeah . 
yes sir . 
we ' re just waiting for you to leave . 
anything else ? 
nah . 
since we have nothing to talk about we only talked for an hour . 
okay . 
so 
if 
yeah that ' s right . 
yeah . 
uh well we started late . 
all right . 
so uh welcome back . 
thank you for coming . 
um so what i thought we ' d do today is pick up where we were last time . 
and maybe uh go over some some ideas about um 
well the return to the conventions . 
but i also wanted to uh share with you a couple of the things that i ' ve picked up in terms of checking . 
and these are uh these are things that came up with the with the tigerfish transcripts . 
i ' m just doing this because i think it ' s interesting . 
okay so um i have an example 
thank you . 
oh there ' s hold on . 
which 
um so there ' re a couple of examples . 
i have one in front of you which is the one where 
um um 
leah leah noticed this one where i said something and um the transcriber interpreted it as twosome gruesome uh different sizes different this . 
and um actually what i meant to say was um so you ' re saying groups of different sizes . 
different size groups . 
whoa . 
yeah . 
wow . 
i 
it ' s really enormously far away . 
now this this could be one of those cases where the auditory was just really bad . 
that ' s what i was just thinking . 
or maybe it was really quiet or something . 
i don ' t know . 
maybe very very soft . 
maybe with the microphone noise . 
yeah . 
or something from someone else . 
or an overlap . 
uhhuh . 
or 
but they ' re not usually that bad i i don ' t think . 
uhhuh . 
then um i have a couple of others . 
so there ' s one um 
so the person said interesting idea . 
but tigerfish thought it was uh just an idea . 
now that changes the meaning . 
right . 
huh . 
it ' s interesting . 
huh . 
right . 
and then there are various ones like um um ish decay instead of h . t . k . 
oh . 
ugh . 
and now this one 
ish decay ? 
ish decay . 
now ish was in parentheses . 
ish decay . 
yeah what ' s an ish ? 
well they they they were suspicious that wasn ' t right . 
but that was the closest they could come . 
uhhuh . 
and you know with when you ' re dealing with acronyms 
wow . 
that ' s that ' s that shows one of the problems with acronyms . 
yeah . 
is that it ' s clear if you know it . 
i wonder if that was someone who was who had an accent maybe . 
but 
always conceivable . 
i don ' t remember off hand . 
i did check the example . 
and um 
well and this this would be consistent . 
so uh it was transcribed as with h . . 
but it was really with age . 
huh . 
huh . 
uhhuh . 
yeah . 
and uh then there are some where actually punctuation changes the meaning . 
so this is these are things that barbara uh found . 
spurts wouldn ' t be right was what it looked like . 
but actually when you listen to it it would be spurts wouldn ' t be right . 
oh . 
huh . 
huh . 
oh . 
that ' s very subtle . 
it is subtle . 
and yet you know it ' s like and instead of instead of and it ' s they put annette ' s . 
annette ' s ? 
now this this is interesting . 
because it ' s like you know we know that there ' s no annette on any of the meetings we ' ve ever dealt with . 
right . 
right . 
but um it ' s you know conceivable . 
right . 
huh . 
and then 
um 
let ' s see . 
there ' s one other here i thought was interesting . 
well this was 
okay so it should have been the quals the the quals slides will be fine . 
this is jerry feldman . 
and uh instead it was transcribed with the and then an uncertain syllable the the and then all the slides will be fine . 
uh . 
which is interesting . 
oh . 
and and you know this was a case where the timebin was off . 
huh . 
i wanted to bring an example where 
uhhuh . 
oh . 
yeah . 
so all the slides it ' s started too late . 
right . 
it ' s another case of devoicing at the initial 
right . 
uhhuh . 
yeah . 
so i thought that was very interesting . 
and i think that it shows um these sorts of things i was thinking it would be interesting to do an analysis of these things . 
because i think that 
um 
if well first of all there ' s this overall point that it shows a degree to which when you listen to speech and when you ' re just in general listening probably . 
but it shows specifically this to this task that it ' s very constructive . 
you ' re not going on simply the auditory there ' s a huge contribution from the top down processing . 
and the you know different types . 
you ' ve got the contextual information . 
you have syntax . 
you have your mastery of english and these various things . 
but i think these kinds of errors it just shows the degree which it ' s not strictly an acoustic task . 
uhhuh yeah . 
oh yeah . 
and the other thing i think that ' s interesting is the types of the types of confusions that happen um do preserve certain aspects of the stimulus . 
uhhuh . 
so the stress tends to be preserved . 
you know the content word will be substituted for another content word . 
and um 
it ' s it ' s not surprising that they would hear this . 
i ' m i ' m often surprised by how how plausible something can be with without it being correct . 
uhhuh . 
because it really seems like it ' s 
uhhuh . 
and then often you know it ' s um there ' s the parentheses are used . 
so the person knew it wasn ' t really a perfect match . 
uhhuh . 
but uh 
okay now having said that i ' m i ' m impressed by how by how um well how infrequent these these kinds of extreme cases are . 
most of the types of things that i find in checking are much much more mild . 
yeah so so 
uhhuh . 
do you want to 
actually that comes back to a point . 
we had talked about this last week where you were interested in so . 
uhhuh . 
saying so at the end of something . 
uhhuh . 
and sometimes that would get transcribed as 
okay so let me just think of an example . 
um 
okay let ' s say i say well that would be hard to do so . 
uhhuh . 
okay right ? 
and the way i would transcribe it i would put that so that would be hard comma so . 
at the end . 
uhhuh . 
because it ' s kind of just the end of that the 
uhhuh . 
would you put a period after so ? 
right . 
you would or you wouldn ' t ? 
so 
yeah . 
yeah i would just sort of end it . 
yes . 
uhhuh . 
but then sometimes they transcribe it like so that would be a problem period new word like capitalized so . 
oh . 
uhhuh . 
right . 
oh like it ' s a whole new utterance . 
like it ' s not connected . 
right and and it just seems to totally that that ' s not the meaning . 
uhhuh . 
and and it changes the meaning i think . 
um 
in a way 
so uh let me be sure i understand . 
so you ' re saying 
boy it ' s hard to uh that ignore that word ! 
uhhuh . 
um 
so the example is that would be hard . 
or whatever yeah . 
that would be a problem . 
that ' d be a problem . 
whatever . 
right . 
yeah . 
so 
so 
and how does it change the meaning ? 
what ' s what are the two different meanings there ? 
it seems like because if i was just reading that thing i would say so that would be a problem so . 
okay . 
you know what i mean ? 
if if it was like period capital s . o . as opposed to um that would be a problem so . 
oh i see what you ' re saying . 
that would be a problem so . 
right 
it it 
i think the second one where the so is all by itself it ' s like so that would be a problem so . 
you know the so is like disconnected from the 
right as though it ' s leading into something else . 
it ' s like kind of like introducing 
yeah the first one is like the so is connected to the sentence . 
bu and 
and that ' d be a problem so . 
yeah . 
you know it ' s but the next one is like not not connected to that would be a problem . 
it ' s like so . 
it ' s like introducing a new thing that they don ' t talk about . 
a new subject . 
yeah less 
right yeah . 
the first one too is more like 
so 
uhhuh . 
to me i don ' t necessarily put um like a a a a period after that so . 
i might actually either put a dash after it depending on whether or not they got interrupted or something . 
uhhuh . 
or i would maybe even act as though they were um just trailing off . 
right . 
so put that those two dots after it . 
i do that too . 
um uh which depending on what ' s going on like i ' ll do that . 
because to me it sounds more like they ' re trailing off . 
right . 
sometimes though it does sound like they ended a sentence . 
yeah . 
and then i do 
yeah yeah yeah yeah . 
yeah . 
huh . 
like sometimes it ' s just like that ' d be hard so . 
right . 
you know and but and then often it sounds like they were trying to think of something else to say . 
right . 
yeah . 
but they couldn ' t really you know 
and then they get interrupted and then i put a dash . 
yeah . 
yep . 
you know but i never usually put period and then new word so unless it ' s like end of the sentence and then so . 
what are we going to do now . 
but they don ' t say that . 
huh . 
uhhuh . 
yeah . 
yeah . 
uhhuh . 
it ' s it ' s interesting that there are so many cases . 
and i agree . 
i i think those are very good conventions . 
i also like you know this this whole point about how how that the fact that you ' re raising this 
i i like this example that um we have several things that are being cued by intonation . 
right . 
because if if that ' s a nice full falling intonational contour on that ' s a problem . 
uhhuh . 
uh that ' ll be a problem . 
then i would think that there should be a period there . 
period right . 
yeah . 
right . 
and then especially if you ' ve got a pause following it . 
but you don ' t always 
these things are correlated but they ' re not perfect . 
yeah . 
that ' s another thing is if you ' re not a native speaker of english you might not pick up . 
because uh you know every language has different um intonation mappings . 
uhhuh . 
yeah that ' s always one of the hardest parts about the native speakers . 
uhhuh uhhuh . 
and 
is you don ' t know exactly like how to do the punctuation . 
right . 
because their intonation is totally different . 
you mean non native non native speakers . 
i mean non native speakers is what i meant yeah . 
yeah yeah yeah yeah yeah yeah yeah yeah . 
yeah . 
absolutely yeah absolutely . 
and also if you ' re a non native speaker transcribing it you wouldn ' t necessarily uh understand the conventions of english intonation as you know intimately as a native speaker might . 
yeah that ' s true . 
right uhhuh . 
well i would hope they would have native speaker transcribers transcribing . 
ideally wouldn ' t that be something ? 
ideally it would be nice to have like a spaniard transcribing the 
oh yeah . 
oh is that what you mean ? 
or 
no that ' s not what i meant . 
oh . 
but that would be cool . 
that ' d be nice . 
no what i meant was that i would hope that for meetings in english you would have native speakers transcribing it . 
because it you would have more intuitions about what should be there . 
i agree . 
yeah . 
yeah . 
even if you can ' t fully understand the word you can make a guess you can that isn ' t completely off like some of these are . 
right . 
but they ' re pretty rare . 
those things the 
uhhuh . 
the really bad mistakes that they make are pretty rare . 
i think so . 
i i so in terms of like when you ' re going through the tigerfish transcripts you don ' t find a lot of these kinds of extreme cases . 
not this 
not so much no . 
okay . 
i mean 
huh not twosome gruesome . 
no not twosome gruesome . 
sometimes . 
but they tend to be pretty good about parentheses . 
uhhuh . 
uhhuh . 
good good to hear . 
yeah . 
yeah sometimes they they usually put them in parentheses . 
and you think to yourself you were way off . 
yeah . 
but at least you knew you were way off . 
yeah . 
yeah . 
uhhuh . 
exactly . 
yeah i just wonder like what influences them to think of twosome gruesome . 
good . 
like maybe this person just saw a horror movie or something . 
and 
uh this is the interpretation that came to mind or something . 
it ' s could be . 
yeah . 
you know what i mean ? 
like where would you get the word gruesome ? 
i don ' t know . 
you know you just sort of pull it out of the air . 
well i mean you get the g . r . from groups i guess . 
anyway . 
but 
yeah . 
yeah . 
i don ' t know where the rest of it came from . 
uh groups of . 
gruesome . 
group . 
okay . 
groups of . 
gruesome . 
you ' ve got the uh s . in the middle . 
yeah if you if for some reason they didn ' t hear the f . if they didn ' t hear the fuh it might just sound like 
gruesome . 
yeah uh gruesuh . 
yeah . 
yeah it ' s both labial at the end . 
you know and then you would kind of have to come up with some sort of consonant . 
groups of 
and maybe it ' s an m . to you . 
well also 
right . 
group of groups of groups of group 
fff because also i mean f . is fff is um fff 
gruesome groups of gruesome groups of 
i wonder where the p . went though . 
right fff because it ' s 
maybe the p . wasn ' t pronounced very well . 
yeah . 
like groups of . 
yeah because it ' s um bilabial too . 
fff you know you ' ll 
uh or interdental fff . 
uhhuh . 
you know it ' s close enough i guess to huh you know . 
nnn i guess . 
you ' re getting the closure of the lips . 
so maybe that ' s what they were getting . 
i don ' t know . 
it ' s possible . 
huh . 
huh . 
well you know there ' s also this problem that they didn ' t have context to constrain the interpretation . 
yeah . 
yeah . 
because 
yeah . 
yeah that ' s really hard . 
okay . 
to not be able to go and listen to the other channels and figure out the context of what it ' s occurring in . 
yeah . 
yeah when i ' m clearing the parentheses i find that very useful . 
i i sometimes i try to just go through and pick up the parentheses . 
yeah . 
see if i can do it just by itself . 
but it it ' s remarkable how sometimes something can be so totally opaque . 
and then you go back to you know the person ' s previous utterance . 
or you go to the mixed channel . 
or you uh check on the other things . 
and suddenly it becomes perfectly clear . 
uhhuh . 
it ' s very very surprising . 
very surprising . 
yeah . 
good . 
but this other business um that you have at the bottom with people getting transcribed on another channel . 
yes . 
is uh is much more common . 
is that what it ' s about ? 
i wasn ' t i couldn ' t i don ' t know for some reason that didn ' t make sense to me . 
but it ' s about when things are transcribed on other channels than what they ' re set on . 
right . 
okay . 
and what ' s always funny to me is when it ' s you know they miss the gender completely . 
like you know morgan will be on jane ' s channel . 
or just something bizarre like that . 
yeah . 
um so 
well maybe it ' s because they don ' t realize that you ' re supposed to 
do they 
i mean maybe they don ' t really realize that you ' re supposed to split it up or something . 
like they maybe think well i hear it just as clearly . 
i hear this other person ' s voice just as clearly . 
or something . 
and i realize it ' s not jane . 
and i realize it ' s not a female even . 
but um because it ' s so clear on this channel i ' m supposed to transcribe it . 
i ' m supposed to do it . 
uhhuh . 
yeah . 
i i ' d imagine that ' s that might be what that is . 
they probably don ' t even know how many people are at the meeting or anything . 
yeah it ' s really an odd task in in a way . 
because they ' re they have no clues at all about how dominant the speaker is on the channel they ' re transcribing . 
yeah . 
uhhuh . 
yeah . 
uhhuh . 
and the pre - segmenter doesn ' t give them any or the information either . 
i ' m i ' m sure that it ' s because of the 
yeah . 
wow . 
yeah . 
we ' re we ' re really spoiled then with our interface here . 
huh . 
fancy - schmancy . 
right ? 
yeah . 
i mean it ' s very useful . 
if i was going to make just a guess though from my experience it would seem like the men get um 
yes . 
the men get moved onto other channels maybe more frequently . 
and it ' s just probably because they have deeper voices . 
and they ' re getting picked up on more channels um than their own channel . 
that would make that would make some sense . 
yeah . 
um for you know it ' s an acoustic thing . 
okay . 
or they just tend to peak louder maybe . 
that ' s true they do they do say that men ' s voices carry better . 
yeah . 
i mean that ' s why they use like i 
who was telling me ? 
ian maddieson was talking about this that they use male voices in um in um airports . 
oh ! 
huh . 
because the acoustics of it it just fits into the a hearer ' s range . 
for announcements and things ? 
yeah that ' s it fits into a hearer ' s range of perception um better than a lot of female voices . 
huh . 
huh . 
huh . 
and so that ' s why they use male voices . 
we were just talking about that . 
they should do that at bart too . 
because sometimes it ' s hard to hear . 
i see . 
and now they have those strange computerized voices that 
so 
yeah those are actually probably just the computer problem . 
huh . 
not the gender problem . 
huh . 
so so this means that people with hearing problems would hear uh uh one of these announcements better if it were a male voice then . 
yeah depending on their auditory um capabilities . 
uhhuh . 
i mean if their auditory capabilities uh have been you know um squished down like in a certain place where it would be easier for a person with normal um hearing to hear a male ' s voice 
um like if i ' m saying if if they if they had a some sort of um you know damage to part of their brain that processes auditory information then 
and uh 
if that part of the brain normally codes for you know male voices uh in a normal hearer then they might not be able to . 
you know does that make sense ? 
uhhuh uhhuh uhhuh . 
like if that part is damaged . 
so but um 
selective . 
but yeah if i guess for most hearers it ' s just easier . 
and it ' s like a certain uh kind of like rough male voice too . 
kind of graspy . 
raspy i mean . 
huh . 
huh . 
huh . 
apparently . 
huh . 
is better ? 
is better . 
uh it ' s a wider band then . 
because of 
do you think it might be from the 
yeah i guess so . 
she asked this question last time which was um whether our system here the recording system may have some of the same channel some sort of channel restrictions such as they ran across when they were looking at telephone uh transmissions at a certain point . 
because you know telephone transmissions um there ' s some filtering going on . 
you don ' t hear the full the full band of frequencies . 
uhhuh . 
oh . 
right . 
huh . 
and uh i asked a couple of people and they answer came back that 
it ' s really interesting . 
it was an interesting 
it ' s reminded me because of the comment about noise . 
noise being really spreading frequencies across uh using frequencies across a broader spectrum . 
uhhuh . 
yeah . 
so in a way bandwidth can increase with some of these cases of distortion that we have . 
but it ' s it ' s not a useful kind of increase in frequency range . 
right yeah i was just saying that it like you know sometimes um if remember i was saying like if there ' s a discrepancy between fricatives you know like um shuh or suh will show up in a certain part of the spectrum . 
and and uh oftentimes the fuh is like knocked out of the spectrum by 
yeah by filtering or something ? 
um by filtering in some of the older phones . 
uhhuh . 
and that ' s why like 
huh . 
so what was the answer here ? 
it that ' s not the case ? 
answer 
that they don ' t 
that they that they don ' t . 
we don ' t have a reduction in that direction . 
oh okay . 
right . 
oh . 
good . 
that uh i mean you know one could have if one had cheaper microphones than we have . 
but we ' ve got good microphones . 
uhhuh . 
right . 
and another there is sort of an upper limit set on our bandwidth by the sampling rate . 
but then that becomes 
so adam ' s that 
uhhuh . 
then it becomes a matter of is that something that would be relevant to perceptual range . 
and i didn ' t really have the sense that it would . 
i didn ' t get that from him actually . 
i felt like um he ' s basically saying that for our for all intents and purposes with this it ' s covering whatever sounds are necessary to be covered like everything . 
uhhuh . 
uhhuh . 
good i i that was my impression also . 
that ' s that ' s what i 
it so we don ' t have that kind of reduction like you have on telephones . 
and actually in the work that they were doing with the telephone corpora they did run into limitations . 
and uh certain types that they when what their speech recognition approach . 
is because of the of the filtering . 
huh . 
i mean it does seem like when i hear these things except for the distortion parts . 
where the volume ' s too high or of course when the volume ' s too low 
but that ' s a different problem . 
um except for those cases it seems to me that it really is as if the person were speaking in my ear . 
i don ' t feel that it ' s being reduced in any way . 
yeah . 
huh . 
uhhuh . 
yeah that ' s what it seems like . 
yeah yeah i do too . 
yeah . 
yeah ? 
and he was saying in the in the uh areas where you have clipping where it ' s recorded too high and and it starts to saturate and you have trouble . 
right . 
um i thought that was very interesting . 
so bandwidth then gets gets actually wider instead of narrower . 
because you have 
um 
uhoh ! 
you have these you still have the frequencies are represented . 
but the energy distributions are thrown off . 
and um in fact you have also some additional frequencies . 
so you end up with a wider bandwidth functionally . 
i mean 
yeah so like you were saying like in the case of something with clipping . 
but not helpful for speech . 
does it were you saying that uh it it increases to or expands to accommodate that ? 
or 
no technically the bandwidth is wider than 
no . 
so it ' s actually paradoxical in a way . 
because you usually think bandwidth better bandwidth is better . 
oh . 
uhhuh . 
but in the cases of of distortion than you can end up with 
right oh okay yeah . 
uh 
i see what you ' re saying . 
a wider bandwidth which isn ' t useful in terms of understanding speech . 
right . 
right . 
huh . 
so 
i have a question . 
yes . 
in the some of the earlier meetings i guess there was a lot of spikes . 
or what i called spikes . 
yes . 
i was wondering what that is . 
i don ' t even know if it ' s relevant or useful to know . 
but i ' m just curious . 
one source was there was a problem with a connection . 
where the microphone went went into a box . 
uhhuh . 
i was trying trying to think of this as prior to 
yes it was prior to the wireless . 
there was a particular connection which wasn ' t wireless . 
which was um mechanically bad in some some sense . 
loose . 
yeah . 
uhhuh . 
and if it got touched it would it would send an impulse . 
oh . 
huh . 
in an uh an irrelevant non wanted artifact . 
yeah . 
huh . 
because those ones sometimes were extraordinarily bad and 
huh . 
painful . 
yeah . 
yeah . 
i agree absolutely painful . 
they were painful . 
i agree . 
uh 
and that ' s that ' s you know i would watch the visual signal to avoid that . 
oh yeah . 
yeah . 
it ' s like 
yeah . 
yeah and like not listen to them . 
i do remember those actually . 
and then you see it . 
and off with the headphones . 
yeah you could see it coming and you ' d turn the volume down or something . 
or just uh 
yeah yeah yeah yeah i remember i had one one with that and it was just all the time . 
yeah or like skip it entirely . 
yeah . 
oh yeah . 
yeah . 
yeah . 
yeah . 
especially if they also got louder too and they hit it . 
yeah . 
oh ! 
it was just like whoahh ! 
yeah that ' s really awful . 
you ' ve noticed that those have gotten better over the intervening . 
yes absolutely . 
oh yeah uhhuh . 
yes . 
good . 
but sometimes you ' ll see like something coming up . 
like uhoh . 
someone ' s going to cough really loudly . 
and i could tell because of the way it looks . 
yeah . 
or someone ' s about to laugh really loudly . 
and so you turn it down . 
uhhuh . 
oh . 
um yeah . 
yeah yeah yeah . 
and then you ' re just you ' ve got like you know you ' re sort of like 
uhhuh . 
take one off or something . 
yeah . 
no i think 
huh . 
yeah . 
so unless there ' s going to be some speech in there i don ' t think i need to listen that carefully . 
i think that ' s really important . 
yeah i think that ' s really important . 
yeah . 
because i generally have the volume turned up to above normal volume just so i can hear more clearly . 
so 
uhhuh yeah . 
right . 
and if it ' s like that for someone screeching into the microphone than it would be really painful . 
yeah . 
right . 
you could really hurt your ears yeah . 
i think you could yeah . 
uhhuh . 
oh yeah . 
i think so too . 
huh . 
so 
yeah i 
yeah that ' s 
especially we have really good headphones . 
when i realized 
like 
yeah when i realized i i meant to tell everyone to watch that visual signal . 
because that ' s that ' s saved me a bunch of times . 
gives some good clues . 
yeah . 
yeah i mean it ' s very useful in like all senses . 
because 
oh yeah yeah . 
yeah . 
oh yeah . 
yeah . 
it ' s very good . 
sometimes it doesn ' t pick up backchanneling though . 
and so sometimes you have to um try to listen . 
no . 
or turn up 
there ' s no visual . 
but 
yeah you have to the resolution . 
right . 
yeah or like 
right . 
it might be useful to to talk about the interface for for a bit . 
so 
in terms of what it is that you like particularly and what you don ' t . 
uhhuh . 
and uh that kind of thing . 
you know what i would think would be a really um neat feature for the interface ? 
some sort of backwards tab . 
where it could go backwards without you having to go up and do it manually . 
ooh interesting . 
yeah . 
yeah . 
and you know press the button and juh - juh - juh - juh - juh - juh - juh . 
huh . 
because if you miss something and you want to go back to it it ' s such a such a hassle . 
uhhuh . 
that ' s true . 
it ' d be so nice if there was just some sort of like you know uh opposite of tab that you could hit that it would just sort of move backwards . 
there wouldn ' t even have to be any um 
huh . 
but it would play it backwards too . 
i know . 
it you wouldn ' t even have to have the audio . 
that ' s not i wouldn ' t i mean 
but just to move back but not necessarily a whole timebin ? 
just to jump it back . 
yeah . 
interesting . 
right because sometimes you ' ll hear it ' ll be in right in the middle of the timebin . 
huh . 
and you don ' t have to listen to the whole thing again . 
right . 
because you ' ve already gotten the first part . 
right . 
yeah . 
huh . 
oh yeah yeah . 
so you just want it to go back 
i don ' t know . 
yeah some 
and otherwise you have to drag it . 
yeah some timebins are humongous . 
or otherwise drag it or like click on it . 
and if you miss it you know you ' ve got to go back and find it . 
uhhuh . 
and dragging it and looking for it and you may not be able to see it even . 
right . 
yeah . 
you know . 
that ' s true . 
i think that would be useful . 
huh yeah . 
yeah . 
interesting idea . 
i ' ll i ' ll i ' ll suggest that to the charer . 
yeah the less you have to click on the mouse i think the faster you could go . 
yeah because i noticed i started feeling like i was getting some sort of carpal tunnel issues . 
uhhuh . 
yeah you were having some wrist problems and stuff . 
much better now that i have the keyboard tray . 
right ? 
but it was 
yeah . 
i think because i had my hand in one position using it all the time . 
huh . 
and that i would it would crack a lot . 
yeah ooh ! 
it was very weird . 
huh . 
but 
yeah . 
that ' s it ' s good to be careful about the mousing . 
you were going to say ? 
oh yeah um something um maybe i just don ' t know how to do this . 
yeah . 
but when i want to expand a timebin back 
uhhuh . 
uhhuh . 
or even forward . 
i ' ll use the mouse . 
the middle 
how do you mean expand ? 
what do you mean by expand ? 
oh uh in terms of um if uh if it ' s it ' s if it ' s cut off . 
like the beginning of an utterance . 
okay . 
uhhuh . 
oh i see what you ' re saying . 
okay okay . 
i ' ll move it move the line back . 
uhhuh . 
and i usually just use the mouse . 
how do you do that with the keyboard ? 
huh . 
really ? oh i do that with the keyboard . 
well i would press tab . 
i do that with the mouse yeah . 
and listen to where i wanted it to stop . 
uhhuh . 
and then press return create a new timebin . 
return . 
and then 
oh . 
and then shift 
and then shift 
shift what is it ? 
backspace . 
oh okay so you just do it that way . 
shift backspace to collapse it yeah . 
that ' s that ' s what i do . 
okay okay . 
yeah . 
i do it all on the keyboard . 
oh ! 
okay to me that ' s takes longer than to do it with the mouse . 
yeah . 
oh do you drag do you drag the line ? 
oh really ? 
because you can just click 
yeah . 
i just drag the line . 
see i never i never do that for some reason . 
i don ' t do that either . 
i didn ' t even even know you could do that . 
i vary . 
i i should it depends on how much i want to go back . 
yeah . 
and how certain the boundary is . 
if i can see it if it ' s if i can see this thing ' s coming up and it ' s just so clear . 
oh yeah that ' s true . 
yeah . 
right . 
it ' s that mountain right there i can tell then 
yeah . 
right then i ' ll drag it . 
uhhuh . 
yeah dragging is really efficient . 
but if it ' s like a mess in there then it helps me to be able to locate it with the actual clicking . 
uhhuh . 
right . 
yeah . 
huh . 
right . 
huh . 
and then do this what you were just describing . 
yeah . 
but um 
um one thing that ' s gotten me into problems a little bit is having the shift - backspace as the collapser . 
uh yeah . 
because i ' ll tend to delete things . 
yeah . 
or go too far or something . 
or i ' ll be holding down shift because i want to type something as a capital . 
uhhuh . 
oh yeah . 
yeah . 
yep yep yep yep . 
and then end up collapsing the timebins . 
and and then collapse it . 
yep . 
yep . 
i did that so much . 
so it might be better to use a different keys or something . 
oh that ' s annoying . 
yep . 
this if i were to 
yeah . 
if i were to add an option it might be to have an undo for that . 
yeah yeah . 
oh that ' d be good that would be good . 
yeah . 
because i have had that happen . 
yeah that would be nice . 
that would be great . 
or just i mean 
yeah good . 
i ' ve erased entire utterances before accidentally . 
but or just to change the keys used you know for for that option . 
yeah i ' m rather used to it now though . 
i ' m used to it too . 
but i mean 
yeah . 
but then when you go to type on your keyboard at home . 
uhhuh you ' re so scared ! 
do you do this too ? 
i ' m so scared . 
like i i won ' t hold shift down 
yeah . 
to to hold shift down while you ' re backspacing ? 
i won ' t do it . 
yeah . 
you ' re typing capitals and you ' re backspacing and you ' re like oh take the shift off . 
i ' ll collapse everything . 
yeah yeah yeah yeah yeah . 
i ' m just like what am i doing . 
i totally do that now . 
i don ' t think i ' m that bad . 
but 
yeah yeah . 
oh yeah i do find that the keyboard is different here than it is even at my for my school computer . 
huh . 
and so i ' ll i ' ll just be 
if i was just at school and i come here it ' s just 
oh yeah . 
or vice versa . 
it ' s just uh it ' s like i ' ll i ' ll reach for one key and it ' ll do something completely different . 
or vice versa yeah . 
and i have to just get used just get used to it again . 
uhhuh . 
that backspace and the little 
yeah the backspace is in the wrong place . 
and the yeah that little evil apostrophe that keeps showing up . 
the little accent thingy . 
right . 
i don ' t want you . 
yeah i do that too . 
oh yeah and then i ' ll keep i keep caps locking too . 
oh . 
because the caps - lock ' s in a different spot . 
oh yeah . 
yeah . 
so 
huh . 
oh . 
how do you get i don ' t know the evil apostrophe ? 
it ' s just right above the backspace . 
um yeah it ' s one of the backspaces on the keyboards that most of us are probably used to . 
yeah . 
oh oh ! 
so you want to backspace and you get apostrophe apostrophe apostrophe apostrophe . 
yeah yeah yeah yeah . 
huh . 
yeah you ' re like no . 
i see . 
oh . 
yeah i do that all the time . 
yeah . 
okay so this is the difference between the p . c . keyboard and the sun keyboard . 
uhhuh . 
so like i only have one i have one versus two of the others . 
i think so . 
yeah . 
yeah . 
yeah . 
did it 
right . 
is that right ? 
right i i ' m used to it now too . 
so it ' s 
i ' m actually used to 
i ' m used to the sun one i guess now . 
okay . 
yeah . 
but then like i think there ' s a different keyboard on 
uhhuh . 
i always forget 
oh linguine than on um 
there ' s 
basmati ? 
no the other one . 
amaretto ? 
amaretto . 
okay . 
amaretto has a different one . 
linguine is basmati have the same . 
right and it ' s and i always use i tend to use linguine . 
right ? 
but the last couple times like you ' ve stolen linguine before i can get to it . 
ooh ! 
i can get to it . 
so i go onto amaretto . 
which is fine . 
but then like um it takes me a good like ten minutes to get reused to that keyboard . 
yeah . 
and so i keep 
i don ' t know . 
you seem very upset about it . 
so we maybe we should trade . 
no it ' s really okay . 
but yeah i i i have noticed that i ' ll screw some stuff up like when i ' m trying to get 
so which 
but just the beginning . 
i i ' ve forgotten which one is which . 
so which one do you prefer ? 
is it is it the so if we had a show of hands how many people would vote for the sun keyboard versus the 
okay . 
so let ' s put it the other way . 
how many people would not vote for the sun keyboard ? 
would vote for the other one . 
the p . c . p . c . keyboard . 
which is the 
the p . c ? 
the p . c . one ? 
i would vote for the p . c . 
the p . c . one is the amaretto one . 
right ? 
i don ' t know . 
i i ' m not sure . 
it ' s the 
yeah . 
huh . 
i ' m not sure which one is which . 
or no . 
yeah . 
i just get used to it . 
uhoh . 
so 
yeah . 
i like the linguine keyboard . 
yeah . 
i mean like when i first had started working i would have definitely wanted the p . c . keyboard . 
the linguine is okay . 
that ' s all i know . 
but now i ' m i ' m just used to it . 
you ' re 
i prefer i prefer the one on linguine or basmati . 
yeah . 
i don ' t know what it ' s called . 
okay let ' s do it that way . 
uhhuh . 
so so if we if we have a map of the room the one when you first walk in 
uhhuh . 
is basmati . 
oh . 
to the left 
the one on the left is that basmati ? 
by the light switch yeah . 
yep . 
i believe that ' s correct yeah . 
yeah . 
okay . 
linguine must be the one in the left hand corner . 
and 
it ' s the one in in that corner right ? 
linguine is the one in the corner . 
in the 
that that has the p . c . 
right ? 
yeah the one in the 
and then the the far right corner as you walk in ? 
yeah yeah that ' s that one ' s got the the p . c . keyboard . 
and then the two on those sides have the um sun keyboard . 
yeah so basically right as you walk in the door the one straight ahead of you is amaretto . 
right . 
yep . 
huh . 
and the one to the left of that against the far corner is linguine . 
good . 
okay . 
huh . 
and the one close to you is basmati . 
yeah . 
right . 
okay so now who would ' ve 
yes . 
so if you have a strong 
now you ' re bi - keyboardal . 
so 
uh yeah . 
but 
but um 
nice . 
who who would prefer the keyboard on linguine ? 
okay we got two votes for linguine . 
and who would prefer amaretto ? 
amaretto . 
so we got more more multi - keyboardal people . 
ready . 
i just have no preference . 
well that ' s lovely . 
yeah it doesn ' t really matter . 
same here ? 
yeah . 
yeah . 
excellent . 
yeah . 
okay so 
it just goofs me up for like maybe a minute . 
and then i sort of get used to it . 
exactly exactly . 
i i could get used to i could get used to it too . 
yeah i could get used to it too . 
okay . 
uhhuh . 
i just am very used to 
huh . 
right . 
i don ' t know . 
because i always use it . 
i i see . 
i i have experienced this keyboard conflict . 
and with me the things that are confusing are where the control key is . 
so i end up 
huh . 
pressing shifts and control keys whenever i want the other one whichever it is . 
oh that ' s true . 
uhhuh uhhuh . 
i forgot about that one . 
oh . 
yeah . 
huh . 
huh . 
uhhuh . 
uhhuh . 
i could easily put a p . c . keyboard in there if anyone had 
i we already have one . 
i could add another one . 
right . 
we so you know maybe let me know if you want it to have it shifted . 
i ' m 
but um 
okay . 
that ' s good . 
oh let me see . 
so um i i wanted to um maybe comment a little more on the interface in terms of what aspects of it are helpful in this . 
i know we had this interface for a time when people were doing marking of the numbers . 
uhhuh . 
and um um 
i ' ve forgotten someone said that they could recognize a seven when they saw it they could see the the waveform and oh it ' s going to be a seven . 
oh wow . 
oh yeah . 
i i remember recognizing certain numbers . 
i huh i don ' t remember which ones . 
but i think it was maybe 
well i could recognize when there was a fricative at the beginning of a number for some reason . 
it was like a little bit of energy or whatever you call it . 
and then it grew really big . 
so like four and five and three all had this same characteristic . 
and six and seven both had the same characteristics to their in the beginnings . 
huh . 
but six and eight . 
eight um i remember tended that people tended to not pronounce the last t . . 
oh . 
and when they did it was slightly farther away from the rest of the word than you would have expected . 
uhhuh . 
same with six . 
the x . well the k . s . or whatever at the end . 
huh . 
huh . 
but 
yeah . 
that was a that was really interesting to notice that . 
uh 
it ' s a very different interface though . 
i mean it seems very strange . 
uhhuh it is different . 
well it it would it had the benefit of it 
so this this was to handle the digits uh only . 
okay . 
which is what you figure . 
and um did you i thought you might have done that joel . 
did you also ? 
nn huh no . 
so two people did that um i thought . 
i did it a little . 
did you do it ? 
i thought so . 
good good . 
just a little bit . 
yeah . 
yeah . 
okay . 
yeah i only did it a little bit too . 
yeah what happened to that ? 
you just stopped doing it ? 
or 
well i think that we ' ll bring it back . 
oh okay . 
the 
this was a different interface entirely ? 
yeah . 
uh adam wrote this as uh using the same uh computer language as channeltrans is written in . 
uhhuh . 
and what it would do is present you with the digit string that the person was supposed to have said . 
and then you would listen to it . 
and the 
there were two parts to the task . 
one of them was to see if that ' s what they actually said . 
and to indicate you know in the transcribe errors of it . 
huh . 
huh . 
and then the other aspect was to tighten the timebins . 
and those data were actually used in some analyses which showed uh very very good results . 
right . 
good . 
oh wow . 
and so it shows 
i mean it ' s it ' s useful . 
this is this is why we do these digits . 
it ' s a nice standard task . 
uhhuh . 
uhhuh . 
and you have lots of different voices . 
uhhuh . 
uhhuh . 
and it ' s very clear . 
you know what the canonical answer is when a person says a number . 
um at least most of the time you know what number it was they said . 
so its 
right . 
ground truth as they call it is very clear . 
uhhuh . 
huh . 
right . 
so 
but i it was um really rather minimal . 
i mean i i like that interface . 
very efficient . 
and really is um i think that we ' ll probably use it for getting the digits refined in terms of their timebins . 
huh . 
if i remember correctly it seemed to be very efficient in the key strokes that you used to do certain things . 
uhhuh . 
i can ' t remember what they were now . 
but i just remember that it was once you learned them it was very neat and concise . 
and like 
excellent . 
couple keys that you used . 
yeah the hardest thing ' d be finding them . 
huh . 
because i would get the whole i ' d get the whole transcript of the meeting . 
oh that ' s right . 
and you had to find them . 
you ' d have to find where the digits were . 
oh . 
and they ' d usually be at the end somewhere . 
oh wow . 
oh . 
but you had to figure out where the heck in the meeting to to look for them . 
yeah . 
that ' s right . 
uhhuh . 
so 
yeah . 
i also think that wasn ' t this a stage where some of these meetings hadn ' t been transcribed . 
so i don ' t think you could use a string search right ? 
yeah . 
i mean i was trying to remember how that worked . 
huh . 
but it was difficult finding them for some reason . 
yeah . 
yep . 
well it was also like you 
yeah the interface was different . 
i i yeah . 
it was it was more complicated . 
that ' s a down side . 
but anyway . 
uhhuh . 
than what it would be now . 
so 
actually you you also did a different type of transcription uh with respect to um our sister project . 
the smartkom project . 
which involved listening to people who were supposed to be wandering through germany . 
oh right . 
and this is supposed to be something that would be useful in developing an interface to help them find their way . 
uhhuh . 
so um someone else did that too . 
i ' ve forgotten who who else did that . 
did anybody else here do that ? 
okay . 
i feel like i did a little checking or something on that . 
actually i think you might have done this also as i think about it . 
yeah i don ' t know i don ' t remember actually transcribing it . 
but i remember listening to . 
oh . 
uhhuh so actually we started with the words . 
yeah . 
and it was a matter then of trying to find the most efficient way to match the words up with the with the actual sounds . 
because they were reading from a script . 
yeah . 
right . 
huh . 
uhhuh . 
and then there was some conversation in addition that that um needed to be transcribed . 
huh . 
uhhuh . 
but um 
yeah . 
one thing that you learn with this interface right away is that if you have really really really long utterances it ' s extremely inefficient to do anything . 
huh . 
because you end up 
if you try to go up in the transcript you end up with this huge huge space of time . 
uhhuh . 
yep . 
and things covering several screens . 
and it ' s just horribly inefficient . 
yeah . 
yeah . 
so 
yeah . 
one thing that i still can ' t figure out with the interface . 
it does this sometimes . 
but other times it doesn ' t . 
is when you click on 
you know there ' s a bar above where this sound wave is that has um the 
it has a little bar of where the meeting is . 
like in 
yes . 
uhhuh . 
and it goes along as you ' re listening to the meeting . 
and then it ends up the end . 
and if you click on that bar to the right of that little marker then it moves forward . 
uhhuh . 
if you click on the left it moves back . 
but sometimes it moves two frames or two screens . 
uhhuh . 
huh . 
oh yes . 
uhhuh . 
huh . 
i ' ve noticed that . 
and sometimes it doesn ' t . 
i think that ' s totally dependent on how you have the resolution set . 
so that little tiny thing . 
really ? 
and if i increase the resolution so it ' s spread out a bit more then i seem to have more control over it . 
okay . 
but i don ' t have 
huh . 
because i noticed that a few times it would do it it would move twice 
that kind of makes sense . 
yes . 
and then in sometimes it wouldn ' t . 
because 
yeah 
and maybe maybe i had resolution set differently . 
because yeah if the the resolution if it ' s moving too slowly then like if you were to click on some place then it makes sense that it would get kind of confused . 
or i 
but if it ' s moving quickly seems that it ' s covering more ground faster . 
uhhuh . 
so i don ' t know . 
i ' m going to report that to him . 
because i i ' ve i know 
that ' s one of the reasons why when i uh suggested to visual scan the record that i suggested doing it by clicking on the right of the of that navigation bar you ' re mentioning . 
uhhuh . 
or actually clicking on the right of the sound wave and then letting it run past the boundary . 
right . 
because i had the same problem . 
yeah that ' s what i tend to do is i use a soundwave . 
it ' s 
but if i ' m trying to scan through a long period of what appears to be silence sometimes i ' ll ry and be try to scan it . 
because you always know 
yes . 
yeah much more 
uhhuh . 
but i can ' t . 
because 
because you end up missing entire frames . 
it skips yeah . 
so then i end up clicking on the arrow they have the arrow at the far right . 
i was surprised by that . 
yeah . 
yes okay okay . 
and so i use that sometimes . 
so on the on that on that bar you were describing clicking . 
yeah . 
uhhuh . 
at the far right and far left there ' s a little arrow that allows you to go like second by second or something . 
okay . 
i didn ' t know about that . 
i don ' t know . 
really ? 
not second by second . 
but little bit by bit yeah . 
so is this the arrow on the right ? 
oh . 
it would be underneath that little resolution bar ? 
i mean it ' s like in that cluster up there . 
um it ' s not on the resolution part . 
it ' s where you have it ' s where you have the marker of where you are in the meeting . 
so you have this bar uh and then you have a time marker that moves along . 
say you ' re halfway through the meeting it ' s going to be halfway along the line . 
uhhuh . 
i have to do something visually . 
so my i would say you have the transcript screen . 
and then you have a bar . 
i think you ' re referring to this bar aren ' t you ? 
i think 
yeah . 
and then there ' s like this little resolution changer . 
yeah . 
it ' s 
yeah . 
and then down here you have the soundwave . 
and then something down here . 
exactly . 
oh . 
and then you got the the different channels come out . 
so right at the right and left of that 
so right in here you have this bar that you move and as as you go along it 
yeah . 
okay so is are you saying ? 
oh that ! 
yeah . 
you saying that there ' s an arrow right here ? 
yeah . 
okay and then there ' s an arrow right here ? 
yeah yeah . 
okay . 
so you can 
exactly . 
oh does 
that doesn ' t 
i usually just don ' t use that i think . 
yeah that skips 
oh is that what you ' re talking about ? 
oh . 
if you use that 
huh . 
i ' ve never used been able to use that . 
because it i feel like it skips such huge portions . 
maybe we have resolution set totally different . 
yeah . 
because i noticed when jen and i have totally different resolutions . 
maybe we do . 
because hers moves so much quicker than mine . 
i tend to make it move fast . 
oh i i i yeah i wouldn ' t 
which means it ' s more stretched out right ? 
i wouldn ' t use that unless i was trying to get to a whole different part of the 
right right right right . 
yeah i usually have it set to where it has um point five second intervals on the numbers . 
right that ' s when i use it too . 
yeah . 
huh . 
oh that ' s interesting ! 
i haven ' t paid attention to the numbers . 
i sort of like visually 
it helps me to have it be separated enough that i could find a new breaking point if i needed it . 
yeah . 
yeah that ' s the reason i separate it out . 
yeah i 
right . 
yeah . 
i do too . 
but sometimes if it gets too too for me too stretched out um i ' ll tend to think that there ' s a break in between a pause inside of a word or something . 
expanded ? 
uhhuh . 
oh yes . 
i don ' t know . 
because the uh the waveform becomes too stretched out . 
yeah . 
right . 
because 
so i prefer it to be a little bit tighter . 
yeah . 
it ' s nice to have 
but i ' ll stretch i ' ll stretch it in a particular place if i need to or something . 
right . 
a sort of like happy medium so you can make sure that the waveform has its like shape . 
uh right . 
uhhuh . 
yeah . 
yeah . 
yeah . 
now i know what you ' re talking about . 
yeah . 
that ' s kind of interesting though . 
yeah . 
well we ' re coming kind of close to the end of our time here . 
um i did ask about dessert . 
and they told me it was ice cream . 
and it doesn ' t save well . 
so i mean 
oh . 
well if there ' s any left we can grab it . 
if there was pie again 
that ' s right . 
if there was those tarts again i ' d be like set us aside some there . 
ooh those were good . 
huh . 
yeah . 
but 
yeah there ' s some those are those are nice . 
i ' m not a big ice cream fan . 
really ? 
oh . 
nah . 
no ? 
but i did i was thinking you know it is interesting to me to think about how each each of us have sampled different meetings . 
and yet it ' s intriguing to me to think that if i were to describe someone ' s characteristics in terms of their speech patterns i bet you we would all agree on who it who it was . 
uhhuh . 
uhhuh . 
you know . 
i think that ' s so interesting . 
yeah . 
yeah . 
yeah it ' s it ' s a statement of speaker style of course . 
uhhuh . 
but 
and also that we can i don ' t know that we have this shared realm of knowledge kind of . 
and can laugh about things that other people would not understand whatsoever . 
or 
you know ? 
uhhuh . 
the little intricacies and idiosyncracies of people ' s voices . 
yeah yeah i mean it ' s really cool . 
and 
yeah or even just about what we were talking about with the technical part you know the interface . 
yeah . 
right . 
i don ' t know . 
do you have any favorite parts of these meetings ? 
things that you 
i mean we we talked briefly about this last time . 
when people get really loopy . 
and start telling lots of jokes i think . 
yeah . 
i enjoy always transcribing those sections . 
is this do you think this is usually toward the end of the meeting ? 
or does it vary ? 
because it could . 
it ' s yeah it seems to be more at the end . 
the the person . 
eah depends on the person . 
or in the beginning . 
like 
the very beginning . 
yeah in the very beginning . 
yeah yeah . 
yeah . 
okay . 
yeah they ' ll be joking around . 
yeah . 
yeah that ' s true . 
yeah . 
do you have a favorite group that you that you like ? 
i don ' t i don ' t want to cause any partisanship here . 
but 
wait a favorite what ? 
a a a favorite type of meeting that you like . 
or um or 
oh you mean like uh like like um meeting recorder as opposed to e . d . u . as 
like those groups ? 
it whichever . 
that way . 
or or a nature of a meeting . 
oh . 
or 
i prefer ones that are somewhat linguistically related . 
yeah . 
okay . 
because it ' s more interesting for me . 
yeah i like those . 
i don ' t like the technical ones . 
because i don ' t understand what they ' re talking about . 
yeah . 
exactly and it ' s really hard 
and so i ' m just 
yeah and i ' m sitting there bored . 
because i i really have no concept of what they ' re talking about . 
yeah . 
yeah . 
so i ' m going okay . 
i ' m just going to listen to you . 
yeah . 
uhhuh uhhuh . 
yeah the ones that where they ' re talking about linguistic things though are great . 
yeah . 
i 
i love those . 
yeah . 
i like those . 
those are e . would these be the e . d . u . meetings ? 
that ' s what i think . 
is that true ? 
the ones with liz and you . 
uhhuh . 
yeah . 
yeah . 
okay . 
yeah you guys do some in the in the meeting recorder ones there ' s some talk of 
i don ' t know . 
discourse stuff . 
i think it ' s really fun too to listen to when you give reports on transcription . 
oh really ? 
oh i ' m really ? 
yeah because there are always people like you know talking bad about the transcribers . 
oh i ' m glad . 
and just making fun of 
yeah . 
and so it ' s really funny . 
i don ' t know . 
yeah . 
i that ' s why i like johno . 
it ' s really funny to listen to . 
i ' ve never heard anyone make fun of transcribers . 
you haven ' t ? 
really ? 
oh it ' s so funny . 
no ! 
oh johno does a lot of that . 
when you guys were saying that last week i was like never heard that . 
yeah . 
that ' s why i like listening to him . 
it ' s really funny . 
he ' s always making fun of transcribers . 
it would be a kick yeah in a uh in a good natured way . 
yeah yeah yeah . 
yeah . 
it would be really fun to have a collage of all these things like well the transcribers 
so rer - rer - rer - rer . 
and then be some horrible thing the transcriber ' s going to have trouble with this . 
yeah yeah yeah . 
did you hear the meeting where the guy was doing um clicks like from african languages ? 
yes . 
oh my . 
oh my god ! 
wasn ' t that a kick ? 
no . 
i did that . 
no . 
that was really a kick . 
and whistles . 
he was it i you must have been there was a meeting where there was this guy . 
he was making these funky sounds . 
yeah . 
and making funny whistles . 
yep . 
and you must have been sitting next to him . 
i was exactly . 
because you sort of engaged him in a conversation about it . 
exactly so . 
and he was like yeah i can make dogs uh raise their ears . 
exactly . 
exactly ! 
because i can whistle so high . 
wow . 
and you were like that ' s fascinating . 
i remember that meeting . 
i thought it was pretty funny . 
yeah . 
i think it ' s funny when there ' s little side conversations like that that happen at the same time too . 
yeah . 
i think those are interesting . 
yeah . 
and i think it ' s really cool when people . 
start getting really excited about something or angry about something . 
uhhuh . 
because then they tend to interrupt each other a lot . 
and 
i don ' t know . 
i mean i remember one where one person um was really trying to get something out really really desperately . 
and he kept getting interrupted by like three three other people . 
and he was like 
oh . 
and it was i mean it was kind of sad . 
but it was like also really interesting to watch . 
or to listen to . 
both . 
have have you noticed that sometimes you have these a a greater frequency of speech errors i think during times of of overlap ? 
yeah . 
which which is you can just tell a person ' s monitoring at two levels . 
yeah . 
huh . 
uhhuh . 
and it ' s it ' s difficult . 
uhhuh . 
they ' re like just trying really hard to get it out before they get interrupted or something . 
right . 
yeah . 
i don ' t know . 
i like transcribing you . 
because you ' re very polite . 
oh thank you ! 
no really . 
you ' re always like well i was just thinking about this . 
and maybe this might be if 
i uh you know . 
yeah . 
it ' s just it ' s just kind of cute . 
because everybody ' s like oh well okay . 
and they ' ll just listen to you you know . 
yeah . 
they don ' t interrupt you . 
they ' re just like well okay . 
it ' s kind of neat . 
yep . 
thank you . 
yeah . 
let ' s see have you one of the things that i found is is um surprisingly difficult these days is to is to get certain electronic sounds to try and describe them ? 
huh . 
have i was thinking about that the other day . 
yeah . 
it was like it ' s like 
you know 
someone in one of these e . d . u . meetings they have a laptop . 
and they hit the thing . 
and the and there ' s an error screen that comes up . 
and it has this doink kind of sound . 
and it 
huh . 
right right . 
what is that ? 
it ' s not a beep . 
yeah . 
it ' s not a bell . 
it ' s not it ' s not a dong . 
it ' s not a 
i mean you there ' re all these words that i could imagine . 
and so it ' s like it ' s a tinny kind of electronic sound that comes up when you make an error with your laptop . 
and that ' s that ' s not really very helpful . 
i wonder if like microsoft has a word for it . 
now i ' m now i ' m just wondering how they ' re going to transcribe you saying that . 
yes . 
oh you mean the voice quality ? 
the the shift in 
the doink . 
bling . 
oh that thing . 
yeah i know . 
oh 
now you did it again ! 
stop torturing them ! 
no ! 
let ' s not make things hard on ourselves later . 
i know . 
yeah . 
yeah well and then you know there are these other things that i think are really interesting . 
like the vocal changes in character . 
people shifting into a kind of a comic voice . 
uhhuh . 
or sort of a mock this or mock that . 
huh . 
huh . 
huh . 
you know the sighing . 
and the oh no . 
you know it ' s it ' s uh there are lot ' s of nuances which we uh which we use very often . 
uhhuh . 
comic words and things like that . 
you know 
and 
huh . 
sorry . 
yeah . 
sorry to i just remembered one thing that really was you needed . 
yeah . 
i think it was you that pointed out the problem . 
like you needed to be at the meeting to be able to transcribe correctly the noise . 
i think it was adam was making this really strange noise . 
and apparently he was pretending 
eech - eech or something . 
he was like pretending to screw something into his head . 
whee - whee . 
what ? 
was that what it was ? 
yes it was one of these it was this kind of deal . 
oh yeah i had that one . 
yeah yeah . 
oh yeah . 
yes oh yes . 
and he got to transcribe this meeting . 
yeah . 
and there was all this meta stuff about 
that was fun . 
because i was giving a report on what the comments were . 
and it was one of these was this . 
so 
uhhuh . 
yeah . 
whee - whee is what he said . 
and he was going like this at the time . 
uhhuh . 
joel ' s like i am not amused . 
i don ' t even want to like try to repeat what he said . 
because i don ' t want to put the transcriber through it again . 
yes that ' s right . 
let ' s just 
but they actually had a big list of like things that people had transcribed . 
and then they were reading one them one by one . 
and being like what ' s this . 
this . 
you know and then doing the sounds . 
aw . 
and then this sound must be this sound . 
oh . 
oh wow . 
this sound must be this . 
i had one like that where they were describing the different qualities of uhhuh and uh and uah . 
and like what e . h . is versus u . h . versus a . h . 
i had yeah i had one like that too . 
yeah . 
huh . 
oh man . 
that was really hard . 
yeah . 
that ' s really interesting . 
i had 
yeah . 
i had one where they were just they were just like talking about each word you know . 
and they were saying they were just describing the word over and over again . 
and just the the quotes around the word were driving me crazy when they knowing . 
when to put the quotes and when 
and then they were talking about like the difference between uh when it ' s a or when it ' s uh . 
yeah . 
and at some point they were saying it so much i didn ' t know how to transcribe it anymore . 
yeah . 
yeah . 
i was like i don ' t know if you ' re saying a or uh anymore . 
yeah . 
right . 
oh yeah . 
you did an excellent job . 
that was really it was like transcription a meta - transcription and meta meta meta . 
oh thank you . 
yeah . 
yeah cool . 
it ' s really . 
it was fun . 
yeah . 
you know i ' m really interested in this topic . 
would it be a problem if we continued a little bit longer on this ? 
or do you need to do people need to leave ? 
i don ' t want to keep you longer than 
uhhuh . 
i ' m fine . 
i can stay . 
i don ' t have to be anywhere until five . 
sure . 
are we okay ? 
so 
oh okay we won ' t be that long i don ' t think . 
no . 
good . 
sure . 
but but i really appreciate it . 
okay . 
this is just really it ' s so interesting to me the the specific experiences of of having encountered these data in this way . 
does um did anybody else want to say anything about 
i mean just weird things like before 
like i had kind of a weird thing happen . 
and we ' d talked about it . 
it was when i ' d first started working on the project i got this discussion where 
this was before we had the different channels . 
and um dan ellis it was when dan ellis was still here . 
yes . 
so it was like kind of early on right ? 
and um 
he everyone ' s talking . 
and then all of the sudden you hear dan talking to someone else . 
and it ' s different people that you ' d never heard before . 
and and what he had done is he had left the room to 
he ' d and he had brought the microphone with him . 
oh no ! 
and this is without the channelized interface . 
so you you have no idea . 
oh my gosh . 
oh man . 
oh wow . 
you think everyone ' s just become schizophrenic or something . 
oh 
and they ' re all like in they ' re own world or something . 
because then all of the sudden he ' s talking about a he needs a copy machine . 
and i and i ' m just assuming well he ' s still in the room . 
oh 
and what the heck ' s he talking about . 
wow . 
but just sort of just weird things like that . 
and um yeah he had just left the room . 
and gone and made a copy . 
and he still had his microphone on . 
and then you could hear the the the the women behind the desk talking to him . 
and just sort of stuff like that . 
it was just really bizarre . 
so 
that ' s really funny . 
anyway just sort of weird things like that . 
well it is there ' s another case where i ran across like of that type . 
um when i was sitting here and we were doing 
this was like one of the first meetings i ever participated in . 
and and dan was adjusting something here . 
and adam was in the next room . 
and um adam says so i ' ll come in here and check the levels . 
and and he says something . 
and dan says no . 
and it sounds like he ' s saying no to adam . 
and it was if if if so this would have been extremely rude . 
huh . 
but the thing and and the reason that it would be rude is because you don ' t have this information from hearing all these equalized volume channels . 
uhhuh . 
right . 
you don ' t know that they ' re not participating in the same conversation at all . 
yeah . 
yeah . 
yeah . 
it really is strange . 
yeah . 
it lead us it if we 
so 
it is true that this is kind of an artificial . 
and um 
discourse aspect . 
the mixed channel is artificial . 
because we ' re boosting it in order to make everything audible . 
yeah . 
uhhuh . 
huh . 
it ' s interesting because like um when i ' m working late at night i actually don ' t feel so lonely . 
but 
because there ' s so many voices in my head . 
you mean when you leave here ? 
when you ' re somewhere else . 
no no while i while i ' m working here . 
no no okay . 
it ' s like nine o ' clock . 
and nobody ' s here except for me . 
and i ' m like you know i don ' t feel so lonely . 
oh yeah . 
because there are like eight people talking to me all at once . 
i ' m like wow . 
how about these meetings when where there are like eight speakers in one meeting ? 
are those what are those like ? 
takes a long time . 
are 
they take longer to do . 
it takes a long time yeah . 
huh . 
okay . 
yeah . 
in a way they ' re more fun though . 
takes a long time . 
yeah . 
there ' s just more variety . 
i tends i you know what i noticed is it tends to have a still a dominant group of speakers . 
sometimes . 
and then there are two or three people generally who don ' t talk at all . 
huh . 
yeah . 
who won ' t talk . 
except to say their digits or something . 
or who 
and to breathe . 
yeah . 
or to breathe and cough and sniff and whatever . 
right . 
oh god . 
there ' ll be lots of breathing yeah . 
yeah . 
yeah but i i think that still overall you ' re going to have probably three or four or five dominant speakers . 
one thing i noticed is that like 
uhhh there was this one meeting i was transcribing there were nine nine speakers . 
and by the end of it i was so entirely sick of listening to the same conversation all over again . 
yeah . 
nine times in slow mo . 
exactly . 
definitely . 
i was going nuts . 
i was like i cannot take this anymore . 
i can ' t listen to this anymore . 
oh my god . 
i had that same reaction . 
yeah . 
absolutely and sometimes these are meetings i participated in . 
it ' s like 
uhhuh . 
so you ' ve this is like the tenth time for you then . 
i swear it ' s like it ' s like a bad dream . 
that ' s that ' s right . 
it ' s like this is this is keep this keeps happening to me . 
yeah . 
never changes . 
i ' m going to check outside to make sure that we ' re okay with the um 
oh okay . 
oh okay . 
did you guys ever 
when this happened to me when i first started transcribing . 
because i had never really transcribed stuff like this before . 
is it okay if we stay for another half hour in this room ? 
but um 
uhhuh . 
good thanks . 
i would leave here . 
and i would go out and do my daily business . 
and i would hear people speaking to me . 
yeah . 
and i would transcribe them in my head . 
yes yeah yeah yeah oh yeah . 
oh man . 
oh yeah that ' s fun . 
i ' d imagine what i would type . 
yeah yeah . 
huh . 
it went away like maybe after a couple of weeks . 
yeah . 
oh really ? 
but it was just bizarre . 
i still do that i still do that . 
i still do that . 
no i 
yeah . 
really ? 
occasionally . 
yeah . 
yeah . 
like on the bus or something when i ' m bored . 
yep or like i ' ll think 
right it ' s something you ' re not interacting with . 
oh no for me it was unconscious . 
you ' re just listening . 
oh really ? 
it was i didn ' t mean for to be doing it . 
oh okay . 
no yeah yeah . 
oh oh . 
it would just it was an intrusion . 
uhhuh . 
oh that ' s funny . 
um not a not a bad intrusion . 
uhhuh . 
yeah . 
but 
not something i was sort of volitionally sort of 
huh that ' s interesting . 
i would also be really aware of how i was speaking . 
huh . 
yes ! 
because i also tend 
like we were talking about so . 
i do that . 
uhhuh . 
i ' ll end utterances with so or and . 
yeah . 
and it ' ll just be a trailing off and i ' ll think man i would be such a pain in the butt to transcribe . 
yeah ! 
uhhuh . 
huh . 
yeah ! 
like i just uh i 
yeah . 
i ' ll i ' ll do the same thing as you do . 
and i i ' ll listen to somebody and his or her speech will be particularly idiosyncratic . 
yeah yeah . 
and i ' ll go wow i just i ' m glad i ' m not transcribing him or her . 
yeah i noticed a lot of my speech i don ' t know i wouldn ' t call them errors i guess disfluencies a lot more once when i started transcribing . 
i just noticed and in people in general that people break up their speech interestingly . 
huh . 
yeah . 
right . 
yeah . 
huh . 
i ' m amazed sometimes that we manage to communicate . 
yeah . 
actually . 
you know because people will say just like you know monosyllabic little grunts and squeaks and things . 
i think that shows a lot of i think that shows a lot of how um it ' s not all acoustic . 
and it means something . 
i mean there ' s other things involved . 
right . 
eye contact . 
body language . 
right . 
gesture . 
whatever . 
right . 
that raises a question . 
um do you think that um you would have been considerably helped if we had had video tapes of these things ? 
oh sure . 
yes . 
yeah . 
okay . 
i definitely think so . 
yep mhh . 
and i think there would be a lot more interesting data to analyze later on personally . 
huh well uhhuh uhhuh that ' s right . 
uhhuh . 
because you ' re involved in gesture research . 
yeah . 
uhhuh . 
yeah . 
yeah because then you know exactly what ' s going on . 
what the context cues are 
and you can really get a feel for the interpersonal relationships . 
yeah . 
which kind of comes into play maybe not for speech recognition . 
but for other things maybe . 
maybe this is what it ' s like to be blind . 
uhhuh . 
oh interesting . 
huh . 
maybe . 
huh . 
huh . 
yeah . 
huh . 
no no visual input at all . 
yeah you just have to rely on your intonation . 
and other things like that . 
right . 
and you get so much more aware of all of it too . 
yeah uhhuh maybe . 
uhhuh . 
huh . 
yeah . 
that ' s 
i know someone who actually recognizes perfumes in the elevator . 
i mean there ' s a there ' s a blind man in this in this building . 
oh . 
uhhuh . 
and and um lila was in the elevator one day . 
and they hadn ' t spoken yet . 
because he just came on the elevator . 
and he says 
uh and then she then she said something . 
and he says you you ' ve changed your perfume . 
oh wow . 
yeah it ' s pretty interesting pretty interesting . 
huh . 
that ' s pretty amazing . 
had she changed her perfume ? 
that ' s neat . 
yes she had . 
oh wow . 
yeah . 
huh . 
huh . 
yeah . 
oof ! 
yeah . 
huh . 
it ' s very interesting . 
enhanced other senses i guess . 
that ' s really cool . 
right . 
huh . 
have you 
i i ' ve learned several things about having been with the close talking mikes . 
this is this is a new experience . 
because i have of course been involved in in this kind of thing for quite a while . 
but there are several things i didn ' t realize you could hear so reliably . 
uhhuh . 
uhhuh . 
and some of these are the things like when the mouth opens . 
and the inbreath and stuff . 
and it and how extremely audible and and visual . 
uhhuh . 
uhhuh . 
uhhuh . 
i mean you can see these the inbreaths and things . 
uhhuh . 
yeah . 
uhhuh . 
it ' s that was really surprising to me that you it ' s that tangible . 
yeah . 
that ' s something you don ' t hear in normal speech too . 
uhhuh . 
in normal conversations unless it ' s very dramatic or very loud 
uhhuh . 
that people click their their lips are always making funny noises . 
unless you ' re on uh talking on the phone . 
and 
and the phone is the levels are funny . 
yeah . 
then you hear it . 
yeah . 
so it ' s kind of like that . 
right . 
yeah . 
i guess it ' s also one of these things that usually is not meaningful . 
so we sort of screen it out . 
yeah . 
all these different 
because you know i mean we do that all the time with all other well lots of other aspects of the acoustic signal . 
right . 
yeah . 
uhhuh uhhuh . 
it sounds like it ' s a nice smooth melody . 
but these things are voicing and unvoicing are tripping in and out . 
and they don ' t the contour is really not nearly that neat . 
yeah . 
yeah . 
right yeah well yeah most of the time when we ' re listening to other people ' s speech we ' re just trying to get the gist . 
not literally what people are saying . 
uhhuh . 
huh . 
and so 
you know all the uh uh ' s and um ' s and all those different things 
that ' s true . 
yeah we filter all that out . 
we just tune it out . 
yeah . 
yeah . 
uhhuh . 
and uh it ' s that top down thing again . 
just 
right ? 
uhhuh yeah yeah absolutely absolutely . 
in a way . 
just trying to get the um 
you know what is the what is the point of what this person is trying to communicate kind of thing . 
uhhuh . 
that ' s right . 
so 
huh . 
which is a very it ' s that ' s how i tended before studying linguistics anyways and uh definitely before doing transcription how i tended to look all conversations 
that ' s right . 
and then coming here and doing this you have to look at speech in a totally more intense way . 
um 
including i mean every little aspect . 
i and when i tell people what i do here 
and tell them yeah i ' m transcribing . 
and they ' re they think i ' m like a stenographer or something . 
right . 
yeah . 
i ' m like no i don ' t correct the grammar . 
uhhuh . 
i don ' t erase the um s and uh s . 
i record all the sighs and the laughs and the breaths . 
and and they ' re 
i don ' t know . 
this is a very different thing than most people can relate to i guess . 
uhhuh the i agree . 
or know about . 
another thing that i think is interesting in these meetings is certain speakers have a tendency to embed utterances in other uh in other utterances . 
and um you know it ' s very clear when you see it when you hear it with the intonational markers . 
but well just the contours . 
uhhuh . 
but the words on the page it ' s not at all clear . 
yeah . 
and there are a couple people who do this in particular . 
uhhuh . 
i i would say that it ' s both i would say that both jerry and morgan do this . 
uhhuh . 
and it ' s amazing how fluent it is when you hear it . 
but how very complicated it is when you see the words . 
indecipherable . 
yeah . 
yeah . 
and when you think about it they pick up exactly where they left off . 
even though maybe it ' s several seconds later there ' s no glitch in the syntax or anything . 
it ' s we ' re pretty amazing machines . 
or creatures . 
uhhuh . 
whatever . 
huh . 
huh . 
yeah . 
that ' s really cool . 
machines . 
yeah . 
so and then of course there are these these things which i think are also nicely represented in the data . 
which are these funny sounds people make . 
which to some degree is borrowing from comic talk . 
so i notice people going pfft you know if they ' re trying to say something is done . 
uhhuh . 
the germans do this i think in particular . 
yeah . 
uhhuh . 
huh . 
and there are others that we use like that 
which are sort of semi - conventionalized . 
but you wouldn ' t think that you would write them down . 
yeah the one i i get all the time is tsk . 
yeah . 
oh yes good example ! 
huh . 
it ' s it ' s uh like i don ' t know how i just transcribe it as i say like click . 
huh . 
uhhuh . 
it ' s like 
tisk . 
and then i say it ' s like a vocal gesture . 
like a shrug or a vocal some some sort of like well there it is . 
yes . 
yeah . 
yeah . 
or that ' s it . 
yeah . 
or something like that you know . 
that people do that one a lot . 
and there was one speaker who used to do it constantly . 
and after a while i started getting confused as to whether or not he was like just going tsk tsk tsk tsk tsk to himself . 
or whether he was meaning it in 
sometimes it was really obvious that he meant it as some sort of vocal cue . 
uhhuh . 
but then sometimes it was more ambiguous . 
like it was tough to tell . 
um because he would just always be clicking . 
this is this the one that 
i mean it could be the one that we were thinking about . 
it could be . 
but i noticed it more as it was obviously not 
because it was always in a the one i ' m thinking of always came in groups of four or something . 
yes uhhuh . 
and so it wasn ' t ever like a um single 
huh . 
oh okay . 
it would be it would 
yeah this guy does a lot of single ones . 
yeah . 
oh how interesting . 
yeah just kind of um 
and uh that ' s another thing like i i realize i do that too . 
i ' ll ask you who this is later . 
i don ' t want to because 
huh . 
i can ' t remember the name actually . 
okay . 
the the one that i ' m thinking of . 
it ' s a matter of you can tell it ' s in context where he ' s looking in his agenda to see you know do i have time to do this . 
uhhuh . 
and he ' s calculating it in his mind . 
so it ' s sort of almost like a stand in for calculator kind of thing . 
huh . 
and uh but it ' s signaling . 
i ' m sure that everybody i ' m sure that other people can hear it . 
so it ' s sort of like wait a minute i ' m thinking . 
right yeah yeah yeah . 
uhhuh . 
but it ' s not lexicalized . 
this is not a 
huh . 
that ' s kind of the impression i got too . 
not in a standard way . 
oh yeah that ' s a different person . 
it ' s 
okay okay okay . 
yeah okay i know who you ' re talking about . 
but this is somebody somebody 
he must do this in a lot of meetings . 
because i think you know i ' ve run across it several times . 
i don ' t think i ' ve ever heard it . 
no . 
no . 
huh . 
i ' ve heard . 
yeah . 
yeah . 
which i just transcribe as mouth . 
heard that one . 
oh i see . 
i just make a mouth . 
huh . 
because i think i had talked to you about this about 
what what did we do because what was it that i 
oh i was 
lipsmack . 
yeah . 
oh yes . 
yeah . 
i was marking lipsmack . 
and and you said 
that ' s more like the . 
yeah that ' s it ' s a different noise . 
huh . 
yeah . 
but um 
it ' s what made me think of it . 
uh . 
but um 
the one you ' re talking 
and and you said don ' t do lipsmack . 
just do we don ' t need it ' s too specific . 
just do mouth for all all those noises . 
yeah okay now what i would say um 
um 
it ' s good to know this . 
what i what i would say is um if it ' s communicative beyond just the mouth opening and the oh you know the mechanical aspects that happen when you happen to be about to speak then i would like to have it if it ' s communicative i ' d like to have it preserved . 
uhhuh . 
uhhuh . 
uhhuh . 
right . 
but if it ' s just this mechanical stuff mouth is fine . 
uhhuh . 
the it seems like the computer science people use lipsmack for that . 
i personally my choice 
uh we ' ve we ' re still deciding on how we ' re going to encode it in the final version . 
but i tend to not like lipsmack . 
because i think that that ' s could be meaningful . 
and it ' s a little confusing . 
uhhuh . 
uhhuh . 
people talk about you know oh gee that was really good . 
huh . 
and then they do a 
i ' m not going to do it . 
because i don ' t really know how to do lipsmack . 
but but it seems like it would be a a vocal gesture . 
yeah . 
it could be . 
a definite type of thing . 
yeah . 
right yeah i was thinking the one that you just did like tsk makes me think of the what people would write as tsk tsk . 
yes . 
same here yeah . 
yeah me too . 
you know like uh as though they ' re like you know trying to communicate displeasure . 
yeah . 
i would too . 
oh right . 
yeah . 
huh . 
that ' s true yeah . 
right . 
uhhuh . 
and so that 
yeah . 
huh . 
there ' s there ' s at least two or three that i can think of that to me are very different . 
you know there ' s like you know that . 
right . 
and there ' s like um you know well the one i did before that ' s like . 
i don ' t know like um hhh . 
i would say tongue click for that . 
yeah . 
but i would also probably put in parentheses it that i thought it was a vocal gesture . 
uhhuh . 
because i think it ' s communicative of a certain thing . 
yeah . 
yeah . 
i don ' t know what i am never sure whether or not to transcribe um a difference with like huh you know and huh ! . 
oh yeah . 
oh good point yes . 
like how do you transcribe huh ! ? 
it ' s like humph 
i ' ll put like a 
really good point . 
yeah . 
i ' ll usually put a an exclamation point somehow . 
like i ' ll go 
i would too . 
yeah ? 
oh . 
i think it ' s more emphatic . 
uhhuh . 
uhhuh . 
what about transcribing it um h . m . p . h ? 
but it it ' s true that segments are different too . 
what about transcribing it that way ? 
hmph . 
like hmph . 
huh ! 
oh . 
well now this is a good question . 
i guess i would say you know sometimes we ' ve seen hmph in literature meaning 
right . 
but it ' s a a sigh a uh sorry a sound of indignation . 
right . 
uhhuh . 
so if it ' s meant as a sound of indignation then i think that would be how i would capture it with the h . m . p . h . thing . 
uhhuh . 
i usually tend to think that it ' s a more of a 
hhh not indignation . 
something more positive . 
i don ' t know exactly how to characterize it . 
like 
but something more 
oh really ? 
huh . 
sort of like a uh an uh an elevated huh ? 
i hadn ' t thought of that . 
right . 
yeah . 
it ' s like a sort of more surprise or engagement . 
yeah . 
huh . 
yeah . 
or 
hhh . 
i i don ' t know . 
yeah i guess it could have two meanings sort of . 
maybe . 
yeah . 
if it ' s surprise then the exclamation point makes sense too . 
yeah . 
uhhuh . 
and then there ' s the other kind which sounds similar . 
but it ' s really part of a laugh . 
so uhhuh uhhuh huh . 
huh . 
yeah . 
which is i would just say laugh for that . 
yeah uhhuh . 
laugh right . 
yeah . 
uhhuh . 
yeah once adam was laughing . 
and it was actually written out phonetically . 
and i changed it . 
i ' m like it ' s just laughing . 
good . 
yeah . 
well done well done . 
like somebody had written like hyuh - hyuh or or or something . 
and 
i ' ve run across that also . 
and 
right . 
change it to laugh . 
that ' s funny . 
yeah i it was maybe tigerfish had done something . 
well done . 
like they had written out a phonetic laugh . 
yeah yeah . 
and they didn ' t do it at any other place in the transcript . 
that ' s interesting . 
that ' s interesting . 
i ran across a couple ho s 
it was just that one spot . 
i ' ve seen ho s . 
it was just a regular old vanilla laugh you know . 
ho ho ho ? 
and 
oh that is too much fun . 
and heh . 
it wasn ' t anything special . 
yeah . 
yeah that ' s right . 
i noticed as far as problems with laughs is that a lot of them were marked as breaths . 
we 
because a lot of people 
yes . 
i think we already talked about this last time . 
right . 
uhhuh . 
but 
yeah . 
but not so much as i never saw that written out phonetically or whatever . 
well 
well 
well here ' s a question . 
and there ' s been some variance in transcripts that i ' ve looked at . 
when 
okay . 
so when you laugh you ' re exhaling all this air . 
yes . 
and so you need to inhale . 
yes . 
and so how do you transcribe the inhale ? 
some people are transcribing it as a breath . 
i used to you know back in the day back when i was transcribing i would do the whole thing as a laugh . 
yeah yeah yeah yeah . 
yeah that ' s what i used to do too . 
uhhuh yeah yeah . 
because to me the breath is part of the laugh . 
i agree with you . 
oh yeah . 
yeah . 
that ' s that ' s what i prefer . 
huh . 
um so because because in the ones i ' ve been the one i ' ve been checking actually right now that breath gets marked as a breath . 
yeah . 
and i ' ve been taking them out . 
so you would have like laugh breath laugh ? 
good well done . 
so that ' s okay ? 
well done . 
actually it ' d be a laugh . 
transcribed ? 
and then two dots . 
like the next bin will be empty . 
uhhuh . 
and then it ' ll be breath . 
oh i ' ve 
uhhuh . 
yeah . 
and so it ' ll be that 
yeah i was going to say i put 
okay . 
oh . 
i see what you ' re saying . 
yeah . 
it ' ll be three sort of separate units as opposed to i think it ' s sort of one coherent thing . 
yeah . 
yeah . 
uhhuh . 
so 
i put breath laugh in the brackets when i don ' t know whether it ' s a breath or a laugh . 
that ' s good that ' s good . 
uhhuh . 
which is what i remember you telling me to do that . 
oh well yeah that ' s that ' s a different thing . 
that ' s right . 
yeah . 
huh okay . 
yeah because sometimes it ' s not clear . 
that ' s good . 
sometimes it ' s hard to tell . 
like sometimes hhh is a laugh . 
yeah . 
right . 
yeah . 
yeah . 
that ' s right . 
right . 
um and if other people are laughing then i ' ll usually give them and say that they ' re laughing . 
huh . 
and 
i agree with you . 
right . 
and and i think that ' s important . 
yeah . 
because we ' re capturing then the communicative level . 
yeah exactly . 
uhhuh exactly . 
right . 
and it ' s likely that it has a different contour than most breaths as well . 
yeah . 
because it ' s sort of expulsive and and uh that kind of thing . 
uhhuh . 
uhhuh . 
yeah . 
exactly exactly . 
yeah . 
a lot of people go . 
well done . 
so 
yes they do . 
yeah the shyer ones sometimes will laugh with the breath laugh . 
and you can see it . 
right . 
you can see the little little peaks which is interesting . 
right . 
uhhuh . 
right . 
yeah . 
but yes yeah exactly . 
i wouldn ' t uh that ' s a case you know i know generally with the tigerfish things that they put breath and we leave it in . 
but absolutely there yeah . 
good okay . 
laugh change it . 
and you know there are other places where it ' s in the way you know 
i i mainly said not to change their breath s simply because it would take time to move them if 
and if they ' re not in the way then don ' t don ' t mess with it . 
a lot of times though the breaths are um results of bad segmentation . 
but 
and there ' s a segmentation of nothing . 
oh yes ! 
and so they just write it as a breath when it ' s clearly not a breath . 
yeah i ' ve taken out some of those . 
and i usually always take those out . 
yeah . 
i mean usually um it seems like the segmenter um often just sort of um segments 
great . 
when there ' s really long spaces it segments random spaces in between . 
and you know they get that . 
and there ' s nothing there . 
so they mark it as a breath when it ' s really actually nothing . 
so usually i take those out . 
that ' s right . 
yeah . 
well they give the segmenter though 
because they don ' t have the the rich interface that we do . 
so they must be giving the pre - segmenter sort of the benefit of the doubt . 
well there must be something there um whether i can hear it or not . 
right right exactly exactly . 
oh yeah i ' m sure they are . 
so they just say well it ' s a breath then . 
exactly . 
one wonders what it might be 
uhhuh . 
although they did put a missing segment sometimes in brackets . 
yeah . 
yeah there are some where 
yes ! 
oh really ? 
that ' s true . 
oh i always get i always get breath . 
yeah . 
well see i i do a previous filtering before i give the tigerfish ones out . 
i ' ve gotten both . 
and and i i have tried to get the that particular the the missing segment removed . 
uhhuh . 
but i don ' t always do it . 
yeah . 
uhhuh . 
yeah i ' ve seen a few of them . 
huh . 
so yeah you ' ve they slip through . 
well frequently that ' ll also be a misattribution too of voice . 
but i ' ve seen a several breath s too . 
huh ! 
yeah yeah . 
because then you ' ll hear you ' ll hear part of what another person is saying and and that ' s all transcribed on that one level . 
but then you ' ll hear a little bit of it and then missing segment . 
yeah . 
it ' s like okay well they just it ' s in the wrong 
it ' s just in the wrong place . 
that person ' s not talking at all . 
so you just get rid of it . 
yeah . 
yeah . 
huh . 
so 
uhhuh uhhuh . 
yeah . 
interesting . 
okay well let ' s see . 
so um do you think that this has changed your speech in other ways ? 
in terms of 
myself i do feel that i ' m 
when i spend a lot of hours doing this i become less fluent . 
i have more false starts and things . 
really ? 
yeah . 
i don ' t know if it ' s it could just be because there ' re so many more hours i haven ' t been talking . 
huh ! 
i guess i try to be more careful in my speech more often . 
good . 
unless i ' m really not paying any attention . 
like you know if i ' m at a party or something and i ' m just sort of having a good time then it doesn ' t really matter . 
but in you know normal one - on - one speech i i think i tend to try to enunciate more . 
uhhuh uhhuh . 
because i ' ve been told i mumble . 
oh huh . 
um and i guess i used to be worse about it . 
i was told by my parents that i used to mumble a lot . 
uhhuh . 
uh and also i i have this sort of east coast accent that comes in sometimes that makes it hard for people on the west coast to understand what i ' m saying . 
huh ! 
a lot of times like uh if i ' m not paying attention i ' ll say something that uh will not really be heard . 
i tend to leave off final consonants for instance . 
and people uh i have to be conscious of that sometimes . 
huh . 
yeah so 
so mainly for clarity it sounds like like in phrasing or strategies . 
yeah . 
yeah . 
huh one thing that i noticed 
i don ' t know if it ' s a really a question of me being more changing my speech necessarily . 
but i ' m much more aware of interruptions in conversation in normal conversation . 
oh . 
oh yeah that ' s true . 
oh . 
yeah . 
so uh maybe i am more careful in the sense that i maybe don ' t interrupt as much . 
or i ' m more aware of it when i am doing it . 
or something like that . 
but um i just pay attention more to the fact that every pretty much all the time in normal conversation there are interruptions . 
there ' s no 
i mean unless you have really 
i mean i think if there were no interruptions it would sound really awkward . 
uhhuh . 
there would be a lot of pauses . 
and that would kind of imply uncomfortability or something . 
huh . 
right . 
yeah . 
but 
i guess it depends partly on the type of interruption . 
yeah . 
i mean if it ' s a clarifying type like well do you mean when they ' re partway through it in a utterance 
yeah . 
yeah . 
yeah . 
it ' s different . 
yeah i tend to think of a conversation that has no interruptions as being something that ' s unnatural and forced . 
or something like a meeting where you know i mean everybody says their little schpiel . 
yeah . 
and people are meant to be you know pretty pretty quiet and attentive for the most part . 
and then they let them finish . 
and then somebody else comes in . 
and says something about it . 
yeah . 
um 
and in a like a friendly conversation i i notice that that ' s not really true . 
like what you were saying . 
right . 
but even in cases like that even when it is 
see now i ' m contradicting myself . 
but even when it is very turn taking is very like people follow the turn taking rules or whatever and don ' t really blatantly interrupt people 
um 
and i i remember this actually from a meeting because liz was complaining there wasn ' t enough interruptions . 
or not enough overlaps or something . 
huh . 
it wasn ' t interruptions . 
it was overlaps that i was thinking about . 
uhhuh i think this is really 
not enough overlaps . 
yeah . 
and so she wanted to there to be an argument or something so that there ' d be more . 
and what she didn ' t realize was that throughout the meeting up until then there had been . 
they were just very small . 
but they were there . 
i think they ' re there pretty much all the time . 
i agree . 
i did i did do one analysis where i looked at one meeting 
that ' s interesting . 
uhhuh . 
and um 
because the claim had been 
actually one of the people in the meeting had made the claim in the previous meeting that well there probably the overlaps only occur during setup and um you know at the end when we ' re leaving . 
oh . 
oh yeah that ' s totally not true . 
huh . 
no not at all . 
exactly exactly . 
yeah . 
well and you know i think that that ' s sort of the feeling you would get if unless you looked at the data at this level . 
yeah . 
yeah . 
right . 
and so i did an analysis . 
and in fact it was really a pretty constant rate . 
yeah . 
uhhuh . 
all the way through the entire meeting . 
and everyone was involved . 
uhhuh . 
wasn ' t just one you know or two speakers . 
everyone was 
yeah it ' s quite true . 
kind of makes sense . 
because if you ' re if you want to speak next it ' s almost like you got you got to get your foot in the door . 
you got to be the one who you know make sure people recognize that you ' re the one who ' s going to speak next . 
uhhuh . 
that ' s true . 
uhhuh . 
i should say i didn ' t distinguish between overlaps and and interruptions . 
so some of these were backchannels and things like that . 
yeah . 
oh i see . 
but it ' s still it ' s still the case . 
uhhuh . 
you have 
yeah . 
you 
i think um silences are generally like not good in conversation too . 
because once you get a 
you know it it it ' s to your benefit to to try to get in right when you think they ' re done . 
because if there ' s a silence not only is it awkward but then that sort of cues everybody to start thinking of a new topic to stop the silence . 
yeah . 
huh . 
and then you don ' t get to talk about what you wanted to talk about because the whole subject has changed . 
and then everybody talks at once . 
that ' s true that ' s very true . 
you know thinking about it 
you know ? 
i i think i ' ve only noticed a couple times where there ' s been actual silence on all channels for a period of time . 
yeah . 
uhhuh . 
huh . 
it ' s only been like twice . 
it ' s true that ' s very rare . 
it ' s rare . 
yeah . 
i agree . 
yeah . 
uhhuh . 
interesting observation . 
yeah well if they ' re if this has raised a couple of things for me that i wanted to mention . 
yeah . 
because you know at this point we ' re at the at the really fine grain level of of standardization which i hadn ' t really thought of specifying in advance before . 
and um wanted to maybe just mention a couple of things . 
these are 
um 
yeah i don ' t think that these are very common . 
but with the idea that what we ' re trying to do is encode the communicative stuff . 
um when we have these grey areas . 
um um 
i wanted to draw attention to the fact that there are sometimes these stretches where a person is trying to say something and formulating their thought and they ' re coming out with a bunch of segments which really aren ' t part of a word . 
have you run across that where they ' re they ' re saying ? 
huh . 
uhhuh . 
yeah yeah yeah . 
yeah yeah yeah . 
yeah . 
and then they say a word . 
oh . 
right . 
yeah . 
and my feeling on that is that this isn ' t really a phonological transcript . 
and potentially those things could probably be rendered . 
although some of them are not even full segments . 
they ' re even subsegmental i would say . 
i mean you got a a single flap of a vocal cord sometimes . 
uhhuh . 
yeah . 
and you know they ' re it ' s like the the apparatus is sort of almost kicking in . 
they ' re almost going to say . 
but it hasn ' t somehow this somehow this vibration hit before the rest of it . 
and and that ' s not communicative . 
uhhuh . 
so um my my the way i do those things when i hear those if is to i use in parentheses one x . so it ' s marked . 
okay . 
right . 
uhhuh . 
or if it ' s then i then i put six or seven or however many it is 
then 
that ' s what i usually do too . 
right . 
i was wondering who had been putting those in . 
yeah . 
great . 
and then and then what i do is i put in um brackets um uncodeable sorry uncodeable vocal sounds . 
uhhuh . 
yes . 
oh okay okay . 
and of course potentially they ' re codable . 
but i just wanted to mark roughly how how long it is . 
uhhuh . 
then indicate what what the nature of it is so no one ' s going to try and go back and and decode it as something that ' s a word that was not it has a different status than parenthesized uh parts when there are words involved . 
uhhuh . 
just to set it aside . 
have some sort of a length indication . 
and sometimes i ' ll even put them in a in a separate bin . 
although that ' s that ' s not necessary . 
it ' s just sometimes it works out that way that they . 
uhhuh . 
they do this thing . 
i shouldn ' t do that so often . 
i ' m sorry about that . 
they do this sound . 
and then there ' s a pause . 
and then they start speaking . 
uhhuh . 
so then it ' s really obvious i can i can split it apart and it won ' t be any problem . 
i wanted to mention that one . 
man . 
i ' m glad you brought that up . 
yeah . 
because i actually 
i ' m one of the culprits that puts in all the little itsy bitsy tiny sounds in the middle of everything . 
huh . 
i do that too ! 
because i was 
i used to do that ! 
because 
yeah because i was thinking like you ' re just supposed to write down everything you hear as closely as possible . 
well 
uhhuh . 
and so i ' m glad you said that . 
because um that actually takes a good amount of time and like pretty strict concentration to to do that . 
a lot of time . 
yeah . 
yeah i put in the x . s . 
um 
excellent . 
and so 
i put in if it ' s um unintelligible i put i count how many syllables and then i put in six x . . 
i do that if it ' s unintelligible . 
but if i can tell something if somebody goes i ' ll put an r . . 
oh i see . 
i see . 
uh um so if they go i ' ll go r . e . h . huh m . m . . 
oh . 
huh . 
so like i i ' ve been doing that . 
because like that ' s what i can hear . 
okay . 
and i ' m pretty damn sure that 
right . 
sorry sorry ! 
sorry hhh . 
that will have to be transcribed with little uh symbols . 
sorry ! 
i ' m sorry . 
yeah like a a skull and crossbones . 
i feel really bad now . 
oh no ! 
i ' m sorry . 
right . 
okay . 
that ' s okay . 
it ' s all right . 
you ' ve ruined the whole meeting ! 
no problem . 
we can ' t transcribe any of it now ! 
it ' s not it ' s 
oh no i ' m so sorry . 
yeah . 
it ' s not like you said the f . word . 
no no no . 
it ' s not it ' s not an 
this is not 
it ' s still a p . g . 
yeah seriously . 
i wouldn ' t give it a second thought . 
do you remember what you were going to say ? 
oh yeah i i was 
she ' s pretty darn sure that uh 
uh and then yeah that ' s 
you 
yeah 
she could make it out probably . 
okay right . 
i ' m sorry . 
yeah no one ' s ever sworn in any of the meetings . 
well you ' ve heard have you heard shoot ? 
that actually 
i ' ve heard shoot a couple of times . 
i ' ve heard the 
yeah . 
not the swearword version . 
huh . 
no no no no no no . 
the 
just shoot . 
shoot type yeah . 
i ' ve heard the swearword version . 
yeah . 
that ' s okay . 
remember that ? 
oh you have ? 
yeah ? 
remember that ? 
i ' ve never heard the swearword versions . 
oh . 
it was a while back . 
i it was a long time ago . 
i do remember that yeah . 
yeah and i was like oah . 
i emailed you . 
i was like you might want to check this out . 
that ' s right that ' s right . 
yeah i do remember that . 
yeah . 
but it was very quiet . 
so i can see how that would have been sort of gone over by accident . 
it was just very quiet . 
like kind of under the breath kind of thing . 
uhhuh yeah . 
uhhuh . 
yeah it was . 
so that ' s why it was missed . 
yeah . 
uhhuh . 
yeah . 
i can understand . 
huh ! 
uhhuh . 
uhhuh . 
yeah . 
yeah . 
but finish your point . 
so 
oh i was just i was just saying that um i i can i ' m pretty sure that i can tell what exactly what sounds are being produced . 
yes . 
so if it ' s uh i write an r . . 
uhhuh . 
right . 
if it ' s huh i can tell it ' s . 
yeah . 
right . 
uhhuh uhhuh . 
then again i always think that it ' s closer to stick with the x . s . 
because it ' s like how effective is you know the roman alphabet at deciphering all the sounds that a human can make ? 
yeah . 
you know it ' s not the i . p . a . 
and it ' s just i i just sort of think um it ' s best to leave it with x . s . 
huh . 
because i english orthography conventions are just so you know uncertain anyway in the first place . 
and um 
uhhuh . 
you know i i usually only use them when i i know that um the person was trying to make a word . 
i mean i know that the the word they were trying to say . 
and that they were stuttering that . 
then i feel fine just you know writing out the letters . 
but otherwise i sort of don ' t feel right trying to write them out . 
because i feel like it ' s um 
you can ' t really 
just not useful ? 
yeah you can ' t really spell those things with the with the roman alphabet . 
uhhuh . 
yeah . 
you know ? 
yeah . 
uhhuh . 
it ' s it was only set up for 
right . 
it was set up for a different purpose you know . 
not necessarily so phonological . 
i agree and i think there ' s another problem too . 
yeah . 
okay . 
and that is that we do have some short words which are communicative . 
and and sometimes 
so if you have an e . r . as part of one of these fragments we do have a lexicalized uh . 
right . 
which is a which is a a filler item . 
right . 
does have a meaning . 
yeah . 
uhhuh . 
so i think for both of the reasons it ' s good to just leave it in this category of not really communicating in a in a word like way . 
so even if it ' s uh or 
right . 
i would keep uh . 
well e . uh uh if it ' s a filler . 
oh you would keep uh . 
so i mean uh 
right right . 
that that that stays . 
huh 
right oh okay . 
yeah . 
oh yeah . 
but if it ' s uh part on these little fragments no . 
i always 
i often transcribe that as or . 
i always thought that was or sort of with a strange pronunciation . 
oh . 
i ' m making a distinction . 
oh . 
so you have the um comic uh where the person says something and then they pretend that they didn ' t want to say that . 
right . 
and then they throw in an uh . 
oh . 
and that would be an uh . 
oh i don ' t get that one . 
uhhuh . 
uhhuh . 
right . 
e . r . 
but if they ' re saying or in a reduced way so it comes out as uh do it as or . 
right . 
okay . 
because that ' s that falls within the realm of pronunciation variants . 
okay . 
okay . 
right . 
right . 
it ' s just like different ways of saying and . 
uhhuh . 
okay . 
and i have like uh uh two more things i wanted to say . 
one of them is um 
oh yeah . 
this is an interesting category to me . 
and i don ' t um don ' t have to mark this systematically . 
but when you ' re going through the meeting and what i ' d like people to do if if you ' re not uh uh is to go through the meeting 
um 
so if you ' re doing you ' re doing separate channels first and then as a final pass through the mixed channel . 
i don ' t think i ' ve made that explicit . 
but it it ' s really helpful to go through it a a final time though the mixed channel so that you hear things in context . 
and at that point what i sometimes pick up is this meta level where someone is finishes someone ' s someone else ' s utterance 
uhhuh . 
so you ' ll suddenly have this stranded word out in the middle of nowhere and it ' s because . 
this other speaker on this other channel was trying to formulate this thought and they paused . 
and they paused just enough that this person leaped in and gave them a word . 
huh . 
uhhuh . 
right . 
and i think those are interesting . 
so when i find that i i note note it as you know finishing . 
put capital letters . 
capital letter capital letter colon apostrophe s . utterance . 
oh . 
yeah . 
wait wait how do you mark it ? 
wait . 
we add the 
so if so in the in the instance in which 
let ' s say that um morgan ' s talking . 
uh so he ' s talking . 
and then somewhere there ' s a bit of a pause . 
and let ' s say adam fills in a word for him . 
then what i do is on adam ' s channel i say i say completing and this this isn ' t that common of an occurrence completing speaker initial with a colon apostrophe s . s utterance . 
oh i see . 
oh . 
oh . 
okay . 
and what that means is at the time when we 
see we ' re going to go to a stage of anonymization . 
so it ' s important to have the colon here . 
oh . 
because that ' ll make it possible to easily know you know who it was without having to do the math involved in figuring out which channel it was . 
the problem with 
i originally wanted to use channel numbers as the referent index . 
but that that ' s not functional . 
because we have these two different numbering schemes . 
you have the numbering in the channeltrans interface and you have the numbering in the key file . 
yeah . 
and those can be very different . 
right right . 
so you know to be able to 
yeah . 
uh this is redundant in a useful way in that you know that you ' re not going to make a mistake . 
i tried to do it with the numbers . 
and i was making all sorts of inconsistent problems so i stopped it . 
so that ' s probably why you like added in that um thing that automatically puts in the people ' s initials . 
uhhuh . 
initials ? 
that ' s that ' s i did that partly to keep track of things . 
absolutely . 
absolutely . 
i also found that it was easier to deal with the meetings when there are speaker initials . 
uhhuh . 
oh yeah . 
initials . 
the initials ? 
i ' m glad to hear that . 
yeah . 
i i didn ' t do that systematically until uh really rather recently . 
yeah . 
so i ' m glad to know that ' s useful . 
uhhuh . 
it takes an extra step . 
glad it ' s useful . 
okay now i just have one more thing to say . 
and that is that 
um um 
like once this is just such a 
i ' m getting down to like the really eensy - weensy stuff . 
but um once i found a comment that uh in curly brackets about mumbling . 
and um 
that ' s that ' s this is just to mention an instance that happened once . 
it ' s really grasping for details . 
uhhuh . 
but um 
i i i think and it may be that it was not from anybody here . 
so 
but i think that um mumble is only useful in the to me in the sense of whispered . 
if it ' s like a manner of speaking in which case it ' s a qual . 
but not in terms of replacing like this string of undecipherable fragments . 
so 
oh right . 
right oh yeah . 
okay . 
um this this was when it was used . 
they used mumble for 
exactly . 
it was used in place of uh something that was unintelligible . 
okay . 
to fill in i see . 
huh . 
right . 
in which case it would be better to use parentheses and and either exclamation or the number of syllables if you know . 
the number x . . 
and then do qual mumbled or qual whispered or something . 
exactly if it ' s a manner of speaking then it ' s useful . 
i see . 
right . 
and otherwise the parentheses with an estimate of syllables is better . 
okay . 
okay . 
okay . 
so i guess you know i don ' t want to keep you . 
i kept you so long . 
can i ask one more thing about these comments ? 
i really appreciate this . 
yes . 
so we are for 
qual is used for things like whispered or said while laughing or things of that nature . 
yes . 
uhhuh . 
um i remember at some point we were doing a difference between vocal and non vocal sounds . 
oh yes . 
oh but 
good question . 
and you don ' t have to add any of those tags . 
oh . 
the only tags that you need to add is 
so uh there ' s like one exception that ' s just microscopic . 
and that is sometimes 
this is again really rare . 
sometimes i ' ve run across the word noise . 
and offhand i don ' t know if that ' s a vocal noise or non vocal noise . 
huh . 
and so then i listen to it and i figure it out . 
but that ' s the only place you would use a vocal non vocal tag . 
where it ' s potentially ambiguous between those two categories . 
because otherwise what i do when i get these is 
and of course i do my checks . 
and then i have a um a script that i wrote which will separate everything in out that has curly brackets . 
do a listing of them . 
huh . 
and then anything 
some of them already have tags from some previous uh modification . 
but anything that doesn ' t i just go through this list and i i tag it right then . 
and so in one in one in one change i can modify you know five hundred instances of this . 
uhhuh . 
uhhuh . 
so there ' s no need to add the vocal or the non vocal . 
very efficient . 
okay but for like noise that we know is something like mike noise or something like a door whatever then we can mark it as that . 
huh . 
right . 
uhhuh . 
yes . 
and 
you can either if you mark it mike noise then i ' ll know what kind of noise it is when i go through the thing and put v . o . c . or n . v . c . on the in the substitution file . 
yeah right . 
or 
or if it ' s 
uhhuh . 
right . 
but it ' s it ' s uh very efficient for me to add those tags later . 
okay . 
it ' s really not the same thing with the qual . 
just so long as i can tell which of those three categories it is . 
or or pron . 
but you know those that ' s really very obvious . 
the pronunciation . 
yeah . 
so long as i can tell what they are . 
so we do need to add that one ? 
i think it ' s good for you to add the pron . 
okay sure okay . 
i would appreciate the pron come to think of it . 
good . 
but the other three just so long as it ' s clear to me you know from the comment which of those three it is then i ' m fine . 
good . 
that ' s great . 
all right so um i guess um 
do you want to read digits ? 
do you want to do that ? 
oh thank you . 
do we have time ? 
would you mind ? 
yeah that ' s fine . 
can we do digits ? 
yeah that ' s fine . 
no . 
yeah . 
okay so why don ' t 
do you want to do it uh in unison this time ? 
that ' s what we did last time . 
well we did it in unison last time . 
we did it 
oh we did ! 
yeah . 
oh . 
right . 
do it separately then okay . 
sure did . 
yes . 
good deal . 
oh and do you want us to mark the roughly the time we start ? 
that is really what that time field is . 
i used to think it was the beginning of the meeting . 
oh okay . 
but yes . 
quite right quite right . 
oh okay . 
that ' d be good . 
oh all right . 
the time we start digits ? 
so we have to 
huh . 
yeah . 
okay . 
okay so who wants to start ? 
well i guess i ' ll start . 
okay . 
um 
okay i wanted to make one comment and that is some of these are like two digits . 
and just be sure you say both digits separately . 
so one eight instead of eighteen . 
okay ? 
sure . 
oh right . 
i can go . 
okay . 
okay wonderful . 
thank you very very much . 
i really appreciate this . 
no problem . 
sure . 
and um so now we get to turn the microphones off . 
sure . 
and uh 
um so 
if we can ' t we can ' t but uh we ' re going to try to make this an abbreviated meeting . 
because the the next next occupants were pushing for it . 
so 
um . 
so 
agenda is according to this is transcription status darpa demos x m l tools disks backups et cetera and crosspads . 
does anyone have anything to add to the agenda ? 
okay . 
should we just go in order ? 
transcription status . 
who ' s that ' s probably you . 
i can do that quickly . 
um i hired several more transcribers . 
they ' re making great progress . 
seven ? 
several several . 
oh . 
and uh 
and uh 
uh i ' ve been uh finishing up the uh double checking . 
i hoped to have had that done by today . 
but it ' s going to take one more week . 
um 
as a somewhat segue into the next topic um could i get a hold of uh the data even if it ' s not really corrected yet ? 
i 
just so i can get the data formats . 
and make sure the information retrieval stuff is working . 
certainly . 
yeah i mean it ' s in the same place it ' s been . 
so can you just 
oh it is ? 
okay . 
uhhuh no change . 
just so transcripts is the sub directory ? 
uh yes uhhuh . 
okay . 
so i ' ll i ' ll probably just make some copies of those . 
rather than use the ones that are there . 
okay . 
um and then just we ' ll have to remember to delete them once the corrections are made . 
okay . 
okay 
i also got a short remark to the transcription . 
i ' ve uh just processed the first five e d u meetings . 
and they are chunked up . 
so they would they probably can be sent to i b m . 
whenever they want them . 
well the second one of those 
cool . 
yep it ' s already at i b m . 
is already at i b m . 
but the other ones 
that ' s the one that we ' re waiting to hear from them on . 
yeah . 
yeah . 
yeah . 
okay . 
these are separate from the ones that 
as soon as 
i mean these are 
they ' re the i b m set . 
it ' s this one . 
yep . 
excellent . 
yeah . 
good . 
is my mike on ? 
and so as soon as we hear from brian that this one is okay . 
yeah . 
and we get the transcript back . 
and we find out that hopefully there are no problems matching up the transcript with what we gave them . 
then uh we ' ll be ready to go and we ' ll just send them the next four as a big batch . 
excellent . 
and let them work on that . 
and so we ' re doing those as disjoint from the ones we ' re transcribing here ? 
yes . 
okay good . 
exactly . 
we ' re sort of doing things in parallel . 
that way we can get as much done at once . 
yeah i think that ' s the right way to do it . 
yeah . 
especially for the information retrieval stuff . 
anything else on transcription status ? 
hm - huh . 
okay . 
darpa demos . 
we had the submeeting the other day . 
right which uh 
so i ' ve been working on using the thisl tools to do information retrieval on meeting data . 
and the thisl tools are there ' re two sets there ' s a back end and a front end . 
so the front end is the user interface . 
and the back end is the indexing tool and the querying tool . 
and so i ' ve written some tools to convert everything into the right file formats . 
and the command line version of the indexing and the querying is now working . 
so at least on the one meeting that i had the transcript for uh conveniently you can now do information retrieval on it . 
do type in a a string and get back a list of start end times for the meeting . 
uh of hits . 
what what kind of uh what does that look like the string that you type in ? 
what are you are you are they keywords or are they 
keywords . 
okay . 
i see . 
right and so and then it munges it to pass it to the thisl i r which uses an s g m l like format for everything . 
i see . 
and then does it play something back ? 
or that ' s something you ' re having to program ? 
um right now i have a tool that will do that on a command line using our standard tools . 
yeah . 
but my intention is to do a prettier user interface based either 
so so that ' s the other thing i wanted to discuss is well what should we do for the user interface . 
we have two tools that have already been written . 
um the softsound guys did a web based one . 
uhhuh . 
um which i haven ' t used haven ' t looked at . 
dan says it ' s pretty good . 
uhhuh . 
but it does mean you need to be running a web server . 
uhhuh . 
and so it it ' s pretty big and complex . 
uh and it would be difficult to port to windows . 
because it means porting the web server to windows . 
uhhuh . 
uh the other option is dan did the tcl t k thisl gui front end for broadcast news . 
yeah . 
which i think looks great . 
i think that ' s a nice demo . 
um and that would be much easier to port to windows . 
and so i think that ' s the way we should go . 
i can i ask a question ? 
uhhuh . 
so um as it stands within the the channeltrans interface it ' s possible to do a find and a play . 
you can find a searched string and play . 
so are you so you ' re adding like um i don ' t know uh are they fuzzy matches or are they uh 
it ' s a sort of standard text - retrieval - based . 
so it ' s uh term frequency inverse document frequency scoring . 
okay . 
um and then there are all sorts of metrics for spacing . 
how far apart they have to be and things like that . 
so it it ' s 
it ' s a lot more sophisticated than the uh the basically windows based . 
it ' s like doing a google query or anything else like that . 
so it uses so it produces an index ahead of time . 
okay . 
so you don ' t you ' re not doing a linear search through all the documents . 
because you can imagine if with if we have the sixty hours ' worth you do wouldn ' t want to do a search . 
hm - huh . 
um you have to do preindexing . 
good . 
and so that these tools do all that . 
and so the work to get the front end to work would be porting it 
well uh to get it to work on the unix systems our side is just rewriting them and modifying them to work for meetings . 
so that it understands that they ' re different speakers and that it ' s one big audio file instead of a bunch of little ones and just sort of things like that . 
uhhuh . 
uhhuh . 
uhhuh . 
so what does the user see as the result of the query ? 
on which tool ? 
thisl . 
the thisl gui tool which is the one that dan wrote tcl t k . 
yeah . 
um you type in a query and then you get back a list of hits . 
and you can type on them and listen to them . 
click on them rather with a mouse . 
uh . 
so if you typed in small heads or something you could 
huh . 
right you ' d get 
get back a uh uh something that would let you click and listen to some audio where that phrase had occurred . 
something 
you you ' d get to listen to beep . 
or 
that was a really good look . 
it ' s too bad that that couldn ' t come into the 
you couldn ' t get a video . 
guess who i practice on . 
at some point we ' re going to have to say what that private joke is . 
that keeps coming up . 
yeah . 
and then again maybe not . 
so uh 
yeah that that sounds reasonable . 
yeah it it my my recollection of it is it ' s it ' s a pretty reasonable uh demo sort of format . 
right . 
yeah that sounds good . 
and so i think there ' d be minimal effort to get it to work minimally . 
that sounds really neat . 
and then we ' d want to add things like query by speaker and by meeting and all that sort of stuff . 
um dave gelbart expressed some interest in working on that . 
so i ' ll work with him on it . 
and it it ' s looking pretty good . 
you know the fact that i got the query system working . 
so if we want to just do a video based one i think that ' ll be easy . 
uhhuh . 
if we want to get it to windows it ' s going to be a little more work . 
because the thisl i r the information retrieval tool ' s um 
i had difficulty just compiling them on solaris . 
uhhuh . 
so getting them to compile on windows might be challenging . 
uhhuh . 
but you were saying that that the uh that there ' s that set of tools uh cygnus tools that 
so 
it certainly helps . 
uhhuh . 
um i mean without those i wouldn ' t even attempt it . 
yeah . 
uhhuh . 
but what those they what those do is provide sort of a b s d compatibility layer . 
so that the normal unix function calls all work . 
uhhuh . 
uhhuh . 
um 
and you have to have all the 
but the problem is that that the thisl tools didn ' t use anything like autoconf . 
and so you have the normal porting problems of different header files and some things are defined and some things aren ' t . 
and uh different compiler work arounds and so on . 
so the fact that um it took me a day to get it to compile under solaris means it ' s probably going to take me significantly more than that to get it to compile under windows . 
how about having it run under free b s d ? 
well what you need 
free b s d would probably be easier . 
all you need to do is say to dan gee it would be nice if this worked under autoconf and it ' ll be done in a day . 
that ' s true . 
right ? 
uh 
actually you know i should check . 
because he did port it to sprachcore . 
right . 
so he might have done that already . 
i i i wouldn ' t be surprised . 
so 
i ' ll check at that . 
how does it play ? 
what i 
but it would what would serve would serve both purposes is if you contact him and ask him if he ' s already done it . 
yeah right . 
if he has then you learn . 
if he hasn ' t then he ' ll do it . 
right . 
wow . 
i hope he never listens to these meetings . 
that ' s right . 
so and i ' ve been corresponding with dan and also with uh uh softsound guy uh 
it ' s amazing . 
yeah . 
blanking on his name . 
tony robinson ? 
tony robinson ? 
do i mean tony ? 
i guess i do . 
yeah . 
or or steve renals . 
james christie . 
which one do i mean ? 
steve steve renals . 
steve renals is not softsound . 
is he ? 
no . 
my brain is not working . 
i don ' t remember who i ' ve been corresponding with . 
okay . 
steve it ' s steve renals wrote thisl i r . 
then it ' s steve renals . 
okay . 
oh okay . 
so uh just getting documentation and uh and and formats . 
yeah . 
so that ' s all going pretty well . 
i think we ' ll be okay with that . 
right . 
assuming we ' re 
what about issues of playing sound files between the two platforms ? 
um 
we have 
well that ' s a good point too . 
here ' s a here ' s a crazy idea actually . 
i don ' t know . 
why don ' t you try and merge transcriber and thisl i r ? 
well this is one of the reasons 
they ' re both tcl interfaces . 
this is the one of the reasons that i ' m going to have uh dave gelbart gelbart . 
having him volunteer to work on it is a really good thing . 
because he ' s worked on the transcriber stuff . 
right . 
and he ' s more familiar with tcl t k than i am . 
and then you get they then you get the windows media playing for free . 
well that ' s snack not not transcriber . 
right but the point is that the transcriber uses snack and then you can but you can use a a lot of the same functionality . 
yeah yeah i mean i i think thisl thisl gui probably uses snack . 
and it ' s 
and so my intention was just to base it on that . 
yeah . 
well my thought was is that it would be nice it would be nice to have the running transcripts um uh you know from speaker to speaker . 
and if it doesn ' t 
right ? 
do you have you have you know a speaker mark here and a speaker mark here ? 
right we ' ll have to figure out a user interface for that so . 
right well that uh my thought was if you had like multitrans or whatever do it . 
or whatever . 
yeah . 
it might be fairly difficult to get that to work in the little short segments we ' d be talking about . 
and having the search tools and so on . 
we we can look into it . 
but 
yeah . 
the thing i was asking about with um free b s d is that it might be easier to 
get powerpoint shows running in free b s d than to get this other package running in 
yeah i mean we have to i have to sit down and try it before i make too many judgments . 
yeah . 
so uh 
um 
my experience with the gnu compatibility library is really it ' s just as hard and just as easy to port to any system . 
right ? 
the windows system isn ' t any harder . 
because it it looks like a b s d system . 
uhhuh . 
it ' s just you know just like all of them the include files are a little different and the function calls are a little different . 
right . 
so i it might be a little easier . 
but it ' s not going to be a lot easier . 
okay . 
so there was that demo which was one of the main ones . 
and then we talked about um some other stuff . 
which would basically be um showing off the the transcriber interface itself . 
and as you say maybe we could even merge those in some sense . 
but but um 
uh and part of that was showing off what the speech non uh nonspeech stuff that thilo has done looks like . 
yeah . 
can i ask one more thing about thisl ? 
uhhuh . 
so with the i r stuff then you end up with a somewhat prioritized um 
uhhuh . 
ranked . 
excellent . 
excellent . 
yeah . 
so another idea i had just now actually for the demo was whether it might be of interest to to show some of the prosody uh work that don ' s been doing . 
uhhuh . 
um actually show some of the features . 
and then show for instance a task like finding sentence boundaries or finding turn boundaries . 
um 
you know you can show that graphically sort of what the features are doing . 
it you know it doesn ' t work great but it ' s definitely giving us something . 
well i think it 
i don ' t know if that would be of interest or not . 
at the very least we ' re going to want something illustrative with that . 
because i ' m going to want to talk about it . 
and so if there ' s something that shows it graphically it ' s much better than me just having a bullet point . 
yeah . 
pointing at something i don ' t know much about . 
i mean you ' re looking at this now . 
so 
are you looking at waves or matlab ? 
um yeah i ' m starting to . 
and 
um 
yeah we can probably find some examples of different type of prosodic events going on . 
yeah 
so when we here were having this demo meeting what we ' re sort of coming up with is that we want to have all these pieces together to first order by the end of the month . 
and then that ' ll give us a week or so . 
oh the end of this month or next month ? 
ooo the end of 
this month . 
oh you mean like today ? 
oh . 
oh sorry next month . 
june june june . 
next month . 
yeah . 
sorry . 
today isn ' t june first . 
there ' s another one . 
is it ? 
exactly . 
uh that ' ll that ' ll give us that ' ll give us a week or so to uh to port things over to my laptop and make sure that works . 
sorry . 
i think i mean uh where 
yeah . 
yeah i mean i ' ll be here . 
yeah if if don can sort of talk to whoever ' s 
because we ' re doing this anyway as part of our you know the research . 
yeah . 
visualizing what these features are doing . 
yeah . 
and so either 
it might not be integrated . 
but it it could potentially be in it . 
could find some . 
yeah well this is to an audience of researchers . 
so i mean you know 
to let the goal is to let them know what it is we ' re doing . 
i mean it ' s different . 
so that ' s 
i don ' t think anyone has done this on meeting data . 
so it might be neat you know . 
yeah . 
good . 
done with that . 
x m l tools ? 
um 
so i ' ve been doing a bunch of x m l tools . 
where you we ' re sort of moving to x m l as the general format for everything . 
and i think that ' s definitely the right way to go . 
because there are a lot of tools that let you do extraction and reformatting of x m l tools . 
um 
so yet again we should probably meet to talk about transcription formats in x m l . 
because i ' m not particularly happy with what we have now . 
i mean it works with transcriber . 
but it it ' s a pain to use it in other tools . 
uh because it doesn ' t mark start and end . 
start and end of each 
uh 
yeah . 
utterance . 
utterance . 
just marks ? 
so it ' s implicit in in there . 
but you have to do a lot of processing to get it . 
yeah . 
right . 
right . 
and so and also i ' d like to do the indirect time line business . 
um but regardless i mean that ' s something that you me and jane can talk about later . 
um but i ' ve installed x m l tools of various sorts in various languages . 
and so if people are interested in doing extracting any information from any of these files . 
either uh information on users because the user database is that way . 
i ' m converting the key files to x m l so that you can extract uh various uh sorted information on individual meetings . 
cool . 
yeah . 
and then also the transcripts . 
and so just let me know there . 
it ' s mostly java and perl . 
but we can get other languages too if if that ' s desirable . 
oh quick question on that is do we have the the seat information ? 
in in the key files now ? 
uhhuh . 
the seat information is on the key files for the ones which 
uh 
oh in 
it ' s been recorded . 
for the new one . 
okay . 
yeah . 
seat ? 
great . 
yeah . 
where where you ' re sitting . 
oh not not the quality or anything no . 
right . 
okay i see . 
it ' s pretty soft and squishy . 
yeah . 
all right . 
yeah . 
okay . 
oh but that might just be me . 
okay . 
um 
all right . 
that ' s more seat information than we wanted . 
never mind . 
huh 
i ' m just trying to figure out you know when morgan ' s voice appears on someone ' s microphone are they next to him or are they across from him . 
maybe we should bleep that out . 
yeah . 
huh yeah . 
wait a minute . 
right . 
how how uh where is it in the key file ? 
yeah . 
the square bracket . 
because i mean i haven ' t been putting it in . 
and in by 
you haven ' t been putting it in . 
right . 
i have not . 
well 
oh okay . 
isn ' t it always on the digits ? 
and 
some of these are missing . 
aren ' t they ? 
isn ' t it always on the digits forms ? 
some fall out of 
well 
yeah so we can go back and fill them in for the ones we have . 
ooo . 
i mean they ' re on right these . 
but i just hadn ' t ever been putting it in the key files . 
yeah i i never 
and i don ' t think chuck was either . 
i never knew we were supposed to put it in the key file . 
because 
i had told you guys about it . 
oh so we ' re both sorry . 
but 
oh really ? 
so 
i mean this is why i want to use a a tool to do it rather than the plain text . 
okay . 
because with the plain text it ' s very easy to skip those things . 
okay . 
okay . 
so 
um if you use the edit key 
or key edit . 
i think it ' s edit key command . 
edit key . 
did i show you guys that ? 
yep . 
i did show it to you . 
you mentioned it . 
but i think you both said no you ' ll just use text file . 
yeah yeah . 
text . 
um it has it in there a place to fill it in . 
okay . 
okay . 
yeah and so if you don ' t fill it in you ' re not going to get it in the meetings . 
so if 
so 
right well i i just realized i hadn ' t been doing it . 
yep . 
and probably so 
yeah and then the other thing also that thilo noticed is on the microphone . 
on channel zero it says hand held mike or crown mike . 
yeah . 
right . 
you actually have to say which one . 
i know . 
yeah i usually delete the 
so 
i don ' t 
oh okay i didn ' t do that either . 
maybe i forgot to 
yeah . 
takes me no time at all to edit these . 
but it ' s almost 
yeah . 
yeah that ' s because you 
i ' m not doing anything . 
i i know why . 
and i was i was looking at chuck ' s like oh what did chuck do . 
okay i ' ll do that . 
so 
and then uh also in a couple of places instead of filling the participants under participants they were filled in under description . 
uh okay . 
uh 
and so that ' s also a problem . 
so anyway . 
we will do better . 
that ' s it . 
oh uh also i ' m working on another version of this tool . 
the the one that shows up here that will flash yellow if the mike isn ' t connected . 
and it ' s not quite ready to go yet . 
because um it ' s hard to tell whether the mike ' s connected or not . 
because the best quality ones the crown ones are about the same level if they ' re off . 
and no one ' s off or if they ' re on and no one ' s talking . 
huh . 
um these these ones they are much easier . 
there ' s a bigger difference . 
so i ' m working on that . 
and it it sort of works . 
and so eventually we will change to that . 
and then you ' ll be able to see graphically if your mike is dropping in or out . 
will that also include like batteries dying ? 
yep . 
just any time the mike ' s putting out zeros basically . 
yep . 
yep . 
but with the screensaver kicking in it 
now 
but 
yeah . 
well i ' ll turn off the screensaver too . 
yeah . 
yeah . 
oops ! 
um the other thing is as i ' ve said before it is actually on . 
speaking of which . 
the thing . 
there ' s a little level meter . 
but of course no one ever pays attention to it . 
so i think having it on the screen is more easy to notice . 
it would be nice if if these had little light indicators . 
little l e d ' s for 
uh buzzer . 
yeah a buzzer . 
bamp bamp ! 
small shocks . 
yeah . 
actually 
administered to the 
okay . 
okay disk backup et cetera ? 
oh 
um i spoke with dave johnson about putting all the meeting recorder stuff on non backed up disk to save the overhead of backup . 
and he pretty much said yeah you could do that if you want . 
but he thought it was a bad idea . 
in fact what he said is doing the manual one doing uh n w archive to copy it is a good idea . 
and we should do that and have it backed up . 
he he ' s a firm believer in in lots of different modalities of backup . 
i mean his point was well taken . 
this data cannot be recovered . 
yeah . 
and so if a mistake is made and we lose the backup we should have the archive . 
and if then a mistake is made and we lose the archive we should have the backup . 
well i guess it is true that even with something that ' s backed up it ' s not going to 
if it ' s stationary it ' s not going to go through the it ' s not going to burden things in the incremental backups . 
just just the monthly full . 
huh 
yeah so the monthly full will be a bear . 
but 
yeah but he said that that we shouldn ' t worry too much about that . 
that we ' re getting a new backup system . 
and we ' re far enough away from saturation on full backups that it ' s probably okay . 
really ? 
and uh so the only issue here is the timing between getting more disks and uh recording meetings . 
so i guess the idea is that we would be reserving the non backed up space for things that took less than twenty four hours to recreate or something like that . 
things that are recreatable easily and also yeah basically things that are recreatable . 
right ? 
yeah . 
yeah . 
the expanded files and things like that . 
okay . 
they take up a lot more room anyway . 
yeah . 
uh but we do need more disk . 
so we can get more disk . 
yeah . 
yeah so . 
and i i think i agree with him . 
i mean his point was well taken that if we lose one of these we cannot get it back . 
okay . 
i don ' t think there was any other et cetera there . 
well i was allowing someone else to come up with something related that they had uh 
i thought you guys were going to burn c d ' s . 
um unfortunately we could burn c d ' s but first of all it ' s a pain . 
yeah . 
because you have to copy it down to the p c and then burn it . 
and that ' s a multi step procedure . 
and second of all the the write once burners as opposed to a professional press don ' t last . 
yeah . 
so i think burning them for distribution is fine . 
but burning them for backup is not a good idea . 
i see . 
because they they fail after a couple years . 
okay . 
all right . 
i do have uh uh it ' s a different topic can i add one topic . 
we have time ? 
i wanted to ask 
i know that uh that thilo you were um bringing the channeltrans interface onto the windows machine . 
yeah it ' s it basically it ' s done . 
and i wanted to know is 
yeah . 
it ' s all done that ' s wonderful great . 
yeah . 
yes since tcl t k runs on it basically things will just work . 
yeah it 
yeah it was just a problem with the snack version and the transcriber version . 
but it ' s solved . 
so 
does and that does that mean i 
maybe i should know this but i don ' t . 
does this mean that the that this could be uh ported to a think pad or some other type of uh 
yeah basically uh i did install it on my laptop . 
and yeah . 
wonderful . 
it worked . 
wonderful . 
huh ! 
good . 
crosspads ? 
uh i got an email from uh james landay . 
who basically said if you ' re not using them could you return them . 
so he said he doesn ' t need them he just periodically at the end of each term sends out email to everyone who was recorded as having them . 
and asks them if they ' re still using them . 
so we ' ve never used them . 
we used them once . 
we we used them a couple times . 
once ? 
uhhuh . 
them ? 
but 
couple times . 
there ' s more than one ? 
yeah we have two . 
yeah . 
um 
but 
my opinion on it is 
first i never take notes anyway . 
so i ' m not going to use it . 
um and second it ' s another level of infrastructure that we have to deal with . 
and i have uh so my my feeling on it is that i think in principle it ' s a really nice idea . 
and you have the time tags which makes it better than just taking raw notes . 
on the other hand i the down side for me was that i think the pen is really noisy . 
so you have kaplunk kaplunk kaplunk . 
and i and i don ' t know if it ' s audible on the 
but i i sort of thought that was a disadvantage . 
i do take notes . 
i mean i could be taking notes on these things . 
and i guess the plus with the crosspads would be the time markings . 
but 
i don ' t know . 
uh what is a crosspad ? 
so it ' s it ' s um it ' s a regular pad just a regular pad of paper but there ' s this pen which indicates position . 
thank you . 
and so you have time and position stuff stored . 
okay . 
so that you can you have a record of whatever it is you ' ve written . 
okay . 
and then you can download it . 
and they have o c r and searching and all sorts of things . 
okay . 
okay . 
so if you take notes it ' s a great little device . 
could uhhuh 
but i don ' t take notes . 
and one of the reasons that it was brought up originally was because uh we were interested in in higher level things . 
so 
not just the you know microphone stuff but also summarization and so forth . 
and the question is if you were going to go to some gold standard of what what was it that happened in the meeting you know where would it come from . 
and um i think that was one of the things . 
yeah . 
yep . 
yeah . 
right ? 
and so the it seemed like a neat idea . 
we ' ll have a you know have a scribe . 
have somebody uh take good notes and then that ' s part of the record of the meeting . 
and then we did it once or twice and we sort of 
yep and then just sort of died out . 
probably chose the wrong scribe . 
but it was it ' s uh 
yeah that ' s right . 
i mean 
well i did it one time . 
but um 
yep . 
yeah . 
but i guess the the other thing i ' m thinking is if we wanted that kind of thing i wonder if we ' d lose that much by having someone be a scribe . 
by listening to the tape to the recording afterwards . 
and taking notes in some other interface . 
i mean we ' re transcribing it anyways . 
why do we need notes ? 
oh it ' s it ' s useful . 
because that ' s summary . 
have a summary and high points . 
i think 
summary . 
there ' s also 
there ' s this use that 
summarize it from the transcription . 
the 
well what if you ' re sitting there and you just want to make an x ? 
and you don ' t want to take notes . 
and you ' re you just want to 
doodle . 
get the summary of the transcript from this time location . 
like you know and and then while you ' re bored you don ' t do anything . 
and once in a while maybe there ' s a joke and you put a x . 
but 
in in other words you can use that just to highlight times in a very simple way . 
also with i was thinking and i know morgan disagrees with me on this . 
but suppose you have a group in here and you want to let them note whenever they think there might be something later that they might not want to distribute in terms of content . 
they could just sort of make an x near that point . 
or a question mark that sort of alerts them that when they get the transcript back they could get some red flags in that transcript region . 
and they can then look at it . 
so 
i know we haven ' t been using it . 
but i i can imagine it being useful just for sort of marking time periods . 
right . 
which you then get back in a transcript . 
well . 
i guess so you know what what makes one think is maybe we should actually schedule some periods where people go over something later . 
so 
and and and put some kind of summary or something . 
uh you know some there ' d be some scribe who would actually listen who ' d agreed to actually listen to the whole thing . 
not transcribe it but just sort of write down things that struck them as important . 
but then you don ' t you don ' t have the time reference uh that you ' d have if you had it live . 
right . 
and you don ' t have a lot of other cues that might be useful . 
yeah . 
how do you synchronize the time in the crosspad and the time of the recording ? 
so 
i mean that was one of the issues we talked about originally . 
and that ' s part of the difficulty is that we need an infrastructure for using the time the crosspads . 
and so that means synchronizing the time 
oh . 
you know you want it pretty close . 
uhhuh . 
and there ' s a fair amount of skew because it ' s a hand held unit with a battery . 
well when when i 
and so you 
okay . 
so you have to synchronize at the beginning of each meeting all the pads that are being used . 
so that it ' s synchronized with the time on that . 
and then you have to download to an application . 
and then you have to figure out what the data formats are and convert it over if you want to do anything with this information . 
and so there ' s a lot of infrastructure which 
uhhuh . 
why 
there is an alternative . 
unless someone 
there is an alternative . 
i mean it ' s still there ' s uh you know your point stands about there be needing to be an infrastructure . 
but it doesn ' t have to be synchronized with the little clock ' s timer on it . 
you i mean i when i when i did it i synchronized it by voice . 
by whispering one two three four onto the microphone . 
huh 
and uh you know . 
well but then there ' s the infrastructure at the other end . 
right . 
which someone has to listen to that and find that point . 
yeah it ' s transcribed . 
and then mark it . 
it ' s in the transcript . 
so 
yeah . 
well it ' s in the transcript . 
well could we keep one of these things for another year ? 
would i mean is there a big 
we can keep all both of them for the whole whole year . 
just just in case we 
i mean it ' s just 
even maybe some of the transcribers who might be wanting to annotate . 
uh just there ' s a bunch of things that might be neat to do . 
but i it might not be the case that we can actually synchronize them and then do all the infrastructure . 
but we could at least try it out . 
well one thing that we might try um is on some set of meetings some collection of meetings maybe e d u is the right one or maybe something else . 
we we get somebody to buy into the idea of doing this as part of the task . 
i mean 
right . 
uh part of the reason i think part of the reason that adam was so interested in uh the speechcorder sort of idea from the beginning is he said from the beginning he hated taking notes . 
yep . 
and 
and so forth . 
so and and jane is more into it . 
but uh uh 
you know i don ' t know if you want to really do do this all the time . 
so i think the thing is to to get someone to actually buy into it . 
and have at least some series of meetings where we do it . 
um 
and if so it ' s probably worth having one . 
the the the problem with the the more extended view 
all these other you know with uh quibbling about particular applications of it 
is that it looks like it ' s hard to get people to um uh routinely use it . 
i mean it just hasn ' t happened anyway . 
but maybe if we can get a person to 
yeah i don ' t think it has to be part of what everybody does in a meeting . 
but it might be a useful neat part of the project . 
that we can you know show off as a mechanism for synchronizing events in time . 
that happen that you just want to make a note of . 
like what jane was talking about . 
with some later browsing just just as a convenience . 
even if it ' s not a full blown note taking substitute . 
well if you wanted to do that maybe the right architecture for it is to get a p d a with a wireless card . 
and and that way you can synchronize very easily with the the the meeting . 
because you ' ll be you can synchronize with the the linux server . 
and uh 
so what kind of input would you be 
so so i mean if you ' re not worried about 
buttons . 
you ' d just be pressing like a a 
well well you have a p d a . 
and and you could have the same sort of x interface or whatever . 
i mean you ' d have to do a little uh a little bit of coding to do it . 
uhhuh . 
but you could imagine 
yeah . 
that be good . 
i mean if if all you really wanted was you didn ' t want this secondary note taking channel . 
but just sort of being able to use markers of some sort . 
a p d a with a a wireless card would be the probably the right way to go . 
i mean even buttons you could do . 
sort of . 
i mean as you said . 
i mean for what what you ' ve been describing buttons would be even more convenient than anything else . 
right . 
right ? 
that would be fine too . 
you have the 
right . 
i mean i don ' t have you know grandiose ideas in mind . 
but i ' m just sort of thinking well we ' ve we ' re getting into the next year now . 
and we have a lot of these things worked out at in terms of the speech . 
maybe somebody will be interested in this . 
and 
i like this p d a idea . 
yeah . 
yeah i do like the idea of having a couple buttons . 
well i ' m sure there would 
yeah . 
where like one one button was uh oh . 
yeah . 
and then another button was that ' s great . 
and another button that ' s 
or like this is my i ' m supposed to do this kind of button . 
yeah . 
like i better remember to 
action item . 
yeah . 
something like that . 
or 
i mean i think the crosspad idea is a good one . 
and then 
uhhuh . 
it ' s just a question of getting people to use it . 
and getting the infrastructure set up in such a way that it ' s not a lot of extra work . 
i mean that ' s part of the reason why it hasn ' t happened . 
is that it it ' s been a lot of extra work for me . 
yeah . 
right . 
and 
well and not just for you . 
but it ' s also it has this problem of having to go from an analog to a a digital record too . 
doesn ' t it ? 
well it ' s digital but it ' s in a format that is not particularly standard . 
i mean 
but i mean say if if if you ' re writing if you ' re writing notes in it does it it can ' t do handwriting recognition . 
right ? 
no no but it ' s just it ' s just storing the pixel position information . 
okay . 
it ' s all digital . 
i i guess what i ' m thinking is that the p d a solution you you have it already without needing to go from the pixelization to a to a 
i mean 
right . 
you don ' t have to 
the transfer function is less errorful . 
yes . 
yeah yeah . 
yeah . 
oh nicely put . 
yeah yeah . 
well it also it ' s maybe realistic because people are supposed to be bringing their p d a ' s to the meeting eventually . 
right ? 
that ' s why we have this little 
i don ' t know what i don ' t want to cause more work for anyone . 
but i can imagine some interesting things that you could do with it . 
and so if we don ' t have to return it 
and we can keep it for a year 
i don ' t know . 
well we don ' t we certainly don ' t have to return it . 
as i said all all he said is that if you ' re not using it could you return it if you are using it feel free to keep it . 
the point is that we haven ' t used it at all . 
and are we going to . 
so we have no 
but uh by i i would suggest you return one . 
okay . 
yeah . 
because we we you know we we haven ' t used it at all . 
we 
we have some aspirations of using them . 
one would probably be fine . 
maybe we could do like a student project . 
and 
you know maybe someone who wants to do this as their main like project for something would be cool . 
yeah . 
yep . 
i mean if we had them out and sitting on the table people might use them a little more . 
maybe jeremy could sit in some meetings and press a button when there when when somebody laughed . 
although there is a little 
well i ' m yeah that ' s not a bad 
yeah yeah . 
yeah . 
jeremy ' s going to be an he ' s a new student starting on modeling breath and laughter actually . 
which sounds funny . 
but i think it should be cool . 
so 
yeah . 
sounds breathy to me . 
okay . 
breath and 
ha ha ha . 
ha ha ha ha . 
ha ha ha ha . 
well dear ! 
um 
huh . 
that reminded me of something . 
oh well . 
too late . 
it slipped out . 
okay . 
oh ! 
you ' re you ' re going to tease me ? 
equipment . 
okay . 
ordered 
uh well i ' m always going to do that . 
uh we ordered uh more wireless . 
and so they should be coming in at some point . 
great . 
and then at the same time i ' ll probably rewire the room as per jane ' s suggestion . 
so that uh the first n channels are wireless uh are the the close talking and the next n are far field . 
you know what he means . 
but isn ' t that funny sounding ? 
we ordered more wireless . 
it ' s like wires are the things . 
so you ' re wiring you ' re you ' re you we ' re we ordered more absence of the thing . 
that ' s a very philosophical statement from morgan . 
wired less wired more . 
i just it ' s sort of a anachronism . 
i mean it ' s like 
it ' s great . 
should we do digits ? 
anyway . 
do we have anything else ? 
yeah . 
okay . 
i mean there ' s there ' s all this stuff going on uh between uh andreas and and and dave and chuck and others with various kinds of runs . 
uh um recognition runs . 
trying to figure things out about the features . 
but it ' s it ' s all sort of in process . 
so there ' s not much to say . 
right now . 
uh why don ' t we start with our our esteemed guest ? 
okay . 
all right . 
so just the transcript number and then the then the 
this is 
yes this is number two for me today . 
see all you have to do is go away to move way up in the 
oh . 
we could do simultaneous . 
initiate him . 
we we could . 
should we do simultaneous ? 
well i ' m just thinking are you going to try to save the data before this next group comes in ? 
yeah . 
yeah . 
absolutely . 
yeah so we might want to do it simultaneous . 
i mean you sort of have to . 
right so 
well okay so let ' s do one of those simultaneous ones . 
so we might we might need to do that actually . 
okay . 
that sounds good . 
okay . 
everybody ready ? 
yeah . 
a one . 
you have to plug your ears by the way uh eric . 
well i have to . 
or 
i don ' t know about other people . 
or you start laughing . 
okay all right . 
you don ' t have to . 
okay . 
a one and a two and a three . 
well i tend to 
there ' re a couple meetings where there are a lot of preambles like this . 
in which case the transcription doesn ' t start until someone actually says okay . 
really ? 
so we ' re starting right now . 
well that ' s good . 
yeah oh yeah the meeting ' s started . 
this is this is the real thing . 
this is the 
this is the real thing . 
oh well never mind ! 
it wasn ' t . 
there goes chuck . 
just kidding . 
it was . 
okay . 
so 
and chuck gets stuck with the ear plug mike . 
okay last guy in gets the 
yeah . 
didn ' t get the door . 
oh you just get the door now . 
but he didn ' t shut the door . 
yeah . 
i got it . 
since 
yeah so i i adam sent around this thing about what we were going to talk about . 
and and we had had this discussion of uh flipping back and forth between an emphasis on on the technology particularly recognition versus uh the recordings and transcriptions and so on . 
um but um 
i was asking if we could to uh kind of make it just whatever is happening rather than one or the other . 
because uh next weekend next week i ' ll be at a meeting on campus . 
sure . 
and after that i ' ll be europe for uh several meetings ' worth . 
uh you folks will be gone for a couple of the meetings ' worth in in europe also . 
uhhuh . 
i overlap exactly with the times you ' re gone . 
right ? 
really ? 
i mean 
okay yeah . 
yeah . 
so 
so uh you didn ' t you didn ' t get an agenda . 
i guess we ' ve got the usual 
well because no one no one ever responded with any items . 
yeah . 
so i have a couple of minor ones . 
uh 
our normal transcription status . 
just so that we can make some some plans . 
so what ' s up with i b m chuck ? 
do you know ? 
um i think brian is on vacation now . 
but uh before he left we gave him uh another set of meetings to give to the transcribers . 
and 
how many ? 
uh what is it ? 
is is yours working there chuck ? 
four . 
four . 
oh . 
four . 
can you 
you ' re you ' re b ? 
test . 
what am i ? 
is it turned on ? 
there ' s no on . 
test . 
okay . 
yeah . 
oh it ' s just 
channel b . 
i ' ll let me raise the gain on that a little bit . 
okay . 
channel b . 
since it ' s so far from your mouth . 
sorry . 
okay so we sent them 
so we gave them four meetings before he left . 
and um 
that ' s it . 
so um i don ' t think we ' ll hear from him before he gets back . 
okay . 
and 
do they know about your pie chart ? 
i don ' t know . 
okay . 
i don ' t know . 
what pie chart ? 
pie ? 
oh . 
he has a nice pie chart on the uh the current status page . 
pie . 
which shows the amount of amount of data that had been transcribed . 
uhhuh . 
and the amount out of the entire 
and at this point it ' s not quite half . 
wouldn ' t is that what you ' d say with the pie chart ? 
yeah . 
and then of that there ' s uh a little sliver . 
i could try and draw it . 
but it ' s probably better to describe . 
half the data that ' s been recorded has been transcribed ? 
roughly almost . 
not quite . 
wow that ' s getting pretty good . 
and i haven ' t actually caught up with uh 
since i got back so recently from my vacation . 
um i know that the transcribers finished um uh several meetings while i was gone . 
oh . 
and i haven ' t told you . 
because i haven ' t i haven ' t figured out which ones they are are yet . 
right . 
but when that happens then that pie will get even closer to the mid line . 
uhhuh . 
uhhuh . 
it ' s not quite not quite fifty percent . 
but really getting close . 
uhhuh . 
i think it will be . 
okay so also um 
you mean pi will be close to one half ? 
well not mathematically . 
that ' s new . 
now that ' s a strange 
well if we can have three point one four times as much transcribed as we recorded we really would be doing well . 
yep . 
right . 
but it ' s a nice it ' s i recommend his his his graphic . 
um so 
you know this this raises some 
because it ' s it ' s a really nice graphic . 
uhhuh . 
how much 
how do you transcribe that ? 
how much do we need transcribed before it ' s worth doing some trainings ? 
oh uh 
huh 
i mean it seems like probably we have enough now . 
we can 
right ? 
because like like macrophone wasn ' t that much data . 
you mean 
right ? 
and it helped . 
well we already use it for digit training . 
but but that was read speech . 
you only used that for digits . 
i mean 
right . 
well we did do some training on digits 
that ' s right . 
uh rather adaptation on digits digits . 
i mean supervised adaptation . 
uhhuh . 
so 
yeah i mean uh 
maybe like twenty hours we could try . 
but maybe not counting the non native speech . 
because if that that just doesn ' t translate very well . 
well 
i would i would love to do some um 
you know with adaptation you can use fairly small amount of data to improve your performance . 
right . 
um and 
you know it ' s just basically . 
uh uh 
you know i i don ' t have to time to to do too much these days . 
except what i ' m already doing . 
so 
uhhuh . 
um but if there ' s some someone has some free time i ' m i ' ll be happy to show them how it works . 
and you can play with it . 
cool . 
um 
uh i thought you you were already using adaptation on the test set . 
no supervised adaptation . 
supervised . 
so we ' re doing unsupervised speaker adaptation . 
i see . 
but you could build a test set which you sort of take your models and do supervised adaptation . 
oh okay . 
got it . 
and then you start with the speaker adaptation from sort of channel adapted . 
right . 
right . 
or room adapted . 
or whatever . 
yeah yeah yeah whatever this is . 
how would you imagine doing a test set on this corpus ? 
a test set training set division . 
i mean it ' s really weird . 
right ? 
because it ' s it would be hard to get speaker disjoint sets . 
right . 
do do we just give up on that ? 
right and actually the i was thinking about this . 
the original application doesn ' t really 
i mean if you ' re using this over and over again you ' re going to be testing on the same the same speakers . 
well but then you have the supervised versus unsupervised question . 
i just mean that it ' s not a terrible thing to assume that you don ' t that you don ' t have disjoint sets . 
right . 
uhhuh . 
so 
for this particular kind of application . 
i mean 
yeah . 
yeah . 
i mean you could have some parts of it that are disjoint and some that aren ' t . 
it ' s it ' s sort of like in um broadcast news . 
and see what the difference is you know on the others . 
yeah . 
yeah . 
because you have those people who re occur over and over . 
yeah . 
i mean the anchor speakers tend typically 
right . 
so 
um 
yeah as long as you ' re aware that you ' re doing that that ' s i don ' t see that as a problem . 
you can separate it out and see how if they ' re 
and then similarly with subject matter . 
yeah . 
that you know if you ' re training your language model on this meeting only and testing on this meeting only you ' re going to do a lot better than if you start crossing them . 
uhhuh . 
somewhat although what ' s interesting is that the majority of the words in the language model are actually 
uhhuh . 
are the same . 
yeah they ' re actually these like function words . 
sure . 
and yeah and stuff like that . 
uhhuh . 
uhhuh . 
and there there ' s a lot of speaker dependence there . 
even the transcribers will say they know who the speaker is after a while just from their backchannels . 
yeah . 
just from word choice . 
and 
right . 
so so i don ' t think you ' re talking the way you write in in other words . 
most certainly so it ' s just uh if we ' re going to do that we should give some thought to how we want to divide it up . 
yeah yeah so you know maybe someone else would do a lot of the work where probably your advice . 
yeah and similarly with digits we now have a lot of digits . 
yeah . 
would be helpful . 
but most of them aren ' t transcribed . 
so if we wanted to do a forced alignment on them we could start collecting ourselves up a fairly large digit corpus . 
yeah well we ' d 
and so same issue . 
you know we just need to get someone who ' s interested in that to start looking at it . 
we want that for sure . 
yeah . 
so who ' s working on digits currently ? 
uh dave gelbart . 
okay maybe i ' ll talk to him and see if he ' s interested . 
not right away . 
yeah certainly . 
he ' s got prelims . 
he wants to pass the prelims . 
and 
yeah . 
uhhuh . 
um one thing uh uh just a uh uh an announcement of sorts is that um chuck is going to be going to a meeting at nist . 
in uh about a month and a half i guess . 
they ' re still working out the date . 
because they want to gather together sort of one person from each site who is involved in the meeting stuff . 
since they ' re going to be doing a bunch of meeting recordings there . 
uhhuh . 
and so uh 
is uh are the c m u folks going to be there ? 
somebody you know it ' s like one person 
at the moment it ' s one person from each site . 
so there ' ll be somebody from the c m u and somebody from here and somebody from uh a a number of places . 
probably somebody from u w . 
um so 
yeah it ' s possible they ' ll open it up to more people . 
but but i think you know the main thing is just to 
uh uh uh uh it ' s not a it ' s not a conference . 
it ' s not a workshop really . 
right . 
it ' s just connecting with them . 
so 
um so then if they start a bunch of recordings then ultimately they ' ll they ' ll have training sets and test sets . 
and and all that all that stuff . 
and 
but 
but it would be interesting to hear what they intend to do about the speaker overlap for instance . 
right . 
yeah . 
what ' s the plan if were we still going to be like a center for transcribing data ? 
what happens if they don ' t deliver things until next year or something when we have less resources ? 
or 
well again the hope is that uh i mean it ' s it ' s looking i mean i have to ask these folks . 
but uh my impression is that the um i b m path is looking you know more promising . 
yep . 
it it pretty good . 
yeah . 
and if that ' s the case and if it turns out that uh it ' s really a relatively small amount of time . 
for our transcribers to process things before and after . 
if they really have taken out enough of the of the uh uh work that that it ' s feasible then maybe we can do it with a smaller staff next year . 
uhhuh . 
uhhuh . 
i mean next next year uh in which he ' s you ' re referring to is uh next year we we don ' t have a whole lot of guaranteed funding for this this work . 
um other funding may come . 
you know that ' s but but if we want to just count on uh uh what we know about it ' s it ' s more modest than this year . 
uh it ' s still there ' ll still be money . 
but it ' s just more modest . 
so 
um so i would see us as probably not doing more recordings . 
at least for for for meetings or or digits or anything . 
but uh if if we feel that we need to probably still doing some recordings for smartkom or something . 
yeah . 
um but otherwise just you know stop that . 
and just take whatever comes from the other places . 
which 
uh 
i guess we have an unknown rate . 
if it if it starts being if they ' re generating this huge amount and we can ' t handle it then you know we ' ll tell them . 
but 
uh although it would have been nice if that their stuff had come earlier . 
it ' s in some ways a good thing . 
because we ' ve been ironing out this path . 
so 
um well i got a email from one of the u w guys . 
they want to record the meetings at higher uh sampling rate than sixteen kilohertz . 
uh 
i didn ' t ask why . 
but it seems to me that really doesn ' t matter . 
if they have the disk space to do it it seems that that is not a big deal . 
i was just wondering if anyone had an opinion about mismatched rates . 
well it ' s just if that they ' re sending it to us then we have to have the disk space to do it too . 
can ' t we downsample ? 
and uh transcribe on that basis . 
that would be the hope . 
yeah . 
yep . 
are they doing some nice integer multiple ? 
or 
excuse me ? 
are they doing some nice integer multiple of of sixteen ? 
no . 
are they they ' re doing like twenty two ? 
no no no it was like forty something . 
or 
could 
forty eight . 
forty forty four . 
forty four . 
forty two . 
so c d . 
yeah . 
c d rom . 
c d . 
yeah . 
yeah . 
oh forty four point one . 
yeah . 
forty four . 
forty four one . 
yeah . 
yeah . 
something like that . 
oh so that ' s 
well you know we record here at at forty eight or something . 
and then we downsample yep . 
and then we downsample . 
but forty eight ' s a nice multiple of eight . 
but but it but forty four and sixteen are not easy . 
yeah . 
well you can do it . 
you can do it i think . 
yeah ? 
oh absolutely you can do it . 
it ' s not lossy ? 
yeah you can do you can go from anything to anything else . 
you 
but but it ' s it ' s just it ' s it ' s just a little more complicated . 
you get aliasing . 
as long as you ' re 
yeah . 
as long as you ' re not doing the processing on the downsampled . 
there ' s probably some 
i mean just for transcribing it you mean . 
it ' s just like 
yeah . 
so 
yeah i mean it ' s just slightly more complicated . 
but it ' s but you can you can go from any frequency to any other frequency . 
so it ' s 
well the the only thought was if we ' re going to do a combined corpus does it really matter if some ' s sampled at one rate and some ' s sampled at the other ? 
my feeling is no it doesn ' t . 
your audio these days audio tools tend to take care of all of that . 
but i just wanted to double check with other people before i told them yeah no problem . 
also seems like the corpus could all be standardized on on this the uh 
that ' s what i was saying . 
why are why are they asking us ? 
so so 
yeah . 
i don ' t know . 
why are they asking us ? 
because you know we ' re sort of doing the corpus . 
so they want to be as similar as possible . 
and so i 
so but i think the answer is if if we tell him no that ' s not all right what he ' ll probably say is well we ' re going to do it anyway . 
it could be interesting . 
well that ' s that ' s why i ' m asking . 
but uh 
well it will be interesting to find out why they are choosing a higher sampling . 
yeah . 
uh 
yep . 
it ' s kind of a 
well i would suspect it ' s because it ' s what the hardware does . 
for 
oh and they just don ' t want to downsample . 
yeah . 
yeah . 
well someone ' s going to have to downsample . 
but then they ' re just they ' re just there ' s just deferring the problem to later . 
yeah . 
and they might save themselves a lot of disk space problems by doing it right away . 
they ' re taking up more disk space . 
yeah it 
yeah . 
i i think it ' s the sort of thing that ' s deserving of discussion with them . 
okay . 
i i don ' t think it ' s like uh they ' ll ask us we ' ll give a simple answer . 
and come back . 
it needs some back and forth . 
i mean that ' s 
because it ' s it ' s a little gnarly to have parts of the database with different things . 
that ' s like three times three times as much disk space . 
yeah . 
yeah it ' s four or five times . 
and it ' s 
yeah . 
depends what you save . 
um 
you know part of the arguments for the higher sampling rate is that maybe there ' s something you know say in six to ten kilohertz that you might use for for some purposes somewhere . 
if people are doing a wide range of things 
doing location . 
uh you know doing a bunch of things . 
maybe you know why why throw it away if you don ' t need to ? 
um on the other hand 
um i mean 
it ' s sixty kilohertz is plenty . 
yep that ' s that ' s what i thought . 
yeah . 
so so 
so uh i i i think it ' s it ' s uh 
and they are going to be using up a lot of disk . 
both for them and for us when we ' re processing their stuff . 
uhhuh . 
we should warn them that these disk space issues are going to creep up on them very fast . 
uh if they 
yep yep . 
they ' ll have to start kicking people out of the meetings . 
well if if they ' re going at forty four they won ' t even creep . 
yeah but 
like 
yeah . 
yeah . 
as long as they have only like three people per meeting . 
they ' ll just pounce . 
how many channels ? 
i mean they can just limit the number of people . 
um i don ' t remember what their hardware set up was . 
but it was smaller than ours . 
well that might help a bit . 
yeah . 
yeah actually i think at nist they were there were there was some discussion of fairly high sampling rates too . 
well with nist i think 
so 
they ' re they ' re in a different situation because they ' re doing video . 
and so compared to the video the audio is just noise . 
in terms of disk space . 
uhhuh . 
literally . 
i don ' t think that ' s true . 
really ? 
they ' re recording fifty channels of mikes . 
they ' re not recording all fifty of the array . 
they ' re they ' re cooking it down . 
yeah they are . 
yeah they were they said they were going to record 
aren ' t they ? 
they ' re recording all of them . 
i don ' t know if there were fifty . 
but there were definitely above like twenty . 
whew . 
yeah . 
that ' s funny . 
i thought that they were cooking down that data in some way before they were storing it . 
it was it was high . 
i don ' t believe so . 
no i don ' t think so . 
no so i think they they have actually a very large audio data rate . 
i think it is comparable to a video data rate . 
okay . 
so 
how in the world are they going to ever distribute this ? 
yeah distributing 
they ' re not going to . 
uh 
you ' re going to have to just get 
interesting question . 
because our 
you ' ll have to just work on little subsets of it . 
there ' s just no way you could get it all . 
we ' re we ' re estimating that ours 
if we collect say a hundred meetings 
and each meeting is just the audio . 
compressed audio ' s half a gig . 
so there ' s fifty gigs just for our corpus . 
yep . 
for a hundred meetings . 
and uh you know 
that ' s eight kilohertz ? 
and that ' s and that ' s and that ' s no video . 
sixteen . 
sixteen . 
that ' s sixteen . 
sixteen . 
sixteen . 
and so 
sample rate . 
you just get like one backchannel at a time or something . 
yeah . 
oh it ' s shortened . 
even even a distribution of fifty gigs . 
oh okay . 
yeah it ' s shortened . 
and then shortened . 
you know it ' s if you use d v ds or something that ' s 
yeah . 
a lot . 
it ' s still yeah two or three d v ds . 
but 
yeah not if you have to distribute the video also . 
two or three ? 
if you use both sides and the two layer and all that . 
it ' s a lot more than that . 
right ? 
d v d is eight gig . 
well i think you ' ll have some interesting discussions next month when you go out there . 
seventeen . 
yeah yeah . 
i mean how are they going to you know what ' s what ' s the distribution plan ? 
uhhuh . 
if they have something really smart in mind you know maybe we can use it . 
i mean i mean we talked about sending around a disk or a computer . 
i think that ' s definitely the right way to do it . 
someone sends us disk . 
we we load it with data and send it back . 
it ' s going to be easier than any other method . 
uhhuh . 
uhhuh . 
maybe a maybe 
well if not if you want to burn the c ds you ' re welcome to it . 
i say we give it to l d c and let them do it . 
well yeah . 
uhhuh . 
yeah absolutely if they have a way of doing it . 
and there ' s never any talk 
i ' m thinking prior to that . 
what ' s l d c ? 
was there ever any talk of taking the um close talking mikes when people aren ' t talking and deleting those portions ? 
linguistic data consortium . 
huh . 
or is the breathing and things 
we already do that . 
shorten does that automatically . 
yeah ? 
okay . 
that ' s why you why that ' s why shorten that ' s why shorten reduces the size so much . 
and if they ' re still that big ? 
i see yeah that ' s true . 
that ' s why it ' s only fifty gigs . 
right . 
okay so it ' s still really big even if you ' re only one person or two people at most are actually talking all the time . 
yep . 
wow ! 
we should just talk less . 
have shorter meetings ! 
well if you talk less it does in fact use less data . 
yeah . 
so the channels 
yeah . 
hey it ' s it ' s the first time i ' ve ever heard you ask for less data . 
huh 
it ' s actually one way to tell if a microphone is dead in a meeting is if the shortened file is too short . 
thanks morgan . 
it ' s really short yeah yeah . 
then you can be pretty sure that the mike was off . 
oh . 
yeah . 
uh okay . 
and the unfortunately the table top ones 
the six table top which we record all the time no matter how many people are there uh don ' t compress nearly as well . 
because they ' re almost always have signal on them . 
yeah that ' s probably a lot of it . 
yeah . 
yeah . 
and they ' re going to have mikes like that too . 
yeah . 
yep . 
in fact their array their array will be 
most of them . 
all of them are like that . 
yep so they won ' t shorten nearly as well . 
yeah . 
wow ! 
and i assume they ' re going to do it lossless . 
yeah so so they ' re really going to have a huge 
so so for 
for distribution purposes it might make sense to split it by channel uh rather than by meetings . 
yeah . 
so you could distribute like only the near field signals uh uh uh together for a bunch of meetings . 
yep absolutely . 
and then have a second row . 
and then maybe one far field . 
you know . 
it ' s things or the mixed channel . 
yeah . 
yeah i think there are a lot of ways to do it . 
but let ' s not worry about that now . 
uhhuh . 
yeah . 
right . 
yeah . 
how are we on disk space chuck ? 
um we ' re okay . 
we ' ve got for the uh compressed meetings we ' ve still got about 
i think it was four gigs uh on the one disk that we ' re using . 
uhhuh . 
and we ' ve got several 
we ' ve still got uh quite a bit of space on the uh un backed up . 
so 
good . 
but i i think it ' s probably we should start thinking about where to go next . 
especially on the backed up disk space . 
now we bought a little not all that long ago we brought three uh thirty six gigabyte disks . 
that ' s the un backed up . 
yeah those are the 
yeah we ' re using those for the for the expanded . 
so for example the uh guenter ' s wall street data went onto one of those . 
uhhuh . 
uh some other experiment things that people are doing are on there . 
and 
so if you put it there people will use it . 
yeah so 
so i think after that we need another uh rack or something . 
have to change servers actually . 
right ? 
change servers ? 
well we could we could there are a bunch of disks that we have uh that are smaller . 
and they ' re like seventeen . 
we could go to thirty five . 
so we could get some extra space out of that . 
but the right now the server ' s full . 
we couldn ' t add any more disks . 
we could change a smaller disk for a larger one . 
we should probably do that while we have the space left on the on the the existing thirty sixes . 
yeah . 
yeah . 
so that we can 
yeah . 
yeah the problem with that for backed up media is uh the sysadmins want to keep them at eighteen meg eighteen gig partitions . 
shuffle it around . 
uhhuh . 
because that takes about a day to get off back up tape . 
oh . 
well then there ' s the other issue is that to to add more disk now um david says we really need to go to new servers . 
so 
but he wants to go to new servers not just for us . 
but for other groups too . 
for the whole institute . 
yeah . 
so there ' s this sort of coordination issue . 
and 
i guess i need to talk to him more about 
actually going to bigger disks we can do even 
and just maintain the eighteen gig partitions . 
you just partition them into multiple . 
yeah . 
yeah . 
so that ' s probably the next step . 
that ' s right . 
is to get the eighty or ninety gig drives to replace the thirty gig or an eighteen gig that we have now . 
there are eighty gig drives now that you can get for that ? 
yeah yeah . 
see and that ' s probably what we should send around for these to for distribution of this corpus . 
this isn ' t any 
a whole handful of microdrives . 
yeah . 
well when they come out with 
is is the areal density of the microdrive higher than of a normal drive ? 
it must be . 
when they come out with the eighty gig microdrive then we ' ll just send one of those little things around with all the meeting data . 
yep . 
yeah . 
yeah that ' s what i meant . 
well they have the two gig already . 
yeah . 
and i ' m i ' m just thinking forty of them is probably still smaller in area than uh one normal sized drive . 
actually what i think what what uh 
was it was it dave who was suggesting that uh you just get uh uh a a computer ? 
yep . 
that has one of these drives in it . 
and just send the computer around to the different sites . 
oh god 
and you can just get it off the computer . 
put the computer on tour . 
and press the 
yeah a laptop . 
yeah . 
uhhuh . 
laptop yeah . 
yeah . 
send the laptop . 
eighty gig laptop . 
and of course you don ' t want we don ' t want to trust the shippers necessarily . 
so you send a person too . 
and they just kind of go from site to site . 
i ' ll i ' ll do that . 
and 
download their data kind of johnny appleseed . 
it uh uh unfortunately it takes me a week at each site . 
yeah . 
what ? 
it does take a week at each site . 
so 
does it ? 
yeah absolutely if it ' s a nice site . 
especially hawaii . 
yeah there ' s a there ' s a they really need it in novosibirsk . 
yeah right . 
that only takes a day or so . 
anyway . 
i ' m probably mispronouncing it well . 
but the university of hawaii has issued a request . 
yep . 
yeah uhhuh that that needs a month . 
yeah . 
yeah . 
to download . 
things are slower there . 
definitely true . 
yeah . 
okay . 
any other items ? 
so okay so that ' s the meeting stuff 
uh 
so you ' re we ' re you said it was almost half . 
so that means that we have like eighty or so hours . 
and out of that maybe thirty five or something are transcribed . 
yeah the the pie chart shows actually meetings that are 
uh 
it combines the categories of you know currently in 
oh well i ' ve got it right there i think . 
i i saw the pie chart sticking out . 
yeah there ' s there ' s just a few uh 
so 
do you want to write on the on the board ? 
um yeah . 
except i i ' m tethered . 
do we care ? 
he ' s tethered yeah . 
uh 
i could write on the board . 
okay . 
it combines categories . 
so when we say transcribed we mean either in the process of being transcribed either here or at i b m . 
oh . 
yeah . 
or completed transcription . 
and it also includes uh checked . 
so it includes a lot of categories together . 
i see . 
so 
we need different color pens definitely . 
and that i think that that status thing is kind of old actually right now . 
oh that ' s 
yeah that ' s not half . 
yeah . 
last updated in july . 
that one that you have ? 
oh i ' m not sure the one that i saw on the web when i came back . 
okay . 
yeah . 
the 
rustle rustle . 
the date on this one is july twenty sixth . 
so uh i have to update it . 
a couple weeks ago yeah . 
yeah . 
okay . 
but about how much do we have that ' s sort of uh 
so we have total number of meetings is seventy eight meetings . 
and uh uh 
the total meeting time is seventy five hours . 
uhhuh . 
and um so 
oh . 
the ones that are finished being transcribed as opposed to in the process of being transcribed 
we ' ve got twenty six hours that are finished being transcribed . 
oh great . 
what does that mean ? 
finished being transcribed . 
um so there ' s uh several processes to the transcription . 
there ' s uh 
it ranges from being assigned to a transcriber to them finishing transcription to then being checked . 
you know with a double check . 
uhhuh . 
and so when we say the total transcribed that ' s the one that ' s gone through being checked i believe . 
i think that ' s what the i have here . 
okay . 
just not yet approved for 
but not yet approved . 
yeah okay . 
and then there ' s uh the final one is approved for release . 
oh . 
that ' s after the meeting participants have gone through it . 
so i should probably send those to you . 
shouldn ' t i ? 
oh . 
yes at present there ' s none of those are on the pie chart . 
yeah if you know 
yeah currently that ' s zero released uh 
there are five . 
huh ? 
there are five . 
there ' re five ? 
good . 
we have five where uh everyone has replied . 
okay . 
okay so we have five that are potentially releasable then . 
so the the cross hatching there is um is 
it ' s been through the double check . 
right ? 
i mean it ' s this is the it ' s been 
yeah that ' s approval in progress . 
uhhuh . 
everything on the 
yeah . 
so i mean it ' s 
when i add a couple more from that uh that were done in my absence i think that we ' ll be down to about there . 
so it ' s not quite as close to half as i ' d thought . 
but it ' s you know 
it ' s more than a 
and so these right here have been through the double check . 
these haven ' t . 
uhhuh . 
uhhuh . 
oh how nice of you . 
holding holding the thing so i ' m not 
it was falling off uh 
yeah thank you . 
yeah . 
okay . 
uh all right so we still have a long ways to go . 
but maybe the uh the i b m thing will will help push through the the rest of it somewhat quicker . 
okay . 
and there ' s still uh two people for whom i have not been able to get in touch 
have never gotten a response from from any of the emails about uh permission forms . 
so 
are they from one of the foreign language ones ? 
yep . 
i mean 
okay good . 
that ' s so that ' s why the n s a ones have still not been approved though . 
those will figure less prominently in things anyway . 
yep . 
yeah it might it might partly just be european summer vacation issues . 
possibly it ' s been like four months . 
so 
oh . 
wow ! 
uh you know those europeans . 
they got a lot of 
long vacations . 
right huh . 
okay . 
uh what else is going on ? 
you 
why don ' t we just go around ? 
because we only have a few minutes . 
didn ' t you want to say something about the hardware set up ? 
oh that ' s right . 
uh 
yeah we have new hardware . 
so i want to set it up at some point . 
so i just wanted to know what meeting schedules were . 
what new hardware ? 
uh we have several more wireless channels . 
uhhuh . 
so that we can set up . 
and get rid of these uh the wired stuff completely . 
oh . 
and then also we got replacements for these mikes . 
oh really ? 
uhhuh . 
so what ' s your question ? 
yeah . 
oh . 
are they like these ? 
yeah they ' re like those . 
right ? 
those are the only two choices right now unfortunately . 
okay . 
so what ' s your question ? 
question is when are we not recording any meetings for a couple days ? 
so that i can do it . 
and if it doesn ' t work we won ' t impact people . 
well there ' s a point when a bunch of us are off at eurospeech . 
so 
um 
so what ' s smartkom ? 
nothing this week . 
maybe end of next week . 
end of next week . 
and is e d u still recording ? 
they usually do thursdays . 
i don ' t get a lot of advance notice . 
but it ' s always been either mondays or thursdays . 
so 
thursdays ? 
yeah they they often do it after . 
so if i did it like tomorrow that would be all right it sounds like . 
for a while they were doing it after this meeting . 
oh ! 
yeah wednesdays fridays 
okay . 
so it sounds like no one 
definitely definitely wednesday i ' m not here . 
so i don ' t record anything . 
no one early next week . 
yeah let me check with robert again . 
but i i ' m pretty sure that there ' s nothing this week . 
okay . 
okay . 
and then i ' ll also re number . 
so that uh the mikes are in order . 
oh thank you thank you . 
uhhuh . 
okay . 
should help with the transcripts . 
right . 
they so right now the channel numbers are discontiguous . 
uhhuh . 
right . 
yeah i mean you know it ' s an extra step . 
yeah . 
okay . 
so i was just thinking maybe just go around and just briefly look what ' s other things that are going on . 
maybe since we don ' t don ' t have much of a set set agenda . 
and we don ' t have much time . 
uh 
but feel free to overlap . 
okay we ' ll all say what we ' re doing at the same time . 
no i mean i always get scared when you do these portions where you ' re not going to overlap . 
because there ' s less data points . 
well why don ' t we we we deliberately pick two people to 
i mean people could like backchannel . 
and ask questions and stuff . 
yeah . 
i ' ll i ' ll i ' ll keep saying uhhuh yeah . 
okay . 
uhhuh . 
this is absolutely natural meetings . 
we have absolutely no effect from our preconceptions . 
so we had 
right . 
the the transcribers have trouble with your backchannel . 
because 
with my backchannel ? 
yeah with your backchannels . 
uhhuh . 
because sometimes you have this sort of this this uhhuh that you don ' t 
so there ' s uh huh . 
and then there ' s aha . 
uhhuh . 
and it ' s not quite clear always what what it is you mean . 
which uhhuh ? 
which one it is ? 
yeah . 
but i don ' t think it ' s aha . 
yeah . 
it ' s more like uh huh . 
rather than uhhuh . 
i ' m 
yeah . 
yeah . 
yeah . 
i don ' t like the backchannels at all . 
as that ' s really a problem with the speech nonspeech detection . 
yeah let ' s get rid of them . 
so 
that ' s a 
well has anybody done anything ? 
come on . 
what are we doing ? 
i mean i ' ll start if you want . 
i ' ve been uh most recently rewriting transcriber in java for no particular reason . 
yeah . 
uhhuh . 
well for speed . 
uh 
well i mean what happened was that transcriber ' s very slow to load . 
so when you have a big meeting it uh especially on a slower machine it can take five minutes before you can start doing anything . 
uhhuh . 
and so i was thinking about why that was . 
and the data structures i would use . 
and i found myself unable not to sit down and code it . 
uhhuh . 
so i did . 
and so i have a big chunk of transcriber now written in java . 
and it comes up you know in a couple of seconds . 
um 
do you take do you take feature requests ? 
cool . 
great great . 
yeah we should talk to you off line about something . 
well wait a minute . 
i it ' s not really probably not worth doing . 
what 
that would 
well actually i think it is worth doing . 
but we can talk about it . 
yeah . 
because here ' s the thing we ' re sort of we ' re starting to move from transcription to annotation . 
uhhuh . 
and the transcriber interface is fine if essentially what you ' re doing is stringing words together to to make transcripts . 
annotating . 
yep . 
but um in for instance what we ' re doing now with uh communicator data but which we would like to do with meeting data is to actually label utterances or words or whatever units you want with uh you know basically doing a multiple choice type of labelling . 
uhhuh . 
and for those type of tasks it it ' s much more efficient to present uh the present a bunch of uh clickable buttons or whatever . 
yeah . 
buttons . 
uhhuh . 
and um 
but it has to be multi stream . 
they 
in other words the beginning of something could be one speaker . 
and the end of that unit like question answer pair could be a different speaker . 
that ' s why we can ' t just annotate the transcripts uh one listening to one at a time . 
uhhuh . 
so so that ' s why the transcriber ' s nice for sort of listening to it . 
uhhuh . 
but you can ' t actually encode um encode 
yeah i i understand the problem . 
yeah exactly . 
so 
so 
and and that ' s actually a good model which is what this current tool that we ' re using has is to to associate these labels with um attributes of s g m l tags . 
uhhuh . 
so you know you have say a tag for 
i don ' t know . 
what type of utterance ? 
whether it ' s a question or a statement or whatever . 
and then you have an uh you know an a tag attribute . 
and the value of that encodes the choice . 
right . 
right . 
so what i don ' t have with it so far is it doesn ' t play wavefiles . 
and it display wavefiles . 
i just haven ' t done that . 
since that that part wasn ' t 
oh you mean display as in showing the waveform . 
yep . 
okay . 
yep . 
and uh and then also a lot of the fancy user interface stuff that ' s in transcriber i haven ' t done . 
uhhuh . 
but it works . 
what ' s uh the original transcriber written in ? 
tcl t k . 
i see . 
so 
so 
are you using 
which is nice and flexible . 
but very very slow in comparison . 
yeah yeah right . 
are you using the 
oh you oh you are . 
we already talked about that . 
the x m l reading 
yep sax . 
sax yeah . 
because it ' s much faster than dom and uses less memory . 
right right . 
so 
and then uh 
uhhuh . 
preparing for quals . 
uh hopefully second week of september if i can ever get warren sack to answer my emails . 
i probably shouldn ' t say that on the tape . 
beep . 
yeah oh well . 
i got to remember to beep that out . 
who was that ? 
so anyway so i ' ve been preparing for that . 
not answering your calls huh ? 
and uh 
actually i wanted to say off line with you about any literature reviews i should do beforehand . 
war and peace . 
war and peace . 
that ' s a good choice . 
yeah . 
keep me busy . 
yeah . 
it ' s actually not a bad idea to say beep as a word . 
because you can search the transcripts you know for for that to find these places . 
for beep . 
that ' s a good idea . 
no i ' m i ' m totally serious to have one word like beep . 
no absolutely i agree . 
especially with a really long eee like that . 
yeah . 
works great . 
i ' ll i ' ll take that role anytime you want . 
i like saying it . 
so 
okay . 
yeah i ' ve been doing a bunch of recognition experiments on meeting data with different uh segmentations with different different automatic segmentations . 
but it ' s not yet finished . 
it ' s work in progress . 
okay any sense about how how it does on 
yeah for uh for for the paper i i want to submit to a s r u to to uh evaluate the quality of the speech nonspeech detection by using it for speech recognition . 
right but i was just asking if you had a sense yet of of uh whether 
maybe you already did this experiment . 
where there ' s this question of of how much it hurt you or helped you to use segmented versus 
yeah but we didn ' t have the exact comparison . 
it 
but you know there were 
the experiments were based on different segmentations and different transcripts . 
yeah . 
so we weren ' t quite sure which whether the difference came from different transcripts for instance . 
and so thilo ' s 
so it hurts compared to the ideal segmentation when you have the the manual segmentations . 
where you have exact boundaries for each utterances . 
sometimes there are some some words are cut off . 
or there ' s some segments are uh assigned to to speech which there is nothing in . 
and so there are more insertions . 
but most of the time there are more the the number of deletions is higher when when you use the automatic segmentation compared to the ideal one . 
uhhuh . 
and so i ' m just in in progress of yeah trying to feed the recognizer with un segmented data . 
and to see how much worse that is . 
so that that i have three things . 
yeah un segmented the automatic and the the ideal one . 
yeah . 
but the recognizer ' s putting up some resistance . 
because it doesn ' t like the un segmented data . 
yeah . 
uhhuh . 
um yeah i just got back from chicago . 
so 
um fishing went pretty well . 
oh yeah all of us are banging . 
good good . 
and um i was going to post some results you know with uh 
wisconsin fishing . 
with fishing 
wisconsin fishing yeah . 
yeah . 
uh . 
so your so your results are about the same as bush ' s . 
you should have seen the one that got away ? 
basically his 
who yeah right . 
whose result ? 
bush ' s . 
yeah you ' re both you know sort of he ' s he ' s coming back to the heartland . 
and 
yeah right exactly . 
i did my tour of the heartland . 
yeah . 
did you build any houses ? 
yeah . 
yeah i built a few built a few houses . 
um 
but right now i guess uh i ' m working on this paper this isca paper for this workshop that liz and andreas and i are putting together . 
so we ' re just getting uh different results for 
um we fixed up our different uh transcripts with different types of uh annotations . 
and we re ran re ran alignments . 
and we ' re going to develop a new feature database based on those alignments . 
and do some trees and analysis . 
so i ' m kind of in the middle of that . 
and 
hopefully by the twentieth the twenty third . 
uhhuh . 
twentieth . 
the twentieth ! 
yeah we ' ll have it all straightened out . 
yeah . 
so it ' s going to be a busy week . 
yeah . 
you know i ' ll bet you know bush went on this european trip recently . 
and they told him there that they get more vacations . 
uhhuh . 
yeah . 
so he came back here and thought oh i i can afford some more vacation too . 
beep ! 
yeah i i think he ' s he ' s been he will have been off like two months out of his first seven in office . 
yeah it ' s amazing . 
yeah it ' s hard to keep concentration you know . 
that ' s a pretty good deal . 
and the focus on the 
don ' t even really notice . 
do you ? 
anyway . 
um . 
so while he ' s vacationing um we ' ve been uh 
well basically this is like a joint effort . 
uh we were just 
who are you talking about ? 
bush or don . 
yeah . 
um 
you know apart from getting preparing the the the data for the 
um for these experiments for the um uh for this prosody workshop . 
we just um we just had a phone call with mari and her students in fact . 
and they want to um they ' re bringing up their own meeting recognizer . 
which is based on bill byrne ' s uh recognizer from johns hopkins . 
uhhuh . 
based on hub five or like like your 
based on their hub five recognizer . 
uhhuh . 
and uh 
yeah . 
so they ' ve been getting from us the um you know some support in terms of getting the latest transcripts . 
and the also the actually the uh transcripts annotated with events . 
uhhuh . 
uh like sentence boundaries and stuff like that . 
uhhuh . 
yeah . 
um because one of mari ' s students was to wants to do some language modeling for uh predicting overlaps and uh stuff like that . 
yeah . 
um 
yeah actually we had this from the last time that they were here that it ' d be nice to have u w do some work on language modeling that would be trying to get at the same detection as what we do acoustically . 
can i borrow a piece of paper ? 
since they can ramp up much quicker in the language modeling . 
thank you . 
and we you know we ' ll do the uh prosodic side . 
and so this is supposed to be a project that we could actually integrate the posteriors that they get from their language model for every word boundary or every frame boundary . 
and then train up the classifiers . 
yeah . 
uhhuh . 
uhhuh . 
and it ' s i guess it ' s an undergrad too that that ' s going to be doing this work . 
cool . 
yeah . 
so 
um on the recognition side actually um i think the main person doing that is uh harriet from harriet nock from uh formerly of cambridge . 
yeah . 
um and apparently they get reasonable results . 
except in some portions they get very high insertion rates . 
even higher than we get with with the um like even you know on lapel mikes with uh background speech . 
and so they were trying to track that down . 
and 
it could be that our recognizer ' s actually doing relatively well . 
because it has a reject model for you know mismatched speech essentially . 
or for unspecified speech . 
and um so 
oh ! 
so uh they ' ll i sent them our recognition output . 
so they can sort of do a line by line comparison . 
and see if if they um you know their insertions correspond to our rejects and stuff like that . 
so um we ' ll see what that uh leads to . 
um 
yeah other than that uh 
we ' re well that ' s pretty pretty much it as far as meetings are concerned . 
yeah i mean we ' re doing uh 
so i should mention dave and i have sort of been pushing through thinking in terms of an a s r u paper . 
but i ' m still 
uhhuh . 
i think early next week we ' ll decide whether we ' ll we ' ll do one or not . 
um but because you know the results are are still confusing enough that that um 
uhhuh . 
we got to be convinced we understand what ' s going on . 
but it ' s starting to look like it it ' s almost the opposite of the usual situation where um you get some really nice result with uh with digits say . 
and then you go to a large corpus and the result goes away . 
um we had what looked like a good result in digits but but then when we went to more training data that kind of went away . 
uhhuh . 
so uh the digits result right now is kind of equivocal . 
uhhuh . 
um but the conversational speech one while not huge is in sort of hub five or meeting kind of terms . 
actually it ' s it ' s it ' s not bad . 
you know ? 
so so it ' s it ' s you know it ' s like 
right . 
after he did some adjustments more like a percent or so that that absolute that it goes goes down . 
yeah it ' s a p h d . 
and 
but is it still true that basically the speaker adaptation um sort of negates much of the advantage ? 
yeah . 
no i ' m talking about with the adaptation . 
with it . 
without the without the adaptation is a much bigger effect . 
okay . 
so so it ' s it ' s very reasonable to think of as an alternative way of getting this kind kind of improvement . 
uhhuh . 
but i think what ultimately what we have to face with it is that um 
i mean he gets incredibly good results if you artificially reverberate clean you know close close miked data . 
right . 
so i think the thing we really have to face is that our model for what ' s going on is is wrong . 
is it wrong ? 
right . 
or incomplete . 
and that in this situation in particular there ' s a lot of noise . 
right . 
and noise plus reverberation is not at all the same as just reverberation . 
so um uh there ' s that one thing that been thinking of doing is there ' s a whole lot of work that ' s been going on in noise suppression in the in the aurora uh team . 
and so uh they ' ve got some software . 
and i ' m think of of just having us integrate that in . 
uh because it 
just combine it see . 
yeah because it just i mean it just subtracts it out . 
in fact in fact you can run it in sort of enhancement mode where you get speech out . 
and and and uh then just run it through the rest of your recognizer . 
uhhuh . 
so so uh um 
yeah . 
neat . 
so we ' re working on that . 
okay . 
there ' s some work um that 
do you remember this paper or poster by um some c m u folks at uh h l t ? 
they were talking about 
and and they they referred to an upcoming i cassp paper i think at the time . 
someone in karlsruhe i think um worked on uh you know estimating noise from the silent regions . 
and then uh doing some explicit 
i don ' t know if it ' s something akin to parallel model combination or something like that to to uh 
i mean people have done that for a long time . 
right ? 
right anyway uh so i i i couldn ' t judge whether this was original or not . 
but but it seemed like they got pretty good results on their meeting data . 
so we might want to look into that . 
yeah i i don ' t remember the paper . 
right . 
but i mean that that ' s certainly one of the common techniques is to do that . 
right . 
uh and in all the stuff that our team is doing they certainly look at regions that you think are nonspeech in order to get noise statistics . 
uhhuh . 
but uh 
right . 
i mean there ' s a host of different things you could do . 
in the aurora thing we have we have a little bit of a handicap in that they they don ' t let you uh adjust the the statistical models . 
so you have to you have to do everything at the feature level . 
uhhuh . 
um but um um 
but there ' s uh you know wiener filtering and spectral subtraction . 
which are uh sort of can be looked at as minor modifications of one another . 
um 
and they ' ve now built up a nice piece of software that does 
um 
has this sort of general framework for a for it . 
so that you can adjust it to sort of any any any one of a dozen ways that people have done this kind of thing . 
and 
uhhuh . 
they found a particular set of parameters they liked this week . 
and we ' re running with that for a while . 
but 
okay . 
anything else ? 
so well i ' ll just really briefly um 
so i ' ve been working with don and also and and andreas on the this paper on prosody . 
and what we ' re trying to do is predict where people at 
given all information up to whatever point in time you ' re considering try to predict if that ' s a good location for someone else to jump in . 
so that ' s the idea of that paper . 
and that ' s the same task that mari um a student named dustin and also sarah who was at this last meeting will be looking into doing from the language modeling side . 
maybe some kind of you know clustered class n gram or something . 
uhhuh . 
um and also we ' re we ' re using a couple of the labelers who are doing emotion to help us um finalize some transcripts for this . 
so these undergrad students are really helping us out a lot . 
yeah . 
under don ' s supervision actually . 
so that ' s good . 
right . 
so these offices are being uh very busy . 
don ' s and the one across from him . 
and then also um working with jeremy on communicator emotion labelling . 
and most of that up to a few weeks ago was just getting the people labelling these utterances to a computer for emotion . 
and that ' s going pretty well now . 
what kind of emotions do you label ? 
um 
well we ' re mostly looking for places where the person ' s frustrated with the system . 
so there ' s just two categories frustrated and not . 
or no ? 
there there are actually that ' s how we started it . 
yeah . 
and we had different levels . 
now we have things like amuse . 
like oh you finally got it . 
um and disappointed tired like yeah no that ' s wrong again . 
which isn ' t really mad . 
but you know . 
yeah . 
so they gave me a lot of feedback the labelers after doing this . 
uhhuh . 
told me what they wanted as categories . 
and then there ' s jokes . 
and 
yeah . 
yeah right . 
um 
there ' s not a lot of enough frustration for us to really go through quickly . 
because we have to label every meeting . 
and also things like repeats for the same information and so forth . 
and i ' ve been coordinating a little bit with katrin at uh u w who was doing user correction work that she presented at the at the meeting . 
so there ' s some overlap there in what you 
there ' s a correlation between corrections and annoyance or frustration . 
yeah . 
um but jeremy ' s been starting to actually really work on that project now from the acoustic side . 
so we have all these wave forms . 
and he ' s been with morgan ' s help and uh dan ellis ' s i think looking into spectral tilt a bit . 
so he can talk about that . 
it ' s a feature we haven ' t used before . 
um and starting to uh take information from alignments . 
and create a database that we can use sort of as a a large feature vector or table to feed to our decision trees . 
which will try to give us back an answer from the speech only as to whether the person ' s frustrated or not . 
that reminds me of something . 
so 
we we talked about something a ways back and i sort of lost track of it . 
about having a synthesizer driven with 
yeah . 
i haven ' t really had time to do that . 
actually i wanted to talk with you about that . 
yeah . 
because there ' s a similar project at s r i where we ' re using we want to do something like that to look at whether or not some of the stylized pitch stuff is um sort of perceptually similar to the kinds of things that people would mark . 
yeah . 
so i i actually wanted to talk to you about that . 
yeah . 
maybe after wednesday ? 
so 
okay yeah because this will be like after 
yeah because you have this a a s r u deadline . 
yeah yeah . 
okay yeah this will be after september anyway . 
right . 
but that seemed like it would be fairly straight forward that if you take the take the pitch from the real data feed it into the synthesizer and then process the output with a gain box that you also had energy from the from the real data . 
yeah . 
so i 
yeah . 
right . 
yeah . 
yeah there was just no way to use the energy in festival that was 
hey we could use that in the english 
we have to do the english synthesis for smartkom . 
what if we make the system really annoyed ? 
anyway i i should move on . 
because we ' re running late . 
yeah . 
but i wanted to say there ' s one question in my mind which maybe morgan can talk to jeremy about is how to sort of normalize spectral tilt ? 
it ' s just i ' m sort of in this uh area i don ' t know much about . 
and so we should talk off line . 
okay . 
but if you have a certain speaker and you want to sort of get a bunch of data from that speaker but compare it you know directly on a feature to to like a decision tree that won ' t normalize anything for you once you feed it the features how do you sort of normalize over a particular speaker ? 
uhhuh . 
what kinds of what what makes sense to do with that feature ? 
well i ' ll have to hear what he ' s using given different suggestions he ' s gotten . 
so 
yeah . 
but that ' s something we would be glad to have help on . 
but 
okay . 
so go ahead jeremy . 
right so i ' ve been looking at spectral tilt . 
and different ways of perhaps generating it . 
and um i basically have three ways right now that we ' re looking at for uh we ' re going to look at for features . 
uh one is just looking at um the first cepstral coefficient . 
and uh using that . 
um another is looking at the log the difference of log energies between um the high like a high frequency band and a low frequency band . 
and the third is just um taking a slope um of the linear fit of the spectrum and using that . 
so those are the three three ways i have right now for generating these spectral tilt numbers . 
and um 
hopefully soon we can look at some of the labelled stuff . 
and look at uh these numbers and see see which ones seem to be working well and things like that . 
um i also recently wrote a script um that uh generates the kappa statistic . 
um which is a for labeler agreement . 
um so been looking at that as well . 
yeah . 
i mean wh what specifically what you want to do is remove the the the the average uh speaker tilt in some sense ? 
the thing 
yeah we we you want to use spectral tilt to try to get at the the voice quality of these utterances . 
so you could have something like no versus no . 
and these might differ in that way . 
but the problem is we don ' t know we don ' t we don ' t know whether the no is frustrated or not . 
you don ' t know it 
yeah yeah . 
uhhuh . 
so 
right exactly . 
and then you also have the different speakers . 
and so the sort of question is do you want to average all the data together or do you do you 
yeah . 
you want to capture the change in voice quality within a speaker . 
without having to know ahead of time which is which . 
because that would be circular . 
i mean 
so 
maybe maybe this is too obvious to be right . 
this is 
but i mean the the the the normal thing for c one would be to to uh get rid of the mean and and the variance . 
right ? 
to get rid of what ? 
does that the mean and variance have it be zero mean and unity variance . 
mean and variance . 
okay . 
but do you just do this say just in the vowel regions ? 
and then 
and do you 
there ' s there ' s a whole bunch of um sort of unknowns . 
right . 
and we can try all of them . 
and just put them into the tree as features . 
well the answer ' s yeah . 
i mean you want you want it for every place that ' s voiced . 
and 
but but you can ' t do it 
i mean you can ' t just normalize it based on the utterance . 
because then you ' re going to have zero everywhere . 
right ? 
so you ' d have to normalize it based on the 
no everything for that speaker . 
yeah . 
yeah okay but that ' s not really feasible . 
everything up to that point . 
because you ' re having a you have a system a dialogue system where you only have access to the what the speaker said before . 
yeah . 
so it ' d have to be sort of a causal uh version of that . 
oh yeah that ' s okay . 
that that ' s the sort of we keep you keep uh you keep updating those numbers for future utterances . 
yeah . 
that that would work . 
yeah i mean but but the main i think the main thing is that 
or you 
the you ' re right i mean the main distinction is whether it ' s voiced or or voiced or not . 
if it ' s if it ' s if it ' s silence or or unvoiced regions then you you you don ' t really want that in there uh if you can help it . 
yeah . 
but actually i mean just to first order suppose you just didn ' t do anything smart at all . 
and just did you know did that it wouldn ' t be that bad . 
because you ' d get some number that would be skewed by be skewed by that 
so you mean you ' re just using a mean and the and a variance . 
you know uh uh x x x x x x minus mu over sigma yeah . 
you mean just a a z square ? 
like 
right right right okay . 
so it is distributed in a way that you can do this yeah okay . 
huh . 
it it it ' s it ' s sort of the first order thing to do . 
there ' s uh you know uh obviously much much more arcane things to do and complicated things to do . 
okay so that ' s so that was our sort of . 
but that ' s that ' s the first thing to do . 
maybe this will work . 
i don ' t know . 
and then you know then the next thing is well let ' s just look at the voiced regions . 
okay . 
you know and that would be a reasonable thing to do . 
and then if it ' s really when you look at what 
since you ' re looking at something that ' s sort of in log domain cepstral is like log linearly transformed of a log domain it ' s probably not that terrible an assumption to pretend it ' s gaussian anyway . 
and so the other things that get more more tricky are uh to handle the fact that it ' s not not really gaussian . 
and and you may you may not really need that for this . 
well we probably won ' t get that far yeah . 
yeah so i think that would be that would be the obvious thing to do . 
okay . 
okay . 
well we ' re not going to build a parametric model of the of the of the feature . 
yeah . 
right ? 
we ' re just going to we ' re going to use like thresholding or something . 
no i understand . 
it ' s just it it 
no it ' s more that that if you felt something wasn ' t gaussian and you were trying to . normalize for some kind of uh bias of some sort you might use a non parametric measure . 
right right okay . 
like you might use a median . 
median yeah . 
right . 
you know . 
and rank statistics and all that sort of stuff . 
we could just plot plot these for a speaker . 
but i mean you shouldn ' t bother with it if it ' s roughly gaussian . 
and 
get a bunch of histograms . 
right . 
just 
yeah . 
okay . 
okay . 
right . 
uh yeah . 
thanks . 
sure . 
uh and i already i already said what i was doing . 
which is mostly trying to give advice to dave when he he he actually does the real work on this uh reverberation thing . 
but i think it ' s it ' s it ' s a real uh it ' s a real learning experience for both of us . 
and and uh i think it ' s it ' s a problem problem area that people really haven ' t dealt with that much as we know . 
so uh he kind of did he started off with what was in some sense sort of the first obvious thing to do . 
although hardly anybody had done it yet . 
and uh it it does work very well under some conditions . 
and other conditions it doesn ' t . 
uhhuh . 
and now we ' re understanding trying to understand what those are . 
it ' s it ' s it ' s fun . 
do you want to add anything to say anything ? 
she just got back . 
how was did you catch fish ? 
or 
no . 
no no fish okay . 
no . 
you know when bush catches fish . 
they actually put a bunch of fish in the lake for him . 
oh . 
really really hungry fish . 
it ' s part of the budget . 
i ' m i ' m not kidding . 
really they just they they pre stocked it with with a a 
the secret service is out there throwing fish into the ocean into the lake . 
i ' m really not kidding . 
how they 
they got like scuba gear on and like hooking them ? 
but they didn ' t tell her . 
uhhuh . 
uhhuh . 
hey i caught one this one and it ' s already cooked ! 
it you know to keep to keep us uh 
it ' s already dead . 
yeah so we ' re ready to increase our federal funding . 
i think we ' re done . 
should we do uh simultaneous digits so that we actually have time for tea ? 
why why don ' t we 
uhhuh . 
yeah let ' s do that . 
okay . 
huh . 
i still don ' t know if these are going to be any good . 
but it sure does get us out of here quicker . 
a one and a two and a three . 
ready ? 
okay . 
so this time the form discussion should be very short . 
right ? 
it also should be later . 
okay . 
because jane uh is not here yet . 
good point . 
and uh she ' ll be most interested in that . 
uh she ' s probably least involved in the signal processing stuff . 
so maybe we can just just uh 
i don ' t think we should go though an elaborate thing . 
but um uh jose and i were just talking about the uh uh speech energy thing . 
the two last 
yeah . 
and i uh 
we didn ' t talk about the derivatives . 
but i think you know the the 
if i can if you don ' t mind my my speaking for you for a bit um uh 
right now that he ' s not really showing any kind of uh distinction but uh 
but we discussed a couple of the possible things that uh he can look at . 
um and uh one is that uh this is all in log energy . 
and log energy is basically compressing the distances uh between things . 
um another is that he needs to play with the the different uh uh temporal sizes . 
he was he he was taking everything over two hundred milliseconds . 
uh and uh he ' s going to vary that number and also look at moving windows as we discussed before . 
um and uh and the other thing is that the yeah doing the subtracting off the mean and the variance in the uh and dividing it by the standard deviation in the log domain may not be the right thing to do . 
hi . 
hi jane . 
yeah . 
we just started . 
could you take that mike there ? 
are these the long term means ? 
like over the whole 
i mean the means of what ? 
uh between between 
all the frames in the conversation ? 
thanks . 
or of things that 
no . 
between 
neither . 
no . 
it ' s uh between the pauses uh for some segment . 
oh . 
and so his his he ' s making the constraint it has to be at least two hundred milliseconds . 
oh . 
and so you take that . 
and then he ' s he ' s uh measuring at the frame level . 
still at the frame level of what 
right . 
and then and then just uh normalizing with that larger amount . 
um and but one thing he was pointing out is when he he looked at a bunch of examples in log domain it is actually pretty hard to see the change . 
and you can sort of see that because of of just putting it on the board that if you sort of have log x plus log x that ' s the log of x plus the log of two . 
yep . 
yeah maybe it ' s not log distributed . 
huh . 
yeah . 
and it ' s just you know it it diminishes the effect of having two of them . 
but you could do like a c d f there instead ? 
um 
i mean we don ' t know that the distribution here is normally 
yes right . 
so so what i was suggesting to him is that 
so just some kind of a simple 
actually a p d f . 
but you know uh but either way . 
p d f . 
yeah . 
yeah . 
yeah . 
yeah uh 
something like that where it ' s sort of data driven . 
yeah but i think also i think a good first indicator is when the the the researcher looks at examples of the data and can not see a change in how big the the signal is when the two speaker 
yeah yeah . 
then that ' s a problem right there . 
so i think you should at least be able 
oh yeah . 
doing casual looking and can get the sense hey there ' s something there . 
and then you can play around with the measures . 
oh yeah . 
yeah . 
and when he ' s looking in the log domain he ' s not really seeing it . 
so 
and when he ' s looking in straight energy he is . 
so that ' s a good place to start . 
yeah . 
um so that was that was the discussion we just had . 
um the other thing 
actually we had a question for adam in this . 
uh when you did the sampling uh over the speech segments or or sampling over the the individual channels in order to do the uh the amplitude equalization did you do it over just the entire everything in the mike channels ? 
how 
you didn ' t try to find speech ? 
no i just took over the entire uh entire channel . 
um sampled ten minutes randomly . 
right okay . 
so then that means that someone who didn ' t speak very much would be largely represented by silence . 
yep . 
and someone who would who would be 
so the normalization factor probably is is is 
yeah this was quite quick and dirty and it was just for listening . 
yeah . 
yeah . 
okay . 
and for listening it seems to work really well . 
yeah . 
yeah . 
yeah . 
so 
yeah . 
but that ' s 
right . 
but it ' s not not a good measure . 
so 
yeah . 
okay . 
so yeah there there there there ' s a good chance then given that different people do talk different amounts that there is there there is still a lot more to be gained from gain normalization with some sort 
yeah yeah . 
huh . 
yes absolutely . 
if if we can figure out a way to do it . 
yeah . 
uh but we were agreed that in addition to that uh there should be stuff related to pitch and harmonics and so forth . 
yeah . 
so we didn ' t talk at all about uh the other derivatives . 
but uh again just just looking at 
uh i think uh liz has a very good point that in fact it would be much more graphic just to show 
yeah . 
well actually you do have some distributions here uh for these cases . 
yeah . 
you have some histograms . 
yeah . 
um and uh they don ' t look very separate . 
uh separated . 
this is the the first derivate of log of frame energy uh without any kind of normalization . 
what 
yeah . 
yeah . 
yeah . 
log energy . 
these these are the the first experiments uh with comment uh 
sorry . 
frame energy . 
except that it ' s hard to judge this because the they ' re not normalized . 
it ' s just number of frames . 
yeah . 
yeah . 
yeah . 
yeah . 
but yeah even so . 
i mean what i meant is even if you use linear you know raw measures like raw energy or whatever . 
number 
maybe we shouldn ' t make any assumptions about the distribution ' s shape . 
and just use you know use the distribution to model the the mean . 
or what you know rather than the mean take some 
yeah . 
but and so in in these he ' s got that . 
yeah . 
he ' s got some pictures . 
yeah . 
but he doesn ' t he doesn ' t in the i 
just in derivatives but not in the 
yeah . 
oh . 
but he but he doesn ' t doesn ' t 
right so we don ' t know what they look like on the tsk for the raw . 
but he didn ' t have it for the energy . 
he had it for the derivatives . 
yeah . 
so 
yeah . 
i mean there might be something there . 
i don ' t know . 
huh . 
yeah . 
interesting . 
here i i 
oh that yeah that ' s a good 
in no i i i haven ' t the result . 
did did you have this sort of thing for just the just the uh the the unnormalized log energy ? 
okay yeah . 
so she she ' s right . 
but it ' s the it ' s the the the following . 
that ' s a 
well it might be just good to know what it looks like . 
yeah . 
because 
that ' s that ' s uh because i ' d mentioned scatter plots before but she ' s right . 
huh ? 
i mean even before you get the scatter plots just looking at a single feature uh looking at the distribution is a good thing to do . 
yeah . 
uh combining the different possibilities of uh the parameters . 
i i i i mean the the the scatter plot combining uh different two combination . 
yeah but but what she ' s saying is which is right is 
combination of two of energy and derivate 
i mean let ' s start with the 
before we get complicated let ' s start with the most basic thing which is we ' re arguing that if you take energy uh if you look at the energy that when two people are speaking at the same time usually there ' ll be more energy than when one is . 
yeah . 
right ? 
that ' s that sort of hypothesis . 
that ' s right . 
and the first way you ' d look at that uh she ' s you know absolutely right . 
is that you would just take a look at the distribution of those two things . 
yeah . 
much as you ' ve plotted them here . 
you know but just but just just uh do it 
yeah . 
well in this case you have three . 
you have the silence and that that ' s fine . 
yeah . 
so uh with three colors or three shades or whatever . 
just just look at those distributions . 
yeah . 
and then given that as a base you can see if that gets improved you know or or or worsened by the looking at regular energy looking at log energy . 
we were just proposing that maybe it ' s you know it ' s harder to see with the log energy . 
yeah . 
um and uh also these different normalizations does a particular choice of normalization make it better ? 
but i had maybe made it too complicated by suggesting early on that you look at scatter plots . 
because that ' s looking at a distribution in two dimensions . 
let ' s start off just in one uh with this feature . 
yeah . 
yeah . 
yeah . 
i think that ' s probably the most basic thing before anything very complicated . 
yeah . 
um and then i think we ' re agreed that pitch related things are are are going to be a a really likely candidate to help . 
yeah . 
i agree yeah . 
uhhuh . 
um but since uh your intuition from looking at some of the data is that when you looked at the regular energy that it did in fact usually go up when two people were talking that ' s uh you know you should be able to come up with a measure which will match your intuition . 
okay . 
yeah . 
yeah . 
yeah yeah yeah . 
and she ' s right that a that having a having having this table with a whole bunch of things with the standard deviation the variance and so forth it ' s it ' s it ' s harder to interpret than just looking at the the same kind of picture you have here . 
but 
uhhuh . 
yeah . 
but it it ' s curious but uh i i found it in the in the mixed file in one channel that uh in several oh uh several times uh you have an speaker talking alone with a high level of energy . 
uhhuh . 
uhhuh . 
uh in the middle uh a zone of overlapping with huh less energy . 
uhhuh . 
and uh come with another speaker with high energy . 
uhhuh . 
and the overlapping zone has uh less energy . 
yeah so there ' ll be some cases for which 
because there reach very many 
right . 
but the so so they ' ll be 
this is i want to point to visual things . 
but i mean they there ' ll be time there ' ll be overlap between the distributions . 
but the question is if it ' s a reasonable feature at all there ' s some separation . 
yeah . 
yeah . 
especially locally . 
uhhuh . 
so locally 
just locally yeah . 
and i was just going to say that that right now we ' re just exploring . 
and the other thing is 
sorry . 
i 
yeah . 
what you would imagine eventually is that you ' ll feed all of these features into some discriminative system . 
yeah . 
yeah . 
and so even if if one of the features does a good job at one type of overlap another feature might do a good job at another type of overlap . 
yeah . 
yeah . 
yeah this is the 
right i mean the the reason i had suggested the scatter features is i used to do this a lot when we had thirteen or fifteen or twenty features to look at . 
um because something is a good feature uh by itself you don ' t really know how it ' ll behave in combination . 
and so it ' s nice to have as many as many together at the same time as possible in uh in some reasonable visual form . 
there ' s cool graphic things people have had sometimes to put together three or four in some funny funny way . 
but it ' s true that you shouldn ' t do any of that unless you know that the individual ones at least have have some uh some hope . 
yeah . 
well especially for normalizing . 
i mean it ' s really important to pick a normalization that matches the distribution for that feature . 
uhhuh . 
uhhuh . 
and it may not be the same for all the types of overlaps or the windows may not be the same . 
actually i was wondering right now you ' re taking a all of the speech from the whole meeting and you ' re trying to find points of overlap . 
but we don ' t really know which speaker is overlapping with which speaker . 
right ? 
right . 
yeah . 
so i mean another way would just be to take the speech from just say morgan and just jane and then just their overlaps . 
like but by hand . 
by cheating . 
and looking at you know if you can detect something that way . 
because if we can ' t do it that way there ' s no good way that we ' re going to be able to do it . 
no prayer . 
that you know there might be something helpful and cleaner about looking at just individuals and then that combination alone . 
yeah . 
plus i think it has more elegant 
uhhuh . 
the the right model will be easier to see that way . 
so if i don ' t know if you go through and you find adam because he has a lot of overlaps and some other speaker who also has enough speech 
yeah . 
and just sort of look at those three cases of adam and the other person and the overlaps . 
yeah . 
maybe 
and just look at the distributions maybe there is a clear pattern . 
yeah . 
uhhuh . 
but we just can ' t see it because there ' s too many combinations of of people that can overlap . 
yeah . 
i had the same intuition last last last week . 
so 
yeah ? 
just seems sort of complex . 
i think it ' s to start with it ' s your your idea of simplifying . 
starting with something that you can see uh you know without the extra layers of 
right . 
because if energy doesn ' t matter there like 
i don ' t think this is true but what if 
to study individual . 
huh ? 
sorry . 
what ? 
to study individual . 
well you you you don ' t have to study everybody individually . 
well to study the simplest case to get rid of extra 
the the the but consider 
but just simple case . 
and the one that has the lot of data associated with it . 
right . 
because what if it ' s the case and i don ' t think this is true 
that was a great overlap by the way . 
what if it ' s the case that when two people overlap they equate their you know there ' s a conservation of energy and everybody 
both people talk more softly ? 
i don ' t think this happens at all . 
or or what if what if the equipment what if the equipment adjusts somehow ? 
or they get louder . 
there ' s some equalizing in there . 
yeah or 
uh no we don ' t have that . 
i mean 
but 
well but but i think that ' s what i was saying about different types of overlap . 
okay . 
saturation . 
there are there are different types . 
and within those types 
like as jose was saying that sounded like a backchannel overlap . 
meaning the kind that ' s a friendly encouragement like uhhuh . 
great . 
yeah . 
yeah . 
and it doesn ' t take you don ' t take the floor . 
um but some of those as you showed i think can be discriminated by the duration of the overlap . 
yeah . 
so 
it actually the new student don who um adam has met and he was at one of our meetings 
he ' s getting his feet wet and then he ' ll be starting again in mid january . 
he ' s interested in trying to distinguish the types of overlap . 
i don ' t know if he ' s talked with you yet . 
yeah . 
but in sort of honing in on these different types . 
i don ' t now i don ' t consider that possibility . 
and so maybe 
this is a a general studio of the overlapping we ' re studying the 
yeah . 
so it might be something that we can help by categorizing some of them and then you know look at that . 
well i i i i would actually still recommend that he do the overall thing . 
because it would be the quickest thing for him to do . 
he could you see he already has all his stuff in place . 
yeah . 
he has the histogram mechanism . 
he has the stuff that subtracts out 
and all he has to do is change it uh uh from from log to plain energy and plot the histogram and look at it . 
and then he should go on and do the other stuff 
yeah . 
but but this will 
yeah no i didn ' t mean that that for you to do that . 
but i was thinking if if don and i are trying to get categories . 
uhhuh . 
and we label some data for you and we say this is what we think is going 
uhhuh . 
so you don ' t have to worry about it . 
and here ' s the three types of overlaps . 
yeah . 
and we ' ll we ' ll do the labelling for you . 
yeah . 
huh huh . 
um 
consider different class of overlap ? 
yeah that we would be working on anyway . 
if there ' s time . 
yeah . 
then maybe you can try some different things for those three cases and see if that helps or 
yeah . 
this is the thing i i comment with you before that uh we have a great variation of situation of overlapping . 
uhhuh . 
and the behavior for energy is uh log energy is not uh the same all the time . 
uhhuh . 
and 
but i guess i was just saying that that right now uh from the means that you gave i don ' t have any sense of whether even you know there are any significant number of cases for which there is distinct 
and i would imagine there should be some you know there should be the distributions should be somewhat separated . 
yeah . 
yeah . 
uh and i i would still guess that if they are not separated at all that there ' s some there ' s there ' s most likely something wrong in the way that we ' re measuring it . 
yeah . 
yeah . 
yeah . 
um but um for instance i mean i wouldn ' t expect that it was very common overall that when two people were talking at the same time that it would that it really was lower . 
yeah . 
although sometimes as you say it would . 
yeah . 
yeah no that was that was a 
so so 
or a sort of a case where where you would never know that unless you actually go and look at two individuals . 
yeah . 
i mean 
no . 
it could it probably does happen sometimes . 
yeah . 
yeah . 
right . 
yeah . 
yeah . 
mind if i turned that light off ? 
so 
the flickering is annoying me . 
okay . 
it might the case though that the significant energy just as jose was saying comes in the non backchannel cases . 
because in most people when they ' re talking don ' t change their own energy when they get a backchannel . 
because they ' re not really predicting the backchannel . 
uhhuh . 
and sometimes it ' s a nod and sometimes it ' s an uhhuh . 
yeah . 
and the uhhuh is really usually very low energy . 
yeah . 
so maybe those don ' t actually have much difference in energy . 
but all the other cases might . 
and the backchannels are sort of easy to spot in terms of their words or 
and and again what they what difference there was would kind of be lost in taking the log . 
i mean just listen to it . 
yeah . 
so 
so 
well it would be lost no matter what you do . 
but 
as well . 
yeah . 
it just 
huh no . 
if it ' s if if it ' s 
tone 
well it won ' t be as big . 
i mean even if you take the log you can your model just has a more sensitive measures . 
yeah . 
sure but tone might be very 
so 
yeah you ' re uhhuh tone is going to be very different . 
yeah . 
right right . 
you could imagine doing specialized ones for different types of back channels if you could if you had a good model for it . 
your uhhuh detector . 
if if you ' re i guess my point is if you ' re doing essentially a linear separation taking the log first does in fact make it harder to separate . 
right . 
yeah . 
so it ' s so uh if you so if there if there close to things it does 
yeah . 
it ' s a nonlinear operation that does in fact change the distinction . 
if you ' re doing a if you ' re doing some fancy thing then then 
yeah . 
and right now we ' re essentially doing this linear thing by looking across here and and saying we ' re going to cut it here . 
um and that that ' s the indicator that we ' re getting . 
but anyway yeah we ' re not disagreeing on any of this . 
we should look at it more uh more finely but uh uh i think that this often happens you do fairly complicated things and then you stand back from them and you realize that you haven ' t done something simple . 
so uh if you generated something like that just for the energy and see and then as as liz says when they have uh uh smaller um more coherent groups to look at that would be another interesting thing later . 
uhhuh . 
uhhuh . 
and then that should give us some indication between those should give us some indication of whether there ' s anything to be achieved from energy at all . 
and then you can move on to the uh uh more pitch related stuff . 
uhhuh . 
i i i think this is a good idea . 
okay . 
not consider the log energy . 
uhhuh . 
yeah . 
but then the 
have you started looking at the pitch related stuff at all ? 
or 
the 
pitch related . 
harmonicity and so on . 
i i ' m preparing the the program but i don ' t i don ' t begin because uh i saw your email . 
preparing to 
yeah . 
and i agree with you it ' s better to i suppose it ' s better to to consider the the energy this kind of parameter 
yeah . 
oh that ' s not what i meant . 
no no . 
i i i i 
well we certainly should see this but i i i i think that the 
i certainly wasn ' t saying this was better than the harmonicity and pitch related things . 
i was just saying 
i i go on with the with the pitch . 
yeah . 
aha okay . 
yeah i was just saying 
i i i i understood uh that uh i i had to finish by the moment with the and and concentrate my my energy in that problem . 
okay . 
okay okay . 
but i think like all these derivatives and second derivatives and all these other very fancy things 
i think i would just sort of look at the energy and then get into the harmonicity as as a suggestion . 
okay . 
i go on with the pitch . 
uh okay . 
so maybe uh since we ' re trying to uh compress the meeting . 
um i know adam had some form stuff he wanted to talk about . 
and did you have some 
i wanted to ask just something on the end of this topic . 
so when i presented my results about the uh distribution of overlaps and the speakers and the profiles of the speakers at the bottom of that i did have a proposal . 
uhhuh . 
and i had plan to go through with it of of coding the types of overlaps that people were involved in just with reference to speaker style so you know with reference . 
oh . 
that ' d be great . 
and you know i said that on my in my summary . 
yeah i 
that you know so it ' s like people may have different amounts of being overlapped with or overlapping . 
right . 
but that in itself is not informative without knowing what types of overlaps they ' re involved in . 
so i was planning to do a taxonomy of types overlaps with reference to that . 
that would be great . 
yeah . 
that would be really great . 
so but it you know it ' s like it sounds like you also have uh something in that direction . 
huh . 
is is it 
we have nothing 
you know basically we got his environment set up . 
he ' s he ' s a double e you know . 
so it ' s mostly that if we had to label it ourselves we we would or we ' d have to to get started . 
but if it it would be much better if you can do it . 
you ' d be much better at doing it also . 
because you know i i ' m not i don ' t have a good feel for how they should be sorted out . 
interesting . 
and i really didn ' t want to go into that if i didn ' t have to . 
so if if you ' re willing to do that or or 
well maybe we can 
it would be interesting though to talk maybe not at the meeting but at some other time about what are the classes . 
okay . 
yeah . 
uhhuh . 
yeah . 
yeah . 
uhhuh . 
i think that ' s a research effort in and of itself . 
yeah it would be interesting . 
because you can read the literature but i don ' t know how it ' ll turn out . 
yeah . 
and you know it ' s always an interesting question . 
i would think it ' s interesting yeah . 
it seems like we also with reference to a purpose too that we we ' d want to have them coded . 
yeah . 
that ' d be great . 
yeah . 
yep . 
that ' d be really great . 
okay . 
and we ' d still have some funding for this project . 
i can do that . 
uh uh 
like probably if we had to hire some like an undergrad because uh don is being covered half time on something else . 
uhhuh . 
i mean he we ' re not paying him the full r a ship for all the time . 
so um if we got it to where we wanted we needed someone to do that 
i don ' t think there ' s really enough data where where 
uhhuh . 
yeah i see this as a prototype to use the only the the already transcribed meeting as just a prototype . 
yeah . 
yeah . 
i i think another parameter we we we can consider is uh the duration . 
but 
uhhuh . 
another besides uh the the class of overlap the duration . 
because is possible uh some um uh some classes uh has uh a type of a duration . 
uh a duration very short uh when we have we have overlapping with speech . 
uhhuh . 
yeah definitely . 
yeah maybe it may be correlated . 
is possible to have 
uhhuh . 
and it ' s interesting i think to consider the the window of normalization . 
normalization window . 
uh because uh if we have a type of a kind of uh overlap uh back channel overlap with a short duration is possible uh to 
that if we normalize uh with uh uh consider only the the uh window uh by the left uh uh side on the right side overlapping with a a very uh oh a small window 
uh the if the fit of normalization is uh huh bigger uh in that overlapping zone uh very short . 
uhhuh . 
yeah that ' s true . 
the window shouldn ' t be larger than the backchannel . 
i i i i understand . 
i mean that you have uh you have a backchannel uh uh you have a overlapping zone very short . 
yeah . 
and you consider uh uh all the channel to normalize this very short uh 
uhhuh . 
uhhuh . 
for example huh uhhuh huh uh . 
and the energy is not uh height . 
uh i think if you consider all the channel to normalize and the channel is huh bigger uh uh uh compared with the with the overlapping uh duration . 
uhhuh . 
uh the effect is huh stronger . 
uh that i i mean the the effect of the normalization uh with the mean and the and the variance uh is different that if you consider only a window compared uh with the the duration of overlapping . 
uhhuh . 
not 
you you want it around the overlapping part . 
you want it to include something that ' s not in overlapping . 
yeah . 
yeah . 
but but uh 
yeah . 
uhhuh . 
i i don ' t know . 
is if 
yeah . 
well it ' s a sliding window . 
right ? 
so if you take the the measure in the center of the overlapped piece you know there ' d better be something . 
uhhuh . 
yeah . 
yeah . 
but if your window is really huge then yeah you ' re right . 
you won ' t even 
yeah this is the this is the the idea to consider only the the small window near near near the the overlapping zone . 
the portion of the of the backchannel won ' t won ' t effect anything . 
but you 
yeah . 
so 
you know you shouldn ' t be more than 
like you should definitely not be three times as big as your as your backchannel . 
yeah . 
then you ' re going to have a wash . 
uhhuh . 
and hopefully it ' s more like on the order of 
i ' m not sure that ' s necessarily true . 
yeah . 
it is an empirical question it seems like . 
because because it because um again if you ' re just compensating for the gain 
yeah . 
yeah . 
you know the fact that this this gain thing was crude . 
and the gain if someone is speaking relatively at consistent level just to to give a an extreme example all you ' re doing is compensating for that . 
and then you still and then if you look at the frame with respect to that it still should should uh change . 
yeah it depends how different your normalization is as you slide your window across . 
i mean that ' s something we don ' t know . 
uhhuh . 
it ' s possible to try it both ways . 
well i mean we ' re also talking about a couple of different things . 
isn ' t it ? 
in this small 
i mean one is your analysis window and then the other is any sort of normalization that you ' re doing . 
yeah i was talking about the normalization window . 
and the and they could be quite different . 
yeah . 
right . 
yeah . 
this was sort of where where we were last week . 
yeah . 
that ' s true yeah . 
yep . 
but anyway we we ' ll have to look at some core things . 
um 
okay . 
okay . 
but that ' d be great if if you ' re marking those 
and um 
great . 
okay . 
yeah . 
but it is definitely true that we need to have the time marks . 
uhhuh . 
and i was assuming that will be inherited because if you have the words and they ' re roughly aligned in time via forced alignment or whatever we end up using then you know this student and i would be looking at the time marks . 
yep i agree . 
uhhuh . 
and classifying all the frames inside those as whatever labels jane gave . 
coming off of the other 
yeah . 
good . 
so it wouldn ' t be i wasn ' t planning to label the time marks . 
i can give you my transcription file . 
i was thinking that that would come from the engineering side . 
i don ' t think you need to . 
no ? 
yeah . 
yeah that should be linked to the words which are linked to time somehow . 
there you go . 
right ? 
well we ' re not any time soon going to get a forced alignment . 
not now . 
so 
yeah . 
um if it ' s not hand marked then we ' re not going to get the times . 
well it ' s something that 
well we we wouldn ' t be able to do any work without a forced alignment anyway . 
yes 
so somehow if once he gets going we ' re going to have to come up with one . 
and 
yes . 
yeah . 
good good . 
i mean i guess we could do a very bad one with broadcast news . 
so whatever you would label would be attached to the words i think . 
great ! 
good good . 
yeah . 
uhhuh . 
well again for the close mike stuff we could come up take a take the switchboard system or something . 
that might be good enough . 
yeah . 
and um 
it ' d be worth a try . 
it would be interesting to see what we get . 
just you know low pass filter the speech and 
because there ' s there ' s a lot of work you can ' t do without that . 
i mean how how would you 
yeah . 
you ' d have to go in and measure every start and stop point next to a word . 
is if you ' re interested in anything to do with words . 
it would be very inefficient . 
yep . 
yeah . 
so 
uhhuh . 
anyway so that ' d be great . 
good okay . 
yeah . 
there ' s something we should talk about later . 
but maybe not just now . 
but uh should talk about our options as far as the uh uh transcription . 
but well but we ' ll do that later . 
yep if i b m doesn ' t . 
okay . 
good . 
do we have to turn 
are we supposed to keep recording here ? 
yeah let ' s do that later . 
yeah . 
yeah right . 
we ' ll talk about it later . 
yeah . 
so uh uh 
forms . 
you had something on forms . 
forms next iteration of forms . 
oops . 
oh ! 
oh good okay . 
um 
oh . 
how so it ' s two pages per person ? 
nope . 
one ' s a digit form . 
one ' s a speaker form . 
oh ! 
so one is a one time only speaker form and the other is the digits . 
oh i see . 
oh it ' s the same . 
oh no no . 
is is new is okay . 
so don ' t fill these out . 
all right . 
this is just the suggestion for uh what the new forms would look like . 
so they incorporate the changes that we talked about . 
date and time . 
uh why did you switch the order of the date and time fields ? 
this is rather a low level but 
on which one ? 
on on the new one time comes first and then date . 
but i thought 
oh you mean on the digit form ? 
this is this is rather a low level question but but it used used to be date came first . 
uh because the user fills out the first three fields and i fill out the rest . 
oh i see . 
so it was intentional . 
well how would the how would the user know the time if they didn ' t know the date ? 
it ' s an interesting observation . 
but it was intentional . 
because the date is when you actually read the digits and the time and 
excuse me . 
the time is when you actually read the digits but i ' m filling out the date beforehand . 
if you look at the form in front of you that you ' re going to fill out when you read the digits you ' ll see i ' ve already filled in the date but not the time . 
yeah . 
i always assumed 
so the time is supposed to be pretty exact . 
because i ' ve just been taking beginning time time of the meeting . 
yeah me too . 
yeah i 
yeah i ' ve noticed that in the forms . 
yeah . 
the the reason i put the time in is so that the person who ' s extracting the digits meaning me will know where to look in the meeting to try to find the digits . 
me too . 
oh . 
oh dear ! 
but i am put i am putting the beginning of the meeting . 
we ' ve been we ' ve been messing up your forms . 
i know . 
so you should call it like digits start time or 
and i haven ' t said anything . 
yep . 
in on there . 
why what what were you putting in ? 
oh well i was saying if we started the meeting at two thirty . 
yeah . 
i ' d put two thirty and i guess everyone was putting two thirty . 
oh . 
yeah . 
and i didn ' t realize there was uh oh i ' m about to read this and i should 
no it ' s about fifty fifty . 
actually it ' s about one third each . 
about one third of them are blank . 
about one third of them are when the digits are read . 
and about one third of them are when the meeting starts . 
oh . 
so 
this would be a radical suggestion but 
i could put instructions ? 
either that or maybe you could maybe write down when people start reading digits on that particular session . 
nah . 
yeah . 
but if i ' m not at the meeting i can ' t do that . 
i know okay . 
yeah he ' s been setting stuff up and going away so 
that ' s a good point . 
i see . 
good point good point . 
for some reason he doesn ' t want to sit through every meeting that ' s 
yep but that is the reason name email and time are where they are . 
oh okay . 
yeah . 
all right . 
i rest my 
and then the others are later on . 
uhhuh . 
okay . 
and the seat is this number ? 
uhhuh . 
seat and session . 
for official use only . 
that ' s well he ' s very professional . 
use only 
actually you could 
well that does raise another question which is why is the professional use only line not higher ? 
why doesn ' t it come in at the point of date and seat ? 
oh because we ' re filling in other things . 
what ? 
what ? 
well because if your your professional use 
you ' re going to already have the date and the 
what which form are you talking about ? 
well i ' m comparing the new one with the old one . 
this is the digit form . 
oh . 
oh you ' re talking about the digit form . 
yeah . 
digit digit form . 
oh i wasn ' t supposed to 
the digit form doesn ' t the digit 
yeah . 
sorry sorry . 
no that ' s all right . 
the digit form doesn ' t have a for official use only line . 
it just has a line which is what you ' re supposed to read . 
that 
uh okay . 
sorry about that . 
so on the digits form everything above the line is a fill in form . 
yeah . 
yeah . 
and everything below the line is digits that the user reads . 
okay . 
all right but i didn ' t mean to derail our discussion here . 
so you really wanted to start with this other form . 
no either way is fine . 
i just you just started talking about something and i didn ' t know which form you were referring to . 
all right yeah i was comparing 
so this is so i was looking at the change first . 
so it ' s like we started with this and now we ' ve got a new version of it with reference to this . 
so the digit form . 
we had one already . 
now the the fields are slightly different . 
so the main thing that the person fills out um is the name and email and time ? 
yeah . 
right . 
uh 
you do the rest ? 
yep . 
just as uh as i have for all the others . 
right . 
what and there ' s an addition of the native language which is a bit redundant . 
this one has native language and this one does too . 
that ' s because the one the digit form that has native language is the old form . 
oh thank you thank you thank you . 
not the new form . 
yeah . 
there we go . 
oh yeah . 
i ' ll catch up here . 
okay i see . 
south midland north midland 
that ' s the old and that ' s the new . 
yeah this was the problem with these categories . 
i i picked those categories from timit . 
i don ' t know what those are . 
actually the only way i know is from working with the data base and having to figure it out . 
what 
with timit . 
uhhuh . 
yeah ? 
so is south midland like kansas ? 
what 
so i was going to ask 
i mean 
and north midland like like uh illinois or 
well yeah . 
yeah . 
um 
so so what accent are we speaking ? 
western ? 
by definition ? 
and for simple for for me ? 
is mean my native language spanish spanish ? 
well 
probably western yeah . 
uh the original is the center of spain and the 
yeah i mean you could call it whatever you want . 
for the foreign language we couldn ' t classify every single one . 
so i just left it blank and you can put whatever you want . 
because is different the uh the spanish language from the the north of spain of the south of the west and the 
sure . 
but 
so i ' m not sure what to do about the region field for english variety . 
yeah . 
you know when i wrote i was writing those down i was thinking you know these are great if you ' re a linguist . 
yeah . 
actually even if you 
but i don ' t know how to i don ' t know how to i don ' t know how to categorize them . 
yeah . 
if you ' re if if 
this wasn ' t developed by these regions weren ' t 
if you ' re a t i or m i t from nineteen eighty five 
yeah . 
yeah . 
so i guess my only question was if if you were a south midland speaking region person would you know it ? 
uhhuh . 
is that what you would call yourself ? 
i don ' t know . 
yeah . 
you know i think if you ' re talking if you ' re thinking in terms of places as opposed to names different names people have given to different ways of talking i would think north midwest and south midwest would be more common than saying midland . 
right ? 
i mean i i went to 
yeah now the usage 
maybe we can give them a like a little map . 
with the regions and they just 
no i ' m serious . 
no that ' s not bad . 
because it takes less time and it ' s sort of cute . 
at this in that side in that side of the the paper . 
yeah . 
there ' s no figure . 
well 
well just a little 
you know it doesn ' t have all the detail . 
but you sort of 
but what if you moved five times and and uh 
well i was thinking you could have multiple ones and then the amount of time 
no but you ' re categorized . 
that ' s the same 
so roughly 
so you could say you know ten years on the east coast five years on the west coast or something or other . 
well we i think we don ' t want to get that level of detail at this form . 
i think that ' s all right if we want to follow up . 
but 
i guess we don ' t really know . 
i mean i as i said i don ' t think there ' s a huge benefit to this region thing . 
it it gets 
the problem is that for some things it ' s really clear and usually listening to it you can tell right away if it ' s a new york or boston accent . 
but new york and boston are two 
well i guess they have the n y c . 
but new england has a bunch of very different dialects . 
and 
uhhuh . 
and so does um so do other places . 
yeah so i picked these regions because we had talked about timit . 
right . 
and those are right from timit . 
and so these would be satisfying like a speech research community if we released the database . 
so 
but as to whether subjects know where they ' re from i ' m not sure because um i know that they had to fill this out for switchboard . 
this is almost exactly the same as switchboard regions . 
oh okay . 
or very close . 
yeah . 
um and i don ' t know how they filled that out . 
but if midland 
yeah midland is the one that ' s difficult i guess . 
i think a lot of people 
also northwest you ' ve got washington and oregon now which uh people don ' t know if it ' s western or northern . 
yeah . 
yeah i certainly don ' t . 
i mean i was saying i don ' t even know what i speak . 
it ' s like northwest 
oh what is northern ? 
am i speaking am i speaking western ? 
well and what and what ' s northern ? 
i think originally it was north northwest . 
northwest . 
yeah . 
but 
yeah so this is a real problem . 
yeah . 
i don ' t know what to do about it . 
i wouldn ' t know how to characterize mine either . 
and and so i would think i would say i ' ve i ' ve got a mix of california and ohio . 
i 
i think at the first level for example we speak the same . 
i don ' t know . 
our our dialects or whatever you region are the same . 
uhhuh . 
but i don ' t know what it is . 
so 
well you have a like techno speak accent i think . 
a techno speak accent ? 
yeah you know 
a 
a a geek region ? 
well it ' s i mean i you can sort of identify 
geek region . 
it it ' s it ' s not not that that ' s 
is different is different . 
but but maybe that maybe we could leave this . 
and see what people see what people choose . 
and then um let them just fill in if they don ' t 
i mean i don ' t know what else we can do because that ' s north midland . 
i ' m wondering about a question like where are you from mostly . 
yeah . 
but i i ' m i ' m now that you mentioned it though i am really am confused by northern . 
yeah . 
i agree i agree . 
i really am . 
yeah . 
i mean if if you ' re in new england that ' s north . 
i agree . 
if you ' re if you ' re 
scandinavian the minnesota area ' s north . 
uh yeah that ' s 
but that ' s also north midland . 
yeah . 
right ? 
oh . 
and and and oregon and and oregon and washington are are western but they ' re also northern . 
yeah . 
okay . 
of course that ' s very different from like michigan or 
huh . 
uhhuh . 
uh idaho ? 
well there are hardly any subjects from idaho . 
montana ? 
no problem . 
just rule them out . 
there ' s only a few people in idaho . 
there are hardly any subjects from beep ! 
yeah . 
sorry . 
no that ' s 
maybe maybe we maybe we should put a little map and say put an x on where you ' re from . 
and is in those 
yeah really . 
and if you put 
we could ask where they ' re from . 
it ' d be pretty simple yeah . 
yeah . 
we went back to that . 
yeah . 
if you put uh the state 
well well we sort of 
where are you from mostly . 
we we went we went around this and then a lot of people ended up saying that it 
uhhuh uhhuh . 
you know . 
well i like the idea of asking what variety of english do you speak as opposed to where you ' re from . 
because if we start asking where we ' re from again you have to start saying well is that the language you speak or is that just where you ' re from . 
yeah . 
huh . 
right right . 
yeah . 
let ' s 
i mean it gives us good information on where they ' re from but that doesn ' t tell us anything 
uhhuh . 
and 
we could always ask them if they ' re from 
well enough about their 
i mean so so i would say germany . 
like 
you know am i speaking with german accent ? 
oh . 
i don ' t think so . 
right . 
well see i ' m thinking where are you from mostly . 
oh okay yeah . 
because you know then you have some some kind of subjective amount of time factored into it . 
yeah . 
yeah . 
yep . 
yeah . 
yeah i guess i could try to put squeeze in a little map . 
i mean there ' s not a lot of of room . 
i ' d say uh boston new york city the south and regular . 
well 
i think of those northern is the only one that i don ' t even know what they ' re meaning . 
oh i don ' t know . 
and and um and usually here people here know what is their kind of huh english language . 
yeah yeah . 
that ' s a joke . 
that ' s 
so let ' s make it up . 
i mean who cares ? 
right ? 
we can make up our own . 
so we can say northwest rest of west or something . 
you know . 
west 
and i mean 
i don ' t think the northwest people speak any differently than i do . 
it doesn ' t even 
yeah exactly . 
that ' s not really a region . 
do you come from the louisiana purchase ? 
i 
so we could take out north northern . 
you sure that people here know what is the the kind of english language uh he 
uh is easy for people to know ? 
that that ' s exactly what we ' re arguing about . 
that ' s 
yeah it ' s in it ' s it ' s harder in america anywhere else basically . 
we don ' t know . 
because you have 
i mean some of them are very obvious . 
if you if you talk to someone speaking with southern drawl you know . 
yeah . 
yeah or boston . 
or boston yeah . 
i can ' t do it but 
or boston ? 
and those people if you ask them to self identify their accent they know . 
yeah . 
yeah . 
yeah they do . 
they know very well . 
yeah i agree i agree i agree . 
they know they don ' t speak the same as the 
but is boston new england ? 
and they ' re proud of it . 
day 
yeah . 
yeah exactly . 
it ' s identity thing . 
and they ' re glad to tell you . 
style . 
well depends who you ask i suppose . 
i guess that ' s the problem with these categories . 
but that ' s why they have new york city but 
well we well why can ' t we just say characterize something like characterize your accent ? 
well boston ' s too . 
or 
characterize your accent if you can . 
and and so i would say i don ' t know . 
yeah . 
right which probably means you have a very 
but someone from boston with a really strong coloration would know . 
and so would an r less maine or something . 
and that ' s actually good . 
yeah . 
i was i was thinking of something along that line . 
yeah . 
how 
because if you don ' t know then you know ruling out the fact that you ' re totally inept or something 
good . 
huh . 
if somebody doesn ' t know it probably means their accent isn ' t very strong compared to the sort of midwest standard . 
well i mean it wasn ' t that long ago that we had somebody here who was from texas who was absolutely sure that he didn ' t have any accent left . 
huh . 
and and had he had a pretty noticeable drawl . 
okay so i propose take out northern add don ' t know . 
oh yeah i i would say more more sweepingly how would you characterize your accent . 
yeah . 
so you want to change the instructions also not just say region ? 
well i think this discussion has made me think that ' s something to consider . 
i don ' t know . 
if i if i read this form i think they ' re going to ask it they ' re going to answer the same way if you say what ' s variety of english do you speak . 
region . 
as if you say what variety of region region do you speak . 
please characterize your accent . 
they ' re going to answer the same way . 
i guess 
well i was not sure that 
huh . 
i 
so i was suggesting not having the options . 
just having them 
oh i see . 
huh . 
well what we talked about with that is is so that they would understand the granularity . 
yes but if as liz is suggesting people who have strong accents know that they do . 
i mean that ' s what i had before and you told me to list the regions to list them . 
and are 
each each one has pros and cons . 
well i know . 
right . 
right . 
so 
i mean we we 
right . 
that ' s true . 
yeah last week last week i was sort of arguing for having it wide open . 
but then everybody said oh no . 
but then it will be hard to interpret . 
because some people will say cincinnati and some will say ohio . 
i mean i had it wide open last week and and you said timit . 
and 
what if we put in both ? 
yeah . 
yeah . 
and would people 
that ' s what the other is for . 
no i mean what if we put in both ways of asking them ? 
so one is region . 
and the another one is if you had to characterize yourself your accent what would you say . 
won ' t they answer the same thing ? 
well they might only answer only one of the questions . 
but if 
yeah that ' s fine . 
you know . 
they might say other for region because they don ' t know what category to use . 
actually 
but they might have something 
right . 
it just and we 
because it is easier to have it open ended . 
we might learn from what they say as to which one ' s a better way to ask it . 
but i because i really don ' t know . 
this is just a small thing . 
but um it says variety and then it gives things that have american as one of the choices . 
but then it says region . 
but region actually just applies to uh u s . 
right ? 
right . 
i mean that ' s why i put the other in . 
well we thought about it . 
uh okay . 
yeah okay . 
we just we sort of thought yes i mean 
at the last meeting my recollection was that we felt people would have uh less 
that that there are so many types and varieties of these other languages . 
and we are not going to have that many subjects from these different language groups . 
and that it ' s a huge waste of of space . 
yep . 
okay . 
so i mean i i mean the way i had it last time was region was blank . 
that ' s what i thought . 
it just said region colon . 
yeah . 
yeah . 
and and i think that that ' s the best way to do it . 
because because of the problems we ' re talking about . 
but what we said last week was no put in a list . 
so i put in a list . 
maybe we can make the list a little smaller . 
so should we go back to 
well certainly dropping northern i think is right because none of us know what that is . 
because i mean 
and keeping other . 
and then maybe this north midland we call it north midwest . 
south midwest or just 
yes i i i think so yeah . 
south midwest . 
does that make sense ? 
south midwest ? 
that would help me 
yeah . 
because 
unless you ' re from midland kansas . 
midland 
but 
yeah . 
i don ' t know where midland is . 
there ' s a or midland midland 
is it midland midland midland texas or midland kansas ? 
is midwest one word ? 
yeah one 
i forget . 
but there ' s a town . 
oh . 
in in there . 
i forget what it is . 
i don ' t think that ' s what they mean . 
but 
yeah so kansas would be south midland . 
yeah . 
right ? 
yeah . 
and and wouldn ' t 
yeah . 
so i ' m from kansas actually . 
and colorado right across the border would be north midland . 
southern midland . 
yeah . 
and uh 
oh right . 
and then the the dropping north 
so it would be western . 
it ' s just one big shebang where of course you have huge variation in dialects . 
but you do in the others too so 
but that ' s true of new england too . 
but but so do you 
yeah . 
so i mean only one 
yeah . 
yeah yeah . 
well i shouldn ' t say that . 
i have no clue . 
i was going to say the only one that doesn ' t have a huge variety is new york city . 
but i have no idea whether it does or not . 
it does seem 
i mean i i would think that these categories would be more would be easier for an analyst to put in rather than the subject himself . 
i think that that was what happened with timit was that it was an analyst . 
okay . 
wait a minute . 
where does where does where where ' s where does uh new new york west of west of uh new york city and pennsylvania uh and uh 
yeah i don ' t know how it came from . 
okay . 
so that ' s new england i think . 
new england . 
no it ' s not ! 
yeah . 
oh no ! 
oh no . 
i sort of thought they were part of the one of the midlands . 
no no no . 
pennsylvania is not 
other . 
it goes under other . 
definitely under other . 
well you know pennsylvania has a pretty strong dialect and it ' s totally different than 
pennsylvania 
yeah pennsylvania is not new england . 
and uh new jersey is not new england and maryland is not new england and none of those are the south . 
okay so 
another suggestion . 
yeah . 
rather than have circle fill in forms say region open paren e g southern comma western comma close paren colon . 
okay . 
okay . 
that ' s good . 
yeah . 
fine by me fine by me . 
sure . 
i like that . 
yeah . 
let ' s just 
yeah . 
and we ' ll see what we get . 
we ' re all sufficiently tired of this that we ' re agreeing with you . 
be easier on the subjects . 
i think that ' s fine . 
so 
no . 
i think 
i like that i like that . 
you like it ? 
okay . 
yeah i do . 
good . 
actually maybe we do one non english one as well . 
southern cockney ? 
yeah and 
yeah . 
is that a real accent ? 
sure yeah . 
yeah . 
how do you spell it ? 
i think that ' s fine . 
cockney ? 
c o 
n e y ? 
yeah . 
you could say liverpool . 
liverpuddlian . 
yeah . 
actually liverpool doesn ' t 
all right . 
yeah . 
it ' s i ' m i 
well well i mean pure 
okay we ' ll do it that way . 
actually i like that a lot . 
okay . 
because that get ' s at both of the things we were trying to do . 
the granularity and the person can just self assess and we don ' t have to argue about what these regions are . 
that ' s right . 
yeah . 
okay . 
and it ' s easy on the subjects . 
yep . 
now i have one suggestion on the next section . 
uhhuh . 
uhhuh . 
so you have native language . 
you have region . 
and then you have time spent in english speaking country . 
now i wonder if it might be useful to have another open field saying which one parenthesis s closed parenthesis . 
because if they spent time in in britain and america 
yes . 
it doesn ' t have to be all at all exact just in the same open field format that you have . 
yep just which one . 
i think that ' s fine . 
uhhuh . 
uhhuh . 
with a with an s . 
which one . 
sss optional s . 
okay . 
huh . 
yeah . 
we uh we done ? 
yep . 
yeah that ' s good . 
okay . 
um any any other uh open mike topics or should we go right to the digits ? 
um did you guys get my email on the multitrans ? 
that 
okay . 
isn ' t that wonderful ? 
yeah . 
excellent ! 
yeah so so i i have a version also which actually displays all the channels . 
thank you . 
it ' s really great . 
but it ' s hideously slow . 
so you this is dan ' s patches dan ellis ' s patches . 
the what the ones i applied that you can actually do are dan ' s because it doesn ' t slow it down . 
fantastic ! 
just uses a lot of memory . 
so when you say slow does that mean to 
no the the one that ' s installed is fine . 
it ' s not slow at all . 
i wrote another version which instead of having the one pane with the one view it has multiple panes with the views . 
yeah . 
uhhuh . 
but the problem with it is the drawing of those waveforms is so slow that every time you do anything it just crawls . 
uhhuh . 
it ' s really bad . 
it ' s so it it ' s the redrawing of the 
that ' s a consideration . 
uhhuh . 
oh uhhuh . 
as you move . 
as you play as you move as you scroll . 
just about anything and it it was so slow it was not usable . 
and this ' ll be a having the multiwave will be a big help . 
so that ' s why i didn ' t install it and didn ' t pursue it . 
because in terms of like disentangling overlaps and things that ' ll be a big help . 
oh yeah . 
so i think that the one dan has is usable enough . 
yeah . 
it doesn ' t display the others . 
it displays just the mixed signal . 
uhhuh . 
but you can listen to any of them . 
that ' s excellent . 
yeah . 
he also has version control which is another nice 
so you the patches that you 
no he suggested that but he didn ' t it ' s not installed . 
oh i thought it was in one of those patches . 
no no . 
oh okay . 
well all right . 
so is there any hope for actually displaying the wave form ? 
um not if we ' re going to use tcl t . k . at least not if we ' re going to use snack . 
okay . 
i mean you would have to do something ourselves . 
well or use the one that crawls . 
okay . 
well i ' m i probably would be trying to use the whatever ' s there . 
and it ' s useful to have the 
why don ' t we we see how dan ' s works and if it if we really need the display 
yeah . 
i mean i wonder i ' m just wondering if we can display things other than the wave form . 
so suppose we have a feature a feature stream . 
and it ' s just you know a a uni dimensional feature varying in time . 
yeah . 
and we want to plot that instead of the whole wave form . 
i mean 
yeah . 
that might be faster . 
right ? 
yeah . 
so 
we we could do that but that would mean changing the code . 
i mean this isn ' t a program we wrote . 
yeah . 
this is a program that we got from someone else and we ' ve done patches on . 
okay . 
okay well i ' ll talk to you about it and we can see . 
uhhuh . 
yeah . 
i mean 
so 
yeah . 
but it ' s definitely great to have the other one . 
that ' s 
if there was some is there some way to have someone write patches in something faster and and link it in or something . 
or is that 
not easily . 
i mean yes we could do that . 
you could you can write widgets in c . 
yeah . 
and try to do it that way but i just don ' t think it 
let ' s try it with dan ' s and if that isn ' t enough we can do it otherwise . 
right . 
i think it is because when i was playing with it the mixed signal has it all in there . 
and so it ' s really it ' s not too bad to find places in the in the stream where things are happening . 
okay . 
and it ' s also also the case that that uh this multi wave thing is proposed to the 
huh . 
so i i don ' t think it ' ll be bad . 
so dan proposed it to the transcriber central people . 
and it ' s likely that uh 
so and and they responded favorably . 
looks as though it will be incorporated in the future version . 
oh . 
they said that the only reason they hadn ' t had the multi the parallel uh stream one before was simply that they hadn ' t had time to do it . 
and uh so it ' s likely that this this may be entered into the this central . 
yeah . 
they may well have not had much demand for it . 
and if if 
well that ' s that ' s that ' s true too . 
yeah . 
this is a a useful thing for us . 
so you mean they could they could do it and it would be fast enough if they do it ? 
yeah . 
oh no i just mean i just mean that it ' s that that his 
depends on how much work they did . 
or 
oh . 
so this one that we now have does have the status of potentially being incorporated likely being incorporated into the central code . 
uhhuh . 
okay . 
now now if we develop further then uh i don ' t 
i mean it ' s i think it ' s a nice feature to have it set that way . 
i think if if if one of us sat down and coded it so that it could be displayed fast enough i ' m sure they would be quite willing to incorporate it . 
uhhuh . 
but it ' s not a trivial task . 
okay . 
uhhuh yeah . 
i just like the idea of it being something that ' s you know tied back into the original so that other people can benefit from it . 
yeah . 
yeah . 
however i also understand that you can have widgets that are very useful for their purpose and that you don ' t need to always go that route . 
yeah . 
okay . 
anyway shall we do digits ? 
yeah . 
yeah let ' s do digits . 
uh and then we ' ll turn off the mikes and then i have one other thing to discuss . 
okay . 
i actually have to leave . 
okay . 
so um i mean i had to leave at three thirty . 
so i can well i can wait for the digits but i can ' t stay for the discussion . 
uh oh ! 
oh . 
okay . 
well you want to go first or 
i i have to make a call . 
so 
okay . 
well we ' ll talk to you about it uh 
well should we should we switch off the 
um 
do you want to go do digits or do you want to just skip digits ? 
no i can do digits if if but i don ' t want to butt in or something . 
then all right you go ahead . 
but if there ' s something on the rest of the 
i ' m i ' ll be around just have to make call before quarter of . 
so 
uhhuh . 
so i 
or we can talk about it . 
why don ' t you read the digits ? 
okay all right . 
yeah why don ' t you read the digits and then you can go . 
oh this is the new one . 
yeah . 
yeah don ' t don ' t read the old one . 
all right . 
the and the time is 
okay . 
if you ' re popular . 
we ' re on . 
so i think we pre crashed . 
so i think we ' re okay . 
pre crashed . 
so it should be a really short meeting i hope . 
uh agenda items number one i want to talk since we were just discussing that is microphone issues . 
what the heck are we going to do about microphones ? 
so uh i got passed on that the e d u group doesn ' t like the uh crown mikes . 
oh . 
who does ? 
i do . 
i do . 
i i think i find them very comfortable . 
yeah i do too . 
uh but it seems to depend on your head shape . 
so you guys need to start going to the e d u meetings . 
i see . 
they don ' t work for me very well . 
that ' s right . 
yeah right . 
i much prefer these . 
yep . 
yeah . 
um 
me too . 
so do i . 
i prefer these . 
but i don ' t mind using those . 
right . 
those are intimidating . 
so apparently they they like 
it has one good effect that people are trying to get there early . 
because the people who get there early get to pick the mike . 
interesting . 
okay . 
people who show up late have to use these . 
so um we should probably get different mikes . 
so the question is the easiest thing to do is certainly to just get two more um sony mikes . 
just two more of those . 
um and that that ' s easy . 
and that will certainly work . 
the other option is to try yet another mike . 
find one we like and potentially get six all the same . 
i have a question about this . 
are the auditory quality is it uh much different between this kind and the the fancy ones ? 
um these are better if they ' re worn correctly . 
they are ? 
those are better than the sonys ? 
okay . 
have you have you listened to to them ? 
yeah yeah definitely . 
yeah . 
yeah ? 
yeah . 
okay . 
so i mean they ' re not a lot better . 
but they are a little better . 
are they more directional ? 
the microphones as far as 
um they ' re more directional . 
a little better error uh noise cancellation . 
and also you can really get it right in front of your mouth like this . 
okay . 
whereas that one to avoid breath noise you really have to put it at to the side . 
so you seem to get better signal with this one . 
the other thing is is it just a few people who don ' t like them in the e d u group ? 
because 
i don ' t know . 
but you know in in sort of random polling 
liz liz said something that leaves me believing that nobody likes them . 
they are 
gosh ! 
because i much prefer them . 
i think they ' re a whole lot multiple levels better . 
it seems a shame to discard discard them if if they ' re better auditory quality and there ' re only a few people who who object . 
i mean so 
right . 
yeah that ' s why i was saying if we could just unplug them and plug them in . 
well i mean that ' s the other option is that we could switch the form so it ' s more obvious the distinction between channel and mike . 
you know pretty 
um and then get duplicates . 
huh . 
i mean there ' s no problem with that . 
it ' s just what should we get just more sony ones ? 
i hate the sony ones . 
which ones are those ? 
the one you ' re wearing . 
the one i ' m wearing ? 
those . 
because it it pinches pinches the temples too much . 
oh . 
oh . 
i mean so if you wear it sort of around the back it ' s not too bad . 
and 
yeah . 
yeah . 
i hate it . 
but i 
because it ' s hard to adjust the microphone . 
right . 
i mean i spend all this time fumbling around with it . 
and still not reasonable . 
yeah . 
right . 
so i mean we could try another mike . 
but then we have the wiring issue . 
and so i i don ' t know what to do what do . 
what do people think ? 
but the problem is again the the plug or 
the plug is proprietary . 
so that ' s why i was saying getting more sony ones is trivial . 
okay okay . 
because we can just go out and buy them . 
okay . 
yeah . 
any other ones we have to buy them in pigtail versions and get them wired . 
okay now maybe i just don ' t know this . 
but um are the only two possibilities from sony the two that we ' ve tried ? 
or is there another 
yes . 
so the only possibilities from sony are that one and the lapel mike . 
i see okay . 
okay . 
oh i see . 
so this isn ' t sony . 
this is crown . 
the one we ' re wearing . 
isn ' t that something ? 
okay . 
and so we had these wired for us . 
oh i see okay . 
well it it seems like right now if if what they ' re complaining are those 
and so 
huh i remember that now . 
if we just got two more of these 
i think that ' s probably the right first step is just get two more immediately and have them available . 
yeah . 
okay . 
and then they can just unplug those from the transmitter . 
right and just make sure that you write down crown or sony on the mike number . 
which i ' ll change to mike type or something like that . 
uhhuh . 
uhhuh . 
yeah . 
it might be good to double check at the end of the meeting too . 
because that would be an easy place for uh an error in the data . 
yep . 
for it to be forgotten . 
well it ' ll be me 
it ' ll be whoever ' s setting up the meeting . 
who fills out the key file . 
so 
okay it ' s just i ' m just thinking that if 
it has the same potential for error as everything else . 
it ' d be 
yeah but i know but i mean to have the user fill it out wouldn ' t be as reliable as have the 
no no we definitely would not have the user fill it out . 
good okay . 
it would be me chuck or liz depending on which meeting it is . 
perfect . 
perfect okay . 
okay so we ' ll definitely go ahead and do that . 
how much is it just to buy the mike ? 
couple hundred . 
really ? 
yeah . 
is that more or less than you thought ? 
it depends on how good the mike is . 
oh that ' s way more than i thought . 
i 
yeah . 
oh okay . 
for one of these ? 
yeah . 
well the crown ones were like two fifty . 
i think those are like one ninety . 
god ! 
oops ! 
wow ! 
but 
is there any educational discount ? 
yeah right . 
no . 
student discount . 
yeah good mikes are expensive . 
and when i was at computer motion we used shure . 
so 
the s . m . ten a . ' s . 
uhhuh . 
and i think they were only like eighty bucks or something . 
yeah eighty or ninety for the shures . 
yeah . 
so 
but they were they seemed pretty good . 
i mean the sony ones are expensive . 
because they ' re proprietary . 
so they can charge whatever they want . 
oh . 
these are expensive . 
because they ' re quite high quality . 
right right . 
so 
so we should buzz that out if we send the data to sony . 
uh come on . 
we should keep a list of things we ' re going to bleep out and the conditions under which 
well i ' m just joking . 
so you do not have to bleep that out . 
i don ' t mind if sony knows my opinion . 
so 
huh . 
um . 
also we ' re i want to double check with morgan . 
he did say yes before i went to japan on buying another wireless system . 
so that we can go all wireless instead of the mix of wired and wireless . 
and i think that ' s the right thing to do . 
so then all those red channels there would become wireless ones ? 
and i ' m 
yeah . 
yep . 
cool . 
yep . 
uhhuh . 
four more wireless . 
um 
and also i ' m going to probably replace the andrea mike with a shure . 
but i ' ll test it uh sometime today or tomorrow to make sure the shure one really works . 
because i have an extra shure in my office . 
the andrea mike ? 
yeah . 
yeah apparently it ' s had some problems . 
that ' s causing problems . 
yeah . 
which one is the andrea mike ? 
it was over here sometimes . 
a wired one ? 
the yeah a wired one . 
yeah it ' s uh 
well if you ' re going to go to all wireless 
oh you mean in the meantime . 
this one . 
in the meantime right . 
uh i see . 
because uh it ' ll it ' ll probably take a couple weeks to get it delivered from sony anyway . 
yeah . 
yeah . 
i haven ' t in the meetings that i recorded it ' s always been at most six people . 
so 
so i ' ve never had to 
oh really ? 
yeah . 
recently i haven ' t had to used any of the wired ones at all . 
i guess because everyone ' s been out of town . 
probably over the summer it ' ll be the same . 
yeah . 
because it tends to be less fewer people . 
um 
file 
uh done with microphone issues i think ? 
should we close the door ? 
if you want . 
oh i ' m thinking i don ' t know about the acoustics . 
that ' s that ' s all i was wondering about . 
and this way we can get a door slam in the uh in the transcript file . 
yeah . 
yeah that ' s right we got to get the obligatory door slam . 
oh well . 
not quite a slam . 
there ' s some knocks . 
get a special phone for that . 
uhhuh . 
uh the door slam phone ? 
i guess 
right the door slam phone . 
yeah . 
you have a special phone ? 
no we could add one . 
oh we could add one yeah . 
and then we could have the phone phone . 
yeah . 
for for when the phone rings . 
that ' s an idea . 
um 
uh file reorganization . 
this is something we were talking about before i left . 
and saying we should probably wait until after i ' m back . 
and now i ' m back . 
so we should do that at some point . 
so we should get ourselves a list of everything we want to do to reorganize the file structure and anything else . 
can i can i just mention something ? 
sure . 
um uh i think the file regards reorganization also um another issue there is disk space probably . 
right ? 
uhhuh . 
um so 
i know that the files that you ' ve been cutting up for us for the recognition experiments 
uhhuh . 
uh one way one really brain uh brain dead way of of of not causing any trouble but saving disk space is to uh use the the sphere the nist uh w encode program to to encode you know to compress them . 
shorten ? 
is that the same as shorten ? 
uh yeah but it does it it happens so that the program that reads the waveforms does the unshortening transparently . 
yeah . 
well okay you mean it ' s built into the s r i . 
because we have the same thing with shorten in the sound tools . 
so 
uh i guess . 
but it 
um 
so it ' s just a question of of what decompression is built into your tools . 
well it ' s it ' s actually built into the sphere library that nist delivers . 
well like 
oh really ? 
so 
i didn ' t know that . 
right . 
and actually the sound tools don ' t understand that for the 
at least feacalc doesn ' t . 
at least feacalc doesn ' t . 
so 
well that ' s not a sound tool . 
right ? 
but since since these files are made to be used with the s r i recognizer 
uh and the s r i front end uses the sphere library which in turn does this transparently um uh that will be a quick and quick and easy way to just uh get you know uh be able to use more 
yeah . 
uhhuh . 
the other thing i could do to relieve some of the pressure um is just move everything to my eighteen gig disk which is local . 
but that ' s going to be only temporary . 
well i mean i don ' t know 
i mean you should do that too probably . 
but but as you do that you can also just run the 
yeah it is kind of a temporary solution . 
to shorten everything ? 
well actually the what you do is you run 
oh now i have another use for the 
the way i recently used it 
and there might be better ways . 
so the program ' s called w encode . 
huh . 
and i think the type you say um i think dash t . 
and then there are different different encoding methods . 
but if you want to use the shorten one you say minus t shorten . 
and then the old uh wavefile and the new wavefile . 
and then 
oops ! 
and then i check you know if this works 
so you can use the the shell and operator or something . 
then i just move the new wavefile to the you know to the old wavefile . 
right . 
and then you have replaced the old one with one that behaves identically as long as your programs that use it know how to decode it on the fly . 
uhhuh . 
and that that just saved my butt . 
okay . 
because i actually was running on a different experiment . 
i had segmented i was processing the whole switchboard two corpus . 
which is two hundred eighty hours of speech . 
and i was noticing as i was almost finishing the processing that i was running out of disk space . 
and and so 
uhhuh . 
i uh had this flash of inspiration of just 
uh the same the same disk had the segmented waveforms on them . 
shortening everything on the fly . 
so i while this other thing was still going on i was i was running this this thing . 
you had another process running that was shortening it . 
wow wow . 
yep . 
and low and behold i gained three three gig of space . 
and um you know 
wow . 
did you have to re nice one of the processes to make sure that shorten ? 
no no actually it was fast enough . 
this is very fast this this really runs quickly . 
wow . 
and that ' s 
that must have been suspenseful . 
that was very suspenseful . 
watching the disk meter . 
that was that was the most excitement i had all weekend . 
uh uh boy ! 
it uh came out just fine . 
to be okay . 
so 
you know what would be a 
i don ' t know if this would mess other things up . 
but it seems like kind of a pain to have all these split up files around . 
what would be easier would be like pointers . 
the list . 
yep . 
you know lists like original wavefile start end . 
start end . 
yep the way feacalc calc does it . 
this is 
right the the only reason we do this is because the the s r i front end doesn ' t have a way to to um go into a a longer file with indices . 
um so i i suppose someone could try to put a hack like that into the 
and segment on the fly . 
it would be easy . 
it wouldn ' t be hard at all . 
someone just needs to sit down and do it who has some time . 
so 
but there ' s also some 
i guess 
and that way we wouldn ' t have multiple versions floating around . 
about the only difficulty with that is if it ' s compressed then you really do have to decompress it first . 
that ' s true . 
right ? 
because the pointers are 
you don ' t know how much it ' s 
it doesn ' t compress it by a fixed amount . 
exactly right right right right right . 
well is there is there is there a nist routine which can seek in a compressed file but with uncompressed indices ? 
i don ' t think so . 
and yeah i mean that it 
no no i mean if you 
the the the 
if you can operate on the full 
if you don ' t have to segment it then there would be less of a reason to do the compression . 
because you don ' t have that wasted that extra copy . 
right right we i mean the original switchboard files are not compressed . 
so 
yeah . 
right ? 
right . 
so we could leave those as they are . 
well i mean it just depends on how much disk space is a problem . 
right . 
i mean the what you could do is decompress it to a temporary place . 
and then operate on it and then delete it . 
but 
i mean the segmentation also saves you space in the sense that you cut out all the nonspeech regions . 
just silences . 
yeah . 
and if you have you know twenty channels and only five speakers then it ' s 
that ' s true . 
uhhuh . 
well assuming you ' d yeah assuming that you then off load the original switchboard files . 
yeah . 
so 
huh 
yeah . 
well it seems like just shortening them is a good short term solution . 
yeah yeah . 
so we don ' t have to do any coding . 
yeah . 
but i think kind of we ' ve had there was a big disk crash when you were gone . 
so 
and 
no it was i was still here . 
it was the day i left . 
oh was that the day you left ? 
that ' s suspicious . 
he did it on purpose . 
yeah . 
leave to japan the day the disk crashes . 
no if i if i had done it on purpose i would have timed it right after i left . 
but um 
yeah so chuck helped me out in uh regenerating all the the different channel files for like a few meetings . 
uhhuh . 
for like six meetings . 
so i think they ' re split up even further . 
it ' s kind of even more disorganized now . 
since we moved some of the meetings to different directories . 
they ' re on a different disk even . 
right ? 
i think you didn ' t you expand them to x e on abbott ? 
are they ? 
x f . 
no you the ones that you the ones that you put them on when you put them on x e . 
oh different ones ? 
i don ' t remember where i put them now . 
i think you put them on x e . 
okay . 
so 
well what we what we found out was that um the disk that crashed was it with a with a meta disk allocation you had both transcripts and the shortened files and the expanded files were all on x e were on the same 
sorry . 
different partitions of the same physical disk . 
physical disk . 
huh . 
and it ' s conceivable 
i mean i i don ' t 
i mean so um i was told that it ' s possible that that might have uh caused additional wear on it maybe caused it to to go bad sooner . 
huh . 
well i think there was something else going on . 
because uh dave johnson said that d d was getting accessed frequently . 
oh uhhuh . 
and it shouldn ' t be . 
right ? 
that data never gets touched . 
well why not ? 
because we write it once and then we never touch it again . 
oh sure it does . 
just the backed up space . 
yeah after each meeting we copy the data to 
except that 
well i mean so the wavefiles or or anything at all because the transcripts are there as well ? 
the wave files . 
i mean he was saying gigabytes . 
oh gigabytes i see . 
and so it has to be the wave files . 
yeah there was something weird about that . 
yeah that ' s right . 
yeah so i asked dave about it and he hasn ' t looked into it yet . 
but we should definitely double check on it . 
yeah like like the same meeting shortened files that we pull off of popcorn when we ' re done doing the recording looked to the backup software as if they had been written you know every single night for you know a week in a row . 
yeah . 
every night . 
is that right ? 
that ' s very strange . 
which is really weird . 
wow ! 
i didn ' t realize that . 
okay . 
so at any rate so for file reorganization we need to first decide what we ' re going to do and then when we ' re going to do it . 
yeah . 
so i ' m not sure who isn ' t involved with that . 
i mean certainly me chuck and jane . 
anyone else care ? 
no . 
and i and i ' d like in terms of the conventions to also uh you know send a bit to dan ellis to see if it ' s if there ' s any get his input on it . 
i don ' t think i don ' t think that ' ll be 
right . 
yeah . 
so maybe we should do that 
yeah . 
not during this meeting but another time . 
yeah . 
and just get a list of everything we ' re going to do . 
yeah . 
yeah . 
maybe next week if we could . 
okay . 
i ' m trying to finish up some stuff . 
yeah sure i ' d like to 
so just update all the naming conventions . 
and put all the files where they really belong on one disk . 
that sounds like a good idea . 
and then leave leave everything in place until the back up until the next full back up . 
and then delete the old ones . 
uhhuh . 
okay now and you ' re just you ' re not talking about the the x disks the x uh partitions . 
so 
just the backed up space . 
or 
well both need to be reorganized . 
okay . 
so um 
various paths 
i mean this is why we have to do it in a synchronized way . 
because um 
i think we should also at the same time try to uh convert over to your new naming conventions . 
yes exactly . 
that too . 
that ' d be good . 
so that ' s what i was saying we need to get a list of all that stuff that we want to do . 
yeah . 
okay . 
and so 
i didn ' t really get any responses from the naming conventions that i sent out . 
so i assume that ' s all right with everyone . 
i actually haven ' t looked at it yet i haven ' t had a chance . 
i haven ' t either . 
oh . 
no . 
huh . 
sorry . 
so 
i will by next week though . 
and 
uh i don ' t know about the naming . 
okay then i should have made that as an agenda item . 
i mean so these names that we ' ve been using so far are with 
uh uh uh 
i wouldn ' t just want to change them you know without some advance notice . 
right . 
i mean that ' s all these segment names that we ' ve been using 
yeah . 
i would rather not mess with them until we have some closure on some of the things we are currently dealing with . 
yeah i ' m 
right . 
well i mean how you choose to do it the naming is up to you . 
so 
well 
right . 
so 
you ' re talking about different files . 
i mean it should probably be eventually should probably be consistent with what you ' re doing . 
but 
yep . 
yeah i kind of agree with andreas . 
like i ' m a little bit 
i mean these 
i looked at the naming conventions . 
and they look fine to me . 
but at the same time it was just like you know to rename everything would be 
well if we 
if we change things it won ' t really affect what you ' re doing . 
no but i think just to be consistent we should also i mean have the same conventions just in case you want 
this 
will it ? 
right . 
yeah so you but you can switch that any time you want . 
yeah yeah i mean it ' s only going to affect my work . 
right ? 
so 
yeah it ' s not going to 
i mean if we 
i assume you ' re not going to go like into you know my directories and change my file names . 
right . 
so 
i actually i was going to do a global search replace on all entries at at icsi . 
everybody will use it . 
yeah . 
fine slash u slash star . 
to change m r to m r m at all places at icsi . 
yeah . 
that ' d be great . 
really enjoy that . 
with no with no advance warning . 
you 
well maybe i shouldn ' t say that on record . 
okay . 
there was a typo in some of the contracts that morgan got that someone 
one of our sponsors did a global search and replace for between sponsor and their name . 
uhhuh . 
oh no oh no . 
and so it it was saying uh 
well anyway . 
i won ' t 
yeah . 
i ' m not sure whether that ' s right . 
one one can imagine that that might be problematic . 
yeah one can imagine the problems that that would engender . 
but this this name change affects a subset . 
so 
doesn ' t need to reflect everything . 
yeah . 
right . 
right . 
um 
thilo you had you wanted to talk about the 
yeah i had one one short point . 
i have just installed a transcriber version on one of our n t machines . 
so it ' s available under windows now . 
oh great ! 
actually someone i just got an email this week from someone 
isn ' t that great ? 
yeah i responded to i have already responded to him . 
i i don ' t know what what what he what the problem was . 
to anant ? 
it was really straightforward . 
really easy . 
and this is not 
oh i ' m sorry . 
i i just 
uhhuh . 
so who did you talk to ? 
there was some some guy from s r i who wanted to to install 
anant ? 
yeah . 
anant venkataraman ? 
yeah . 
okay . 
and he sent an email that he couldn ' t couldn ' t install it . 
yeah okay great . 
and i i just described him well what i did . 
yeah okay . 
great great thanks thanks . 
and it was really straightforward . 
so 
and this is not just the transcriber . 
this is the channeltrans . 
right ? 
yeah it ' s the channeltrans . 
yeah . 
so the the things that dave gelbart 
yeah excellent . 
cool . 
excellent . 
so you should probably talk to a sys admin and get it put in some central place . 
so that it ' ll work on all the n t machines . 
well i mean as it stands i i guess . 
okay . 
yeah i see what you mean . 
it ' ll it ' ll be on the on the unix side . 
i ' ve 
but accessible through the h drive . 
right . 
yeah . 
okay yeah i could do that . 
so i assume tcl t k wasn ' t already on the machine so you had to install it . 
yeah . 
i had to install it yeah . 
huh yeah . 
uh 
so andreas would it be appropriate to ask how the experiments are going ? 
uh 
oh well yeah i i i actually wasn ' t sure whether this is the right meeting for it . 
because it has uh very little to do with with meeting recordings . 
huh . 
but you know i did uh run um some recognition experiments with icsi front end . 
um uh 
and and you know this is the joint work with chuck . 
and uh um 
so first uh you know we had we figured out sometime last week how to um 
and and chuck wrote this really nice little script perl script that takes a uh waveform runs the feature calculation and then dumps it out into the into um a so - called uh cepstra file . 
which is what the s r i system uses to read features . 
it ' s essentially uh uh nist headered uh waveform . 
you know it looks like a waveform except instead of samples you have feature vectors following the header . 
uhhuh . 
and um that ' s all done um by the script . 
and it works great . 
and uh i first trained up two systems . 
because it ' s you know the s r i system is gender dependent . 
so to be comparable i trained uh um on a on a so - called short training set . 
um a male system and a female system 
and uh 
also for debugging purposes and for the heck of it i trained um trained uh on the same training set uh a standard system with the s r i front end from scratch . 
um and compared the two . 
so what features did you use ? 
well we used uh twelve p l p uh uh 
so not rasta . 
just p l p . 
just p l p . 
just p l p . 
and actually that uh one of the questions i had was what the rasta would possibly buy us . 
but um we ' ll talk about that later . 
so the uh so the baseline system the s r i system was uh used uh also uh uh used twelve uh mel uh mel cepstra um based on a twenty four filter bank um analysis . 
um 
i do not know what 
so the the bandwidth of the um s r i front end is from hundreds hertz to thirty 
thirty seven fifty . 
thirty seven fifty or something like that . 
and i do not know what the um icsi um front end would do . 
i mean what the bandwidth is . 
um 
but the results are such that 
uh let ' s see . 
there ' s one other slight difference . 
right ? 
or two two differences . 
oh yeah . 
so the s r i system also does um vocal tract length normalization . 
and we couldn ' t figure out how to do that yet with the icsi features . 
so that ' s one difference . 
and the other difference is that in the uh in the s r i system the uh the first the c zero the energy uh feature is normalized slightly differently from the rest . 
and what they do is they they subtract the maximum 
huh . 
for each waveform segment they subtract the maximum of of over that waveform segment from from the values of for that waveform . 
which is a kind of automatic gain control that is localized 
do they subtract the max from each one or do they subtract each one from the max ? 
who cares ? 
they subtract 
doesn ' t matter ? 
no just would be a sign change . 
except you get a lot of negatives the other way . 
right right right . 
um and then after but after they done this waveform based normalization they then do a conversation length normalization just like all the other features . 
so it ' s their kind of two stage normalization . 
oh oh ! 
um now i understand that the common practice here has been to just do standard uh mean subtraction um on the waveform . 
um 
for the c zero . 
right but in what we ' ve done so far because we didn ' t have any special provision for c zero we just treat it as as any of the other features 
we ' ve done standard mean subtraction over the whole conversation side . 
so um since both s r i and icsi use this sort of local normalization for c zero that ' s presumably you know someone has done some experiments to and found out that that works better . 
um so that ' s another difference . 
and that might account for some of the discrepancies in the results . 
um but you know so the the results are 
um 
where should i start ? 
uh the 
so there ' s a two 
oh i tried it with and without 
uh 
so without and with adaptation . 
how many iterations ? 
for the adaptation ? 
uhhuh . 
well we always do three e m iterations to 
okay . 
and it ' s it ' s this it ' s this quick and dirty 
the phone loop adaptation which doesn ' t actually require prior recognition paths 
and and so this is not the best you can do with adaptation . 
but it gives you sort of a first idea of what you could gain with it . 
and then you know so we have the the s r i front end . 
and the icsi front end . 
and other than that the system configuration was identical . 
so it was the same 
they came up with um you know same number of uh gaussians per state cluster . 
um same the clustering used the same information loss threshold . 
which actually led to roughly the same number of gaussians overall . 
so that the system configuration is is comparable . 
um and the uh 
so without adaptation 
you had forty nine 
that ' s error rate or recognition rate ? 
this is error rate . 
in percent . 
and with adaptation it ' s forty seven point one . 
and this this was fifty two point six . 
and fifty one point three . 
huh ! 
and then when i combined them 
i can actually combine them with something like rover . 
it ' s actually more sophisticated than rover . 
but it ' s 
um here i got forty eight point five . 
and here i got forty six point five . 
so this is just combination at the utterance level . 
um 
at the utterance level right . 
why do you think the icsi front end is so much worse ? 
good question . 
that ' s fine . 
that seems really odd to me . 
um so one percent i would attribute to the lack of v t l . 
about one percent . 
oh right right right right . 
okay . 
okay uh okay . 
and then maybe another up 
i don ' t know how much the c zero normalization business really matters . 
i can ' t it see i mean can ' t see it the 
can you run the s r i just as an experiment run the s r i front end without vocal tract normalization and see how much difference it makes ? 
i could yeah . 
i could certainly do that yeah . 
um 
we could also do the vocal tract length normalization with the icsi features . 
yeah . 
that ' s something we wanted to do . 
if we could figure out how . 
yeah . 
we could i was actually thinking we could use the warping factors that we compute for the m f c c ' s and just try them with the icsi uh front end . 
yeah . 
because we already have the capability to apply the warping to the um to the p l p 
yeah dan added that in . 
yeah but the 
but 
uh dan added the 
so 
they won ' t 
they don ' t correspond one to one though . 
no but they should be close since this 
i mean the 
anyway but i can certainly try the s r i front end without uh v t l . 
that that ' s that ' s certainly quick to do . 
yeah . 
um and so 
yeah and and then there ' s all these 
um 
you know the number of um 
you know this front end had a fair amount of experimentation going into it . 
uhhuh . 
you know how many filter banks do you use ? 
what what bandwidth do you use and stuff like that ? 
and uh we could play the same kind of games with the icsi front end . 
right . 
uh actually the analysis bandwidth played a very crucial role . 
we used to use a narrow bandwidth . 
and uh 
uh that hurt us . 
so this is um and this is we ' ve now used roughly what everybody else is using . 
so 
huh ! 
um there ' s some room for improvements i figure in this in the icsi front end . 
um so 
but the good news is that even with this with the icsi system being that much worse you still get a win out of combining the two . 
so that gives some hope for the future . 
um 
unfortunately however this seems to be reduced with adaptation . 
so . um . 
also interestingly the um the difference actually widens . 
i would actually expect it or or hope that the adaptation reduces the difference . 
because it might um for instance um remove some of the 
um 
you know if you if you have some some difference in the front end processing that uh is suboptimal but can be possibly remedied by you know moving the um moving the models around 
but but apparently that doesn ' t doesn ' t really 
actually the difference becomes larger . 
so 
um anyway so right now what i ' m doing is um 
uh well there ' s several things going on . 
one is that chuck is working on uh getting the tandem features um into a form that we can train the tandem the system on the tandem features . 
so that would actually be the more interesting experiment . 
um the other thing is i ' m training uh retraining the models on the large training set that we usually use to build our evaluation models . 
right . 
and then we can 
and i actually want to do the system combination um with our eval system um on some subset of the data at least . 
probably only for the males . 
because i don ' t have time to train both males and females . 
but um uh and um 
what about concatenating the two feature vectors into a single one ? 
it gets pretty big . 
it does get pretty big yeah . 
huh . 
and my experience with that in broadcast news was usually combining at other levels works better . 
huh . 
so 
for for whatever that ' s worth . 
oh you tried that on broadcast news ? 
oh yeah . 
concatenating . 
yeah . 
so 
different feature sets . 
yep . 
yeah . 
did you try uh 
it was mostly m s g p l p rasta . 
i see . 
so you know the feature sets we had available . 
i see . 
and it was almost always better to combine at the probability level . 
you know so we ' d run the neural nets and combine the probabilities . 
okay . 
all right . 
oh . 
yeah and it does become sort of unwieldy to have these very large feature vectors . 
yep . 
and that would blow up the 
you ' d also have to do some sort of normalization afterwards so that they ' re uh orthogonal . 
uh 
right . 
so you ' d want to do a linear transform also . 
right . 
um so the 
yeah and then we could start experimenting a little bit to try to get the icsi front end to perform better . 
um and and as a preliminary just sort of diagnostic experiment we can i can certainly run a s r i system without v t l . 
yep . 
just uh to get 
without what without v t l . 
just 
vocal tract thing . 
yeah . 
okay . 
yeah . 
and that that ' s quick to do . 
so 
i was thinking about tandem system . 
well let ' s not talk about it here . 
but i had some thoughts about the tandem system . 
yeah . 
so but things are moving ahead . 
so 
okay should we do digits ? 
digits sure . 
do we have any other topics ? 
okay let ' s do them one at a time instead of simultaneous since we actually have time . 
poetic reading of digits . 
oh no . 
you can really tell from the prosody where it goes . 
meeting . 
i actually have one more thing that 
i don ' t know if it ' s if if it ' s allowed to to bring up after the 
after digits ? 
i don ' t know . 
anyway . 
but it might be important for um 
go ahead . 
so liz remarked that she had recorded a meeting where it was later found that several of the microphones were turned off . 
uhhuh . 
um 
and this must become a problem especially with non speech meetings . 
so um 
is there a way that the software could warn you if it gets zeros from some of the channels ? 
or 
probably we could probably build that in to the front end . 
because it you know it ' s really annoying if you go through all that trouble . 
and then basically the meetings aren ' t useable . 
because uh even 
what are people doing ? 
they ' re switching their mikes off or something ? 
i don ' t know what they do . 
maybe the batteries went dead . 
or they just didn ' t they played with the thing and it didn ' t leave it in the on position or whatever . 
i don ' t know . 
uh uh fff ! 
what would you like it to do when that happens ? 
well no if if you um 
i mean obviously you always 
i mean there ' s never going to be a signal from all the channels . 
right ? 
because 
or rarely . 
um but uh 
well if an unblacked out channel is zero is actually spitting out zeros you can be pretty sure it ' s off . 
right . 
because it doesn ' t spit out zeros . 
it spits out epsilons . 
right ? 
because there ' s little background noise . 
the question is when the software detects it what do you want it to do ? 
exactly . 
that ' s a good question . 
i don ' t know . 
but is there some we can collectively think of some of some mechanism that might reduce the risk of of just 
i mean it it it 
we we already have visual feedback . 
right ? 
you can see whether your mike is working or not . 
right . 
right . 
um . 
so maybe it ' s just to admonish people to actually look at the screen at the beginning of the meeting to make sure they get a signal . 
yep . 
test 
turn off the screen saver during the meeting . 
tell them to test their mikes or 
yeah something . 
i think they 
yeah i i don ' t know what to do other than 
it it can beep if one of the channels dies while recording . 
there ' s no sound out right now . 
oh . 
never mind . 
it should give the electric shock to the person recording the meeting . 
yep yep yeah yeah that would be good . 
oh yeah that ' s a good one . 
wow ! 
that ' s not a bad idea . 
well we can think about what to do about it . 
yeah okay . 
but it it ' s pretty clear we can detect it 
so 
yeah . 
okay are we done ? 
all right . 
yeah . 
uh okay . 
so then let ' s start with our weekly meeting . 
the last time ' s uh we learned too much i believe . 
so 
uh today i have two topics . 
and the first topic um we have a new member in our group . 
miguel sanchez . 
i believe everybody knows him very well in the meantime because he stayed here quite a little time . 
hi . 
and i think he is talking to everybody in the meantime . 
so but anyway i would like that miguel sanchez will introduce himself a little bit concerning his background what he intend to do . 
and because i discussing with him uh uh many things concerning uh his skills and what the n . s . a . group intends to do . 
uhhuh . 
i hope there will be a match uh then for his future work . 
and the second topic is then to discuss a proposal in much more detail . 
i believe we still haven ' t left our starting position . 
and um yesterday i also discussed with wilbert some things . 
and i would like to focus on the question what problem we are going to solve with such a proposal . 
not so will they have a common activity within the group itself and maybe with other partners outside . 
but the technical problem . 
but that ' s under the second topic . 
so first i would like that miguel will told us a little bit about his skills and and uh his background . 
okay . 
okay . 
thank you joe . 
so please . 
well i uh as all of you know i came from from spain . 
from the uh polytechnic university of valencia . 
and uh i um just finished my p . h . d . thesis about uh power saving techniques for wireless networking . 
uh in fact i have developed an algorithm to control the radio frequency power uh of a wireless transceiver . 
and uh i ' ve been working also in routing issues especially in the so - called ad hoc wireless networks . 
where uh you have a set of uh mobile nodes and no other infrastructure . 
no base stations . 
so all the routing functions are done by the node by the same nodes . 
okay ? 
so nodes act as both end points and routers . 
uh 
i ' ve in the study for some time these kind of networks . 
and uh in fact there are a lot of of research uh articles about this this kind of networks because you know uh huh infrastructure based network network has been a long topic of research . 
so 
for example routing on on wired networks is a a topic still to be researched . 
but it has an important background . 
but mobile this kind of mobile networks is a little bit uh newer . 
especially because uh until not so long uh the the things were too heavy to have a computer a wireless transceiver on a more or less portable thing . 
so with the advent of this new technology low power uh high uh processing capability and wireless uh networking capability in a really small package new kind of devices are are being built and are appearing in the market . 
and uh well this is more or less what i have done . 
and the kind of uh things i ' m interested is more or less all around this these kind of networks . 
but i could say uh in general mobile service is not only about uh these specific kind of networks . 
but in general about uh services uh over mobile or services that can benefit from the uh capability of nodes to move around . 
and uh well i i ' ve been teaching now for twelve years uh at a computer sciences school in my university . 
i ' ve been teaching computer networks . 
and well i am more or less uh knowledgeable about well t . c . p . i . p . networking i . s . o . uh networking . 
and uh 
well i ' m i ' m a computer guy . 
so i ' m really um well i can say uh proudly uh more or less computer skilled . 
i mean uh operating systems uh programming languages uh networking . 
so this kind of things i think i ' m more or less well - trained . 
so 
this is i think um my first presentation . 
next maybe next meeting i will uh do a small sketch about uh my past work and well presenting some a little bit more detailed approach with some schemes and and some things from previous talks so you can have a better idea of the kind of work i ' ve been doing . 
okay ? 
uhhuh . 
thank you . 
so thanks miguel . 
yeah we discussed it yesterday that you ' ll maybe will have a talk next tuesday . 
yeah . 
but give me a sign and send me an abstract so that i can announce it then for the next meeting . 
yeah . 
that ' s okay . 
um 
one short other topic is uh claudia did a lot of work concerning the web pages in the meantime . 
oh . 
okay . 
and despite busy stuff with waivers and uh and visas and whatever uh she found the time to um write with what we discussed before and in the form of h . t . m . l . stuff . 
and we want to put it on the web pages in the next days . 
so i will send an email then to everybody that they should check their web pages whether they ' re aligned with um their own views and opinions of what we should what should be presented on the web pages . 
and any feedback is then well appreciated . 
no ? 
okay . 
so 
let ' s switch to the project proposal . 
um i mentioned that it is still 
uh . 
sorry . 
can i 
yeah ? 
maybe i can add something . 
claudia 
yeah if there ' s anything else which we what we could add on the web site . 
so for example if you have a small abstract or some pictures or whatever about the work you did before what you are planning to do here that would be fine . 
okay . 
because now we can add some more stuff there . 
or if you have something or if somebody has some slides or articles whatever he wants to be published there . 
yeah . 
then everybody sees the structure how it is uh structured really structured . 
yeah . 
and 
then maybe you can easy offer some additional input which should be presented then on the web pages . 
yeah it depends what what everybody wants to do . 
yeah . 
yeah . 
so 
about the projects will be something . 
then about publications will be another point . 
and yeah additional information about how is life in berkeley and yep i don ' t know some some hints some web sites or links which are useful when somebody arrives or stuff like that . 
yeah it is . 
yeah . 
uhhuh huh . 
half collection of necessary information . 
but there ' s no personal homepage for everybody ? 
or is it planned or not ? 
yeah you can have 
or 
yeah you can have it . 
because as uh uh uh 
i ' m not interested in this . 
that makes work . 
no . 
but this is oh uh everybody ' s obliged to do it for his own you know . 
yeah . 
so there is not uh claudia is not the webmaster here to uh get the collection for for for everything . 
okay . 
oh oh no i ' m not doing it for everybody . 
so 
but what i can 
this is responsible for uh everybody ' s responsible for his own . 
yeah . 
yeah but but what is planned is that i do something like previous you know layout and give everybody the uh uh the possibility to the chance to put his content inside . 
sure . 
okay . 
his name and so on . 
so that the layout is for everybody the same . 
yeah . 
well like have a blueprint . 
so about the projects and stuff . 
okay . 
uhhuh . 
so there will be something . 
yeah . 
yeah . 
okay . 
thanks . 
so 
let ' s switch to the proposal . 
i ask everybody whether read it in the meantime and understand everything . 
yeah . 
everybody say yes ? 
yeah ? 
yes . 
yes . 
okay . 
um 
from my point of view as i mentioned before we still in the starting position . 
i think the four building blocks on the network level will have really a major impact on on current um available wireless networks and uh also for future generations . 
and what the missing thing is really what kind of problem we are want to solve with such a project proposal . 
and wilbert yesterday mentioned and he is right that what kind of maybe service we are really going to offer . 
the linkage between such kind of application also interactive multimedia application and uh this kind of networking stuff is um maybe not very well aligned . 
because there will be of course a portion of mobile access to such kind of application . 
but i think that ' s not the majority . 
and that is not the major focus of um this kind of um this kind of application anyway . 
so i would like to to uh split in principle the discussions of what kind of application tsk um far away . 
and i would like to more to focus if we have certain kind of vision concerning these building blocks and the network um what kind of problem we are going to solve . 
what kind of uh um um glue between these four building blocks exists . 
and what kind of synergy effects in principle as if they work and fit very well together exists for networking stuff . 
and what kind of service could we provide in that area . 
we will have these kind of uh really closely working together of these four building blocks . 
so maybe uh wilbert you can start to oder to to tell the group about what you mentioned yesterday concerning certain kind of ideas . 
maybe it ' s a brainstorming um of of these things . 
and maybe we can comment later on these uh these ideas . 
and i saw you still discuss with with uh mark right ? 
some stuff . 
was it also related with with these things ? 
no . 
no . 
okay it was . 
this afternoon you mean ? 
yeah . 
no this was unrelated to to the things of yesterday and last weeks . 
okay . 
yeah yeah . 
then maybe then one one uh sentence before . 
i believe everybody fits very well in these kind of things . 
because from the mathematical description with q . s . in advance me as an expert for quality of service and uh michael as an expert for uh m . p . l . s . and wilbert an expert for for multicast and uh i discussed with miguel it ' s uh maybe a little bit the shift to active routing . 
but it is still in the area of routing . 
so my idea is in principle to have independently of any funding independently of any outer contact such such a core activity in principle . 
and we can see how much from the outer world can fit in . 
first of all the first stage is the institution which is behind everybody . 
that means uh k . p . n . in your case and siemens in our case . 
and maybe then in the broader world here other partners registered in the proposal 
tomorrow i will go to cisco for instance . 
and i will discuss uh all this kind of things . 
maybe they have certain additional activities and they ' re interested in the results before . 
the benefit here is in principle that the results are available . 
they are not restricted any way . 
if you have your own common activity that makes a little bit more easier . 
and uh if there is a technical linkage between such uh um between the outer world and us okay the better it is . 
but anyway if we come to a certain kind of uh common work within the core of the n . s . a . group i think that ' s really beneficial to everybody . 
and uh especially wilbert if you have in mind to go in the huh uh really from the project proposal view i think we can build it on this this core . 
you know ? 
and go to the outer world with and and and align it in a certain way . 
for instance that it also fit maybe to k . p . n . and siemens and in other companies . 
yeah . 
yeah and this probably has to be a brainstorm right now . 
yep . 
um what i told joachim yesterday was that uh uh for my company the company i work for they are more interested in in an explicit service than in core technology . 
me on the other hand i ' m more interested in uh core service or core technology myself . 
so i ' m i was thinking about uh how i could combine the both of them . 
k . p . n . was um they ' re interested in having uh like six people or something working on the project for one year . 
or maybe uh three people working on the project for two years . 
and have a kind of a demonstration uh for a specifically u . m . t . s . service . 
uhhuh . 
i was thinking that um as a well not really a u . m . t . s . service but yesterday what i discussed with joachim was uh a little bit based on your ad hoc networking also . 
that it would be interesting to have a kind of a device where you can switch from a wavelan technology to um u . m . t . s . 
i think that ' s uh it ' s in in the future that will be a main competitor of uh of u . m . t . s . 
uhhuh huh . 
too like the the the lucent uh equipment has a huge scope already . 
like five hundred feet or or even more sometimes . 
so that ' s it ' s might be interesting for a service to walk into a building or whatever is available on that network . 
you can switch from u . m . t . s . or uh uh to wavelan technologies . 
huh . 
uhhuh huh . 
uh maybe i will write a few keywords on the on the whiteboard . 
sure . 
okay ? 
of course it sounds strange for a company that does u . m . t . s . to switch to to be able to switch or provide the service to switch to wavelan . 
but at the end it makes it easier for your and cheaper for your customers . 
so if they don ' t do it somebody else will probably do it . 
and you can build a a an a a double technology adapter too . 
so you can market these double technology adapters . 
and this can be a a potential uh um you know uh income too . 
yeah . 
because you just have to license uh uh wavelan technology . 
you can build uh the whole thing . 
yeah . 
this u . u . m . t . s . wavelan mixed together . 
and 
yeah something like that could be possible . 
maybe even a u . m . t . s . to wavelan gateway . 
or i ' m not sure if that ' s possible like u . if u . m . t . s . contains redirects or whatever like switches . 
i ' m not sure about it . 
it could be . 
huh . 
i think they are using different uh radio technologies . 
so uh at the physical level they ' re they ' re they are not compatible . 
it ' s not a problem . 
no but you could have a u . m . t . s . gateway that translates everything to that uh local . 
yeah . 
yeah . 
if you will . 
that that ' s right . 
yet the basic idea is in principle to switch seamlessly between wireless lan technology whatever and u . m . t . s . 
right ? 
yes . 
and you see the benefit that in principle the customer will save a lot of money . 
because if in - house communication like wavelan or maybe i see it also in the american market some wavelan communication in the outer world will be available the and that is your assumption that the more cost uh extensive um u . m . t . s . connection could be principle used i would like to say over wavelan . 
and then i have a normal wavelan connection right ? 
yes . 
and the router and the wavelan connection goes into the core internet elsewhere . 
and the connection is not dropped between this seamless hand off i would like to say . 
uhhuh . 
right ? 
or what or 
well . 
if connection is lost i am i ' m not sure if sometimes you ' d simply have to drop a connection if you have outstanding connections . 
what 
yeah . 
but that ' s uh one thing of the internet . 
right ? 
it ' s should be able to unplug a host bring it somewhere else and everything continues like it should be . 
i ' m not sure if it ' s uh if you really have to uh save a connection for all applications . 
i i don ' t think so . 
yeah but if this is the final goal . 
it should be as much as possible available that you do not have to break the connection if you switch between the subnets ' technology . 
right ? 
yeah but i i have a point uh regarding the this question is uh the cost function . 
i mean . 
uh 
what about the user who is switching from one let ' s say zero cost area network to another network where he has to pay ? 
it is okay for the service to continue when he uh switches from one network to another . 
but probably the user wants to be aware that he ' s switching from one place from one network to another . 
because maybe while he ' s uh having let ' s say a video conference uh over the the wavelan oh he ' s not paying any extra cost . 
but when he continues with this service on the u . m . t . s . he ' s having to cover uh an important let ' s say an important cost or some cost non - null cost . 
yeah . 
non - null . 
so uh 
this can be something that probably the user wants to be aware of . 
of course this doesn ' t mean that the user wants the connection to be dropped when he switches to the uh uh from the zero cost area network to to the uh um non - null cost area network . 
but maybe some users want to do this . 
because they say okay . 
i ' m not willing to pay any back for this service . 
because i ' m just watching uh you know the sports news . 
so if i switch if if because of my motion i ' m switching or i ' m going out of the coverage of the of the uh wave uh wireless uh local area network well i i want the service to be uh stopped . 
and this can be some pattern then that some users will follow . 
yeah . 
yeah but if your 
uh i believe everybody is aware about the u . s . a . i . a . architecture . 
and uh this one is here this stuff is here also related to this kind what is mentioned there concerning the end system . 
and in my uh considered end system there is a certain kind of policy concerning how to use subnets technologies and and all these kind of things . 
how to use quality of service you know in advance . 
because you have to pay for certain technologies and maybe for certain services . 
and that should not be done automatically . 
but it could be done automatically . 
but nevertheless there must be a certain kind of um user interaction always possible that you could set up a certain kind of mini database how to deal with all these kind of things . 
i think that ' s not a problem . 
but uh what i i would like to ask wilbert here and we discuss it yesterday is it only the usage of that p . c . m . c . i . a . card where you have instead of g . s . m . today u . m . t . s . and instead of wireless lan today also wireless lan . 
remember your four and one card uh concerning um 
what is the name from 
no . 
dacom . 
oh the one i have sitcom ? 
where you can enable four technologies and you plug in in your laptop . 
yeah . 
and then you have every four uh subnet layer technologies available in your laptop . 
is that the problem ? 
yeah that ' s not the problem . 
right . 
um 
well the switching itself could be a problem . 
why ? 
well it ' s a depends . 
maybe you are . 
i don ' t know . 
so that could be a topic for research . 
yeah but this 
so maybe you know more about it . 
yeah but this is only the probing to figure out that you get at a certain location the information that a certain coverage of a certain subnet technology is available . 
and if so then what miguel mentions then you add a certain kind of policy to switch or not to switch to this kind of technology . 
yeah . 
right ? 
yes . 
but this is end system related . 
that ' s not network related . 
i see no network related stuff within these in this uh idea . 
um 
it ' s only to set up 
for me it ' s like a laptop to plug one p . c . m . c . i . a . and currently will have two p . c . m . c . i . a . cards and i compare g . s . m . with u . m . t . s . 
uhhuh huh . 
and today i would like to have g . s . m . 
and then i have my g . s . m . connectivity . 
and i cannot use it other technology . 
only g . s . m . because the interfaces the driver interface does not permit me to switch between the between different technologies . 
so if i want to go to wireless lan i have to stop my connection and put in my wireless lan p . c . m . c . i . a . card . 
and then i can go on and set up the the same connection one more time . 
and what you have in mind to do it a bit more seamlessly and that makes an only sense for me if both technologies in principle were close together in that sense for application . 
for instance the application would be that i have my laptop here . 
and i work here with with my device . 
any kind of device . 
and i work here in wireless lan area . 
and then i go outside and want to go still on leaving the coverage of uh of the uh wireless lan . 
and at a certain state the device uh receives certain signals that the coverage of u . m . t . s . or g . s . m . is available . 
and at that state you automatically or based on the certain kind of user profile switched to the um u . m . t . s . or g . s . m . uh network . 
that ' s the only senseful application . 
from my understanding that means only to have a certain kind of control layer for the different drivers . 
which you also mentioned as a u . s . a . i . a . architecture . 
and uh then to do the switching for an existing stream or application between these uh transparently to this application between those uh these both technologies . 
maybe there ' s more potential . 
i don ' t see it . 
but maybe you have a additional idea . 
and i don ' t think that this end system device uh architecture which will come automatically . 
and i believe there ' s a lot of activity throughout the world . 
because this seamlessly communication is always mentioned elsewhere where you where you listen to . 
so 
uh 
if if you can leave it out the network that will be really cool . 
that ' s what you what i would like to do . 
so 
yes . 
but when quality of service comes to the uh scene well i think we have a a bigger problem . 
because maybe this this uh uh seamless migration cannot be seamless at all . 
because maybe the the quality of service we are getting when we are connected to a certain network let ' s say high - speed networking cannot be sustained when we are switching to a different technology . 
so this is another thing that is uh putting a little bit in more trouble our our scheme . 
or 
now i would like not to hear only three opinions . 
but maybe there are also other opinions . 
okay . 
yeah . 
oh sorry . 
and maybe everybody should uh give a short 
i think you 
let us understand built for everybody and their whether their comments . 
yeah . 
i think we should 
in this thing of seamless handoff or handovers should think more maybe in different layers ? 
so one layer is having the seamless handover . 
it ' s clear if a technology doesn ' t provide that quality of service you can ' t do magic and have it . 
there are certain constraints on that . 
it ' s true . 
that ' s still in mind . 
but for with the cases there there it is possible . 
so that should be made possible then ? 
uhhuh . 
yeah . 
yeah . 
so 
it can be done . 
it is just huh uh trying to to to to to pinpoint the the possible problems . 
yeah . 
there are still enough problems in doing it . 
yeah . 
yep . 
but it might be the wrong thing to promise uh ten megabits to everywhere . 
there you are . 
but saying okay if it ' s a if the technology is okay you can do it . 
yeah . 
in fact if you take the slower technology of the ones you are planning to to support you can offer this this uh this throughput as uh the minimum warranty you you can get . 
yep . 
yep . 
yeah . 
so if everybody is is asking for less than this minimum amount no problem at all . 
but in this case maybe not too much effort should be put on providing this quality of service . 
because you just have a usually a huge bandwidth compared on a a with what the user is is using . 
yeah . 
yep . 
uhhuh . 
i mean if you have a ten megabits bandwidth and the user is asking two kilobits per second of course you can uh build uh certain reserve mechanisms to warranty the user these two kilobits per second bandwidth . 
but probably in it isn ' t it is not worth because you have so many uh available bandwidths that maybe uh it is not a problem . 
huh ? 
oh ! 
okay . 
uh 
okay . 
oh okay . 
good luck . 
the the thing is that we are looking for a research topic on on those uh four areas . 
yeah . 
yeah . 
and the building blocks . 
yeah . 
multicast not a topic . 
so 
so we 
routing ? 
so so we went through uh uh to through multicast . 
so this architecture with 
well at least no wireless environment or a mobile i . p . environment comparable to uh u . m . t . s . environments we really did not find any well difficulties there . 
on the blackboard that is . 
of course in real life there will probably be some problems . 
have you have you read about this uh barwan project held at berkeley university ? 
well what you the pointer the pointer you sent yesterday . 
iceberg ? 
yeah . 
yeah . 
i i didn ' t find the time yeah to do so . 
okay . 
but 
uh 
you mean the iceberg project ? 
barwan . 
barwan of uh e . s . 
barwan . 
how ' s it start ? 
i know there ' s one that ' s of uh randy katz . 
uh it was another related project called daedalus . 
yes . 
and uh well it seems they what they were doing was some kind of uh things somehow similar to this . 
they worked together little bit with nokia ? 
uh don ' t know . 
palo alto ? 
mountain view ? 
i i i i just uh take a a quick uh look at the at the thing . 
because i i was uh read about this uh a long time ago . 
and it the the latest report i i found was in nineteen ninety eight . 
and in this report well they they they have uh some slides some uh papers some well a lot of things . 
huh . 
and well the main thing and the quick uh thing i i was uh looking at was a a video available in m . in m . p . g . m . peg format . 
and uh 
well what this video was presenting was a kind of test of of one guy with a portable computer moving across different networks . 
so starting at the c . s . department at berkeley . 
and then going out the street . 
switching to the a campus wide network . 
uh um i think it ' s a metricom uh network . 
which is uh a test 
a ricochet here right ? 
ricochet . 
yeah . 
yeah . 
yeah . 
that ' s right . 
yeah . 
and then finally switching to i think it was city p . d . or something like this . 
okay ? 
i as uh as the as the user is moving out of the of the coverage area of this second network . 
and well what they have built is a a kind of uh proxy structure . 
so they are they are putting most of the work of this adaptational layer on on the side of the proxies . 
so the client or the server is not changed . 
it is the proxy the one that does the work . 
yeah . 
okay ? 
so you can even for example use 
it ' s the same ? 
uh we just discussed a lot about proxies . 
oh okay . 
that ' s a fun . 
i like them . 
so 
okay . 
i 
it is just that that well maybe we can we can take a look at oh maybe a more in - depth look at this project . 
just to see if we are doing the same or if we are doing something similar . 
it would be important for us to to highlight the differences . 
yeah . 
because if not well they can say oh you are doing the same thing . 
this was done now . 
or maybe talk to them about operations they thought of but didn ' t touch yet . 
yeah well we are close . 
uhhuh . 
uh maybe a few comments . 
first of all um do you mind miguel to write the name of the project on the whiteboard ? 
yeah . 
no problem . 
so that everybody 
uh i i will send also the pointer which miguel sent to me to everybody so that everybody can take a look to this uh project . 
i was 
and uh i don ' t know what information is available . 
because i didn ' t find the time currently to check it out . 
it ' s a project of the u . c . 
but first of 
yeah . 
oh yeah . 
u . c . uh berkeley . 
yeah . 
when did you go through this ? 
yeah . 
i ' ll i you uh i seen uh uh reports from nineteen uh ninety six ninety seven and ninety eight . 
because yesterday i was uh well coincidentally i bumped into this project here . 
maybe the project 
uh 
it ' s funny . 
uh sorry ? 
uh do 
yeah yesterday i was just surfing a little bit . 
uhhuh . 
uh . 
and then from nokia i came to this that project . 
uh . 
okay . 
i see . 
so 
yeah . 
nokia research . 
i think that that the leader was uh professor katz . 
and then 
okay . 
that ' s right . 
and he ' s also board in nokia research . 
okay . 
so 
uhhuh . 
then the second thing is that uh daimler - chrysler research here in palo alto as well as in germany ulm is doing in principle the same with a car . 
uhhuh . 
they have a specific antenna for uh g . s . m . oh g . p . s . and and for future extended g . uh g . s . m . networks and wireless lan and and other and other network technology . 
in the roof of the car they have a lot of servers . 
in the trunk of the car then they collect data how it is with handoff and all these kind of things . 
and they are driving around the different areas . 
and the same car exists here in palo alto uh based on wireless lan g . s . m . and 2 x ricochet networks . 
uhhuh . 
they collect the collect collecting a lot of data concerning the seamless handoffs and whether it works very well with speed . 
and um 
uh thomas is going to build mobile i . p . stuff in their servers . 
uh 
because they want to 
so i think there is a lot of activities in the area . 
uh 
and my third uh comment is uh if we are going something in that direction that is quite different from this thing here . 
but anyway maybe as a core technology with a real product in mind . 
i see some difficulty because nobody currently has here certain kind uh of u . m . t . s . know how . 
uhhuh . 
and you need it definitely . 
because then it must be your uh bible i would like to say that you are very familiar with u . m . t . s . if you want to go in in that way . 
and as far as i know the u . m . t . s . standardization is not finished yet . 
ninety percent maybe or eighty percent . 
i i ' m not sure . 
but uh 
yeah . 
let me let me ask you a question about uh u . m . t . s . or or third or possible generation wireless communication systems . 
that 
yeah . 
uh from the point of view of the user uh is there uh something more that nnn that than more speed ? 
is there any other advantage from the point of view of the user or of of the terminals ? 
users of of u . m . t . s ? 
yeah . 
you can request certain kind of q . s . 
you can even request it in g . p . s . 
but it ' s not end to end quality of service . 
uhhuh huh . 
it is only um what the gateways get . 
okay . 
yeah . 
and within the core network there are certain kind of tunnels set up in the core network itself of the access provider . 
not the internet backbone core . 
and you use certain kind of tunnel mechanism to combine in principle the base station cluster control . 
but this is uh is controlled by a certain kind of node . 
uhhuh huh . 
and you have the gateway to the p . d . n . or the public data network . 
and between both there ' s a certain kind of tunnel set up . 
but in fact 
but in fact now at the g . s . m . level what you have is that every voice channel you use provides a a a pretty fine fixed uh data speed . 
so we can say that every voice channel has an an uh implied um quality of service . 
which is nnn ninety six hundred bits per second . 
full duplex . 
you mean now for g . s . m ? 
doesn ' t it ? 
or 
yeah . 
yeah . 
yeah . 
so 
yeah what is what means quality of service . 
a certain degree . 
right ? 
yeah . 
uh 
sometimes we have some 
no but um but not only because of of data speed . 
but also about delay . 
you know . 
because g . s . m . networks were developed to uh with a voice service in mind . 
uh delay is also considered in these networks . 
so 
uh in fact for every voice channel you have uh a pretty fine maximum uh delay and jitter and a a a specified um data speed . 
so you can scale up scale up this uh this um thing by using several channels . 
so in fact you have using just g . s . m . technology you have more or less the same building blocks as you can get uh with the u . m . t . s . 
i mean that one thing is that the technology is a little bit different . 
that uh the base station thing is different . 
and maybe uh the the internal routing uh inside the network is different . 
but from the point of view of the mobile things uh i ' m not sure if if 
it ' s packaged data oriented . 
it ' s not really circuit switched . 
in u . m . t . s . you have always g . p . s . as a a involvement in the core network . 
you have in principle the path which still is available for for the g . s . m . network . 
also they use in principle the same uh the same mechanism . 
uhhuh . 
but you also have a uh packet oriented communication that ' s on the g . p . s . stuff . 
and that ' s also related to u . m . t . s . 
yeah but the you know it is also being uh developed this g . uh p . d . p . r . s . thing g . p . r . s . thing . 
so 
that is 
which is uh uh packet data over g . s . m . 
so 
i mean uh i don ' t see that a a lot of difference . 
we can expect a lot of differences uh from the uh mobile terminal point of view uh when uh u . m . t . s . be deployed . 
what i ' m trying to say is that is that well uh maybe uh it is not a big problem that any of us uh be uh um were um a u . m . t . s . expert . 
because uh i i don ' t see it i think that the u . m . t . s . thing is more a technology issue than a research issue . 
maybe i ' m wrong . 
just 
um 
no i think there ' s a lot . 
explaining my 
yeah . 
i think there ' s a lot of research . 
but the question is is this uh a research in which direction we are going ? 
i mean to be done here . 
and because 
for 
not not at the 
of course you know i ' m i i agree with you that there are a lot of things to be developed . 
but but the point is that uh this is probably not here . 
because uh well you know the the the orientation of our group which is uh networks services and applications not uh wireless technology or the underlying wireless technology . 
you think more about hardware technology . 
yeah . 
so there is a lot of hardware to develop but not 
you know radio frequency technology . 
wide band uh c . d . m . a . 
these kind of things all have a lot of things to be to be uh researched . 
but uh i don ' t think this is not something we are doing here . 
right . 
but bear in mind the picture is a is a little bit different . 
the picture i have in mind concerning u . m . t . s . is first of all if you use u . m . t . s . only for voice like you did it or are doing now for g . s . m . it ' s not worth to have this kind of network . 
and currently in europe where it will be deployed first i believe it will be very hard in principle to get some money back if you have only for using it for voice . 
voice . 
yeah . 
because they paid a lot of money . 
so 
what is the point ? 
the point is that you use the u . m . t . s . to connect to the internet and have certain kind of services which are still not available up to now . 
but the problem is if you have the internet content and you have maybe your small uh um device of maybe only evolution based for for these uh new technologies for for certain mobile phones then you have certain kind of problems . 
uhhuh huh . 
you know ? 
because you cannot use these things . 
and wap is not an answer for for these kind of things . 
you know ? 
so 
the i believe there is a lot of research work . 
and also if you see the end to end scope of the internet from the mobile node up to the certain kind of server correspondent node or whatever you call this destination then you have certain kind of models for instance for the quality of service and all these kind of things . 
and then is u . m . t . s . only one link where you have certain kind of subnet layer technology . 
and you have to match these things anyway . 
it ' s like a normal ethernet . 
uhhuh huh . 
whatever you see it is only an additional subnet layer technology . 
yeah . 
and you have all the things mapped to the uh to to the to the the internet stuff in principle to this technology . 
and furthermore you see that the trend is to put more i . p . technology really really i . p . technology and not certain kind of modifications and adaptations to their access network itself . 
and 
there ' s a lot of potential as i believe for for uh certain research work . 
but the question is first of all do we have the competence to do something like that ? 
first of all . 
second we are not hardware builders in that sense to set up certain kind of end systems . 
we can design them yeah from the protocol layering . 
and and maybe have some simulations or whatever . 
but isn ' t the final outcome really such a device ? 
prototype linux based . 
and we go around here and we have maybe a g . p . s . base station sponsored by ericsson . 
since they are living not so far away . 
and and maybe wavelan connection here . 
now a testbed . 
and then then figure out that it works ? 
so that ' s my point . 
well just to make the list a little bit longer . 
yep . 
um you could also think about uh session management . 
i do along with uh the network applications and services uh as you might know . 
it ' s a a 
if you can do it in the end systems or at specific servers then i ' m in favor of that . 
but session management i mean uh the authentication if you go from one network to the other it ' s not solved . 
uh 
nobody really wants a a guest on your network . 
unless you get some money through some way uh through some way . 
then there is also the session management in the sense that a lot of these things at the barwan project as you said go through proxies . 
there might be kind of handoffs at uh at proxies . 
like the zip uh zip proxy that we also discussed before a little bit . 
that that ' s i think also in the line of uh session management . 
then there is this uh perfect thing uh the berkeley sockets . 
it ' s almost perfect . 
they kind of skipped uh layer five uh session management or session layer i think . 
that ' s um normally with if you do a socket programming it ' s directly the application protocol on layer four uh t . c . p . socket or layer five for u . d . p . socket . 
there might also be some research 
well . 
could you introduce such a session management ? 
or 
what they do right now is they make it part of the application level protocol . 
that ' s what they do most often . 
like with session management for mobile the uh applications such as instant messaging or uh talks and so on uh like zip it ' s just doing a a reconnect . 
if they think that the network is different or different capabilities come into play they simply do a reconnect . 
so it ' s part of the protocol . 
that ' s all what i think about session management . 
like part of in proxies or is it embedded in application level protocols . 
but it ' s really higher level . 
right ? 
it ' s no more related to a network . 
it ' s 
we are leaving the network area . 
that ' s dangerous . 
so how do you want to focus on network services . 
because if you go to the 
if you 
for me that ' s starting with middleware aspects . 
you know ? 
well 
and 
so network applications if you look at the name of the group one thing is that um they used to call a a a network that was uh if it was like distributed between two systems connected by a network . 
if you look at network from the o . z . layer then it ' s uh level two or something or maybe level three but everything below three . 
so there are i think two two different interpretations of uh network . 
no i believe network is if you see it really from from the i . p . protocol suite is then layer one in principle up including layer four . 
despite the fact that layer four is only residing normally in the end system and in the gateways . 
but are there network applications then ? 
yeah . 
so the the name is network services and applications . 
so what could be an example of a network application if you look at the o . z . stick ? 
yeah we have i think some . 
yeah . 
do you see this word application related to a network ? 
or do you see this word independently ? 
that was never discussed in detail . 
network services and applications . 
so everything in the world . 
okay . 
or is the application related to the network ? 
for my understanding and as far as we discussed so such a long time uh these applications should . 
for instance ecommerce . 
okay okay well they will i didn ' t want to get a discussion now . 
and it ' s really really 
yeah 
you know ? 
that 
yeah . 
no no uh that is a typical application i think . 
which is in principle also a little bit related to uh to the network . 
but not any application . 
and we also have the aspects for security . 
miguel you mentioned here authentication and and triple a . . 
but we do not have any expert anymore . 
because hannes was an expert for that . 
so the problem for me it still exists that we have in principle here basic building blocks in the proposal from the networking side . 
we could have a certain kind of application . 
and there ' s a lot of activities in the outside world . 
and i believe there ' s a lot of contacts . 
or there could be a lot of contacts uh with with these people . 
especially at uh georgia tech . 
i know on next week on tuesday . 
tuesday right . 
we will go to u . c . b . 
there are three guys . 
then morgan mentioned one . 
i do not know exactly um uh what he is doing . 
but he ' s also interesting in some kind of collaboration . 
he ' s also a professor in the u . c . b . 
and uh many universities . 
maybe claudia mentioned duisburg . 
and uh in principle most of the university have some activities in that area . 
we will not take care about these one . 
but we can use them as um for field uh field trial access . 
and and and maybe some support . 
and and whatever kind of thing . 
and we focus really on the networking stuff . 
and going in more detail in this area . 
and the alternative is maybe what uh 
currently we have only uh this uh proposal from wilbert to go more in the smaller scope . 
figure out some potential from maybe this uh wavelan u . m . t . s . stuff . 
and and starting from that . 
or are there other suggestions ? 
i think we uh have already so much work put into this proposal . 
why to switch now ? 
so i don ' t see the reason for that . 
maybe the application we suggested is not the best one . 
so we have to think about an application which which is um um for mobile users more relevant . 
i don ' t know . 
maybe video games . 
if you are traveling 
uh it ' s boring to travel . 
and then you decide to play a video game with somebody else who ' s traveling . 
yeah you know it ' s still mentioned in the proposal . 
so 
and 
um 
i i ' m sure okay that it is the wrong place to get the foundation why we are use this kind of application . 
but uh and in in the end of the text in the end of the text of the proposal . 
but it is mentioned that it is only an example . 
and that we use this application in principle while it is then very very easy to get a certain kind of access to these kind of things . 
when you have a video game server and and you want to have mobile access you must at least have one in your consortium or as a partner whatever who provides this service . 
and then we we are playing videos in principle if you have a field trial . 
and that is i think much more harder than to have a certain kind of certain kind of access to the university . 
and uh to this server which is run on the campus of the university . 
okay that ' s right . 
and that is the point . 
you can have this to figure out all the things . 
and the the um 
and the the um 
um now how to say the requirements of this application using this classroom scenario . 
but nevertheless it ' s not the best for 3 x . 
and and and and uh 
networking stuff . 
you are right . 
but it does anybody see certain kind of potential here to go on ? 
and to start the work maybe in this little bit smaller oh uh scope based on these building blocks . 
because multicast you still uh you mentioned that there is no potential . 
i think it ' s described here that the potential if you use it for the mapping to the next generation networks in the wireless access area they are still some potential to map multicast . 
because they do not use it . 
and to figure out whether they ' re useful instead of using certain kind of tunneling mechanism and to set up these tunnels 
and have the mapping between a p . s . d . n . uh telephone number or whatever kind of number they are using to i . p . addresses and then there ' s the tunnel i . d . ' s 
and and all this kind of things i think is very beneficial as well for for telecommunication providers . 
as well as for i . s . p . ' s . 
i i think the potential is still there . 
you you neglected that . 
but i don ' t think that you are right in that sense . 
well think it works . 
but uh 
yes the mapping of course between multicasting and the u . m . t . s . or or whatever . 
in next generation ? 
yeah . 
that ' s or c . d . m . a . or whatever that ' s uh yeah probably a thing that has to be find out . 
yeah . 
i don ' t know what statuses . 
maybe they already did it as part of u . m . t . s . 
i ' m not sure . 
i don ' t have a clue . 
i i only know how it works on copper and like ethernet . 
and on p . s . p . p . p . over something . 
and how it works like that . 
but on the wireless i ' m not sure . 
now what do you see about the 
um um 
k . p . n . interests . 
because i believe if the argument changes as follows that you are here and that you are very familiar with uh the multicast stuff and k . p . n . is very interesting in u . m . t . s . stuff and this is one potential target network environment we are focusing on but only for the uh i . p . layer technology then why do the mapping of also potential mapping of multicast i think must be of major interest for them . 
right ? 
one question . 
yes but if if it ' s available 
that means 
so so if uh if it ' s already part of the u . m . t . s . standardization then uh it ' s immediately finished . 
like okay you can tell k . p . n . well go to ericsson or nokia and buy it . 
and if it ' s not in there yet well it could be a suggestion . 
and then the hardware people will make it part like the etsi or whatever where u . wherever u . m . t . s . is standardized they will well go for it . 
uhhuh . 
of course yeah this this group could do that too . 
could be . 
but 
i have a an important doubt about the i . p . availability over u . m . t . s . 
i mean you know that the carriers and some manufacturers have done an important effort in developing this web thing . 
and uh i ' m not sure what they plan to do with next generation . 
i mean are they maintaining are they holding the same web technology ? 
or are just they discarding this technology ? 
and forgetting about the thing . 
i i don ' t know what will happen . 
uh i i don ' t have a clue . 
probably if after searching a little bit on the on the net i can get the answer . 
but initially this is something to to to have in mind . 
i mean because maybe this u . m . t . s . thing will appear on the market without i . p . as a native protocol . 
and if this is the case well thus seamless integration could be strongly affected . 
at least uh if you we want to use u . m . t . s . 
i ' m i ' m just uh throwing the question . 
uh i mean looking for an answer . 
because i don ' t know if uh some of you have a clue about this . 
i don ' t know what what carriers are planning to do about this . 
i ' m not really sure . 
but i thought i i had the impression that we can throw away our nokia stuff when our web gateways when we even go to g . p . r . s . 
so 
let alone u . m . t . s . 
now wap is ja not only related now to available bandwidth . 
that ' s the impression i get . 
that ' s not the only thing . 
it ' s only the adaptation towards the capabilities of the end device . 
right ? 
yeah definitely . 
so 
uh i never was a friend 
but but still a it ' s a it ' s a fundamental 
huh . 
yeah . 
uh it ' s a part of a of design like the the 
the terminal has a wap stick . 
and there ' s a box that has also a a wap stick . 
so yeah . 
and they do sometime most cases they do share an i . p . address . 
but doesn ' t uh have to deal with i . p . at all . 
it ' s just a thirty bit number . 
uhhuh . 
that actually is an assigned number . 
but it ' s all only used for identification . 
that ' s the only thing . 
it ' s stored in a wap cookie . 
much like h . t . p . 
in a cookie and from the wap gateway 
then it will be h . t . p . real h . t . p . or something . 
so it ' s it ' s really a different uh type of connection . 
it looks a little bit like uh the the well w . m . l . looks a little bit like h . t . m . l . 
but that ' s all what ' s uh 
it ' s not i . p . at all . 
right . 
because there is a gateway you can access with almost the same microbrowser . 
the same uh web servers . 
if they provide the right content uh spit out the right uh w . m . l . language . 
so it ' s it ' s really a different network technology i think . 
yeah . 
it ' s transparent in principle what you can carry . 
but 
anyway you have the gateway . 
it must be uh the uh uh conversion of the media . 
yeah . 
but 
of the contents in principle . 
but i don ' t see that uh 
it ' s too late i believe . 
if wap was available in the beginning of g . s . m . then i think it was there would be a good chance that it is well deployed . 
uhhuh . 
but now the first generation of web - browsers are in the and and uh i would say handies . 
so that ' s wrong in the mobile phones . 
but the the next generation of networks are still available . 
and the uh the bandwidth constraints are no more applicable . 
well 
right now there is still a lot of wap actually . 
and 
so that the 
uhhuh . 
yeah but the hype . 
but 
pffft 
uh 
well users usage . 
i never saw a user using wap . 
please raise your hand who is using wap . 
my colleagues are . 
yeah ? 
yeah . 
yeah they are using wap . 
yeah ? 
okay one of six . 
so 
i don ' t have a mobile phone . 
yeah . 
oh . 
who is using mobile phones ? 
well you don ' t have a mobile phone in in the u . s . a . here . 
no . 
no . 
so that ' s maybe the reason . 
not me . 
and i ' m not i doubt that it ' s not available in germany . 
it ' s would be unbelievable to me . 
now do you yeah do you see the chance for wap ? 
i don ' t see it . 
it it is . 
in in in sweden it is also there . 
and in the netherlands it is also available . 
huh . 
every provider provides 
in spain it ' s available . 
but uh you know uh my main complaint has been all the time that it is difficult to me to believe that i can do interesting work with a 4 lines display . 
uh maybe check the lottery result or something like this . 
oh . 
yeah but 
oh ! 
i ' m the first one to admit that ' s a that it is a hype . 
but 
but and but i ' m i just wanted to say it is being used . 
but if it makes sense to me and to especially to have wap in in between no . 
i ' m not a supporter of it . 
huh huh - huh . 
so they have this optimized protocol to to transmit a few ascii bytes that can refresh the screen with a different animation every well second a few times . 
yeah . 
so that ' s that ' s true . 
i immediately agree . 
but the thing was you just asked well will will it be the same will there be wap for u . m . t . s . and so on q . p . r . s . 
well 
and well i don ' t have the answer . 
i i don ' t know what will 
but i thought it was not . 
i ' m just it ' s weird it ' s weird to stop doing it with g . p . r . s . 
yeah . 
uhhuh huh . 
but usually wap shouldn ' t is so general that it can be used with u . m . t . s . 
so if you still want to use wap with u . m . t . s . you might be able to do it . 
but 
yes . 
that shouldn ' t be your only way of 
there ' s a you can put the gateway . 
if you want to do it in a in a mobile phone want to implement it as a light stack or something . 
yeah . 
yeah . 
yes ? 
yep . 
sure . 
but usually that ' s not the reason to have u . m . t . s . 
no not not if you have a big uh web pad or something . 
yep . 
then you there there ' s an i . p . stack in it . 
uhhuh . 
and 
uhhuh . 
so maybe i would like to ask claudia 
huh . 
you read the proposal in the meantime ? 
yeah but the task changed really a lot . 
yeah . 
so i ' d i rather would like to 
yes that ' s right . 
and do you have some comments on it ? 
from the next this is version zero dot five right yeah . 
yeah but i ' d rather like to follow the discussion before i gave any comments . 
because it ' s really the first point is it ' s much more than it was before i left . 
so it ' s like five weeks in between so it ' s like that whew . 
that big now . 
that ' s right . 
and it really changed a lot . 
yeah . 
because the i mean i found the classroom inside . 
but the thing where i left the discussion was that we are talking about uh a classroom where you know everybody could look on with any kind of device and follow lectures or do exercise or whatever . 
so 
now we are talking about something which is much more precise . 
and the the range of stuff is maybe more narrow than before . 
so i ' d rather like to to follow it a bit and then to get more into the ideas . 
okay . 
can i do another one like 
u . m . t . s . or wireless generally are will be more expensive . 
and especially u . m . t . s . 
if they want to get back the money . 
so is it maybe a research topic to focus on the 
not really billing of course . 
i wouldn ' t 
but at least the different application of protocol based usage . 
so you have uh one connection one application uses f . t . p . whatever . 
bit voice or some other 
that those type of application you may might want to make more out of a megabit per second or something . 
could that be something ? 
or 
also we want to go more in the triple a . area right ? 
because billing alone 
or is 
no well it ' s 
or or um billing is related to accounting . 
accounting is related to authentification and authorization . 
yeah that ' s true . 
so 
and then you are still at the triple a . service uh activity . 
yeah that ' s right . 
and nobody is has the skills to deal with that . 
and then we are leaving our scope anyway . 
okay . 
my impression on this proposal is that every single block has some research done already . 
so multicast this means that there are many things done . 
oh what was it ? 
maybe i was routing mobility management . 
but no one actually put them together . 
yeah that ' s 
but so that ' s the big problem . 
that is a 
but the problem with this problem might be that it ' s too big . 
to put all these big pieces to 
what do you mean by put together ? 
so that you really have a complete a complete scenario . 
as it what i mean the synergy effect right ? 
from from 
yeah . 
you have in one scenario multicast quality of service routing and mobile um networking . 
yeah . 
uh . 
uhhuh . 
not just the islands alone . 
so why i wasn ' t 
well yeah uh hold myself back a bit with comments is uh because when i left the discussion the discussion was what to to have something like a big umbrella about everybody who was at this point here . 
and so the discussion was much broader than it is maybe right now . 
and there i had the impression the umbrella was this kind of classroom thing . 
right ? 
or wrong ? 
yeah in principle it is related to the current state . 
but the networking stuff is more explained in much more detail . 
yeah yeah yeah it is . 
of course . 
and the work packages are better oder what could be derived for work packages is much better aligned . 
yeah . 
yeah yeah yeah . 
that ' s that ' s clear . 
but that has not changed yeah ? 
yeah that ' s that ' s clear . 
but then i don ' t get 
because when we were discussion discussing this uh stuff weeks ago uh i had the impression that you know everything of these work packages uh fit together under this one big umbrella . 
and now it sounds different . 
so that ' s what i don ' t understand . 
uh but it ' s also because i missed the last four weeks . 
so 
yeah the problem is if you 
it ' s a a bit hard for me to follow the development what happened in the last four weeks . 
yeah okay maybe one sentence one sentence . 
why it changed so . 
if you ' re focussing on the argument chain as follows i have an application . 
this application has certain kind of requirements . 
these requirements are maybe multicast and and and quality of service and mobility . 
access and then mobility management . 
and that is it . 
i want to focus on it . 
then you have in mind that or you must have in mind that all other applications and all other networking stuff is not affected by this . 
that you can use it with every application . 
and if you introduce some new mechanism in the network that is not related only to interactive multimedia applications like the classroom it must be fit end to end . 
and if you assume something like we discussed it very hard with with multicast that you assume that multicast will be available at certain portions of the network or if you if you want to have it end to end this mechanism must be applied really for all throughout of the internet . 
otherwise it makes no sense . 
and we come to the conclusion okay uh multicast we must deal with both approaches . 
that you have uh application layer multicast . 
as well as maybe some other multicast and maybe really multicast . 
and then the point is how to select these mechanism if you want to have not a certain kind of access to the server elsewhere in the network you want to use any application . 
so if i understand i it right what has changed is before we were focussing on 
yeah ? 
and 
so because what ' s difficult for me is what is meant by application . 
so because i have sometimes the impression that everybody is defining application in different way . 
so what exactly is mean by application ? 
the application for instance here that uh the interactive classroom . 
but elsewhere any application in in in any kind of video audio . 
yeah . 
oh okay . 
so what has changed 
or whatever kind of game server . 
what kind of interactive multimedia especially uh downstreaming applications maybe uh video on demand then uh whatever kind of application you can consider . 
so what has changed is that we ' re not only focussing on this intelligent classroom but on everything . 
not on everything . 
that ' s not true . 
but we 
that ' s why we say here that we have a certain kind of uh possibility to change in the access networks . 
uhhuh . 
that means the wireless networks . 
because that provides in principle the mobility . 
and these 
and you see that there ' s a trend to provide i . p . functionality more and more in these kind of networks . 
but the problem is that you could not focus on this kind of um technology only for the access network . 
you have to have in mind always the end to end scope . 
and if you see for instance we have routing algorithm but different protocols and whatever kinds of things 
especially also for multicast . 
different things really for different providers . 
and uh and it ' s uh very easy to change it maybe in the access network for novel things . 
for instance that ' s one provider domain . 
and you can say well why not use active routing in that provider domain . 
so it means that packet are delivering information . 
and you do not have the separation of routing and and and forwarding process . 
it ' s impossible to deal with that in the whole internet . 
because security reasons and whatever kinds of things make it impossible . 
so how to combine these uh potential um extensions in the um access networks and 
without losing the end to end scope in the internet . 
then you can have certain novel features . 
give the providers like k . p . n . or whatever the the potential in principle to to uh see the building blocks for the future networks . 
because there ' s a three third generation like u . m . t . s . a . fourth generation more i . p . related . 
there will be a fifth generation i ' m sure . 
and then you derive the certain kind of building blocks for this network . 
if you ever really full i uh uh full i . p . end to end . 
but nevertheless you can only not only focus on okay i provide this mechanism . 
because you are accessing a certain kind of server node in the internet using any application . 
and then this mechanism must fit it there . 
but nevertheless uh internet backbone is in the meantime based on its success . 
impossible to change . 
you see the difficulties with i . p . version six . 
uh uh you see the difficulties with multicast . 
they are discussed since you know ten years or whatever . 
the specification are rather stable and and available . 
but we have only islands in that . 
we cannot assume that everything is end to end available . 
and so you have to to have to have in mind that certain kinds of mechanisms are maybe at a certain stage end to end available . 
maybe we have a lucky that the islands are connected to each other . 
or the same applies for m . p . l . s . for instance . 
maybe they are only portions available . 
how to deal with that when the islands are not available ? 
and maybe nothing is available . 
but you have to select it . 
because i have a mobile phone a mobile node or whatever kind of device . 
and i want to contact a certain kind of content in the internet . 
so is it possible to have certain kind of normal features in the access network without losing the end to end scope of with these difficulties we are dealing with . 
i always say that the success of internet make it unflexible . 
it ' s impossible to change something very easy . 
it ' s easy maybe more on the access network as in the internet backbone . 
so that is uh overall picture that we have in mind with these things . 
and we can not 
we we are six people . 
or seven or whatever . 
if hannes come . 
we are not able to solve the problems uh in in uh in the few years or whatever . 
what the whole internet community has um done in in since uh since a decade . 
but we can pick up some some um potential and and and to start with something . 
and that ' s my missing point . 
that we have here in principle really the description of this problem i mentioned . 
and focus really on the reasonable size of the project . 
maybe in the first stage for the n . s . a . core itself . 
and maybe possible extension from for instance if k . p . n . say yes that ' s great . 
that ' s the right direction . 
we will support that . 
and if siemens say okay great we will support it . 
and and what it 
huh university of berlin or something . 
and maybe university of mannheim or duisburg . 
or in spain oder whatever . 
so if we have all the similar project then you have only to take care about that ' s a little bit aligned . 
that there ' s some transparency concerning the results . 
and and the activities are literally going in the in the same um pace . 
so that ' s the basic idea . 
but really it ' s to to figure out certain kind of smaller activities where we can start it . 
that ' s the point . 
and if we get some funding back 
and we have certain uh potential partners in the boat 
okay we can go to a broader scope of this whole thing yeah . 
let me let me propose a a a a reasoning way . 
uh let ' s assume that we are successful with this proposal . 
so we get the funding to do whatever what we want to do . 
so my question is what we want to do is 
let ' s assume that we have the funding . 
what will be our first and or or and second steps ? 
uh what kind of things uh we uh we will buy ? 
what kind of things we will uh program or we will deploy ? 
because answering this these questions we can know much better what the application we want . 
so let ' s assume 
yeah but the problem is that funding is the second step . 
huh . 
well i ' m not sure . 
i i i think i agree with him . 
but uh right now we ' re looking at a you want to do a big thing instead of a great thing . 
yeah . 
so if you assume that it should connect uh really good to siemens and to uh k . p . n . and to the then it starts to get big we should all go to the in the same direction . 
if you already assume well okay they paid money and now you think okay what what great thing you want to do then it gives you more freedom to think about this great thing you want to do . 
yeah but we have no uh current no public funding . 
no . 
okay everybody ' s paid here . 
yeah . 
yeah but but 
but you but you don ' t get one if you if you try to to align k . p . n . with siemens for instance . 
yeah . 
yeah . 
but 
yeah . 
yeah . 
but for theoretical or for historical reasons a really good question if we would have the money what would we do with that . 
uh 
so if we don ' t know what we would like to do with the money we probably wouldn ' t get any money to do what we don ' t know . 
uhhuh . 
that ' s right . 
absolutely . 
that ' s right . 
yeah . 
yeah . 
so that ' s why i think yeah it ' s a good question . 
yeah . 
now that ' s the point why i am focussing on more on the 
yep . 
yeah 
i want to have really the activities . 
you know what is really the outcome ? 
what is really the problem we are going to solve ? 
these are my questions . 
and if we have identified this block then it is possible to raise some money . 
yeah . 
that ' s just the same question just other way around . 
let let me put an example . 
you know i some days ago i bought like some of you this kind of things . 
this is a p . d . a . 
uh three com uh palm pilot compatible . 
modernistic stuff . 
nothing nothing that great . 
completely useless . 
but it has some some possibility of being expanded . 
but the point is uh the only in here the only thing wireless thing i can put on on this is just uh this omnisky modem . 
which is uh i think it is a subscription based uh thing . 
you have to pay every every month . 
and uh of course i cannot imagine that uh tomorrow i ' ll be able to buy a different thing with four different networks . 
four different providers on it . 
maybe i ' m wrong . 
but 
if i have the funding i say okay well i can buy this or even i can buy a mobile computer . 
a notebook . 
okay ? 
a lot more expensive . 
but that ' s okay . 
i have the funding . 
then i can add a couple of cards at most . 
because huh the majority of the of the notebooks only have two p . c . cards uh type two slots . 
so 
in in the better case maybe i ' m only able to add two different networks to this thing . 
so uh 
the difficulty i see is that uh if we are if you want to think in in two three four different technologies um maybe we are uh too advanced too um let ' s say uh too in advance for the current technology . 
which is not bad . 
but uh i ' m just saying that it will be able it will 
sorry . 
it will be difficult for us to develop a a reasonable test bed with the available technology . 
if somebody tell us okay now here you have the thing and just put these four networks you want on the thing how can i do it now ? 
so huh 
i ' m still trying to you know to get used to the uh all the ideas . 
and to see that all the things are really connecting . 
because this the uh most difficult thing i see to to to get this alignment to this connection point among the different things we are trying to align . 
so that ' s why i was proposing this this question . 
let ' s assume we have the funding . 
now let ' s proceed . 
what what kind of things we can buy we can put together we can program ? 
because oh at the end uh somebody will uh be asking us okay did you do your homework . 
did you do what you 
so 
it ' s clear . 
now from my point of view in the beginning one more time if i see the four building blocks and uh i could speak only for my skills i believe to derive a certain kind of q . s . reservation in advance scheme much more uh general as it is done for for u . s . a . i . a . 
uhhuh . 
but mapped then really to desired network subnet layer technologies . 
but for different networks ? 
yes . 
the point is for 
for 
no for u . m . t . s . 
but first of all a generic system . 
but because you can have several mechanism . 
really using certain kind of of um um quantitative description . 
you can have more of a qualitative description . 
you can have taken into account moving patterns . 
and and and whatever kind of things . 
but there are a lot of lot of ways to have certain kind of q . s . reservation in advance . 
and i see it as definitely is necessary to have this one . 
if i want be mobile and i want to have not a interruption of my in my application qualities of service . 
uhhuh huh . 
so 
um 
but then to go for instance to u . m . t . s . and figure out what is available within u . m . t . s . 
and if i really have an i . p . application where i need this kind of of quality of service and having in mind that certain kind of q . s . will be available in the rest of the internet 
so how can i map these things uh to the u . m . t . s . stuff ? 
and what is the trend towards u . m . t . s . to the first generation ? 
and how it is possible to map this one to this technology ? 
and if you have the building blocks identified what is really necessary for q . s . uh q . s . in advance for for mobile systems then you have in principle the ideas for the following generation what you could improve . 
uhhuh . 
because then you are maybe no more related to this kind of thing . 
i believe the same applies for multicast . 
and i believe the same applies for routing . 
so in principle in the beginning there would be a certain kind of uh paperwork anyway . 
some theoretical examination of these problems . 
i think so . 
and then some prototypes must be derived from that . 
and then maybe we will start here with a certain kind of uh testbed equipment we still have here . 
we have four uh p . c . ' s available . 
maybe we have to extend it then . 
and figure out some real scenarios . 
and maybe then pfff . 
oh yeah . 
because uh despite the 
uh uh hopefully then we have with the money also not uh only for the room . 
that would be great . 
but there are also some sponsors then then then we add a certain kind of field trial . 
but i think that ' s pfff that ' s years you know . 
a long way yeah . 
that ' s years . 
that ' s right . 
but in the beginning we must have a certain kind of theoretical framework with the relevant technology . 
real technology . 
maybe you can start with g . p . s . or or u . m . t . s . or whatever . 
because these technology will definitely available in europe . 
there ' s some money spent on it . 
so that it will be in a certain kind of flavor . 
it will be available . 
uhhuh huh . 
and it will be also available in the u . s . a . 
because there is a big uh harmonization effort . 
despite the fact they are not aligned to each other anyway . 
but they will have also certain kind of third generation and fourth generation networks . 
so 
and after this theoretical framework if this one is aligned okay you have some specification . 
and you set up some linux or free b . s . d . or whatever kind of prototype . 
so that is what i have in mind with that . 
and then okay and then you will see . 
uhhuh . 
the problem is which i see is that it could be fruitful to standardization . 
that it could be fruitful to some extent to telecommunication providers . 
but there ' s not a real product like you say . 
there ' s not the selling idea behind it . 
uhhuh huh . 
yeah ? 
if you go with something what what wilbert mentioned okay let ' s have this one here we have a new p . c . m . c . i . a . card and and extend something and the end system or what you mentioned here was the seamless four technologies inter working in the end then you have an an a device which you can sell . 
if you go for a networking pfff um uh improvements in principle and and understanding next generation building blocks uh there ' s no product . 
uhhuh . 
but it is a long term it ' s long term i think uh work you can do . 
and it ' s more related i believe to the skills . 
to what is available . 
and and currently as i see what uh will be available within the n . s . a . group . 
okay . 
and uh the point is if we focus on on this networking small more networking stuff and them some application guys came into the boat and they focus on their application stuff whatever this means it might be we have then the active classroom . 
but it could be another one . 
that is not representative . 
yeah but there ' s something needed to sell it . 
it ' s only 
huh ? 
and i think 
yeah . 
then then is something available . 
but i don ' t know . 
you know i ' m not an application expert . 
i 
we have some content . 
we will then discuss it on next tuesday as i mentioned . 
bless you . 
bless you . 
uh anyway but uh that were is my answer to the question if some money is available . 
the good thing is that the money is available . 
because everybody is paid here . 
so that is money that the the smallest portion of money which is available . 
uhhuh huh . 
but first of all wilbert need more definitely . 
because maybe then k . p . n . is uh no more interesting to go on with this work . 
or we can convince with these kind of things which we have in mind . 
uh companies like k . p . n . 
so 
and if we have other suggestions and uh have this as a long term 
n . s . a . core group activity . 
and this theoretical framework whether it is finished in half a year or one year doesn ' t matter in principle . 
because the road map for the the next generation networks is is uh is for many years . 
and before u . m . t . s . will be deployed very well i believe uh it will be common uh two thousand four or something like that . 
so 
and and have an intermediate project which is related in this direction something like the seamless handover for two technologies or whatever . 
this is a smaller portion in the more generic framework i would like to say from this proposal . 
why not go in this way ? 
okay . 
i i don ' t know . 
but uh that ' s the point uh we are sitting here together . 
yeah . 
but 
but for for dietmar i think uh uh he mentioned it to me it ' s very clear that he will go on with a portion of time with this u . s . a . i . a . stuff . 
that ' s right . 
it depends on my 
in the matical sense . 
because that means for you in a certain kind a certain extent you are decoupled from networking stuff . 
because your focusing on the mathematical thing of whether it ' s a network or other thing . 
well i ' m 
it doesn ' t matter . 
i ' m focused on performance evaluation . 
yeah . 
yeah . 
and um especially of communication networks . 
and 
yeah . 
i never uh um dealed with um mobile communications . 
so why not ? 
yeah . 
so 
so that ' s uh to open my mind . 
there is it still ongoing activity with uh maybe a portion of time at the university of berlin berlin . 
and independently whether i will leave the uh uh i . c . s . i . in in the mid of december or not i will still focus on on on these q . s . in advance schemes . 
uh also within siemens . 
and also with some project there . 
and i believe your routing stuff is also available . 
huh huh . 
uh 
and when you when you will go back to spain right ? 
yeah . 
yeah sure . 
yeah so and and that ' s why in principle the skills will be always available i guess . 
yeah . 
and and 
if there is a certain type of project in the home countries and then the uh institutions and 
uhhuh . 
not only this . 
we can even use this platform to to get some european projects in the future . 
because you know sometimes uh it ' s a good thing . 
yeah . 
maybe . 
currently no money is available you know . 
yeah but uh this will i think this will improve over time i ' m sure . 
so uh 
probably . 
you know this kind of joint work of different countries companies universities this is usually the best uh the best place to to put a project on . 
because it is involving different partners from different points of of europe . 
now i will not prevent anybody from getting some cake . 
and we are sitting here together . 
it ' s uh very uh very slow in principle . 
but my last question is for wilbert . 
wilbert you i i think you got the basic idea . 
because it was mostly discussed with you here from this current available scrap project proposal . 
don ' t you think that k . p . n . could be convinced to go on this way what i mentioned before ? 
there ' s no way . 
no . 
they needed definitely in principle some kind of service or device or product or whatever . 
yeah . 
that ' s right now the the status . 
yes . 
can we both have together maybe i think it ' s a little bit more easier a discussion on thursday ? 
i ' m out for one a week and a half . 
so on wednesday thursday friday i have a workshop at stanford . 
okay . 
and next week i have a week on holiday . 
okay . 
maybe that ' s enough time for you to consider a little bit more in this direction . 
could be . 
and then we could have uh discussion . 
and maybe this one is an overall work in principle where everybody could hook in and and get certain kind of small portions to solve it . 
yeah . 
so so the only solution would for for k . p . n . would be that there is a a project in this area . 
and 
so that makes sense to do in this this i mean the bay area . 
huh huh . 
with a group of uh a few people . 
like four or something . 
and that connects to this project . 
so one somebody or two some bodies can be found uh founded or get money to join this project . 
but that the other four should build a service on top of it that has a clear business focus . 
uhhuh . 
it means uh a a u . m . t . s . service basically . 
uhhuh . 
can you consider also in the meantime some potential u . m . t . s . services besides this one ? 
yeah . 
yeah but you see the the they ask something pretty strange . 
and 
they they want something pretty strange from me that i think of a service . 
a network service . 
there are sixty million billion people in the in the world that think of services all day . 
and try to make a lot of money with it in the form of start - ups or whatever . 
and just think of a service like that if i could do this . 
no but uh fff maybe based on this one and you see the networking stuff . 
that it is a little bit more evolved and than in the the core network technology in the access network i would like to say . 
uhhuh . 
and this is aligned then as much as possible to the internet . 
that ' s the basic idea . 
that you can have a certain kind of service which make use of these novel things . 
uhhuh . 
because normally i i believe the the the people are either on the application layer . 
i you know 
that means higher than layer four . 
or they are on layer one to up to layer four . 
and the service people are considering 
okay u . m . t . s . 
you have some location information . 
and maybe you are have the infrastructure in the car . 
so if i provide a certain kind of service independently what the network is offering you know . 
because they do not consider it very well . 
they know there is a certain kind of location information . 
and you have a g . p . s . 
and they know okay it ' s based on satellite . 
and there ' s u . m . t . s . that is based on base station . 
there ' s all that they consider . 
and then assume okay i can do that . 
and the networking guy said okay it would be great to have multicast and all these kind of things in the network . 
but do not consider really what a sense of benefit uh for applications . 
there were new old application make use of it . 
and how can new application arise . 
which we haven ' t considered up to now based on this new network function l . a . t . enrich enriched network function l . a . t . 
so i think it ' s worth to to consider something in that way . 
well until now i have been trying to think about it . 
but uh to me 
what i have every every time i encountered it it is all this is all pretty close by . 
like the industry is already behind this . 
yeah what is our 
so they they want to make this available pretty soon . 
so i ' m just trying to think uh more ahead like uh use the wireless device as a only as a signalling thing or something . 
so so whenever you come in with your uh g . s . m . phone and there is a p . c . available like everything will be directed to the the bigger device or something . 
so more services like that . 
i think they are working pretty hard to get i . p . available very good and efficiently from uh two mobile devices or wireless devices . 
not currently there is a technology split . 
a thing 
of course you have i . p . in the mobile device . 
but if you see the strange protocols text . 
there ' s i . p . over i . p . and tunnels and and whatever . 
so but it ' s uh looks very strange to me . 
because you have different numbering screens concerning you have a phone number . 
you have to map it to i . p . addresses . 
and and so on . 
but for me you have not the end to end parts of for for i . p . functionality . 
we are far away from that . 
and if you take a really look to the g . p . r . s . protocols texts and i believe also they apply for u . m . t . s . but i ' m not 
uh very familiar with that . 
and the next generations access network is will come soon . 
you see it ' s every three years or four years they will have a new generation . 
and there ' s a we 
but anyway you 
our group might want to focus on the uh i . p . over ether no nets . 
yeah . 
yeah . 
or something like 
or over ether . 
why ? 
what kind what kind i . p . over what do you call it ? 
no nets . 
no net ? 
yeah . 
that would be great . 
over 
like only over ether . 
carefully integrated for net . 
but there is no net . 
if you want to do make like also for wireless devices end to end i . p . available that could be a vision . 
like 
can you repeat it ? 
well so he he says well i . p . to i . p . or end to end i . p . is far well it ' s far away . 
um 
so you what you might want to do is well get u . m . t . s . out there . 
and just do uh i . p . ' s playing over radio . 
uhhuh . 
something like that is my final vision . 
like like s . d . h . i . p . over fiber or w . d . w . d . m . 
uhhuh . 
this gets rid of the s . d . h . 
or well start with get rid of the a . t . m . first . 
yeah . 
a . t . m . stuff . 
yeah . 
yeah . 
and then get rid of s . d . h . 
there ' s the problem is is you see that the providers uh have always there broken view for for the management . 
if you have different kind of protocols texts and network management system and the billing system and all these kinds of things which is besides the networking stuff in principle but you still need it is uh not aligned . 
yeah . 
we have it for different islands . 
uhhuh huh . 
and and 
well that ' s my final vision you know . 
if you have really then i . p . networks at a certain generation where you have really the physical media and where necessary uh additional maclear protocols . 
and then you have really always end to end . 
it makes you things much more simple much more easier . 
uh 
uh but is far far away you know . 
unless unless we speak about quality of service . 
yeah . 
yeah . 
yeah . 
which is not uh embedded on on i . p . services . 
yeah but you have the extension for the uh quality of service mechanism . 
yeah but 
which you have to map then to the underlying technology . 
yeah but for example nobody ' s really using r . s . v . p . 
and 
yeah but maybe in the lan interface it makes . 
since to use it 
uh you guys do that discussion later on please . 
and and but 
yeah . 
uh ? 
but i think we we will miss the cake . 
okay sorry sorry . 
r . s . v . p . 
and i think we should stop now but please everybody 
short 
uh 
go on with considerations and potential . 
and and uh 
um we didn ' t make much progress today in the meeting . 
but anyway this kind of activity lives from all from the input of all . 
and so i really 
if somebody has an idea send an email . 
and then i would like to enforce everybody 
not that i ' m doing everything . 
i could not i didn ' t have the time in the past . 
and i will not have it in the future . 
and maybe i will stay here only four weeks or five weeks . 
so it would be really not the best thing if the activity is dead when i am leaving . 
and if i stay longer of course we can go on . 
but nevertheless i rely heavily uh also from the contributions of everybody . 
and it ' s in their own interest . 
uhhuh huh . 
that ' s right . 
so if there is certain kind of idea or questions or whatever we are only a small group of people . 
we can easily join on a white board and and start a discussion . 
well if klaus 
it must not be on every tuesday you know . 
okay . 
at a certain time . 
and i try to motivate the people . 
that it ' s free . 
that ' s a starting . 
that ' s a ramp . 
and we can go in different directions . 
and if you have a real focus on the certain novel thing for the services or u . m . t . s . or whatever great . 
if not the long term and then these things must be nevertheless must be defined in much more detail . 
yeah . 
okay ? 
so thanks . 
okay . 
okay . 
please do not um what adam mentioned to . 
not to switch off . 
uh switch off . 
don ' t switch it off . 
do not don ' t switch it off . 
okay . 
yeah that ' s right . 
so maybe i will find him . 
oh can you call adam ? 
cake area . 
at this number . 
and 
now let me see whether he will be here . 
and 
we did not forget . 
we are done . 
yeah just leave them on for now . 
sometimes if you turn it off while it ' s recording it crashes . 
okay okay . 
hopefully everything went fine . 
gee here we all are ! 
uh 
so the only agenda items were jane was jane wanted to talk about some of the i b m transcription process . 
there ' s an agenda ? 
i sort of condensed the three things you said into that . 
and then just i only have like this afternoon and maybe tomorrow morning to get anything done before i go to japan for ten days . 
so if there ' s anything that absolutely desperately needs to be done you should let me know now . 
uh and you just sent off a eurospeech paper . 
so 
right . 
i hope they accept it . 
i mean i 
right . 
both as as a submission and you know as a paper . 
um 
but 
well yeah you sent it in late . 
yeah i guess you first you have to do the first one . 
yeah . 
and then 
yeah . 
we actually exceeded the delayed deadline by another day . 
so 
oops . 
oh they they had some extension that they announced or something ? 
well yeah . 
liz had sent them a note saying could we please have another i don ' t know three days or something . 
and they said yes . 
and then she said did i say three . 
i meant four . 
oh . 
that was the other thing . 
uh 
but 
uh dave gelbart sent me email i think he sent it to you too that um there ' s a special topic section in in eurospeech on new corpora . 
and it ' s not due until like may fifteenth . 
oh this isn ' t the aurora one ? 
it ' s another one ? 
no . 
no . 
it ' s a different one . 
it ' s 
huh ! 
yeah . 
yeah . 
and uh 
oh ! 
i got this mail from 
i forwarded it to jane as i thought being the most relevant person . 
um 
so i thought it was highly relevant . 
that ' s 
yeah i ' m 
yeah . 
i think so too . 
have you did you look at the u r l ? 
um i haven ' t gotten over to there yet . 
but what our discussion yesterday i really i i want to submit one . 
uhhuh . 
was this smartkom message ? 
yeah . 
i think christoph draxler sent this . 
and you offered to to join me if you want me to . 
yeah . 
i ' ll help . 
but obviously i can ' t really do most of it . 
yeah . 
i think several people sent this . 
yeah that ' s right . 
yeah . 
so 
yeah . 
uhhuh . 
but any any help you need i can certainly provide . 
well 
yeah . 
that ' s that ' s a great idea . 
well 
there there were some interesting results in this paper though . 
for instance that morgan uh accounted for fifty six percent of the robustness meetings in terms of number of words . 
wow . 
in in terms of what ? 
number of words . 
in 
one 
wow ! 
okay . 
that ' s just because he talks really fast . 
do you mean 
no . 
oh . 
short words . 
because 
i 
is it partly uh correctly identified words ? 
or is it 
no well according to the transcripts . 
or just overall volume ? 
yeah . 
but well regardless i think it ' s he ' s he ' s in all of them . 
oh okay . 
i mean we didn ' t mention morgan by name . 
and he talks a lot . 
we just 
well we have now . 
one participant . 
we we we something about 
but 
did you identify him as a senior member ? 
no . 
we identify him as the person dominating the conversation . 
well . 
yeah . 
okay . 
i mean i get these a a r p things . 
but i ' m not really senior yet . 
right . 
but 
huh . 
um 
but uh other than that delightful result what was the rest of the paper about ? 
um 
well it was about it had three sections . 
you sent it to me . 
but i haven ' t seen it yet . 
uh 
three kinds of uh results if you will . 
uh the one was that the just the the amount of overlap . 
the good the bad and the ugly . 
um 
in terms of in terms of number of words . 
and also we computed something called a spurt . 
which is essentially a stretch of speech with uh no pauses exceeding five hundred milliseconds . 
um and we computed how many overlapped uh spurts there were and how many overlapped words there were um for four different corpora . 
the meeting recorder meetings . 
the robustness meetings . 
switchboard . 
and callhome . 
and found and sort of compared the numbers . 
um 
and found that the 
uh 
you know as you might expect the meeting recorder meetings had the most overlap . 
uh but next were switchboard and callhome . 
which both had roughly the same . 
almost identical in fact . 
and the robustness meetings were had the least . 
so 
one sort of unexpected result there is that uh two party telephone conversations have about the same amount of overlap . 
i ' m surprised . 
sort of in you know order of magnitude wise as uh as face to face meetings with multiple 
i have i had better start changing all my slides . 
yeah . 
also i in the levinson the pragmatics book in you know uh textbook there ' s i found this great quote where he says you know you know how people it talks about how uh how how people are so good at turn taking . 
uhhuh . 
yeah . 
yeah . 
and so they ' re so good that generally the overlapped speech does not is less than five percent . 
oh . 
that ' s interesting . 
so 
yeah . 
this is way more than five percent . 
did he mean face like face to face ? 
or 
well in real conversations . 
everyday conversations . 
huh . 
it ' s what these conversation analysts have been studying for years and years there . 
uhhuh . 
uhhuh . 
well of course no it doesn ' t necessarily go against what he said . 
but 
because he said generally speaking in order to to go against that kind of a claim you ' d have to big canvassing . 
huh . 
and in 
well he he made a claim . 
well 
well 
yeah we we have pretty limited sample here . 
also 
but 
five percent of time or five percent of what ? 
yeah . 
yeah i was going to ask that too . 
well it ' s time . 
yeah . 
exactly . 
so but still but still 
it ' s it ' s not against his conclusion . 
yeah . 
so 
it just says that it ' s a bell curve and that you have something that has a nice range in your sampling . 
yeah . 
so there are slight 
there are differences in how you measure it . 
but still it ' s you know the difference between um between that number and what we have in meetings . 
which is more like you know close to in meetings like these uh you know close to twenty percent . 
uhhuh . 
what was it like say in the robustness meeting for instance ? 
uhhuh . 
that 
but 
robustness meeting ? 
it was about half of the 
so in terms of number of words it ' s like seventeen or eighteen percent for the meeting recorder meetings and about half that for uh the robustness . 
maybe ten percent ? 
but i don ' t know if that ' s really a fair way of comparing between multi party conversations and two party conversations . 
then then then you have to 
yeah . 
i i i don ' t know . 
i mean that ' s just something 
yeah i just wonder if you have to normalize by the numbers of speakers or something . 
yeah . 
then yeah then normalize by by something like that . 
well we didn ' t get to look at that . 
yeah . 
that ' s a good point . 
yeah . 
yeah . 
but this obvious thing to see if if there ' s a dependence on the number of uh participants . 
good idea . 
i mean 
i bet there ' s a weak dependence . 
yeah . 
i ' m sure it ' s it ' s not a real strong one . 
right . 
right ? 
because not everybody talks . 
because 
right . 
right . 
yeah . 
you have a lot of a lot of two party subsets within the meeting . 
right . 
uhhuh . 
well regardless . 
so 
it ' s an interesting result regardless . 
right . 
and and and then and we also computed this both with and without backchannels . 
yes that ' s right . 
uhhuh . 
so you might think that backchannels have a special status because they ' re essentially just 
uhhuh . 
so did we all said uhhuh and nodded at the same time . 
right . 
but even if you take out all the backchannels 
so 
so basically you treat backchannels as nonspeech as pauses . 
uhhuh . 
uhhuh . 
you still have significant overlap . 
you know it goes down from maybe for switchboard it goes down from i don ' t know um i don ' t know fourteen percent of the words to maybe uh i don ' t know eleven percent or something . 
it ' s it ' s not a dramatic change . 
so it ' s 
uhhuh . 
anyway . 
so it ' s uh 
that was that was one set of results . 
and then the second one was just basically the the stuff we had in the in the h l t paper on how overlaps effect the recognition performance . 
huh . 
nope . 
right . 
uhhuh . 
and we rescored things um a little bit more carefully . 
we also fixed the transcripts in in numerous ways . 
uh but mostly we added one one number which was 
what if you uh basically score ignoring all 
so so the the conjecture from the h l t results was that most of the added recognition error is from insertions due to background speech . 
so we scored all the recognition results uh in such a way that the 
uh 
oh by the way who ' s on channel four ? 
yeah . 
you ' re getting a lot of breath . 
that ' s 
i was just wondering . 
yeah . 
that ' s me . 
uh well don ' s been working hard . 
that ' s right . 
okay . 
so so if you have the foreground speaker speaking here and then there ' s some background speech may be overlapping it somehow . 
um and this is the time bin that we used . 
then of course you ' re going to get insertion errors here and here . 
right . 
right ? 
so we scored everything . 
and i must say the nist scoring tools are pretty nice for this . 
where you just basically ignore everything outside of the uh region that was deemed to be foreground speech . 
and where that was we had to use the forced alignment uh results from for . 
so 
that ' s somewhat that ' s somewhat subject to error . 
but still we we uh don did some hand checking . 
and and we think that based on that we think that the results are you know valid . 
although of course some error is going to be in there . 
but basically what we found is after we take out these regions so we only score the regions that were certified as foreground speech the recognition error went down to almost uh the level of the non overlapped speech . 
so that means that even if you do have background speech if you can somehow separate out or find where it is uh the recognizer does a good job . 
that ' s great . 
yeah . 
even though there is this 
yeah i guess that doesn ' t surprise me . 
because with the close talking mikes the the signal will be so much stronger . 
right . 
right . 
uhhuh . 
uhhuh . 
um 
so 
what what sort of normalization do you do ? 
uh well we just we do you know 
i mean in you recognizer . 
in the s r i recognizer . 
well we do uh v t l vocal tract length normalization . 
and we uh you know we we uh make all the features have zero mean and unit variance . 
and 
over an entire utterance ? 
over over the entire over the entire channel . 
or windowed ? 
don ' t train 
over the 
but you know 
huh . 
um now we didn ' t re align the recognizer for this . 
we just took the old 
so this is actually a sub optimal way of doing it . 
right . 
right ? 
right . 
so we took the old recognition output . 
and we just scored it differently . 
so the recognizer didn ' t have the benefit of knowing where the foreground speech 
were you including the the lapel in this ? 
yes . 
and did the did did the did the the problems with the lapel go away also ? 
um it yeah . 
or 
for for insertions ? 
it not per i mean not completely . 
but yes . 
dramatically . 
less so . 
so we have to 
um 
i mean you still 
well i should bring the should bring the table with results . 
maybe we can look at it monday . 
i would presume that you still would have somewhat higher error with the lapel for insertions than 
yes . 
it ' s it ' s 
yes . 
yeah . 
yeah . 
because again looking forward to the non close miked case i think that we still 
uhhuh . 
i ' m not looking forward to it . 
it ' s the high signal to noise ratio . 
right . 
here that that helps you . 
right . 
so 
so that was number that was the second set of uh the second section . 
and then the third thing was we looked at uh what we call interrupts . 
although that ' s that may be a misnomer . 
but basically we looked at cases where 
uh so we we used the punctuation from the original transcripts . 
and we inferred the beginnings and ends of sentences . 
so 
you know 
did you use upper lower case also or not ? 
um 
huh ? 
upper lower case or no 
no . 
we only used you know uh periods uh question marks and exclamation . 
okay . 
and we know that there ' s that ' s not a very 
i mean we miss a lot of them . 
yeah . 
but but it ' s 
that ' s okay . 
but 
comma also or not ? 
no commas . 
no . 
and then we looked at locations where 
uh 
if you have overlapping speech and someone else starts a sentence you know where do these where do other people start their turns not turns really but you know sentences ? 
uh 
um 
so we only looked at cases where there was a foreground speaker . 
and then at the at the so the the foreground speaker started into their sentence and then someone else started later . 
okay ? 
somewhere in between the start and the end . 
and so what 
okay . 
sorry ? 
somewhere in between the start and the end of the foreground . 
yes . 
uh so that such that there was overlap between the two sentences . 
yeah . 
so the the question was how can we what can we say about the places where the second or or actually several second speakers um start their interrupts as we call them . 
three words from the end . 
at pause boundaries . 
and we looked at this in terms of 
um 
on t closures only . 
so so we had we had 
um 
to for for the purposes of this analysis we tagged the word sequences and and we time aligned them . 
um 
and we considered it interrupt if it occurred in the middle of a word . 
we basically you know considered that to be a interrupt as if it were at at the beginning of the word . 
so that if any part of the word was overlapped it was considered an interrupted word . 
uhhuh . 
and then we looked at the the the um you know the features that the tags . 
because we had tagged these word strings um that that occurred right before these these uh interrupt locations . 
tag by 
and the tags we looked at are the spurt tag . 
which basically says 
or actually 
sorry . 
end of spurt . 
so whether there was a pause essentially here . 
because spurts are a defined as being you know five hundred milliseconds or longer pauses . 
and then we had things like discourse markers . 
uh backchannels . 
uh disfluencies . 
um 
uh filled pauses . 
so the d s are for um the interruption points of a disfluency . 
so where you hesitate or where you start the repair there . 
uh what else do we had ? 
uh repeated you know repeated words is another of that kind of disfluencies and so forth . 
so we had both the beginnings and ends of these . 
uh so the end of a filled pause . 
and the end of a discourse marker . 
and we just eyeballed 
i mean we didn ' t really hand tag all of these things . 
we just looked at the distribution of words . 
and so every so yeah and okay uh and uhhuh were were the were deemed to be backchannels . 
and wow and so and uh right uh were um not right right is a backchannel . 
but so we sort of just based on the lexical um identity of the words we we tagged them as one of these things . 
and of course the the interruption points we got from the original transcripts . 
so 
and then we looked at the 
so we looked at the distribution of these different kinds of tags overall . 
uh and and and particularly at the interruption points . 
and uh we found that there is a marked difference . 
so 
that for instance after 
so at the end after a discourse marker or after backchannel or after filled pause you ' re much more likely to be interrupted than before . 
okay . 
and also of course after spurt ends . 
which means basically in inside pauses . 
so pauses are always an opportunity for 
so we have this little histogram which shows these distributions . 
and um 
i wonder 
you know it ' s it ' s it ' s not no big surprises . 
but it is sort of interesting from 
it ' s nice to actually measure it though . 
yeah . 
i wonder about the cause and effect there . 
in other words uh if you weren ' t going to pause you you will because you ' re being interrupted . 
well we ' re 
uh 
right . 
there ' s no statement about cause and effect . 
yeah . 
this is just a statistical correlation . 
right . 
no no no . 
right . 
i i see . 
yeah . 
yeah . 
but he yeah he ' s he ' s right . 
i mean maybe 
you weren ' t intending to pause at all . 
but you were intending to stop for fifty seven milliseconds . 
right . 
right . 
but then chuck came in . 
and so you paused for a second . 
yeah . 
right . 
so 
or more . 
uh and that was basically it . 
and and we so we wrote this . 
and then we found we were at six pages . 
and then we started cutting furiously . 
oops . 
and threw out half of the material again . 
and uh played with the latex stuff . 
and 
uh 
and until it 
made the font smaller and the narrows longer . 
font smaller . 
yeah . 
no no . 
well you couldn ' t really make everything smaller . 
but we we put 
put the abstract end . 
oh i i 
you know the the gap between the two columns is like ten millimeters . 
took out white space . 
yeah . 
so i shrunk it to eight millimeters . 
and that helped some and stuff like that . 
wasn ' t there wasn ' t there some result andreas ? 
yeah . 
i i thought maybe liz presented this at some conference a while ago about uh backchannels . 
uhhuh . 
uhhuh . 
uh 
and that they tend to happen when uh the pitch drops . 
you know you get a falling pitch . 
yeah . 
and so that ' s when people tend to backchannel . 
well 
do you 
we didn ' t talk about uh prosodic uh properties at all . 
right right . 
although that ' s i i take it that ' s something that uh don will will look at . 
but 
now that we have the data and we have the alignment . 
yeah we ' re going to be looking at that . 
so 
this is purely based on you know the words . 
and 
uhhuh . 
i have a reference for that though . 
oh you do ? 
yeah . 
uhhuh . 
so am i recalling correctly ? 
anyway so . 
about 
well i didn ' t know about liz ' s finding on that . 
uhhuh . 
but i know of another paper that talks about something . 
huh . 
that 
i ' d like to see that reference too . 
it made me think about a cool little device that could be built . 
okay . 
to 
uh 
to handle those people that call you on the phone and just like to talk and talk and talk . 
and you just have this little detector that listens for these drops in pitch and gives them the backchannel . 
and so then you hook that to the phone and go off . 
yeah . 
and do the do whatever you want to do . 
uhhuh . 
oh yeah . 
well 
while that thing keeps them busy . 
there ' s actually uh there ' s this a former student of here from berkeley . 
nigel nigel ward . 
do you know him ? 
uhhuh . 
sure . 
yeah . 
he did a system uh in 
he he lives in japan now . 
and he did this backchanneling automatic backchanneling system . 
right . 
it ' s a very 
oh . 
so exactly what you describe . 
but for japanese . 
huh . 
and it ' s apparently for in japanese it ' s really important that you backchannel . 
it ' s really impolite if you don ' t . 
and 
so 
huh . 
actually for a lot of these people i think you could just sort of backchannel continuously . 
and it would pretty much be fine . 
it wouldn ' t matter . 
yeah . 
yeah . 
that ' s that ' s what i do . 
random intervals . 
there was there was of course a monty python sketch with that . 
where the barber who was afraid of scissors was playing a a tape of clipping sounds and saying uhhuh . 
yeah . 
how about them sports teams ? 
anyway . 
so the paper ' s online . 
and 
i i think i uh i c c ' ed a message to meeting recorder with the u r l . 
so you can get it . 
yep . 
yeah . 
printed it out . 
um uh one more thing . 
haven ' t read it yet . 
yeah . 
so i i ' m actually about to send brian kingsbury an e mail saying where he can find the the the the material he wanted for the for the speech recognition experiment . 
so 
but i haven ' t sent it out yet . 
because actually my desktop locked up . 
like i can ' t type anything . 
uh 
so if there ' s any suggestions you have for that i was just going to send him the 
is it the same directory that you had suggested ? 
i made a directory . 
i called it 
um 
he still has his unix account here you know . 
he does ? 
yeah . 
yeah . 
and he and he ' s 
but but but he has to 
i ' d have to add him to meeting recorder i guess . 
he he said he would prefer f t p . 
but 
okay . 
and also um the other person that wants it there is one person at s r i who wants to look at the um you know the uh the data we have so far . 
okay . 
and so i figured that f t p is the best approach . 
so what i did is i um i made a new directory . 
after chuck said that would that was going to be a good thing . 
uh so it ' s f t p pub 
pub real . 
real . 
exactly . 
m t g c . 
what is it again ? 
c r 
r d r d r . 
ask dan ellis . 
or 
yeah . 
yeah . 
right . 
the same the same as the mailing list . 
and 
yeah . 
yeah . 
the no vowels . 
um 
and then under there 
yeah . 
um actually oh and this directory is not readable . 
it ' s only uh accessible . 
so in other words to access anything under there you have to be told what the name is . 
so that ' s sort of a quick and dirty way of doing access control . 
right . 
uhhuh . 
so 
uh and the directory for this i call it a s r zero point one . 
because it ' s sort of meant for recognition . 
so anyone who hears this meeting now knows the 
beta . 
and then then in there i have a file that lists all the other files . 
so that someone can get that file and then know the file names and therefore download them . 
if you don ' t know the file names you can ' t 
is that a dash or a dot in there ? 
i mean you can 
don ' t don ' t don ' t say . 
dash . 
anyway . 
so all i all i was going to do there was stick the the transcripts after we the way that we munged them for scoring . 
because that ' s what he cares about . 
and 
um 
and also and then the the waveforms that don segmented . 
i mean just basically tar them all up i mean for each meeting i tar them all into one tar file and g . zip them and stick them there . 
i uh put digits in my own home directory home f t p directory . 
and so . 
but i ' ll probably move them there as well . 
oh okay . 
okay . 
so we could point mari to this also for her march o one request ? 
yeah . 
march o one ? 
oh ! 
or 
you remember she was 
oh she wanted that also ? 
well she was saying that it would be nice if we had they had a 
or was she talking ? 
yeah . 
she was saying it would be nice if they had uh the same set . 
so that when they did experiments they could compare . 
right . 
but they don ' t have a recognizer even . 
yeah . 
um 
but yeah . 
we can send i can c c mari on this so that she knows 
yeah . 
so for the thing that 
that ' s good . 
we need to give brian the beeps file . 
right . 
so i was going to probably put it 
we can put it in the same place . 
yeah 
just put in another directory . 
well make make another directory . 
i ' ll make another directory . 
yeah . 
you don ' t 
exactly . 
yeah . 
yeah . 
yeah . 
and andreas um sampled . 
they are ? 
i think so . 
yeah . 
okay . 
um so either we should regenerate the original versions or um we should just make a note of it . 
oh . 
well 
okay because in one directory there ' s two versions . 
yeah that ' s the first meeting i cut both versions . 
okay . 
just to check which if there is a significant difference . 
and so i 
but 
okay . 
so but for the other meetings it ' s the downsampled version that you have . 
they ' re all downsampled . 
yeah . 
oh okay . 
oh that ' s important to know . 
okay . 
so 
we should probably uh give them the non downsampled versions . 
yeah . 
so 
okay . 
all right then i ' ll hold off on that and i ' ll wait for you to 
um 
probably by tomorrow . 
i can 
okay . 
i ' ll send you an email . 
all right . 
okay . 
yeah definitely they should have the full bandwidth version . 
okay . 
yeah . 
because i mean i think liz decided to go ahead with the downsampled versions because we can there was no like significant difference . 
well it takes it takes up less disk space for one thing . 
it does take up less disk space . 
and apparently it did even better than the original than the original versions . 
yeah . 
yeah . 
right . 
which you know is just probably random . 
yeah it was a small difference . 
but yeah . 
but um they probably want the originals . 
yeah . 
okay . 
okay . 
good . 
good that 
well it ' s a good thing that 
okay i think we ' re losing don and andreas at three thirty . 
right ? 
yeah . 
hey mon have to booga . 
okay . 
so 
that ' s why it was good to have andreas say these things . 
but 
so we should probably talk about the i b m transcription process stuff that 
okay . 
huh . 
so um you know that adam created um a a script to generate the beep file ? 
to then create something to send to i b m . 
and um 
you you should probably talk about that . 
but but you were going to to use the originally transcribed file . 
because i tightened the time bins . 
and that ' s also the one that they had already in trying to debug the first stage of this . 
and uh 
my understanding was that 
um 
i haven ' t i haven ' t listened to it yet . 
but it sounded very good . 
uhhuh . 
and and i understand that you guys were going to have a meeting today before this meeting . 
it was just to talk about how to generate it . 
um just so that while i ' m gone you can regenerate it if you decide to do it a different way . 
excellent . 
so uh chuck and thilo should now more or less know how to generate the file . 
okay . 
and the other thing chuck pointed out is that um since this one is hand marked there are discourse boundaries . 
right ? 
uhhuh . 
so so when one person is speaking there ' s breaks . 
whereas thilo ' s won ' t have that . 
oh . 
okay . 
so what what we ' re probably going to do is just write a script that if two chunks are very close to each other on the same channel we ' ll just merge them . 
uh interesting . 
yeah . 
yeah . 
oh sure . 
yeah sure . 
makes sense . 
so uh and that will get around the problem of the you know one word beep one word beep one word beep one word beep . 
yeah . 
uh . 
clever . 
yes . 
clever . 
yeah . 
excellent . 
yeah in fact after our meeting uh this morning thilo came in and said that um there could be other differences between the uh already transcribed meeting with the beeps in it and one that has just been run through his process . 
and that ' s the purpose . 
yeah . 
so tomorrow when we go to make the um uh chunked file for i b m we ' re going to actually compare the two . 
so he ' s going to run his process on that same meeting . 
great idea . 
and then we ' re going to do the beep ify on both and listen to them and see if we notice any real differences . 
beep ify ! 
okay . 
now one thing that prevented us from you you from applying 
exactly . 
the training . 
so that is the training meeting . 
yeah . 
and we know that . 
okay . 
uh we just want to if if there ' re any major differences between doing it on the 
uhhuh . 
oh interesting . 
uh . 
okay . 
huh . 
interesting idea . 
so this training meeting uh is that uh some data where we have uh very um you know accurate time marks for 
great . 
i went back and hand marked the the bins . 
i i mentioned that last week . 
okay . 
yeah . 
but the but there ' s yeah but there is this one issue with them in that there ' re there are time boundaries in there that occur in the middle of speech . 
because 
so 
like when we went to 
um 
when i was listening to the original file that adam had it ' s like you you hear a word then you hear a beep and then you hear the continuation of what is the same sentence . 
that ' s on the other channel . 
that ' s because of channel overlap . 
well 
and and so the 
huh 
so there are these chunks that look like uh that have uh 
it ' s 
i mean that ' s not going to be true of the foreground speaker . 
that ' ll only be if it ' s the background speaker . 
right . 
so you ' ll you ' ll have a chunk of you know channel a which starts at zero and ends at ten . 
and then the same channel starting at eleven . 
ending at fifteen . 
and then again starting at sixteen . 
ending at twenty . 
right ? 
so that ' s three chunks where actually we can just make one chunk out of that . 
uhhuh . 
which is a zero twenty . 
yeah . 
sure . 
that ' s what i just said . 
sure . 
yeah . 
yeah . 
so i just wanted to make sure that it was clear . 
yeah . 
i thought that was . 
so if you were to use these you have to be careful not to pull out these individual 
yeah . 
oh . 
i mean it 
right . 
i mean i mean what i would i was interested in is having a having time marks for the beginnings and ends of speech . 
by each speaker . 
well that ' s definitely a problem . 
uh because we could use that to fine tune our alignment process . 
to make it more accurate . 
yeah . 
battery . 
battery ? 
uhhuh . 
so 
uh 
it i don ' t care that you know there ' s actually abutting segments that we have to join together . 
that ' s fine . 
okay . 
but what we do care about is that the beginnings and ends um are actually close to the speech inside of that 
yeah . 
uh 
i think jane tightened these up by hand . 
okay . 
okay . 
yeah . 
so what is the sort of how tight are they ? 
uh it looks much better . 
yeah . 
looks good . 
they were um reasonably tight but not excruciatingly tight . 
oh . 
that would ' ve taken more time . 
i just wanted to get it so so that if you have like yeah in a swimming in a big bin then it ' s 
no no . 
i 
actually i i 
let me make a note on yours . 
i it ' s 
yeah . 
that ' s fine . 
because we don ' t want to 
that ' s perfectly fine . 
in fact it ' s good . 
you always want to have a little bit of pause or nonspeech around the speech say for recognition purposes . 
uh 
but just just you know get an i just wanted to have an idea of the of how much extra you allowed . 
um 
so that i can interpret the numbers if i compared that with a forced alignment segmentation . 
so 
i can ' t answer that . 
but but my main goal was um in these areas where you have a three way overlap and one of the overlaps involves yeah and it ' s swimming in this huge bin i wanted to get it so that it was more closely localized . 
uhhuh . 
uhhuh . 
right . 
but are we talking about i don ' t know a tenth of a second ? 
a 
you know ? 
how how much how much extra would you allow at most ? 
i i wanted to 
i wanted it to be able to be heard normally . 
uhhuh . 
so that if you if you play back that bin and have it in the mode where it stops at the boundary it sounds like a normal word . 
okay . 
it doesn ' t sound like the person . 
it sounds normal . 
it ' s as if the person could ' ve stopped there . 
uhhuh . 
okay . 
and it wouldn ' t have been an awkward place to stop . 
now sometimes you know it ' s these are involved in places where there was no time . 
and so there wouldn ' t be a gap afterwards because 
okay . 
i mean some cases there ' re some people um who who have very long segments of discourse where you know they ' ll they ' ll breath and then i put a break . 
uhhuh . 
but other than that it ' s really pretty continuous . 
and this includes things like going from one sentence into the one utterance into the next one sentence into the next . 
um 
without really stopping . 
i mean they 
you know in writing you have this two spaces and a big gap . 
uhhuh . 
you know ? 
right . 
but but uh some people are planning 
and you know i mean a lot we always are planning what we ' re going to say next . 
okay . 
but uh in which case the gap between these two complete syntactic units um which of course spoken things are not always complete syntactically . 
but but it would be a shorter shorter break than maybe you might like . 
uhhuh . 
but the goal there was to not have the text be so so crudely parsed in a time bin . 
i mean because from a discourse purpose it ' s it ' s more it ' s more useful to be able to see 
and also you know from a speech recognition purpose my impression is that if you have too long a unit it ' s it doesn ' t help you very much either . 
because of the memory . 
well yeah . 
that ' s fine . 
so that means that the amount of time after something is variable depending partly on context . 
but my general goal when there was sufficient space room pause after it to have it be kind of a natural feeling gap . 
okay . 
which i i don ' t know what it would be quantified as . 
you know wally chafe says that um in producing narratives the spurts that people use tend to be uh that the the what would be a pause might be something like two two seconds . 
huh . 
and um that would be you know one speaker . 
the discourse the people who look at turn taking often do use 
uhhuh . 
i was interested that you chose uh you know um the you know that unit you use . 
because i think that ' s a unit that would be more consistent with sociolinguistics . 
well we chose um you know half a second . 
yeah . 
because if if you go much larger you have a you know your your statement about how much overlap there is becomes less um precise . 
because you include more of actual pause time into what you consider overlap speech . 
uhhuh . 
um 
so 
it ' s sort of a compromise . 
and it ' s also based 
i mean liz suggested that value based on the distribution of pause times that you see in switchboard and and other corpora . 
uhhuh . 
um 
so 
yeah i also used i think something around zero point five seconds for the speech nonspeech detector . 
for the minimum silence length . 
uhhuh . 
i see . 
so 
yeah . 
uhhuh . 
okay . 
in any case this this uh meeting that i hand 
i hand adjusted two of them . 
i mentioned before . 
uhhuh . 
okay . 
and i sent i sent email . 
so so at some point we will try to fine tune our forced alignment . 
so 
and i sent the path . 
maybe using those as references . 
because you know what you would do is you would play with different parameters . 
and to get an you need an objective measure of how closely you can align the models to the actual speech . 
and that ' s where your your data would be very important to have . 
so i will 
um 
yeah and hopefully the new meetings which will start from the channelized version will will have better time boundaries and alignments . 
uhhuh . 
right . 
but i like this idea of uh for our purposes for the for the i b m preparation uh having these joined together . 
yeah . 
and uh 
yeah . 
it makes a lot of sense . 
and in terms of transcription it would be easy to do it that way . 
yeah . 
the way that they have with the longer units . 
yeah . 
not having to fuss with adding these units at this time . 
yeah . 
right . 
which could have one drawback if there is uh a backchannel in between those three things . 
uhhuh . 
the the the backchannel will will occur at the end of of those three . 
yes . 
and and in in the in the previous version where in the which is used now there the backchannel would would be in between there somewhere . 
i see . 
so 
yeah . 
that would be more natural . 
well 
but 
that ' s that ' s right . 
but you know this brings me to the other stage of this which i discussed with you earlier today . 
yeah . 
which is the second stage is um what to do in terms of the transcribers adjustment of these data . 
i discussed this with you too . 
um the 
so the idea initially was we would get uh for the new meetings . 
so the e d u meetings that thilo has now presegmented all of them for us on a channel by channel basis . 
and um 
so i ' ve assigned i ' ve i ' ve assigned them to our transcribers . 
and um 
so far i ' ve discussed it with one . 
with uh 
and i had a about an hour discussion with her about this yesterday . 
we went through uh e d u one at some extent . 
and it occurred to me that um that basically what we have in this kind of a format is you could consider it as a staggered mixed file . 
we had some discussion over the weekend about at at this other meeting that we were all at . 
um about whether the the i b m transcribers should hear a single channel audio or a mixed channel audio . 
and um in in a way by by having this this chunk and then the backchannel after it it ' s like a staggered mixed channel . 
and um it occurred to me in my discussion with her yesterday that um 
um 
the the the maximal gain it ' s from the i b m people may be in long stretches of connected speech . 
so it ' s basically a whole bunch of words which they can really do because of the continuity within that person ' s turn . 
so what i ' m thinking and it may be that not all meetings will be good for this but but what i ' m thinking is that in the e d u meetings they tend to be driven by a couple of dominant speakers . 
and if the chunked files focused on the dominant speakers then when when it got patched together when it comes back from i b m we can add the backchannels . 
it seems to me that um you know the backchannels per se wouldn ' t be so hard . 
but then there ' s this question of the time uh marking and whether the beeps would be uh 
and i ' m not exactly sure how that how that would work with the with the backchannels . 
and 
so um 
and certainly things that are intrusions of multiple words taken out of context and displaced in time from where they occurred that would be hard . 
so my thought is i ' m having this transcriber go through the e d one meeting and indicate a start time for each dominant speaker end time for each dominant speaker . 
and the idea that these units would be generated for the dominant speakers and maybe not for the other channels . 
yeah the only um disadvantage of that is then it ' s hard to use an automatic method to do that . 
the advantage is that it ' s probably faster to do that than it is to use the automated method and correct it . 
so 
well it 
okay . 
we ' ll just have to see . 
i think i i think um you know the original plan was that the transcriber would adjust the the boundaries and all that for all the channels . 
but you know that is so time consuming . 
and since we have a bottleneck here we want to get i b m things that are usable as soon as possible . 
then this seemed to me it ' d be a way of to get them a flood of data . 
which would be useful when it comes back to us . 
and um 
oh also at the same time she when she goes through this she ' ll be uh if there ' s anything that was encoded as a pause but really has something transcribable in it then she ' s going to uh make a mark . 
yeah . 
uh so you know that that bin would be marked as it as double dots . 
and she ' ll just add an s . 
and in the other in the other case if it ' s marked as speech and really there ' s nothing transcribable in it then she ' s going to put a dash . 
and i ' ll go through and it and um you know with a with a substitution command get it so that it ' s clear that those are the other category . 
i ' ll just you know recode them . 
but um um the transcribable events that um i ' m considering in this uh continue to be laugh as well as speech and cough and things like that . 
so i ' m not stripping things out anything . 
just just you know being very lenient in what ' s considered speech . 
jane ? 
yeah ? 
in terms of the this new procedure you ' re suggesting um what is the 
it ' s not that different . 
so i ' m a little confused . 
because how do we know where to put beeps ? 
is it is it 
oh okay . 
so what it what it what it involves is is really a uh uh the original procedure . 
transcriber will do it . 
but only applied to uh a certain strategically chosen aspect of the data . 
we pick the easy parts of the data basically . 
so 
and transcriber marks it by hand . 
you got it . 
and because 
but after we ' ve done thilo ' s thing . 
no . 
yes . 
oh after . 
yes . 
oh okay . 
oh yeah ! 
i didn ' t i didn ' t understand that . 
okay . 
so 
i ' m now i ' m confused . 
okay . 
we start with your presegmented version . 
okay and i ' m leaving . 
yeah i have to go as well . 
so um 
okay leave the mikes on . 
and just put them on the table . 
okay . 
thanks . 
we start with the presegmented version . 
let me mark you as no digits . 
you start with the presegmentation . 
yeah ? 
yeah . 
and then um the transcriber instead of going painstakingly through all the channels and moving the boundaries around and deciding if it ' s speech or not but not transcribing anything . 
okay . 
instead of doing that which was our original plan the they focus on the dominant speaker . 
uhhuh . 
they just do that on the main channels . 
yeah . 
so what they do is they identify who ' s the dominant speaker and when the speaker starts . 
okay . 
yeah ? 
okay . 
so i mean you ' re still going to 
so we ' re 
and you just 
it ' s based on your presegmentation . 
that ' s the basic thing . 
and you just use the the segments of the dominant speaker then for for sending to to i b m ? 
or 
yeah . 
exactly . 
so now jane my question is when they ' re all done adjusting the time boundaries for the dominant speaker have they then also erased the time boundaries for the other ones ? 
uhhuh . 
uh no no no . 
so how will we know who 
huh uh . 
yeah . 
that ' s that ' s why she ' s notating the start and end points of the dominant speakers . 
so on a you know so in e d u one as far as i listened to it you start off with a a section by jerry . 
so jerry starts at minute so - and - so . 
and goes until minute so - and - so . 
and then mark paskin comes in . 
and he starts at minute such and such . 
and goes on till minute so - and - so . 
okay . 
and then meanwhile she ' s listening to both of these guys ' channels . 
determining if there ' re any cases of misclassification of speech as nothing and nothing as speech . 
uhhuh . 
okay . 
and and adding a tag if that happens . 
so she does the adjustments on those guys ? 
but you know i wanted to say his segmentation is so good that um the part that i listened to with her yesterday didn ' t need any adjustments of the bins . 
on that meeting . 
uhhuh . 
so far we haven ' t . 
so this is not going to be a major part of the process . 
at least least not in not on ones that that really 
so if you don ' t have to adjust the bins why not just do what it for all the channels ? 
uhhuh . 
why not just throw all the channels to i b m ? 
well there ' s the question of whether 
well okay . 
she it ' s a question of how much time we want our transcriber to invest here when she ' s going to have to invest that when it comes back from i b m anyway . 
uhhuh . 
so if it ' s only inserting uhhuh s here and there then wouldn ' t that be something that would be just as efficient to do at this end instead of having it go through i b m then be patched together then be double checked here ? 
uhhuh . 
right . 
yeah . 
but 
but then we could just use the the output of the detector and do the beeping on it and send it to i b m . 
without having her check anything . 
right . 
yeah . 
well i guess 
for some meetings i ' m i ' m sure it 
i think we just we just have to listen to it and see how good they are . 
i ' m i ' m open to that . 
it was 
yeah if it ' s working well . 
that sounds like a good idea . 
that ' s and some on some meetings it ' s good . 
since as you say you have to do stuff with the other end anyway . 
yeah . 
well 
okay good . 
yeah i mean we have to fix it when it comes back anyhow . 
i mean the detector this 
yeah . 
now you were saying that they they differ in how well they work depending on channel systems and stuff . 
yeah . 
so we should perhaps just select meetings on which the speech nonspeech detection works well . 
but e d u is great . 
and just use those meetings to to to send to i b m and do the other ones . 
release to begin with . 
how interesting . 
what ' s the problem the i forget . 
you know 
is the problem the lapel ? 
or or 
uh it really depends . 
um my my my impression is that it ' s better for meetings with fewer speakers . 
and it ' s better for for meetings where nobody is breathing . 
oh . 
the dead meetings . 
yeah . 
get 
that ' s it . 
so in fact this might suggest an alternative sort of a a a hybrid between these two things . 
no the undead meeting . 
yeah . 
yeah . 
yeah ? 
so the the one suggestion is you know we we run thilo ' s thing . 
and then we have somebody go and adjust all the time boundaries . 
yeah ? 
and we send it to i b m . 
yeah . 
the other one is we just run his thing and send it to i b m . 
there ' s a another possibility if we find that there are some problems . 
yeah . 
yeah . 
and that is if we go ahead and we just run his and we generate the beeps file then we have somebody listen beeps file . 
yeah . 
yeah . 
and they listen to each section and say yes no whether that section is 
and erase . 
yeah . 
is intelligible . 
intelligible or not . 
and it just you know there ' s a little interface which will for all the yes it then that will be the final beep file . 
yeah . 
blech . 
that ' s interesting . 
because that ' s that ' s directly related to the end task . 
stress test . 
uhhuh . 
how interesting ! 
yeah . 
i mean it wouldn ' t be that much fun for a transcriber to sit there hear it beep yes or no . 
nope . 
i i i don ' t know . 
but it would be quick . 
it would be kind of quick . 
but they ' re still listening to everything . 
but there ' s no adjusting . 
and that ' s what ' s slow . 
there ' s no adjusting of time boundaries . 
well uh listening does take time too . 
yeah . 
yeah . 
i don ' t know . 
i i think i ' m i ' m really tending towards 
one and a half times real time . 
i mean what ' s the worst that happens ? 
do the transcribers 
i mean as long as on the other end they can say there ' s there ' s something conventions so that they say huh . 
yeah . 
right . 
and then we can flag those later . 
they they 
yeah . 
it 
that ' s true . 
we can just catch it at the catch everything at this side . 
yeah . 
well maybe that ' s the best way to go . 
just 
how interesting . 
i mean it just depends on how 
well e d u 
yeah . 
sorry go ahead . 
so i was going to say e d u one is good enough . 
yeah . 
maybe we could include it in this in this set of uh this stuff we send . 
yeah there ' s i i think there are some meetings where it would would it ' s possible like this . 
yeah i i think we won ' t know until we generate a bunch of beep files automatically listen to them and see how bad they are . 
yeah . 
yeah . 
yeah . 
we won ' t be able to include it with this first thing . 
uhhuh . 
huh . 
if 
oh okay . 
because there ' s a part of the process of the beep file which requires knowing the normalization coefficients . 
oh i see . 
and so 
that ' s not hard to do . 
just it takes you know it just takes five minutes rather than taking a second . 
yeah . 
right . 
except i don ' t think that the the instructions for doing that was in that directory . 
so i just hand hard coded it . 
right ? 
i i didn ' t see where you had 
no but it ' s easy enough to do . 
what 
but i but i have a 
doing the gain it ' s no problem . 
doing 
adjusting the gain ? 
no getting the coefficients . 
for each channel . 
know what numbers . 
yeah that ' s no problem . 
okay . 
so we just run that one 
we can do that . 
there are lots of ways to do it . 
i have one program that ' ll do it . 
yeah . 
you can find other programs . 
i i used it . 
we just run that j sound stat ? 
so 
yep . 
yeah . 
yeah . 
okay okay . 
minus d capital d . 
but 
yeah . 
but but i i i have another suggestion on that which is since really what this is is is is trying to in the large send the right thing to them and there is going to be this this post processing step . 
um 
why don ' t we check through a bunch of things by sampling it ? 
uhhuh . 
right ? 
in other words rather than um uh saying we ' re going to listen to everything 
i didn ' t mean listen to everything . 
i meant just see if they ' re any good . 
yeah . 
so you do a bunch of meetings . 
you listen to to a little bit here and there . 
yeah . 
if it sounds like it ' s almost always right and there ' s not any big problem you send it to them . 
send it to them . 
yeah . 
okay . 
and you know then they ' ll send us back what we what what they send back to us . 
oh that ' d be great . 
and we ' ll we ' ll fix things up . 
and some meetings will cost more time to fix up than others . 
we should 
yeah . 
yeah . 
and we should just double check with brian on a few simple conventions on how they should mark things . 
okay . 
sure . 
when they when there ' s either no speech in there . 
yeah . 
or something they don ' t understand . 
yeah . 
yeah . 
things like that . 
uhhuh . 
yeah . 
yeah because what i had originally said to brian was well they ' ll have to mark when they can ' t distinguish between the foreground and background . 
because i thought that was going to be the most prevalent . 
uhhuh . 
but if we send them without editing then we ' re also going to have to have uh notations for words that are cut off . 
yeah . 
uhhuh . 
yeah . 
and other sorts of uh acoustic problems . 
and they may just guess at what those cut off words are . 
they do already . 
yeah . 
but i mean we ' re going to adjust everything when we come back . 
but what what we would like them to do is be conservative . 
so that they should only write down the transcript if they ' re sure . 
yeah . 
and otherwise they should mark it so that we can check . 
mark it . 
sure . 
yeah . 
yeah . 
uhhuh . 
well we have the unintelligibility convention . 
and actually they have one also . 
uhhuh . 
right . 
which 
can i maybe have have an order of 
it ' s probably in your paper that i haven ' t looked at lately . 
but 
uh an order of magnitude . 
certainty . 
notion of of how on a good meeting how often uh do you get segments that come in the middle of words and so forth ? 
and uh in a bad meeting how often ? 
uh . 
was is it in a in a what what is the 
well he ' s saying you know that the the e d u meeting was a good good meeting . 
in a good meeting . 
what 
yeah . 
right ? 
yeah . 
uh and so so so it was almost it was almost always doing the right thing . 
oh i see . 
the characteristics . 
so i wanted to get some sense of what what almost always meant . 
and then uh in a bad meeting or some meetings where he said oh he ' s had some problems what does that mean . 
uhhuh . 
so i mean does one of does it mean one percent and ten percent ? 
okay . 
or does it mean five percent and fifty percent ? 
okay . 
uh 
so 
or maybe percentage isn ' t the right word . 
just . 
but you know how many how many per minute . 
yeah 
or 
you know . 
yeah . 
the the problem is that nnn the numbers ian gave in the paper is just uh some frame error rate . 
so that ' s that ' s not really what will be effective for for the transcribers is . 
they have to yeah they have to insure that that ' s a real spurt or something . 
and but the numbers 
oops ! 
um 
huh . 
let me think . 
so the speech the amount of speech that is missed by the detector for a good meeting i is around or under one percent i would say . 
but there can be 
yeah . 
for 
yeah . 
but there can be more 
there ' s there ' s more amount speech . 
uh more amount of 
yeah well the detector says there is speech . 
but there is none . 
so that that can be a lot when when it ' s really a breathy channel . 
but i think that ' s less of a problem . 
they ' ll just listen . 
yeah . 
it ' s just wasted time . 
yeah . 
and and that ' s for a good meeting . 
now what about in a meeting that you said we ' ve you ' ve had some more trouble with ? 
i can ' t really hhh tsk i don ' t have really representative numbers i think . 
that ' s really 
i i did this on on four meetings and only five minutes of of every of of these meetings . 
so it ' s not not that representative . 
but 
it ' s perhaps 
um 
yeah it ' s perhaps then it ' s perhaps five percent of something . 
which uh the the frames speech frames which are which are missed . 
but um i can ' t can ' t really tell . 
right . 
so i so sometime we might want to go back and look at it more in terms of how many times is there a spurt that ' s that ' s uh interrupted . 
yeah . 
yeah . 
yeah . 
something like that . 
the other problem is that when it when it uh on the breathy ones where you get breathing uh indicated as speech . 
and 
so 
and i guess we could just indicate to the transcribers not to encode that if they 
we could still do the beep file . 
yeah again i i think that that is probably less of a problem . 
because if you ' re if there ' s if if a if a word is is split then they might have to listen to it a few times to really understand that they can ' t quite get it . 
okay . 
okay . 
okay . 
whereas if they listen to it and there ' s don ' t hear any speech i think they ' d probably just listen to it once . 
but 
yeah . 
so there ' d you ' d think there ' d be a a factor of three or four in in uh cost function . 
okay . 
you know between them or something . 
yeah . 
so but i think that ' s that really doesn ' t happen very often that that that a word is cut in the middle or something . 
that ' s that ' s really not not normal . 
so so what you ' re saying is that nearly always what happens when there ' s a problem is that is that uh there ' s some uh uh nonspeech that uh that is interpreted as speech . 
that is marked as speech . 
yeah . 
yeah . 
well then we really should just send the stuff . 
that would be great . 
right ? 
because that doesn ' t do any harm . 
yeah . 
you know if they they hear you know a dog bark and they say what was the word . 
it ' s 
they you know they 
yeah i i 
ruff ruff ! 
yeah i also thought of there there are really some channels where it is almost um only breathing in it . 
yeah ? 
and to to re run ' s 
uh um yeah i ' ve got a a p a method with loops into the cross correlation with the p z m mike . 
uhhuh . 
and then to reject everything which which seems to be breath . 
so i could run this on those breathy channels . 
and perhaps throw out 
that ' s a good idea . 
wow that ' s a great idea . 
yeah . 
but i think i again i think that sort of that that would be good . 
and what that ' ll do is just cut the time a little further . 
yeah . 
uhhuh . 
yeah . 
but i think none of this is stuff that really needs somebody doing these these uh uh explicit markings . 
yeah . 
excellent . 
oh i ' d be delighted with that . 
i i was very impressed with the with the result . 
yeah . 
yeah because the other thing that was concerning me about it was that it seemed kind of specialized to the e d u meeting . 
and and that then when you get a meeting like this or something . 
yeah . 
and and you have a a bunch of different dominant speakers . 
oh yeah . 
interesting . 
you know how are you going to handle it ? 
whereas this sounds like a more general solution . 
oh yeah . 
is 
oh yeah . 
i i much prefer this . 
i was just trying to find a way 
yeah . 
because i i don ' t think the staggered mixed channel is awfully good as a way of handling overlaps . 
uhhuh . 
but 
well good . 
but uh 
that that really simplifies thing then . 
yeah . 
and we can just you know get the meeting . 
process it . 
put the beeps file . 
send it off to i b m . 
you know ? 
uhhuh . 
with very little work on our side . 
yeah . 
process it . 
hear into it . 
i would 
do what ? 
um listen to it . 
and then 
or at least sample it . 
well sample it . 
yeah . 
i i would just use some samples . 
sample it . 
yeah . 
yeah . 
make sure you don ' t send them three hours of bzzz or something . 
yeah . 
yeah . 
yeah . 
no . 
right . 
that won ' t be good . 
yeah . 
yeah . 
yeah that would be very good . 
yeah . 
and then we can you know 
yeah . 
that ' ll ought to be a good way to get the pipeline going . 
oh i ' d be delighted . 
yeah . 
and there ' s there ' s one point which i uh yeah which which i we covered when i when i listened to one of the e d u meetings . 
great . 
and that ' s that somebody is playing sound from his laptop . 
uhhuh . 
and the speech nonspeech detector just assigns randomly the speech to to one of the channels . 
so 
i i didn ' t think of of of this before . 
what can you do ? 
but what what shall we do about things like this ? 
well you were suggesting you suggested maybe just not sending that part of the meeting . 
yep huh . 
but 
but 
sometimes the the the laptop is in the background . 
and some somebody is is talking . 
and that ' s really a little bit confusing . 
but 
that ' s life . 
it ' s a little bit confusing . 
yeah . 
i mean what ' re we going to do ? 
yeah . 
okay . 
yeah . 
even a hand transcription would 
do you 
a hand transcriber would have trouble with that . 
yeah . 
that ' s that ' s a second question . 
so 
what what will different transcribers do with with the laptop sound ? 
what was the what was the laptop sound ? 
would you would 
yeah go ahead . 
i mean was it speech ? 
or was it 
yeah . 
it ' s speech . 
great . 
well 
so 
i mean 
so my standard approach has been if it ' s not someone close miked then they don ' t end up on one of the close miked channels . 
they end up on a different channel . 
and we have any number of channels available . 
uhhuh . 
i mean it ' s an infinite number of channels . 
yeah . 
so just put them on some other channel . 
but 
when when this is sent to to the i m uh i b m transcribers i don ' t know if if they can tell that ' s really 
yeah . 
that ' s right . 
yeah because there will be no channel on which it is foreground . 
yeah . 
yeah . 
well they have a convention in their own procedures which is for a background sound . 
uh 
right but uh in general i don ' t think we want them transcribing the background . 
because that would be too much work . 
yeah . 
yeah . 
right . 
for it 
because in the overlap sections then 
well i don ' t think jane ' s saying they ' re going to transcribe it . 
but they ' ll just mark it as being there ' s some background stuff there . 
but that ' s going to be all over the place . 
right ? 
yeah . 
how how will they tell the difference between that sort of background and the dormal normal background of two people talking at once ? 
yeah . 
oh i think i think it ' d be easy to to say background laptop . 
but wait a minute . 
how would they know that ? 
why would they treat them differently ? 
yeah . 
well because one of them 
because otherwise it ' s going to be too much work for them to mark it . 
they ' ll be marking it all over the place . 
yeah . 
oh i 
background laptop or background l t wouldn ' t take any time . 
sure . 
but how are they going to tell the difference between that and two people just talking at the same time ? 
and 
oh you can tell . 
yeah . 
acoustically can ' t you tell ? 
it ' s really good sound . 
so 
oh is it ? 
oh ! 
well i mean 
isn ' t there a category something like uh sounds for someone for whom there is no close mike ? 
yeah that would be very important . 
yeah . 
but how do we how do we do that for the i b m folks ? 
yeah . 
how can they tell that ? 
well we may just have to do it when it gets back here . 
yes . 
that ' s my opinion as well . 
yeah . 
so we don ' t do anything for it with it . 
okay . 
yeah . 
that sounds good . 
that sounds good . 
yeah . 
and they ' ll just mark it however they mark it . 
and we ' ll correct it when it comes back . 
so 
yeah . 
okay . 
there was a category for speech . 
yeah . 
the default . 
yeah . 
okay . 
no not default . 
well as it comes back we have a uh when we can use the channelized interface for encoding it then it ' ll be easy for us to handle . 
yeah . 
but but if if out of context they can ' t tell if it ' s a channeled uh you know a close miked speaker or not then that would be confusing to them . 
okay . 
right . 
okay . 
i don ' t know . 
i it doesn ' t 
i don ' t 
either way would be fine with me . 
i don ' t really care . 
yeah . 
so 
shall we uh do digits and get out of here ? 
i have i have one question . 
yep . 
do you think we should send the um that whole meeting to them and not worry about pre processing it ? 
yes ma ' am . 
or 
uh what i mean is we we should leave the part with the audio in the uh beep file that we send to i b m for that one . 
or should we start after the that part of the meeting is over ? 
which part ? 
in what we send . 
so the part where they ' re using sounds from their from their laptops . 
with 
with the laptop sound ? 
or 
if we have speech from the laptop should we just uh excise that from what we send to i b m ? 
just 
or should we give it to them and let them do with it what they can ? 
i think we should just 
it it ' s going to be too much work if we have to worry about that i think . 
okay . 
that ' d be nice to have a a uniform procedure . 
yeah i think if we just send it all to them . 
you know . 
good . 
worry about it when we get back . 
let 
and see how well they do . 
yeah worry about it when we get back in . 
yeah . 
and give them freedom to to indicate if it ' s just not workable . 
yeah . 
yeah . 
yeah . 
okay . 
because i wouldn ' t don ' t think we would mind having that transcribed if they did it . 
excellent . 
i think 
yeah . 
as i say we ' ll just have to listen to it and see how horrible it is . 
yeah 
yeah . 
yeah . 
okay . 
sample it rather . 
all right . 
yeah . 
i think that that will be a little bit of a problem . 
that ' s great . 
as it really switches around between two different channels i think . 
uhhuh . 
what what i would 
and and they ' re very it ' s very audible on the close talking channels ? 
yeah . 
oh well . 
yeah . 
i mean it ' s the same problem as the lapel mike . 
yeah . 
but 
oh interesting . 
comparable . 
yeah . 
yeah . 
okay . 
all right . 
okay . 
let ' s do digits . 
digits . 
okay so we read the transcript number first . 
right ? 
are we going to do it altogether or separately ? 
so 
what time is it ? 
uh why don ' t we do it together ? 
uh quarter to four . 
oh okay . 
that ' s that ' s a nice fast way to do it . 
uhhuh . 
one two three . 
go . 
okay so let ' s uh 
let ' s discuss agenda items . 
i should have brought more 
what did we have ? 
yes . 
uh you you were announce some things . 
i have a couple things about speaker form 
about forms in general . 
okay forms is one thing . 
uh there ' s status on on the uh transcription discussion which will take us about thirty seconds . 
stuff . 
uh and then uh jose as usual uh the one among us who ' s actually doing a bunch of things on this . 
uh he has this and i think we can have some 
i was just glancing through it so i think we have something to discuss about . 
uhhuh . 
um and um we just sent in that uh n s f pre proposal . 
but i don ' t think there ' s much to say about that except we ' ve sent it in and we ' ll see what happens . 
um anybody ? 
anything ? 
anything else going on ? 
that ' s it . 
no . 
okay . 
so why don ' t we do it in that order ? 
okay . 
go ahead . 
i uh probably should have printed out more of these . 
so one of the things that i ' ve been doing with the digits forms is i ' ve been adding more and more speaker specific information to them . 
and it ' s getting pretty crowded and you have to fill it out each time . 
so what i thought was it would be nice to have a single speaker form that you fill out once . 
and then on the digits form you just have to put your name down and you can look it up from the speaker form . 
so i had a first pass of it . 
and i spoke with jane a bit about how to specify what language and education and that sort of stuff . 
and so i have a first pass at it . 
and i was uh just wondering if people had any comments on information that should or shouldn ' t be on it . 
and i only did one copy which was really stupid of me . 
um so i ' ll just sort of say what it ' s on and then i can hand it around . 
so the top of it is uh name sex email or other contact information . 
and i put the contact information just in case we have people with the same name so that you can distinguish them . 
and then also just to have a separate contact from the consent form . 
and then uh we talked a little bit about whether to do how we get at the background . 
and we could do profession but it ' s so uniform that we figured what was more important was actually the education level . 
um at least that would get at some idea of their background . 
so i have a and 
well and it ' s also relevant to status . 
i i can insert that . 
and relevant to status . 
uhhuh . 
so that what i have is uh 
status ? 
which might affect the discourse aspects . 
so go ahead . 
oh oh stats kind of status okay . 
his 
uhhuh yeah . 
so uh i have uh five things that you can circle . 
categories . 
undergrad grad post doc professor and then other with a colon and a place where you can fill in if there ' s some other . 
so i think the problem with that is that there ' s not a necessarily easy equivalent for our visitors who are not used to the u s education levels . 
and may need some help to translate what that means . 
how fine a resolution do you need on that for this ? 
is the question . 
i mean maybe not so much . 
uhhuh . 
student non student . 
oh i think undergrad is useful . 
can you just write something like position ? 
and people can fill in their own you know post doc or visitor or whatever . 
prone . 
yeah . 
sitting . 
well the problem with that is um i think the same as the problem of profession . 
that it it will be there will be a tendency all for everyone to put down speech researcher or or something at that granularity . 
oh . 
so i don ' t think there ' s a problem asking the education level i at least i don ' t feel like there is . 
um i think the only question is whether the what categories should there be ? 
yeah . 
i think that 
so uh did are were you suggesting that it should be more fine grained than this ? 
no no . 
less . 
less . 
less ? 
what would you suggest as a as a change ? 
um huh um well do you think there ' s 
i don ' t really know . 
i mean were you thinking uh that it would be useful for some research later to know say you said undergrad for instance so undergrad versus grad ? 
uhhuh uhhuh . 
do you think that ' s important ? 
i do and the reason is because i think that um well having been a grad student as yeah as others here at at berkeley that um i think there ' s almost like a quantum leap from undergrad to grad in terms of like the status . 
okay . 
i mean i mean you notice it in various ways like simply trying to meet with a professor during office hours . 
you know in in my department it was always the case grad students had a huge amount of different priority . 
and were treated as equals and and helpers you know in in research uh uh uh roles and things that they that they 
in terms of like the the social dynamics of interactions i would expect them to be less deferent . 
uhhuh . 
and um maybe less assertive of their own views and things like that . 
i see . 
i don ' t think that we ' re going to have a lot of undergrads . 
right . 
unless we branch out to different types of meetings but 
how about you could say if you ' re giving a talk how likely are you to be challenged ? 
this is the dimension . 
well this is the dimension . 
well one of the one of the criteria i had for designing this form is that i didn ' t want a separate instruction sheet . 
yeah but one one dimension . 
yeah . 
and so we ' ll get to that in a moment when we talk about language also . 
uhhuh . 
is i did not want to have to you know come down and quiz each person and have a uh social dynamics expert being the one who ' s filling out the answers . 
i want it to be self evaluating . 
you can give it to them and they can understand what you ' re asking . 
uhhuh . 
and it ' s non threatening . 
i mean this this compared to you know exactly what level of professorship and and 
yep . 
well sounds like you really need to know something kind of like that . 
you need to know sort of in this meeting sort of what is your social status . 
that ' s a separate question . 
so we ' ll we ' ll get to that in a moment . 
well i agree with him though . 
i 
yeah . 
but i i agree that this is that the the motivation was things that could affect social dynamics in ways that are relevant to the research without being threatening to the person . 
but but but it ' s going to depend on who ' s 
and this particular form 
i know . 
so this particular form is speaker is dependent only on the speaker . 
yeah . 
not on the meeting . 
uhhuh . 
you could imagine then having another form that you might want to do during a meeting to get out the relationships . 
uhhuh . 
yeah . 
but then that ' s interfering with the meeting . 
so what i like about this information is you give it to them once and they fill it out once . 
and and then you have that information . 
well and we also discussed the idea of having the separate d t d ' s would handle maybe specific meeting specific things that might be relevant . 
i 
d t d ? 
uh the data so that 
you know his x m l thing ? 
you got the data type definition the document type definition part that it ' s can be used for relational things . 
oh . 
oh okay . 
uh yeah . 
yeah . 
d t d . 
yeah . 
i guess i guess it seems to me like you know i trying to deduce information about the person ' s status from the meeting independent form will be useless because 
not at all . 
i mean the fact that one person ' s an undergrad and the other ' s a full professor is interesting . 
so the question is how much of this information um can 
but that will depend on what the meeting ' s about . 
right ? 
well absolutely ! 
let ' s say the undergrad was an expert in physics and 
but but you want to have that information . 
yeah . 
right ? 
so if you don ' t have that information how are you going to do anything ? 
uhhuh . 
i guess i ' m wondering how can you make a conclusion based on that if you don ' t know about the meeting ? 
yeah . 
where ' d this is just well you know we ' re we ' re talking at at a general level of description . 
yeah . 
you can always get more specific . 
and it may be 
i mean so what would you suggest ? 
i don ' t know . 
i ' m just that ' s why i was wondering about if you can put something about the 
right . 
can you repeat the categories you had ? 
yeah . 
maybe they ' re fine . 
undergrad grad post doc professor other . 
so that yeah i think that ' s fine except the one thing is there are a lot of icsi 
like i don ' t know what i would be here . 
just i ' m not a professor . 
i ' m not a 
so so anything that like a visitor icsi visitor or icsi 
oh that ' s right . 
you know i was saying professor 
i mean a visiting researcher or whatever . 
uhhuh . 
yeah when i said professor i guess what i was thinking in my mind was more p h d but not post doc . 
how about yeah how about post p h d researcher or something ? 
so if if we can put something 
and or maybe post doc change post doc to p h d ? 
yeah that then then i think what you have is great . 
yeah . 
right ? 
for for that purpose and 
so change would we change post doc to post p h d researcher ? 
or just 
you could say 
because i think p h d and professor are are distinct . 
yeah . 
aren ' t they ? 
yeah . 
wait what ' s a p h d ? 
it ' s possible . 
like if you have a p h d and you ' re hanging around here and you ' re not a professor and you ' re not a post doc then that ' s like what we are so there ' s a bunch of people like that . 
someone who has a p h d . 
yeah so for for me there ' s there ' s a there are people 
um this got very tricky in fact when we got involved with the spanish program actually . 
because uh when we said in our original forms post doc what we were used to from the german program and from the u s standard when you say post doc it meant somebody who had just gotten a p h d who was doing one year someplace . 
yeah . 
right . 
but when we did the spanish call many people said oh i want to be uh have a post doc slot and they were twenty years out . 
yeah . 
yeah . 
right . 
yeah . 
because they were post their doc . 
right . 
yeah . 
yeah . 
so you can say post p h d researcher or if there ' s one more category that ' s sort of general like that . 
so 
sure . 
i i i think that 
right . 
it might be hard to do a finer thing than that because whether somebody is going to be dominant in a meeting is really i think it ' s going to be so clouded by everything else . 
someone who ' s just gotten their p h d uh could be very very uh strongly opinionated about something and somebody who ' s been twenty years out could be shy you know 
so maybe undergrad grad post p h d and other ? 
uhhuh . 
yeah . 
that ' s true . 
what ' s other ? 
um other 
for the european . 
it ' s just to allow . 
if instead of instead of instead of professor or instead of post doc ? 
you i think you could keep professor but you could say post p h d researcher or something . 
yep . 
it could be it could be that ' s true . 
no instead of post post doc or post p h d just wrap all the people that are post p h d and non professors together . 
so you want professor to be in a separate category . 
you think you think uh think think we 
so as i said undergrad 
i think professors probably want it . 
i don ' t care . 
undergrad grad post p h d professor other ? 
yeah . 
well yeah the post p h d one is the one that can be like post doc or post p h d researcher or whatever . 
uhhuh . 
yeah . 
right . 
then it ' d be fine . 
i think it ' s fine . 
so i ' m i ' m tending to push toward simpler . 
even though i know that more detailed means more potential information for someone later who ' s doing research in in this area . 
i uh the the the thing making me lean toward simpler where possible is that uh the more a thing 
many of the meetings that we record uh may be the kind where we just record somebody once . 
even though we want to get a lot of data that has uh many meetings with the same people . 
and so the more forms we have and the more lines in the forms that ' s the more overhead for that one time thing makes it harder to do . 
well the whole reason that i ' m doing it this way is is uh my experience so far has been the exact reverse . 
that 
right that ' s what we ' ve done so far . 
right . 
right ? 
and so i ' m saying i expect us to do both kinds . 
i guess we could have another type of form for less frequent . 
yeah . 
well one thing so you understand he he he wants you to do this only once for each person ? 
yes . 
okay okay . 
so i ' m saying there are going to be what i imagine once we ' ve collected a lot of data a chunk of it will be uh the same people many times . 
so 
and another chunk of it will be people random meetings that we got with from different people . 
uhhuh . 
uhhuh . 
yeah . 
uhhuh . 
and i think it ' s we ' ve talked about this before it ' s useful to have both kinds of data i think . 
well i think that if if we ' re planning to do that then we should probably have another set of forms . 
okay . 
you know a single form that ' s the consent form and the speaker information form and not have them do digits . 
okay . 
no i like the idea of putting down the the status information . 
because i think you probably can get a lot of there can be a lot of interesting research on that . 
uhhuh . 
uhhuh . 
i ' m wondering could we add something to the form that gets filled out at each meeting that would somehow 
this is a topic i want to bring up after i get through this . 
yeah . 
okay . 
so that that that ' s another form that i want to discuss um with the digits forms . 
well i guess i was thinking maybe you know how you were taking information off of the digits and putting it onto that ? 
so can we get 
uhhuh . 
could we put one more thing on here maybe ? 
that ' s what i want to talk about in a 
yeah i ' m i have that as a topic also . 
okay . 
so let ' s finish with the speaker form speaker form and then we ' ll get over get over to that one . 
because you said separate forms so i thought maybe 
okay . 
so education level undergrad grad post p h d professor other . 
okay ? 
okay . 
um and then i put optional with a big optional in parentheses age . 
wait why is that optional ? 
because i think a lot of people are sensitive to it and won ' t want to write it down . 
yeah . 
so i don ' t want to make them feel like they have to . 
yeah . 
i don ' t know . 
it it would be very good to get age for a lot of purposes . 
yeah . 
i mean a lot of corpora 
uh sure but if someone doesn ' t want to write it down i don ' t want them to say you can ' t record me . 
yeah so we we have these age ranges or something ? 
oh right . 
well it 
well wait wait wait wait a minute . 
you know like 
um it ' s not illegal or anything . 
right ? 
it ' s not pushing on anything unethical or illegal whatever to ask for their age . 
no not at all . 
right ? 
every most corpora have that you know information . 
so 
i suggest you ask for their age . 
and if they say i don ' t want to give it say okay . 
in in like the london lund they they the researchers themselves estimate the age after the fact . 
yeah . 
so they say you know uh middle thirties you know fifties or sixties . 
yeah . 
and they and they just they estimate for the person but 
well i think that just having on the form saying optional age again means i don ' t have to be sitting here and explaining the form every time we do this . 
yeah that ' s okay . 
yeah . 
and it isn ' t it isn ' t that 
and having a little instruction sheet and say if you ' re in this range do this and if you ' re in this rage do that . 
i see . 
yeah . 
yeah . 
and it ' s and it isn ' t really that prominent . 
so 
how about 
it ' s you know his optional is not really boldface but 
how about optional but highly desirable ? 
please please ! 
yeah . 
age or approximate age . 
so somebody can say thirties if they ' re thirty nine . 
actually approximate ? 
age is optional but those who don ' t give it will be given the uncomfortable microphones . 
yeah right . 
that ' s right . 
well those who don ' t give it we will be estimating your age for you . 
uhhuh . 
yeah if not given we will estimate . 
so maybe you ' ll prefer to 
i i think is not 
the the mean of the estimates from the group will be used 
yeah . 
i think it ' s not necessary to put uh optional . 
yeah people can leave it blank if they 
i think people decide uh in that moment . 
i i think people in speech are going to want to 
because if you put optional i think you you give uh 
they ' re very strong willed . 
you know ? 
people 
well i think maybe that ' s because no one here is sensitive about their age . 
they can always lie . 
but i would rather let them leave it blank than lie . 
okay in some sense you could say that please leave blank but but don ' t lie . 
so that ' s why i want to put that ' s why i want to put optional age . 
so that if they don ' t want to put it they leave it blank . 
they might lie anyway . 
yeah . 
but if you put optional won ' t they just leave it blank rather than lie ? 
i don ' t know . 
okay . 
i think i think you can put optional . 
i mean i mean the the people i ' ve known who ' ve lied about it i think would just lie about it . 
it ' s not going to 
right . 
you don ' t think they ' d just leave it blank if it says has a big optional right next to it ? 
yeah . 
you know people who lie about it ? 
oh yeah . 
well they might leave it blank if they didn ' t care about their age being known but it says optional they might not . 
hey jack benny was thirty nine for forty years . 
anyway it ' s fine . 
i don ' t know . 
well the thing the reason uh one reason for putting optional might be if it uh made the form seem gentler and and not as intrusive kind of thing . 
kinder and gentler . 
yeah i noticed i was afraid you ' d i shouldn ' t say that . 
yeah . 
they uh that you know if you say optional then it ' s sort of 
if people who get nervous about the age question then they realize that oh well but they ' re not trying to ask me lots of things . 
yeah i think it ' s okay . 
i don ' t think it matters . 
people will put it i i 
i i don ' t think it matters . 
if it makes you more comfortable put optional . 
it it i think it ' s better to put optional . 
i i don ' t think it ' s 
okay . 
i mean that ' s why i put it there 
then 
okay . 
okay okay . 
but it seems like maybe you disagree . 
i like it . 
i think it ' s softening . 
i i i don ' t think it ' s important but i also don ' t think it ' s an important point the other way . 
uhhuh . 
and i don ' t want to make you do it some different way than you want to do it . 
yeah . 
yeah it ' s okay . 
so 
huh . 
okay . 
as long as we put it high enough up that it doesn ' t sort of get lost in the optional if there are a lot of other optional things on the form . 
well i didn ' t mark anything else as specifically optional . 
that ' s that ' s the only optional thing . 
let ' s see . 
that ' s the only other one . 
that ' s the only one . 
okay . 
so 
um and then the next are two sections . 
one indented separately . 
so one ' s for native english speakers and one for non native english speakers . 
okay so for the native english speaker it asks for a variety of english with three circle boxes . 
american british indian and other for write in . 
now what was this thing that 
who was telling 
was it steve ? 
somebody was telling us about asking about uh 
where you lived between the ages of 
yep jane and i discussed this and it was it was again the same problem . 
that it ' s going to be a self evaluation anyway . 
and so i don ' t want to have to be standing over the person and asking them well do you mean that your native language was british when you were born and then it changed to american when you were two and then it changed to and so on . 
well also you you you he has a separate subject for region . 
uhhuh . 
and so it ' s a self assessment of what you think your closest variety is of english . 
and then following that a characterization of of region . 
now we discussed maybe indicating a a time frame . 
so where did you live during your you know childhood and adolescence . 
right . 
uhhuh . 
which would be 
which is more objective than somebody saying i think i speak this or that . 
yes uhhuh . 
although you know i mean a lot of people there won ' t be much difference . 
i mean there ' s room on the form to put a line of instruction but i ' m just not sure what it should really be . 
i i i ' m sorry so you ' re saying 
but 
uhhuh . 
uh i i i just missed something though . 
are you saying that you have both ? 
uhhuh . 
that you ' re saying uh what is your 
uhhuh . 
so the the for the non for the native english speakers we have variety of english and region . 
yeah . 
and that ' s it . 
and that ' s partly to pick up 
and then we have another form later down which is um list other language influences . 
yeah . 
uhhuh . 
so what does region mean ? 
yeah i was just going to ask the same thing . 
and like if i see this form i wouldn ' t be quite sure what you mean by region . 
region 
right neither would i . 
do you want to have give choices and have them circle one or 
i mean 
well we when we when we discussed it it was it was where where you lived during your childhood and adolescence . 
um i don ' t think we can do that because it would be different for 
does that mean region of 
region of the u s or region of the world 
if you ' re american english it would be region of the u s . 
well it ' s it ' s where you lived . 
okay . 
that that so that ' s why i didn ' t have circle forms . 
but i mean 
because it would be different depending on what your language is . 
so 
do you mean state or do you mean more broad than the state level ? 
huh . 
you mean like you know southern u s or northeastern or 
i think it would be however you would identify your own . 
and as i said i don ' t really see a way of doing a circle fill in because there would be there would have to be one for american english one for british english one for you know one for each type . 
uhhuh . 
if you wanted to get regions for american english you could copy what they did in timit . 
well and also 
they had divided things up into regions . 
but but that would mean i would have to do generate a different form for circles if you ' re american english or british english or indian english . 
no no . 
it would only be if you said american english . 
yeah maybe not for the others because there aren ' t going to be enough people to really group them . 
then you ' d put the regions . 
for the others you would just leave it . 
yeah . 
we wouldn ' t have enough to really make them difference on those . 
and you know when you talk about dialects in england i mean that ' s really 
well 
every block of london has a different 
huh . 
so 
yeah . 
i haven ' t seen what what they did in timit . 
my fair lady ' s 
are you do they have a bunch of options like uh 
oh it ' s like six regions of the country or something . 
yeah . 
i see . 
very just a limited number . 
okay . 
and then if you ' re american you would just circle the region where 
yeah . 
well that ' s the concept . 
yeah . 
uhhuh . 
yeah and henry higgins could say which block you were from . 
well 
right ? 
yeah . 
so that ' s 
that ' s right . 
well that you know that was the concept of having the region thing . 
i it would be no problem to change it to options if um if that were desirable . 
yeah i just don ' t know what to do about the other varieties of english . 
although for different 
well that ' s true . 
you ' d just leave them . 
i mean indian english i wouldn ' t know 
you don ' t even ask . 
i i there are huge differences you know in the others . 
what 
well that ' s why i wanted to just leave it something that you could write it down . 
so it might be better to just do it for the 
yeah you could leave region for for the others but have circled choice for the american english . 
one one good reason to use the timit ones is if anybody asks you you know about the data later on you can say well i chose these based on timit and 
right . 
that is kind of nice . 
what 
what about just doing the the sort of the steve suggestion uh as as an add on to it ? 
right ? 
rather than saying region just say where did you live between the ages of here and here . 
that was the concept of region . 
and that would apply to everybody then ? 
yeah . 
just 
and it ' s just the wording of it . 
and then you could map those to the timit regions later if people wanted to . 
uhhuh . 
and then they they could 
right yeah they could say it different ways . 
yeah . 
yeah . 
that ' s more general . 
they could say cincinnati or they could say midwest or 
yeah . 
that ' s true . 
yeah . 
actually that is true for them . 
but it means that you ' re going to get a bunch of different level levels of resolution in your survey it it ' ll be more of a pain later . 
so 
somebody ' s going to have to do some data 
well there could be a circle one . 
it depends . 
i guess there ' s 
right ? 
so you could say what region did you grow up in from these years . 
and have a set of of six or seven circles 
yeah that that ' s good . 
but if you have it totally free form first of all some people take you 
yeah . 
a lot of post processing ? 
well and some people would give you more specific information than others . 
and that ' s a waste because you can only use the least common denominator of specificity and generally . 
yeah but that but the good thing about it is it is it frees you from coming up with exactly what the right categories are . 
um right ? 
i don ' t know . 
later on if if somebody just says midwest now all these other people who said you know then that ' ll have to become your category . 
yeah . 
and it ' s it ' s harder later on i it ' s easier for the person . 
i see . 
there is another problem . 
but it ' s harder for the 
it actually less informative for us . 
because you can ' t enforce any minimum level of specificity . 
but i think that if you ' re going to have it be general uh 
so it ' s 
so the idea again was you know you might want to also know if if they grew up in germany or if they grew up 
and so uh i think you want to the idea the motivation i think for this being suggested before was that it did cover a range of these cases that might um 
you know if you say your native language was was english but uh you you grew up in germany uh i think this 
yeah there is actu you made me think about another wrinkle in this whole thing which is that just asking them where they grew up between certain ages isn ' t enough . 
because somebody could grow up in germany but live on an army base speaking english . 
uhhuh . 
yeah . 
or someone could in in in new york and have i mean any number of different types of speech patterns . 
or their parents live 
yeah . 
yeah so you sort of have to say what languages were spoken in the home between the ages of 
and their parents 
well we have this we have to 
so he hasn ' t given you the overview . 
but you have like the native speaker category the non native speaker category . 
and then you have other language influences for example bilingual dialects things like that . 
oh that ' s nice okay . 
now there ' s this issue of not like you ' re saying you don ' t want the forms to be hugely complicated and take half the meeting to complete . 
uhhuh . 
so it ' s trying to there ' s this trying to trying to hold this balance between the amount of information needed . 
and uh you know not taking too much meeting time . 
and then in addition add to it the third level of the balance uh um this this issue of not being too intrusive asking in a way that they don ' t mind . 
uhhuh . 
if we release this corpus what do we want ? 
i mean if you do this free form um the free form solution where some questions are very open ended then you need someone needs to enter that . 
and they ' ll be notes and it will be very difficult for somebody later actually use that without mapping it . 
well i think i think that we need to remember that we have first of all it ' s not all free form . 
it ' s okay . 
but it ' s 
we have several categories that are specifically constrained . 
uhhuh . 
and in terms of the more open ones we have the we ' re in the enviable position of having the contact information and also knowing most of the people who will be participating in the meeting data . 
we can find it we can resolve certain issues later if 
huh . 
yeah and the question is how extensive this gets ? 
i mean i guess what you really want is if there ' s some information you want to know 
uhhuh . 
so we want some rough idea of their dialect basically . 
that ' s it . 
then we should have some question where it ' s not free form except for these people who are who have non american english accents . 
there we probably have to have a category non american english and then a few choices . 
and we should have something that ' s simple that people can circle like these timit regions or something so that we have something that minimally you can 
because a lot of times if you give the data out that ' s what people are going to use . 
they ' re going to want some small set of places . 
and then but anything additional people can fill out and we can put it in as a note or something . 
but if we don ' t have that someone ' s got to sit there and figure out you know i ' ve got twenty people who said midwest . 
and i ' ve got a few people who said something else . 
and these don ' t overlap or these 
isn ' t it i mean i think that we ' re going a little bit in a circle because i like the timit suggestion very much . 
and i think it ' s a question of how to incorporate it . 
and and we ' ve already suggested i mean it ' s come up in this discussion that the suggestion that we could have um the timit categories for the american . 
and and then make the choice or not as to whether we do it for british . 
oh okay so 
yeah as long as you have 
i mean we sort of discussed one way or the other . 
and it doesn ' t matter to me . 
i don ' t know if adam has has a preference . 
but but 
but we could have you know a a sub categorization for american . 
we could even use the timit subcategorization . 
i don ' t know if it has one for british or whatever . 
uhhuh . 
but you know just have it you know a short simple form that you can categorize yourself in a in a systematic way . 
what about the the phrasing that um chuck used uh which was in in relation to the question i was trying to formulate of uh where where did you what 
what was that what how did you phrase it ? 
what language was spoken in the home . 
what language was 
yeah so it ' s not where did you grow up but what language was spoken in the home between the ages of what would it be five and twelve or something like that ? 
huh . 
yeah . 
it ' s a good idea . 
depends of who you ask what the age range is . 
well in the home the influence of the home is much lower age than that . 
yeah . 
i mean once you go beyond the age five or six then it ' s the the school influence as well and and 
and the peers . 
yeah . 
so in the home it ' s sort of your phonetic first level . 
that ' s one part though . 
um so it ' s you know it starts to get sort of complicated . 
yeah so this is why i 
well it ' s that ' s not a problem though . 
so so 
i mean that would be a good question to ask . 
and then you could add a question . 
you know would uh among your peers . 
you know . 
because he does make a good point about the region . 
specify the age range . 
not necessarily again if you ' re on the army base or 
right . 
well the way it ' s phrased right now it ' s clearly asking about language . 
yeah . 
and so what it ' s trying to get at is what you think you speak . 
now i think that the point is well taken that sometimes people are wrong about what they think they speak . 
right . 
but other than having a trained linguist interview them and ask these very specific questions i don ' t see a way around it . 
uhhuh . 
because as you said what you ' re going to have to stay say is well list the languages that your parents spoke when you were in home and how good they were at it and how long they spoke it . 
and now list the ones in preschool . 
and now list the ones in first grade . 
and now list the ones your friends speak 
sort of like as soon as you get to the cases on the edge the complexity just shoots up . 
yeah that ' s right . 
right . 
uhhuh . 
so i want to try to keep the complexity so someone can fill out this form at the beginning of a meeting without taking uh forty five minutes . 
uhhuh . 
and we ' re 
and then we like i said we have the enviable benefit of knowing most of these people . 
and being able to ask them follow ups if we need to . 
for now . 
right ? 
so it ' s i mean again we are hoping to expand this out . 
for now . 
that ' s true . 
washington and stuff yeah . 
yeah . 
that ' s true . 
so i think that adding the the timit categories is a good idea . 
because that ' s very easy for a person to fill out . 
but i think we still have this problem of is it going to be a self evaluation ? 
or are we going to ask them what was it when you were four years old or what was it when you were six years old or what 
what ' s the best way of phrasing the question ? 
well you know the other thing too is that it seems like one of the reasons you would gather real detailed information about their native language is if you were going to do fine grained phonetic analysis or something . 
and i don ' t 
well it ' s 
and somebody might . 
or or adaptation . 
most of but most of those people don ' t rely on the self evaluations anyway . 
well that ' s what i was going to ask . 
is that 
they ' ll probably listen to the speech . 
so 
well i you know i i was thinking of it as 
that ' s a good point . 
but i was thinking uh you know with reference to the language model issue which uh 
and i guess it could be done inductively . 
but if you have a bunch of say r less dialects and uh you know if they 
but even you know in switchboard i i remember looking really carefully at 
they have information sort of like timit . 
i don ' t know it ' s how well they categorized . 
but they had north atlantic mid atlantic and 
you know texas was definitely out on 
i mean most of the people from certain places in the south were from specific texas locations . 
but other than that you had a huge range of 
you know people would say boston and they had nothing like what i would call a boston accent . 
uhhuh . 
so it was 
interesting . 
were they putting down where they lived at the moment they recordings were made ? 
is that why ? 
um no the question was really geared towards trying to get people ' s self evaluation of their dialect region . 
rather than where they grew up ? 
uhhuh . 
huh . 
but you have a lot of stratification in any region . 
and you know for instance you know minnesota midwest is totally different than michigan midwest which is totally 
yeah . 
right . 
interesting . 
these were all settled by very different type people . 
so it it ' s sort of a general help . 
but i think that anyone who ' s doing phonetics wouldn ' t rely on that they would probably use it as a first pass or something . 
so then we probably don ' t need the fine grained information . 
well maybe should we just 
then maybe we shouldn ' t just shouldn ' t ask . 
well i think we do need to make sure about the the non native accents because those are you know 
yeah . 
but we don ' t need to be really really specific about the others because it won ' t be very helpful anyway . 
uhhuh . 
well maybe for the native english speakers we shouldn ' t even ask the region if it ' s that unreliable . 
i think we should because other databases do . 
it ' s sort of a political thing . 
and there are some general 
like you will find more new yorkers in the new york category . 
but it ' s not 
it can ' t be relied on only . 
right . 
the other thing also is that i ' m asking for the variety of english and i did just put american british indian and other . 
so i didn ' t put canadian australian and all the other varieties . 
uhhuh . 
but other is there and people will fill that out . 
but do you think those three are okay ? 
they ' ll see by example . 
yeah that ' s i think that ' s fine . 
yeah i think those are good . 
okay . 
they ' ll say oh i ' m not one of these . 
i ' m canadian or 
yeah . 
so internally we have texas and other . 
huh . 
so that for the native english speakers we ' ll do variety of english regions from the timit labels and another field . 
right . 
i mean even like l a is totally different than 
and then 
i mean you really can ' t um 
well 
uhhuh . 
we could ask them for more information but i don ' t think it ' s necessary and it ' s not going to solve this problem . 
i thought this was be fast . 
yeah . 
well that ' s what the final the the third category was designed to do . 
because i mean you have a bunch of different types of accents in new york . 
you know . 
native speaking new yorkers as a as a function of their social uh groups and their ethnic identifications and their you know . 
oh yeah . 
uhhuh . 
there are lots of things that are very identifiable as um you know other other aspects which is why we have this third category . 
uhhuh . 
so we wanted to certainly distinguish american versus british and other types at that level . 
and then allow people to self identify if there are other specific things . 
and then in addition this issue of regions with some sort of time frame for the region because i think that if you live in massachusetts now versus you know in childhood and adolescence 
so if you if if you 
air conditioning . 
you know . 
so region with respect to a time frame is what i would suggest . 
where did you live . 
i mean what you said . 
you know where where where did you live . 
or uh what you were saying languages in the home . 
but i think that uh a time frame on the region would be useful . 
instead of region now say it ' s a little bit unbounded . 
um so are you suggesting that you put something in about childhood in there ? 
well you know there ' s this issue of of what age is relevant for the formation of your speech patterns whatever they are . 
well you could distinguish between pre five and five five to twelve . 
and oh that ' s interesting . 
right ? 
so depending on what someone ' s interest was in the formation of the phonetic kinds of categories or whether or whether you ' re talking more about their linguistic speech patterns . 
you know uh 
so 
but again it depends how fine we want to get . 
but we could say uh where did you live before you were five . 
where did you live after you were five . 
i don ' t know . 
oh that ' s interesting . 
from five to fifteen or something is a 
yeah . 
i mean i think the question on regions is really to ask people how did they define their dialect region now . 
whether they picked it up at the one age or another . 
pretty much i mean most people will know whether they have a southern accent or not . 
uhhuh . 
um but they may have lived you know in other places too . 
so if we ask the question about dialect regions it makes no sense to say where do you live now . 
right . 
right ? 
you ask how would you best define your your accent or your dialect style . 
right . 
right the way the way the form reads now i think it ' s pretty clear that ' s what we ' re asking because it says native english speakers variety of english american british indian other region . 
okay . 
uhhuh . 
and then we ' ll have southern english you know whatever whatever the timit categories are . 
so i think if you look at this 
or you could say to somebody how do you define your your the accent that you have . 
right . 
um and then you can ask these other questions as well . 
but what we don ' t want them to think is that they ' re living in a certain place . 
and that therefore they ' re 
i mean nowadays hardly anybody from california has a native californian accent . 
right . 
yeah . 
well i i 
okay . 
so 
i don ' t think it was ever the intent to talk about the region now . 
because 
right so i it seems to me that if you read this form i it ' s pretty obvious that it ' s a subcategory of the language that you think you speak . 
okay . 
it ' s it ' s a sub categorization . 
as long as it ' s clear . 
uhhuh . 
not where you live . 
i mean i don ' t say anything about where you live on the form . 
okay . 
yeah . 
okay . 
okay . 
so it ' s just in the section talking about language . 
okay . 
why don ' t we try it out and see see what kind of responses we get from people . 
yeah . 
yeah . 
anyway 
and then uh as jane said the last question is list other language influences bilingual dialects et cetera . 
and that ' s just and open ended place for them to do . 
oh . 
uhhuh . 
sounds good . 
that ' s to handle that unusual percent or two . 
and then 
yeah . 
and then the bottom of the form is for not for them to fill out but for us to fill out for um the aliases and database speaker database that the person is in since we ' ll eventually anonymize . 
and this will be a a place for us to connect the two . 
and then the meetings that they attended . 
uhhuh . 
because there ' ll be one form for each person . 
sounds good . 
it ' s very efficient . 
okay so 
yeah i guess i ' ll fiddle around yet again with the language stuff . 
i don ' t think you really have to do all that much . 
yeah . 
it it gets into a can of worms . 
well you 
uhhuh . 
i mean the more you ask the more you realize that you ' re not getting great answers to what you ' re asking and 
yeah . 
right yeah . 
well you didn ' t really talk about the non english speaker categories . 
so 
right . 
so there ' s another area which is non native english speakers which asks for native language region and variety of english . 
and that ' s it . 
because it used to be that germans would learn british english and now i think there ' s you know is a certain percentage of them who who ' ve to tend toward american english . 
what about proficiency in english as well ? 
proficiency . 
that ' s a good idea . 
uh i 
that ' s hard though for self identification 
i 
you don ' t want to do it for political reasons ? 
huh . 
i mean i ' m i wasn ' t thinking about that . 
i was just thinking gee i ' d like to know actually 
i wasn ' t thinking 
oh no no . 
i wasn ' t thinking political at all . 
oh okay . 
i was just saying looking at applications of people over the years for post docs here . 
they ' re generally not very good at assessing their own abilities . 
well do you think that ' s that ' s also because they know that it ' s a important for them to be good at it . 
but 
okay . 
i agree . 
that could be . 
so don ' t don ' t you think they overrate rather than underrate ? 
that could be . 
yes . 
well so maybe that ' s 
so but 
no i think proficiency is actually a good thing to have on this sort of form . 
maybe we maybe we shouldn ' t ask it . 
the the question are what are what would the categories be ? 
i don ' t know . 
well i ' d 
i ' d have to i i ' d want to relate it back to training . 
good . 
bad . 
how many years did you study english . 
or you know have you lived in the america in a an english country before . 
but it seems like that ' s so 
i mean i think that you know if a person who 
what about something like how comfortable are you in a meeting conducted in english ? 
or how easy is it for you ? 
or something like that where it ' s 
how how about how long have you been uh in in an english speaking country ? 
yeah that ' s a good one . 
yeah . 
that ' d be okay . 
yeah . 
something 
what do you think ? 
what ' s it 
is better . 
i mean 
i think it ' s better . 
how 
yeah ? 
how long have you been in an english speaking country . 
yeah . 
okay . 
yeah i like that . 
i like that . 
that ' s that ' s non threatening and it ' s also an a good indicator . 
yeah . 
and there are people who haven ' t ever lived in an english speaking country and who are superb . 
however um that ' s you know i do think it ' s a pretty good indicator . 
huh . 
and then there will be people who live in an english speaking country but all their meetings are held in another language . 
that ' s true too . 
or even you know i mean some people who just don ' t change much in their 
so 
yeah . 
yeah i ' m i don ' t know . 
yeah . 
yochai ' s company is like that . 
being totally monolingual i ' m not the right person to ask to talk about this . 
everybody speaks hebrew . 
really ? 
but it just seems to me that that doesn ' t the length of time doesn ' t really get at what we ' re asking . 
right ? 
it seems to be that asking about the proficiency even if it ' s self rated is what we want to know . 
except that you have some many biasing factors . 
yeah . 
you have you have people who are highly confident when they really should be a little bit less confident . 
and then you have uh other people who are just the reverse and and it 
yes . 
so many things that vary i 
and also we want to keep it simple and non evaluative . 
uhhuh . 
okay . 
we done ? 
with that form . 
yeah . 
oh there ' s another form . 
shall we wait for other forms later or you keep going more form 
no you got what ' s the other form ? 
uh the other form is a modified digits form . 
uh and it ' s pretty this one ' s pretty simple . 
it ' s it ' s very much what like the digits forms in front of us except it doesn ' t ask for sex or native language . 
um so it ' s name email time date seat session mike number channel mike type . 
why do we need that much information ? 
why do we need the email address for example ? 
uh in case people have the same name . 
oh i see . 
how often would that happen ? 
in case people what ? 
so i wanted 
have the same name . 
oh . 
yeah i ' m particularly sensitive to this because a good friend of mine in in seattle was named scott smith and there were fourteen of them in at boeing . 
i see . 
so we could drop email . 
so the only so 
i mean that ' s not a big deal . 
it ' s just uh 
well it ' s an it ' s an interesting identifier i i now that i realize the the reason for it . 
the that ' s true too . 
well the other thing is that potentially if this is done over a period of time someone ' s email could change . 
right . 
well the other way i was thinking about it was assigning them an i d . 
yeah . 
but i hate it when people do that to me . 
when they say here ' s you i d . 
don ' t forget it . 
oh yeah that ' s bad . 
so i i wanted just something that would give us a hint of who the person is if the name field isn ' t readable or it ' s a duplicate . 
thanks . 
that ' s interesting . 
how about their birthday ? 
good idea . 
i don ' t know . 
i mean not not the year not the year . 
it ' s the age question again . 
your mother ' s maiden name mother ' s maiden name . 
oh i see . 
then you don ' t have to ask the age . 
yeah . 
not the year but just their birthday . 
not the year . 
i don ' t know . 
what are the chances of people having the same name ? 
social security number . 
yeah that ' s right . 
and a bank where you frequent 
yeah . 
pin . 
they 
social social security number . 
the pin ! 
so although the email email will change i think that ' s a good way of doing it . 
yeah . 
we ' ll be able to backtrack from email . 
i like that . 
i never thought of that as an identifier . 
that makes sense . 
um and then the other thing i was thinking about and it probably wouldn ' t be on the digits form . 
but it it is something that some form about the individual meeting . 
yeah . 
now the problem i have with that is i don ' t know who would be filling it out . 
well that i think someone internal to the meeting could do after the fact . 
and this would and and we discussed this . 
this is with reference to like the d t d . 
what you would put in the d t d that ' s meeting specific ? 
so and it could be something like oh by the way the guy giving the presentation today is the student of the professor who you know 
whatever . 
so speaker a is his professor and they and he ' s preparing for his quals or some such thing like that . 
or it could be you know so - and - so and so - and - so are married . 
huh . 
just to pick up an arbitrary an example . 
so - and - so and so 
we this wouldn ' t be relevant all the time . 
but you know if there ' s a big discussion on you know the the um best way to move house then and these people are talking a whole lot then it might be interesting information to say oh by the way they ' re married or 
i i don ' t mean uh you know . 
right . 
so so the sorts of questions i had were one who ' s going to fill it out and who ' s going to take responsibility for filling it out in each meeting ? 
i mean will we will we require it ? 
i would tend to leave that spontaneous . 
i think that at the stage of uh uh scanning the transcripts after they ' ve been produced by by our by i b m at that point i think that some of these dynamics will appear to be important . 
uhhuh . 
uhhuh . 
and you could you could spend a lot of time enumerating all the different relationships that people have . 
and that was my other question which is um what sort of information do we want to record ? 
yeah . 
i mean so i think pairwise relationships are pretty easy . 
uhhuh . 
you know source destination relation . 
are there other sorts of things that might we might want to record ? 
well i i was just thinking with reference to uh things that have that bear on the content or the status relations would be the things 
without being exhaustive by any means . 
but just like i said if there ' s a a certain topic that comes up in the meeting and that knowing their relationship will clarify it or if there ' s a certain dynamic that comes up 
so i mean a person is asked a whole bunch of questions more than you ' d usually think they ' d be asked . 
and it turns out it ' s because he ' s being prepared for a job interview or something like that then it ' s useful to know that that relationship . 
right . 
i think that fits in well with the whole meeting map mapping meetings concept is that ' s another way of looking at looking at it . 
but not to be exhaustive . 
interesting . 
so are there anything other than pairwise ? 
oh well yeah you could have people who are all part of the same football league or uh or chess club or 
oh yeah okay . 
so isn ' t this an open ended like basically a notes column ? 
i mean you can imagine wanting you should be able always to attach some notes to 
yes shirt certainly . 
is this the the place where we would do that or is there another place ? 
i ' ve been i it seems to be that there is we could attach more structure if we wanted to . 
especially because a lot of these relationships are pairwise power relationships . 
maybe i was missing something maybe . 
but i mean this is something one would try to infer . 
but how do how would you how would you freeze that information about what uh 
i mean we already have these things about someone ' s a professor and someone ' s a student or something . 
but would you would you some person would be writing okay this person was leading the meeting and that was or or 
uhhuh . 
is that what you mean or 
what what what uh 
um just as an example it would be source adam janin destination morgan relationship advisor . 
oh so you ' re just putting preexisting relationships that are 
that are relevant . 
i think that starts to there ' s definitely some clear cases . 
i see . 
but there are a lot of gray areas where the context happens just in that meeting . 
yeah . 
yep . 
or 
i mean where you don ' t want to sort of have to make a distinction between a pre existing relationship or 
yeah i 
well realize this was the idea was that this would be meeting specific . 
otherwise they would it would be possible to have a higher level thing . 
but i mean there are some that generalize over many meetings and there are some that don ' t and there are some things that happen in between meetings . 
right but that example was not 
that ' s true that ' s true . 
right so my example was not a good one because that ' s 
yeah . 
so i mean for today for instance . 
and 
this is the second meeting recorded today . 
the first meeting was a was a front end meeting . 
and in that one the basic form of that was uh i was the leader . 
and i was saying uh what are the results you ' ve gotten in the last week . 
and they were and uh one person was sort of taking the lead in describing what the results were . 
and then uh chuck was taking the role of saying well what did you mean by that . 
so he was sort of like the semi outsider asking curiosity questions . 
and then it would come back to me with saying well you know you showed me that but you know i think you should do this in the future . 
so it was very much sort of leader and and and and led sort of relationship . 
and um the guy i was primarily doing this with uh is is a visiting researcher uh in this meeting uh you are my graduate student . 
but uh it ' s not taking that kind of role at all . 
right ? 
right . 
you ' re you ' re you ' re actually leading the meeting for the most part most of this meeting . 
well it ' s just because it ' s my turn . 
so it ' s 
yeah well whatever . 
so uh yeah so i i don ' t know . 
so you ' re suggesting 
i think this one needs to be open ended . 
completely open ended . 
and the only concern i would have is if there ' s something we want to be able to say and we can ' t put it in that field . 
well there ' s i mean . 
i you you ' re the expert on the d t d ' s . 
well the d t d ' s mean we can do whatever however we want it . 
but 
yeah . 
but what i what i was thinking uh the reason that i didn ' t want to make it completely open ended is that it does seems like there is some structure which is common . 
especially with these pairwise ones where you can describe them and pairwise . 
so you mean like 
and you might want a tool that used that information . 
is there a way that we can add keywords or 
i don ' t know what you would call them but little labels for things that we decide are useful things to have ? 
sure absolutely . 
but you know as long as we have this one place where it can all be stored then we ' re fine i think . 
right because it seems like it ' s sort of a 
and those will probably occur i mean to us we ' ll think of a few of them some other researcher will think of some totally different keyword . 
right . 
exactly . 
it ' s sort of a research question you you ' re analyzing the meeting and you ' re deciding uh there ' s this kind of structure to it . 
yeah it ' s it ' s it ' s going to change . 
yeah . 
it ' s going to change . 
yeah . 
and maybe we want to regroup things under different labels later 
interesting . 
if we figure out that these pairwise things are 
right well i think being being in a common organization was one i hadn ' t thought of that 
well 
so you ' re football league was a good one . 
so the ones i ' ve been thinking of are all sort of uh power responsibility . 
i guess husband wife is yet another one . 
and so you know in discourse analysis you get things like the role . 
ach ! 
you have you have a role in relationships and it has to do with your negotiating your how you ' re perceived and how and how the other 
huh . 
role yeah . 
yeah . 
you know and so there are various things you negotiate . 
and i ' m i ' m wondering if we might be able to do it in sort of a loose way but with by having a searchable field like role . 
and then you know within this context this person has the following roles and it could be very loose . 
uhhuh . 
yeah . 
but then it would be possible to do something as simple as a grep across a database . 
and if you ' re interested in you know which which which ones this person serves as an advisor in and versus you know a uh uh whatever a leader speaker whatever you could just grep for role and and you know some some particular value . 
uhhuh . 
so it sounds like having the facility is great . 
uhhuh . 
and then over a period of time as the research happens on this we might develop some of these categories that would be generally useful . 
some more . 
and it it sounds like a good thing to do . 
and 
okay . 
interesting good . 
and systematize also maybe the encoding of it if as we find some are useful and some are not so useful . 
nope . 
yeah so what i have right now is all pairwise . 
uhhuh . 
so that ' s probably not sufficient . 
i think you don ' t need to have that much structure built in and that would be less time consuming to do it this way first and then find out what structure ' s needed . 
yeah maybe not . 
yep okay . 
what about all of the meetings that have been recorded so far that without this ? 
will will somebody go back and fill that in or we just won ' t have it or 
well i think that in a lot of the meetings people won ' t be filling this out anyway . 
so really what i want to have is a place that if a researcher wants that information they can add it . 
huh . 
almost all of the meetings that we have are recorded with roughly this group . 
right . 
uh and uh you know and a fair minority with the group that we have in the morning . 
so this is not a lot of people . 
we could easily there ' s just a couple other meetings that 
right . 
so it we can regenerate a lot of this information . 
so it wouldn ' t be that hard to go back and 
yeah . 
yeah . 
but even if we can ' t generate it i think it ' s all right to have some of the sections in your database blank that this information was not collected for this meeting . 
uhhuh . 
and there ' s just not going to be a way around that . 
that ' s just going to happen . 
like the n s a meeting the networks meeting . 
i don ' t think they ' re going to want to fill out that information . 
yeah . 
so 
okay enough on forms . 
okay so we ' re running kind of late . 
okay . 
so we ' ll probably want to zip through some other things maybe do some more time on on jose ' s stuff later . 
um uh status of transcription . 
uh i guess you know we we recently woke up um our friends . 
and uh 
so i i guess you ' ve sent off this the uh c d roms . 
and you got some response from from uh i b m about 
they haven ' t received them yet . 
but i did get a response from them saying yes we ' re still alive . 
we haven ' t done anything yet basically . 
yeah . 
and uh 
was there some suggestion that they might soon or 
yeah . 
yeah . 
so so they ' ve transferred the responsibility to someone else . 
i can ' t remember his name . 
mccoond . 
mccoond ? 
yeah . 
something like that . 
but uh 
and so he sent me email and said he ' s going to be starting to work on it . 
and i haven ' t received anything else . 
great okay . 
so 
well that was that one . 
uhhuh . 
um 
so tomorrow i ' ll send a email and just ask if he received it . 
he should be getting it today . 
actually he should have gotten it yesterday . 
but give him a day . 
um and i think we should just sort of look at this thing from you off line jose . 
because it ' s getting kind of late . 
yeah . 
but i mean i think the bottom line just glancing through it is that there ' s there ' s a lot of overlap in just energy related things . 
yeah . 
and so you need something else . 
i mean that ' s sort of 
okay . 
right ? 
and uh what the so i ' d 
what about that error that that uh the the supposed 
the residual error ? 
no the supposed bug that was that we were 
we were guessing you had a bug before . 
because you went through and you concatenated all of these things together 
uhhuh . 
uh yeah yeah . 
i i found the error and i repeated the experiments . 
uh and here uh you can find the new results uh with 
uh . 
okay so this is post bug fix . 
yeah yeah . 
okay ? 
good okay . 
so um so i had two thought just glancing through this . 
so one is one is that um that uh we might want to talk about normalization . 
i mean i don ' t know what normalizations you use . 
sometimes things have more overlap before you ' ve done some kind of normalization . 
and we might think about what different kinds of normalizations are possible . 
yeah . 
and the other thing is that if that isn ' t uh so much of the issue then probably 
yeah . 
i mean residual l p c energy and just plain energy are very closely related even though they ' re different . 
and um so um you really may need to go to something that looks at in some sense harmonicity or um um relationship to or fit fit to pitch tracks on uh on either side of of it for instance . 
yeah . 
huh . 
yeah . 
you know so if if there ' s uh a really bad fit between where the pitch is going in this suppose uh hypothesized region of overlap and the the and one or the other uh side you know then this this this might uh suggest a 
another side . 
an alteration in in the tracking way . 
excuse me ? 
you mean that uh you um huh 
i understand that uh you you mean uh to to study the alteration between the the tracking of the pitch uh if we compare the overlapping zone with a speaker zone . 
if you have two if you have two if you have uh two people speaking uh and there ' s an overlap then i mean the first thing is that there should be a mixture of harmonics uh during overlapped voice sections anyway . 
in the in the context . 
yeah . 
uhhuh . 
and um the any a measure that you have of how much of the energy is due to your best guess at a particular harmonic sequence it ' s also going to be a smaller fraction . 
this is you know related to the harmonicity sort of thing . 
uhhuh . 
and then the other thing i ' m saying is that if you look at the temporal evolution of the pitch there should be something like a discontinuity there . 
yeah . 
yeah . 
now there ' s other places where you ' ll have discontinuities in pitch and speech . 
but but maybe it ' ll have something to have a different character . 
but it seems like energy energy tells you something . 
but uh if unless this is a normalization problem it looks from your results like there ' s so much overlap that certainly you need something that isn ' t energy like in addition to it at least . 
uhhuh . 
okay . 
are are the things in the 
i don ' t normalicized uh in these experiments by the moment . 
i don ' t normalicize . 
okay so the question is is would some kind of normalization help ? 
yeah . 
you know uh it could be that if you normalized uh by the overall um energy uh for uh you know some some longer period of time or something uh that that there would be more of a distinction . 
nnn . 
yeah . 
the different zone . 
uh i i don ' t know . 
so uh from from these charts are 
yeah . 
huh i ' m just trying to remember where we were . 
but uh were you were interested in finding out if you can tell the difference between overlap and single speakers by looking at the energy ? 
like say for example the mean of the energy . 
was that the idea ? 
yeah . 
okay . 
yeah . 
so if you look at on this page that has uh frame energy . 
you look at the mean for the overlap that ' s forty four point sixty two versus the mean for the speakers thirty nine point sixty two . 
yeah . 
yeah . 
so there seems to be more energy when there ' s overlapping which makes sense . 
which is the intuition . 
yeah . 
unfortunately there ' s a standard deviation of like ten . 
yeah . 
but 
yeah . 
yeah . 
oh . 
so for each one 
the product of the deviation is the is the variance . 
different than standard deviation . 
yeah . 
yeah . 
but are we assuming that you could know the energy for a speaker when there ' s no overlap ? 
i mean i can imagine a model where you say okay you know i ' m i ' m going to give myself 
and and and did is this from the mixed signal ? 
it ' s cheating . 
but not completely if they ' re often not overlapping and normalized for the speaker . 
yeah . 
or is that not allowed ? 
i mean what ' s the 
well that ' s what i was suggesting that you want to do some kind of longer time normalization uh with the 
yeah . 
yeah . 
but 
even if you make a mistake occasionally that that is roughly is there some corresponding to that speaker so that if you if if uh if you 
right . 
yeah . 
because that that ' s going to spread out these distributions really a lot to not do any kind of normalization . 
right . 
and so that that could mask the effect somewhat . 
so the um just one more clarifying question . 
on the overlap category is that overlapping of speakers only ? 
yeah . 
it doesn ' t include some of the other sounds ? 
no . 
okay . 
it ' s a pure overlapping zone . 
so that ' s why it doesn ' t add up down . 
i mean that uh overlapping between two three four uh uh speaker . 
okay . 
okay . 
yeah . 
okay so there is some normalization already in that they ' ve been volume equalized uh over the entire signal . 
right right . 
yeah . 
right . 
that ' s what makes it seem difficult . 
because they they ' re 
because you ' re already left with a high standard deviation . 
yeah . 
yeah . 
and they ' re already roughly 
so that each person ' s hearable . 
right ? 
sort of equally loud perceptually anyway . 
right . 
right . 
what about doing it with just the single channels ? 
sorry ? 
what about 
uh 
say this graphic ? 
well i i ' m thinking so they ' re raising the question about the fact that if you use the mixed signal there ' s already been a 
yeah . 
i use the mixed signal without normalization without normalization . 
well but the mixed signal already has a normalization in it . 
i i ' m 
but but 
exactly . 
so what i ' m wondering is what about doing some of this with the single channel recordings . 
uh . 
i i don ' t study the single channel yet . 
but uh is uh is an idea . 
well i think it ' ll be worse . 
right ? 
i think the mixed 
to to begin to work with the uh with the single channel now . 
i have another another thought . 
um this is this is frame energy . 
of course frame frames have a lot of variance to them . 
because different sounds are different loudnesses . 
so i mean what if you took uh one second chunks or something like that ? 
yeah . 
or or maybe not even a second . 
maybe a quarter of a second or something . 
so that you would typically have two or three basically syllable kind of length 
yeah like two hundred milliseconds . 
yeah . 
or twenty to twenty five frames . 
right . 
or window it . 
or 
yeah . 
so then you you ' ll you know 
hamming window . 
something . 
yeah . 
yeah . 
yeah . 
so so i mean so you know two hundred three hundred four hundred 
some longer chunk of time . 
and then you looked at the amount of energy in that . 
and how does that vary over these different cases ? 
uhhuh . 
or voiced regions . 
i mean can we tell ? 
or voiced regions . 
interesting . 
can we sorry i mean is it known whether something ' s voiced here or is it roughly estimate estimateable ? 
well i mean you could do a you could first determine that something was voiced or not . 
i mean like if one speaker ' s voicing and the other one isn ' t and they ' re overlapping do we know that the first speaker ' s voicing or not ? 
well i mean the overlaps are typically more than just a tiny little bit of time . 
uh . 
and so uh there could be voiced and non voiced pieces during the overlap . 
huh . 
uhhuh . 
but will we be able to detect the voicing when there ' s overlap ? 
that ' s what i just wondered . 
i don ' t know . 
because it ' s it ' s this this has to do with these questions of harmonicity and so forth . 
okay . 
so if we could or if you could do some of it 
yeah . 
yeah . 
yeah . 
yeah . 
right ? 
then um voiced regions would be like probably more informative for energy . 
yeah . 
because 
right so you could do something like uh 
and and pitch for that matter . 
but 
sure . 
but i think what will be easy for him to do would be to do this thing of looking over a large enough region of time . 
because if you look over a large enough region of time most of the time you ' ll have some voiced a fair amount of voiced uh energy in it . 
right . 
and so i think that would be 
and he has on his graph something like forty per cent . 
it looked like fifty per cent or more are point two seconds or longer overlap . 
it ' s i think the last page . 
yeah . 
is it ? 
that ' ll also lessen the standard deviation . 
here in the yeah it it ' s a new new a new diapositive with information about the context for overlapping zone . 
nope not the last page . 
um 
where was it ? 
it was one of the tables . 
what 
how define ? 
are you using a pitch detector in this yet in your experiments ? 
uh 
do you have a pitch detector that you ' re using ? 
my 
do you do you have a a pitch detector that you are using in these experiments ? 
pitch ? 
uh i i ' m working now with pitch detector . 
well it ' s the fifth page i guess . 
yeah . 
i ' m working now but uh i haven ' t uh results yet . 
fifth page . 
but uh at this moment i i i prepare i am i am preparing the the pitch uh uh tracking pitch tracker uh algorithm that i have . 
oh it ' s seventy five per cent ! 
does does it have a voiced unvoiced uh detector in it ? 
but uh 
uh 
no . 
it doesn ' t . 
it just finds the it just finds the pitch even when it ' s unvoiced ? 
i mean it must have some it has to tell you something . 
uh i i 
it has to tell you . 
it has to give you at least a zero one . 
yeah . 
right ? 
i mean uh binary 
yeah . 
it ' s based on uh a correlation between frame the utterance . 
yeah . 
but uh i don ' t know what is um uh 
right . 
because it ' s no my my algorithm . 
yeah so ordinarily in these things it does tell you that it ' s it ' s voiced with a pitch of such and such . 
is 
and it will it will say something like zero . 
uhhuh . 
or you know it ' ll have something that it says when it ' s when it can ' t find a good good uh uh period . 
uhhuh . 
right ? 
so it ' s looking for some periodic behavior . 
and if it can ' t find a period it tells you for for most things like that . 
uhhuh . 
for most . 
so i mean this is getting back to what liz was suggesting . 
which i think actually is good the more i think of it . 
that that um for normalization you could do something like take voiced sections and normalize to equalize the energy in that . 
i ' m just still going back to normalization that even though it ' s roughly normalized uh for overall gain i think it it ' s it it may not be normalized enough . 
uhhuh . 
for for both for uh the frame energy and uh residular l p c uh energy too ? 
uh for both . 
yeah . 
for both . 
yeah . 
yeah . 
but uh i test different normalization . 
i uh 
what kind of normalization ? 
i i 
okay so so i think i mean this is something to to experimentally determine . 
this is 
yeah . 
but i mean if um 
yeah . 
as i understand it you have you have some regions that uh um are marked as 
you have training data that you ' re trying to find a threshold . 
right ? 
and so um um if you take um all the things all the uh speak things marked s p k and uh look for the voiced uh energy in them 
uhhuh . 
uhhuh . 
and uh 
well just in in each case take a take a take a frame . 
take the 
uh uh 
if it ' s if it ' s voiced include it . 
just separate out from the from the normal things . 
uhhuh uhhuh . 
separate out voiced . 
yeah . 
right . 
then you ' re going to end up with uh a a uh a mean uh standard deviation and so forth . 
and then do your normalization based on that . 
yeah . 
yeah . 
and once you do that just for voiced 
um um 
i guess you ' d 
you can also look at just the voiced regions later . 
i mean that would be the most sensitive measure . 
because you know if you ' re normalizing for voiced and then you look at regions that are voiced with the same robustness in estimation of what voicing is um you should be much more sensitive to the to the overlaps then if you 
yeah . 
you know if you normalize but you look everywhere at at at fricatives or something you won ' t really know anything . 
yeah . 
so i mean assuming if it ' s true that the overlap regions are sort of long enough that there ' s some voicing in each of them by each of the speakers then you should do very well if you do this . 
right . 
right . 
right . 
but you ' ll only know that in the voiced regions . 
huh . 
but those are close enough to the 
you know there ' s enough voicing going on and off uh that if you can capture the voicing and if you can capture it when there ' s overlap then you should do quite well there . 
uhhuh . 
huh . 
i ' m wondering about um if there 
i suppose this is still just that one that one data sample . 
right ? 
that one meeting ? 
yeah . 
but it seems like to have it it seems like a very hard test to have it be looking at the energy of all the speakers combined rather than taking you know maybe two extreme speakers out of the mix and seeing if if it ' s promising with respect to that type of analysis . 
if you take like a target speaker and maybe 
yeah . 
well i mean if there ' s enough data maybe two . 
two target speakers . 
and then compare that to the mixture of all the speakers . 
you could do that . 
yeah . 
i mean be and if they still overlapped i i the 
that ' s hard . 
but but i i think that this is a good first thing to just sort of see . 
and and what this says is that that without any special normalization at least this is there ' s a lot of overlap here . 
yeah . 
okay . 
and so i mean coming back to jose ' s question 
i mean there ' s still this issue of of of how much time 
i mean 
what do you look at in order to normalize ? 
i mean you you get some data in you don ' t know which it is how do you how do you what period of time do you look over to normalize it by ? 
yeah . 
and and uh that ' s that ' s something to think about and experiment with . 
yeah . 
i think also the harmonics would be very important . 
so if you can find voiced regions and 
yes . 
you know if you have two speakers and they ' re both voicing 
unless they have very similar you know pitch you should be able to see the difference in harmonics pretty clearly . 
right so that ' s what we were talking about before with with harmonicity measure . 
just by counting them . 
um and the length 
i mean 
yeah . 
yeah so even if you ' re not exactly sure when the overlap starts and ends because there ' s some non voiced regions at least you can have these islands of reliability where you ' re pretty sure . 
yeah so 
yeah . 
it seems like with the overlaps being fairly long that should make it easier . 
yeah . 
yeah . 
right . 
that that was an interesting statistic . 
yeah . 
and you could put an estimate estimate you know a fuzzy start and end time . 
yeah . 
yeah . 
that they ' re much longer than i expected . 
but this is very short . 
ninety per cent of them are over two two hundred milliseconds . 
yeah . 
yeah . 
yeah . 
is a problem to detect . 
well it ' s sort of good though if you ' re for for your accuracy . 
but it ' s a problem to it ' s a problem to identify and to detect too with uh the javier system for example . 
it is good . 
but it ' s uh but it surprised me . 
uh gives you a little more time to try to detect them . 
yes . 
for example . 
for example . 
it ' s a problem . 
yeah . 
uh well 
uh 
uh what 
good . 
sorry . 
yeah . 
what what happened with the different contexts ? 
because uh uh you are talking about uh the period or the the duration of the the window to uh the the long of the window to to consider normalization . 
no ? 
yeah and i i 
but uh we have different contexts . 
the the the the period the the the length of the window to to normalize uh the energy is uh in the context of the overlapping zone ? 
is uh in the in the left context as in in the right context considering uh the these frames ? 
you mean ? 
i don ' t know . 
i i want to think about it . 
and you should think about it . 
yeah . 
i i i didn ' t want to just pop out an answer . 
because i realized i i hadn ' t thought about it enough . 
okay . 
two hundred milliseconds hamming window . 
because because the the the problem is that we have different contexts . 
yeah something 
different situation and 
something like that . 
that ' s true . 
that ' s complicated . 
too . 
just out of curiosity what was the bug ? 
i ' m not sure . 
yeah . 
what was the bug that you found ? 
what the 
the bug from last uh meeting . 
uh the bug . 
the bug of was the the f seek function in c . 
because doesn ' t work uh when you uh you try to to to to do an a dated access to to a file a big file uh uh moving the the head of the in the hard disk uh forward and backward a lot of time 
uhhuh . 
uhhuh . 
uh in a moment f seek function doesn ' t work . 
huh . 
and i had an problem . 
uh that ' s interesting . 
and it didn ' t give you good error messages . 
yes this is this is it ' s incredible . 
huh . 
huh ! 
i i i do the same in in another in another way . 
so it was positioning randomly ? 
and i haven ' t problem . 
did you typecast to long ? 
or size t or whatever it is ? 
i don ' t remember what it is . 
one of the problems if the file is large um and you ' re cast to the wrong type . 
i i i don ' t know . 
but uh i i think the the position in the file uh doesn ' t work uh uh in long file . 
a very long file . 
well what he ' s saying is that the typecasting could be the issue for f seek . 
right if you ' re sending at an integer instead of a long . 
the typecast ? 
typecast from integer int i n t or long or unsigned long . 
yeah . 
uh it ' s um no no it ' s unsigned . 
i think it ' s 
yeah . 
well it ' s one possibility . 
signed . 
yeah because i think in i mean in general f seek works . 
i i i don ' t know . 
so it ' s 
yep . 
i don ' t know . 
but uh i i solved the problem with uh a similar way and i haven ' t problem . 
yeah yeah . 
uhhuh . 
yeah . 
but uh i i i don ' t know because uh uh it doesn ' t uh happen to me before . 
yeah . 
but uh i i i have the same codes in different parts . 
anyway 
and uh i i had to to to change all all the points in the in the code uh to substitute uh for another way . 
yep . 
but uh is 
anyway we ' re we ' re missing snacks here . 
so uh let ' s let ' s let ' s let ' s do our let ' s do our digits . 
oh okay . 
shall we do digits ? 
sorry . 
oh digits . 
and and uh 
okay . 
okay . 
are we done ? 
yes okay . 
yep . 
okay . 
okay we are going off . 
okay so uh um 
i don ' t know whether ami ' s coming or not . 
um 
but i think we ought to just get started . 
nancy is currently in berkeley but not here ? 
nancy ' s still stick ? 
don ' t know . 
okay . 
anyway . 
oh ! 
so there you go . 
anyway so my idea for today 
and we can uh decide that that isn ' t the right thing to do . 
was to at spend at least part of the time trying to uh build the influence links . 
you know which sets of things are uh relevant to which decisions . 
and actually i had uh specific suggestion to start first with the path ones . 
the database ones being in some sense less interesting to us . 
although probably have to be done . 
and so to do that 
so there ' s and the idea was we were going to do two things . 
is your mike on ? 
uh 
oh right well 
yeah . 
we were going to do two things . 
one of which is just lay out the influence structure of what we think influences what . 
that ' s funny . 
and then as a uh separate but related task 
uh particularly bhaskara and i were going to try to decide what kinds of belief nodes are needed in order to um do what we what we need to do . 
once 
so but we should sort of have all of the uh basic design of what influences what done before we decide exactly how to compute it . 
so i didn ' t did you get a chance to look at all yet ? 
yeah i looked at some of that stuff . 
great . 
okay so let ' s start with the uh belief nets the general influence stuff . 
and then we ' ll then we ' ll also at some point break and talk about the techy stuff . 
well i think one could go there ' s 
i think we can discuss everything . 
first of all this i added i knew from sort of basically this has to be there . 
right ? 
um 
oh are you going to go there or not . 
yeah so one 
given given uh uh not transverse the castle the decision is does the person want to go there or is it just 
right . 
true . 
does have to be there . 
and 
and i ' m sure we ' ll find more as we go that 
huh . 
so go there in the first place or not is definitely uh one of the basic ones . 
we can start with that . 
interesting effect . 
um is this basically true or false ? 
or maybe we ' ll get 
well 
which one ? 
what ? 
go there . 
right . 
so there is this question about 
here we 
we actually get just probabilities . 
yeah . 
right ? 
for each down here . 
when we ' re yeah when we ' re done . 
huh . 
so so 
the the reason it might not be true or false is that we did have this idea of when . 
so it ' s you know uh current and so forth and so on or not at all . 
uhhuh . 
right ? 
and so that a decision would be do we want that 
so you could two different things you could do . 
you could have all those values for go there . 
or you could have go there be binary and given that you ' re going there when . 
when . 
how . 
yeah . 
why . 
and so forth . 
yeah . 
so i ' ll let 
we ' ll see . 
huh . 
i mean it seems that you could um uh it seems that those things would be logically independent . 
like you would want to have them separate or binary . 
go there and then the the possibilities of how to go there . 
because 
okay that ' s let ' s start that way . 
because you know it might be easy to figure out that this person is going to need more film eventually from their utterance . 
but it ' s much more complex to query when would be the most appropriate time . 
huh . 
huh . 
okay . 
and so i ' ve tried to come up with some initial things one could observe . 
so who is the user ? 
everything that has user comes from the user model . 
everything that has situation comes from the situation model a . 
we should be be clear . 
but when it comes to sort of writing down 
when you when you do these things 
is it here ? 
you sort of have to write the values this can take . 
right . 
and here i was really uh in some sometimes i was really sort of standing in front of a wall feeling very stupid . 
because um this case it ' s pretty simple . 
but as we will see the other ones um 
for example if it ' s a running budget so what are the discrete values of a running budget . 
so maybe my understanding there is too impoverished . 
huh . 
how can i write here that this is something a number that keeps on changing ? 
no uh 
but okay . 
thus is understandable ? 
yes . 
think so . 
so here for example 
you ' ve have you seen this before at all keith these belief net things ? 
uh no . 
but i think i ' m following it . 
so far . 
so here is the the we had that the user ' s budget may influence the outcome of decisions . 
yeah . 
huh . 
there we wanted to keep sort of a running total of things . 
is this like a number that represents how much money they have left to spend ? 
okay well i mean how is it different from user finance ? 
um the finance is sort of here thought of as as the financial policy a person carries out in his life . 
he is he cheap average or spendy ? 
all right . 
and um i didn ' t come uh 
maybe a user 
i don ' t know . 
i didn ' t want to write greediness . 
but 
yeah . 
huh . 
welcome . 
or cheapness . 
welcome . 
user thrift . 
yeah . 
thrift that ' s good . 
great . 
there it is . 
yeah so keith what ' s behind this is actually a program that will once you fill all this in actually solve your belief nets for you and stuff . 
uhhuh . 
so this is not just a display . 
this is actually a gui to a simulator that will if we tell it all the right things we ' ll wind up with a functioning belief net at the other end . 
okay . 
okay . 
and it ' s so simple even i can use it . 
wow that is simple ! 
okay so here was 
okay i can think of uh people being cheap average or spendy or we can even have a a finer scale moderately cheap . 
doesn ' t matter . 
doesn ' t matter . 
agree there . 
but here um i wasn ' t sure what to write in . 
let ' s 
go ahead . 
well i mean you ' ve written in you ' ve written in what uh seems to be required . 
like what else is is do you want ? 
if that ' s permissible then i ' m happy . 
well yeah so here ' s here ' s what ' s permissible . 
is that you can arrange so that the um the value of that is going to have to be updated . 
and it ' s not a belief update . 
right ? 
it ' s you took some actions you spent money and stuff . 
so the update of that is going to have to be essentially external to the belief net . 
yeah . 
right ? 
and then what you ' re going to need is uh for the things that it influences 
well let ' s first of all let ' s see if it does influence anything . 
and if it does influence anything then you ' re going to need something that converts from the the number here to something that ' s relevant to the decision there . 
so it could be they create different ranges that are relevant for different decisions or whatever . 
but for the moment this is just a node that is conditioned externally and might influence various things . 
huh . 
yeah this is where um 
okay anyways . 
let ' s forget it . 
well that ' s fine . 
well anyway go ahead . 
okay and so this oh that 
the other thing is that um every time that ' s updated beliefs will have to be propagated . 
but then the question is do you do we want to propagate beliefs every single time it ' s updated or only when we need to ? 
yeah that ' s a good question . 
and uh does it have a lazy mode ? 
i don ' t remember . 
uh 
well i mean in srini ' s thing there was this thing there was this um option like proper inferences which suggests that uh doesn ' t happen automatically . 
oh right ! 
yeah . 
probably does . 
yeah . 
someone has to track that down . 
but i but uh 
i just accidentally 
and and and i think actually uh 
oops ! 
one of the items for the uh user home base uh should be uh essentially non local . 
they ' re only there for the day and they don ' t have a place that they ' re staying . 
well 
oh just uh accidentally erased this . 
i i just had values here such as uh um is he we had in our list we had is he staying in our hotel . 
is he staying with friends . 
and so forth . 
yeah . 
uh 
so we ' re 
okay . 
so 
it ' s clear where where we are right now . 
so my suggestion is we just pick uh 
something down here ? 
one you know one uh particular one of the uh 
well let ' s do the first first one let ' s do the one that we sort of already think we did . 
so that was the of the endpoint ? 
uhhuh . 
and um 
oops ! 
is 
huh . 
uh . 
so it ' s true or false ? 
no no no . 
no that ' s that ' s a 
e v a . 
missed that one . 
so 
what ' s the difference between mode and endpoint ? 
i thought mode . 
yeah . 
although that 
um mode was um 
well that ' s 
mode of transportation ? 
yeah . 
okay . 
also true or false . 
uhhuh . 
no he he hasn ' t filled them in yet is what ' s true . 
yeah okay . 
did i or didn ' t i ? 
no . 
probably nothing done yet . 
oh i just did it on the upper ones okay . 
makes sense . 
okay so this was e v a . 
maybe we can think of more things . 
cross . 
yeah . 
okay . 
climb rob . 
climb emerge . 
no no no . 
uh 
well some of those are subsumed by approach . 
these are that ' s just a point . 
this is 
would it be an endpoint if you were crossing over it ? 
the charles bridge you know . 
yeah would be a for a given segment . 
you know you you go first go the town square . 
well i uh 
no i mean if you go to you know if you go to prague or whatever one of your your key points that you have to do is cross the charles bridge . 
and doesn ' t really matter which way you cross . 
which where you end up at the end . 
but the part the good part is walking over it . 
so 
that ' s subtle but true . 
anyway . 
so let ' s just leave it three with three for now . 
uhhuh . 
yeah . 
and let ' s see if we can get it linked up just to get ourselves started . 
okay we 
you ' ll see it you ' ll see something comes up immediately that the reason i want to do this . 
well the uh user was uh definitely more likely to enter if he ' s a local . 
right . 
right . 
more likely to view if he ' s a tourist . 
um 
and then of course we had the fact that given the fact that he ' s thrifty and there will be admission then we get all these cross um 
we did but the three things that that it contributed to this 
in fact the other two aren ' t up there . 
so one was the ontology . 
we ' ll what type of building is it ? 
yeah . 
yeah . 
and the and the third thing we talked about was something from the discourse . 
what he has mentioned before . 
okay so this is 
right so what i what we seem to need here 
this is why it starts getting into the technical stuff . 
uhhuh . 
the way we had been designing this there were three intermediate nodes . 
uh which were the endpoint decision as seen from the uh user model as seen from the ontology and as seen from the discourse . 
so each of those 
the way we had it designed 
now we can change the design . 
but the design we had was 
there was a decision with the same three outcomes uh based on the those three separate considerations . 
uhhuh . 
so if we wanted to do that would have to put in uh three intermediate nodes . 
uh we can load it up it you know very simple . 
so 
and then what you and i have to talk about is okay if we ' re doing that and they get combined somehow uh how do they get combined . 
but the they ' re they ' re undoubtedly going to be more things to worry about . 
so this was adjusted for this one mode thing . 
oh yes . 
yeah . 
so that ' s in our uh in in johno ' s sort of pictogram everything that could contribute to whether a person wants to enter view or approach something . 
oh it was called mode . 
so this this is mode here means the same as endpoint . 
is now this endpoint . 
right . 
okay why don ' t we can we change that ? 
we can just rename that yeah . 
all right . 
you know but that was actually 
yeah unfortunately that was a um kind of an intermediate 
that ' s i don ' t think what we would currently do . 
can i ask about slurred and angry as inputs to this ? 
that ' s a 
what why ? 
like they ' re either true or false . 
the prosody ? 
and they uh 
okay . 
oh i see . 
if the if the person talking is angry or slurs their speech they might be tired or you know . 
uhhuh . 
okay . 
drunk . 
therefore 
and you know possibly uh 
less likely to enter . 
some 
uh i was thinking less likely to view . 
yeah . 
huh . 
yeah . 
but that ' s that seems to 
yeah . 
so so my advice to do is is get this down to what we think is actually likely to to be a a strong influence . 
okay . 
right . 
but yeah that was what he had in mind . 
so let ' s think about this this question of how do we want to handle 
so there ' re two separate things . 
one is 
uh at least two . 
one is how do we want to handle the notion of the ontology . 
now what we talked about and this is another technical thing bhaskara is uh can we arrange so that 
i think we can . 
so that the belief net itself has properties . 
and the properties are filled in uh from ontology items . 
so the let ' s take the case of the uh this endpoint thing . 
the notion was that if you had a few key properties like is this a tourist site you know some kind of landmark . 
is it a place of business . 
uh is it something you physically could enter . 
uhhuh . 
okay ? 
et cetera . 
so that there ' d be certain properties that would fit into the decision node . 
and then again as part of the outer controlling conditioning of this thing those would be set . 
so that somehow someone would find this word look it up in the ontology pull out these properties put it into the belief net and then the decision would flow . 
uhhuh . 
now 
seems to me that we ' ve sort of embedded a lot embedded a lot of these uh things we had in there previously in in in some of the other final decisions done here . 
for example if we would know that this thing is exhibiting something um 
right . 
right . 
if it ' s exhibiting itself it is a landmark . 
meaning more likely to be viewed . 
yeah . 
yep . 
if it is exhibiting pictures or sculptures and stuff like this then it ' s more likely to be entered . 
i uh that ' s i think that ' s completely right . 
and um i think that ' s good . 
right ? 
so what what that says is that we might be able to uh take and 
in particular 
so so the ones we talked about were uh exhibiting and selling . 
accessibility . 
no accessibility meant 
if it ' s closed one probably won ' t enter . 
or if it ' s not accessible to a tourist ever the likelihood of that person actually wanting to enter it . 
okay . 
given that he knows it of course . 
all right . 
so let me suggest this . 
uh could you move those up about halfway ? 
uh the ones that you and selling i guess . 
yeah all all of these . 
if it ' s fixing things selling things or servicing things . 
right . 
so here here ' s what it looks like to me . 
is that you want an intermediate structure which uh is essentially the or of uh for this purpose of of uh selling fixing or servicing . 
so that it uh 
that is for certain purposes it becomes important . 
but for this kind of purpose uh one of these places is quite like the other . 
does that seem right ? 
so we 
you ' re basically just merging those for just the sake of endpoint decision ? 
if we 
yes . 
yeah . 
so if well it may be more than endpoint decisions . 
uhhuh . 
so the idea would be that you might want to merge those three . 
these three ? 
yeah . 
uh uh selling fixing and servicing . 
yeah . 
what um and so either those is true or false ? 
so 
uh uh well it it here ' s where it gets a little tricky . 
uh from the belief net point of view it is . 
from another point of view of course it ' s it ' s it ' s important to know what it ' s selling or servicing and so forth . 
yeah . 
okay . 
so for this decision it ' s just uh true or false . 
yeah . 
and in this is a case where the or seems just what you want . 
okay . 
that that if any of those things is true then it ' s the kind of place that you uh 
um more likely to enter . 
are more likely to enter . 
so you just want to have them all pointing to a summary thing ? 
you could yeah . 
yeah so let ' s do that . 
no no no uh to to an no an intermediate node . 
oh okay . 
that ' s the part of the idea is 
um is is that the object type node ? 
i 
so are they the is it the kind of object that sells fixes or services things ? 
well open up object type and let ' s see what its values are . 
oh i just created it it has none so far . 
oh well okay first of all it ' s not objects . 
we called them entities . 
yeah . 
right ? 
and then we have sort of the um 
let ' s say i put commercial . 
yeah . 
i i was just going to 
commercial action inside where people 
well couldn ' t i do let ' s do commercial . 
uh landmark . 
and 
and where was the accessible yeah . 
well 
accessible i think is different . 
yeah . 
because that ' s that that varies temporally . 
whereas this is a 
uhhuh . 
what would a hotel fall under ? 
i would call that a service . 
but but i don ' t know . 
well i mean in terms of entity type ? 
say well it ' s i would 
again for this purpose i think it ' s commercial . 
someplace you want to go in to do some kind of business . 
okay . 
um what does the underscore t at the end of each of those things signify ? 
um things . 
so places that service things sell things or fix things and places that exhibit things . 
uhhuh . 
okay . 
okay . 
that also points to entity type i guess . 
so we ' re deriving um this the this feature of whether the the main action at this place happens inside or outside or what we ' re deriving that from what kind of activity is done there ? 
couldn ' t you have it as just a primitive feature of the entity ? 
well you could . 
that ' s a that ' s a choice . 
okay . 
so uh 
i mean it seems like that ' s much more reliable . 
because you could have outdoor places that sell things . 
and you know indoor places that do something else . 
yeah the problem with it is that it sort of putting in a feature just for one decision . 
and 
now we may wind up having to do that . 
huh . 
this anyway this 
okay . 
at a mental level that ' s what we ' re going to have to sort out . 
okay . 
so you know what does this look like . 
what are what are uh intermediate things that are worth computing . 
what are the features we need in order to make all these decisions . 
uhhuh . 
and what ' s the best way to organize this so that um it ' s clean and and consistent and all that sort of stuff . 
okay . 
i ' m just thinking about how people human beings who know about places and places to go and so on would store this . 
and it would probably you wouldn ' t just sort of remember that they sell stuff and then deduce from that that it must be going on inside or something . 
well i think an entity maybe should be regard as a vector of several possible things . 
it can either them do do sell things fix things service things exhibit things it can be a landmark at the same time as doing these things . 
uhhuh . 
it ' s not either or . 
certainly a place can be a hotel and a famous site . 
uhhuh . 
many come to mind . 
things can be generally um a landmark and be accessible . 
i e a a castle . 
or can be a landmark or not accessible some statue . 
uhhuh . 
you know can go inside . 
okay . 
anyway so let me suggest you do something else . 
uh which is to get rid get rid of that long link between who the user and the endpoint . 
could we just move it like this ? 
no no i don ' t want the link there at all . 
oh okay . 
because what we ' re going to want is an intermediate thing . 
which is uh the endpoint the endpoint decision based on the user models . 
so what we we what we talked about is three separate endpoint decisions . 
so let ' s make a new node . 
yeah . 
yeah . 
just as a suggestion maybe you could save as to keep your old one nice and clean . 
and so you can mess with this one . 
huh . 
the old one was not that not that important i think . 
but 
okay well not a big deal then . 
let ' s do it then . 
well the 
isn ' t there a save as inside of java base ? 
but i can just take this . 
okay . 
copy it somewhere else . 
this was user something ? 
or 
well this was 
uh let ' s put it this let ' s do endpoint underbar u . 
end point ? 
endpoint end 
this is 
uh . 
it ' s the endpoint . 
gotcha yeah . 
let ' s say underbar u . 
so that ' s the endpoint decision uh as seen through the 
as related from the user model . 
right . 
so let ' s let ' s actually 
yeah so you can link that up to the 
should i rename this too ? 
uh yeah so that i guess that ' s endpoint uh 
or 
it ' s underscore e . 
underscore e for entity . 
and we may change all this . 
but 
right . 
and 
okay shouldn ' t i be able to move them all ? 
no ? 
or 
can i ? 
where ? 
what ? 
oh i uh i don ' t know . 
actually i guess the easiest thing would move move the endpoint 
well go ahead . 
just do whatever . 
wasn ' t this possible ? 
well 
yeah . 
i think you have to be in move mode before 
uhhuh . 
okay . 
good . 
right . 
so now we ' re looking for user related things that um 
yeah . 
and uh maybe maybe it ' s just one who is the user . 
i don ' t know . 
maybe maybe there ' s more . 
huh . 
well if he ' s if he ' s in a car right now 
what was that ? 
people with harry drove the car into the cafe . 
never mind . 
uh anyway this is crude . 
now but the now so so but then the question is 
uh 
so and and we assume that some of these properties would come indirectly through an ontology . 
but then we had this third idea of input from the discourse . 
well let ' s should we finish this ? 
i mean but surely the user interests 
sure . 
okay . 
the user thrift . 
the user budget . 
yeah yeah . 
well maybe . 
again i 
well okay put them in . 
but what we ' re going to want to do is actually uh 
well is 
here this was one of my problems . 
we have the user interest is a is a vector of five hundred values . 
so 
um that ' s from the user model . 
oh you mean level of interest ? 
uhhuh . 
no not levels of interest . 
but things you can be interested in . 
well 
somebody else has built this user model . 
gothic churches versus baroque townhouses versus 
oh i see . 
right . 
so why is it 
oh it so it ' s like a vector of five hundred one ' s or zeroes ? 
is that 
like for each thing are we are you interested in it or not ? 
yeah . 
uh i i think . 
i see . 
huh . 
okay . 
so uh you and so here let me give you two ways to handle that . 
all right ? 
one is um you could ignore it . 
but the other thing you could do is have an 
and this will give you the flavor of the of what . 
you could have a node that ' s that was a measure of the match between the object ' s feature you know the match between the object the entity i ' m sorry and the user . 
uhhuh . 
uh . 
so you could have a a fit node . 
and again that would have to be computed by someone else . 
uhhuh . 
but uh 
so that uh 
just as a mental note . 
uh 
yeah that ' s all . 
uhhuh . 
and and should we say that this interests uh affects the likelihood of of entering ? 
yeah . 
i mean we could . 
yeah . 
and also if it ' s an expensive place to enter this may also 
okay . 
budget . 
user schedule . 
schedule ? 
do i have time to go in and climb all the way to the top of the koelner dome or do i just have to time to take a picture of the outside . 
right . 
it seems like everything in a user model affects 
well that ' s what we don ' t want to do . 
see that 
yeah . 
because then we get into huge combinatorics and stuff like that . 
uhhuh . 
because if the i mean and if the user is tired the user state . 
well 
right ? 
it would affect stuff . 
but i can ' t see why anything everything in the model wouldn ' t be 
well but 
right . 
well that that ' s we can ' t do that . 
so we ' re going to have to 
yeah . 
but this is a good discussion . 
we ' re going to have to somehow figure out uh some way to encapsulate that . 
uh so if there ' s some general notion of for example the uh relation to the time to do this to the amount of time the guy has or something like that is is the uh compatibility with his current state . 
so that ' s what you ' d have to do . 
you ' d have to get it down to something which uh was itself relatively compact . 
so it could be compatibility with his current state . 
which would include his money and his time and and his energy . 
yeah just seems like it ' d push the problem back a level . 
right . 
it does . 
yeah but 
uhhuh . 
no but it ' s more than that . 
like the the more sort of you break it up . 
like because if you have everything pointing to one node it ' s like exponential . 
whereas if you like keep breaking it up more and more it ' s not exponential anymore . 
so it yeah there are two advantages . 
that ' s there ' s one technical one . 
yeah . 
and the other is it it gets used . 
so we ' d basically be doing subgrouping ? 
subgrouping basically ? 
yeah . 
into 
so basically make it more tree like going backwards ? 
right . 
yeah . 
right . 
but it there ' s two advantages . 
one is the technical one that you don ' t wind up with such big exponential uh c b t ' s . 
bhaskara ? 
the other is it can be it presumably can be used for multiple decisions . 
uhhuh . 
so that if you have this idea of the compatibility with the requirements of an action to the state of the user one could well imagine that that was 
right . 
not only is it is it cleaner to compute it separately but it could be that it ' s used in multiple places . 
anyway so in general this is the design this is really design problem . 
yeah . 
okay you ' ve got a signal a set of decisions . 
um how do we do this ? 
what do i have under user state anyhow ? 
because i named that already something . 
oh that ' s tired fresh . 
yeah . 
maybe should be renamed into physical state . 
or user fatigue even . 
huh . 
that ' s with a g ? 
uhhuh . 
yep . 
whatever . 
then we can make a user state . 
what ' s what we ' re talking about is compatibility . 
uh or something i don ' t know . 
but 
i guess the the question uh is 
it ' s hard for me to imagine how everything wouldn ' t just contribute to user state again . 
or user compatibility . 
oh but the thing is that we uh uh we had some things that uh 
that don ' t . 
that don ' t . 
the user interests and the user who who who the user is are completely apart from the fact whether he is tired broke 
sure but other i thought though the node we ' re creating right now is user compatibility to the current action . 
right ? 
the 
right . 
seems like everything in the user model would contribute to whether or not the user was compatible with something . 
uh maybe not . 
i mean the that ' s the the issue is um 
would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . 
and anyway we ' re going to have to find some way to uh get this sufficiently simple to make it feasible . 
maybe um if we look at the if we split it up again into sort of um 
if we look at the uh the endpoint again we we said that for each of these things there are certain preconditions . 
so you can only enter a place if you are not too tired to do so . 
and also uh have the money to do so if it costs something . 
so if you can afford it and perform it is preconditions . 
viewing usually is cheap or free . 
is that always true ? 
uhhuh . 
i don ' t know . 
well with the way we ' re defining it i think yeah . 
but that uh viewing it without yeah view with our definition of view it ' s free . 
because you 
and so is approaching . 
yeah . 
well what about the grand canyon ? 
right ? 
no never mind . 
i mean are there are there large things that you would have to pay to get up close to ? 
like i mean 
never mind . 
not in the current 
no we have to enter the park . 
okay . 
uh almost by definition um paying involves entering . 
yeah . 
going through some 
okay . 
right sure . 
right . 
uh 
so let me suggest we switch to another one . 
i mean clearly there ' s more work to be done on this . 
uhhuh . 
but i think it ' s going to be more instructive to to think about uh other decisions that we need to make in path land . 
and what they ' re going to look like . 
so you can save this one as and open up the old one . 
right ? 
and 
and then everything would be clean . 
you could do it again . 
why i think it ' s worth saving this one . 
but i think i ' d i ' d like to keep this one . 
yeah . 
because i want to see if if we ' re going to reuse any of this stuff . 
uhhuh . 
um 
so this might be 
what next ? 
well you tell me . 
so in terms of the uh planner what ' s what ' s a good one to do ? 
well let ' s this 
go there or not i think is a good one . 
uh 
is a very basic one . 
so 
what makes things more likely that 
so 
well the see the first thing is getting back to thing we left out of the other is the actual discourse . 
so keith this is going to get into your world . 
because uh we ' re going to want to know you know which constructions indicate various of these properties . 
uhhuh . 
uhhuh . 
and so 
i i don ' t yet know how to do this . 
i guess we ' re going to wind up pulling out uh discourse properties like we have object properties . 
and we don ' t know what they are yet . 
uhhuh . 
so that that the go there decision will have a node from uh discourse . 
and i guess why don ' t we just stick a discourse thing up there to be as a placeholder for 
we we also had discourse features of course for the endpoint . 
of of course . 
identified that . 
yeah . 
and so again that ' s completely correct . 
we have the user model the situation model here . 
we don ' t have the discourse model here yet . 
much the same way as we didn ' t we don ' t have the ontology here . 
well the ontology we sort of said we would pull these various kinds of properties from the ontology like exhibiting selling and so forth . 
really . 
so in some sense it ' s it ' s there . 
uhhuh . 
but the discourse we don ' t have it represented at all yet . 
yeah . 
um 
this be specific for second year . 
um 
and and we probably will have uh something like a discourse for endpoint . 
but if we do it ' ll have the three values . 
huh ? 
it ' ll have the e v a values . 
yeah . 
if if we have it . 
yeah . 
okay just for starters . 
and here discourse um 
for go there probably is true and false let ' s say . 
that ' s what we talked about . 
um 
well i think um we ' re looking at the the little data that we have . 
so people say how do i get to the castle . 
and this usually means they want to go there . 
uhhuh . 
so this should sort of push it in one direction . 
right . 
however people also sometimes say how do i get there . 
in order to find out how to get there . 
without wanting to go there . 
uhhuh . 
and sometimes um people say where is it . 
uhhuh . 
because they want to know where it is . 
but in most cases they probably 
yeah but that doesn ' t change the fact that you ' re you want these two values . 
oh yeah . 
true . 
so this is sort of some external thing that takes all the discourse stuff . 
and then says here it ' s either yep yay a or nay . 
yeah . 
okay . 
and they ' ll be a uh a user go there . 
and maybe that ' s all . 
i don ' t know . 
situation go there . 
i mean because it ' s whether it ' s open or not . 
uhhuh . 
okay good . 
that definitely . 
yep . 
but that now that kind of 
um what ' s the word ? 
huh . 
um the that interacts with the uh e v a thing . 
if they just want to view it then it ' s fine to go there when it ' s closed . 
whereas if they want to um 
right . 
so 
right so that ' s that ' s where it starts getting to be uh uh essentially more interesting . 
so what uh bhaskara says which is completely right is if you know that they ' re only going to view it then it doesn ' t matter whether it ' s closed or not . 
uhhuh . 
in terms of uh uh you know whether whether you want to go there . 
the time of day . 
right ? 
i well right . 
uhhuh . 
it does matter though if there ' s like a strike or riot or something . 
absolutely there are other situational things that do matter . 
right . 
so 
yeah that ' s what i said . 
just having one situational node may not be enough . 
because this that node by itself wouldn ' t distinguish 
well it can have various values . 
yeah but we uh you you ' re right it might not be enough . 
yeah i mean see i ' m i ' m thinking that any node that begins with go there is either going to be true or false . 
well what 
whoops ! 
yeah . 
right . 
uh . 
i see . 
that could be . 
also that node i mean the go there s node would just be fed by separate ones for 
uhhuh . 
could be . 
you know there ' s different things the strikes and the 
yeah . 
like situation traffic and so on . 
yeah . 
yeah the time of day . 
so so now the other thing that bhaskara uh pointed out is what this says is that uh there should be a link . 
and this is where things are going to get very messy . 
from the endpoint uh decision . 
i guess the final 
maybe the they ' re final and i guess the very bottom endpoint decision uh to the go there node . 
and i don ' t worry about layout . 
yeah . 
i mean then we ' ll go we ' ll go nuts . 
uhhuh . 
huh . 
but 
maybe we could um have intermediate node that just the endpoint and the go there s node sort of fed into . 
could be . 
yeah . 
right . 
because that ' s what we i mean that ' s why this situation comes up . 
yeah . 
well the go there actually the endpoint node could feed feed into the go there s . 
yeah right . 
that ' s right . 
so the endpoint node 
uhhuh . 
make that up to the go there then . 
yeah . 
and again we ' ll have to do layout at some point . 
but something like that . 
now it ' s going to be important not to have loops by the way . 
i was just going to 
uh really important in in the belief net world not to have loops . 
uh 
yes . 
how long does it take you to to compute uh 
no it ' s much worse than that . 
it if it it it it it ' s not it ' s not well defined if you ' re there are loops . 
it things don ' t converge yeah . 
uh recursive action ? 
you just you have to 
there are all sorts of ways of breaking it up so that there isn ' t 
uh 
uh but this isn ' t this is this line is just coming from over here . 
okay . 
yeah . 
yeah . 
yeah no it ' s not a loop yet i ' m just saying we we in no in 
huh . 
well but the good thing is we we could have loopy belief propagation which we all love . 
right . 
okay so anyway so that ' s another decision . 
uh what ' s what ' s another decision you like ? 
okay these have no parents yet but i guess that sort of doesn ' t matter . 
right ? 
well the idea is that you go there you go comes from something about the user from something about the situation and the uh the discourse is is a mystery . 
i mean this is sort of 
this comes from traffic and so forth yeah . 
should we just make some ? 
sure if you want . 
um 
if there ' s parking maybe 
huh . 
oh who cares ? 
okay . 
and if he has seen it already or not and so forth . 
right . 
okay . 
um 
and discourse is something that sort of 
should we make a keith note here ? 
that sort of comes from keith . 
sure . 
uhhuh . 
just sort of so we don ' t forget . 
oops ! 
have to get used to this . 
okay . 
whoops ! 
um actually 
and then also the discourse endpoint . 
i i guess endpoint sub d is if you want to make it consistent . 
uh . 
uhhuh . 
um actually is this the the right way to have it ? 
where um go there from the user and go there from the situation just sort of don ' t know about each other but they both feed the go there decision . 
i think so . 
because isn ' t the i mean 
uh 
huh 
okay . 
maybe not . 
but that still allows for the possibility of the of the user model affecting our decision about whether a strike is the sort of thing which is going to keep this user away from 
right . 
that all that that kind of decision making happens at the go there node . 
uh you yeah you you if you needed to do that . 
uh . 
if you needed it to do that . 
yeah . 
but uh okay i was just thinking . 
yeah . 
i guess maybe i ' m conflating that user node with possible possible asking of the user . 
you know ? 
uh . 
hey there ' s a strike on uh does that affect whether or not you want to go or something . 
good point i don ' t i don ' t know how we ' re going to uh 
or 
yeah so that might not come out of a user model . 
but you know directly out of interaction . 
right . 
uh i yes my you know don ' t yeah yeah yeah that ' s enough . 
yeah . 
uh my current idea on that would be that each of these decision nodes has questions associated with it . 
uhhuh . 
and the question wouldn ' t itself be one of these conditional things . 
you know given that you know there ' s a strike do you still want to go . 
okay . 
yeah . 
but uh if you told him a bunch of stuff then you would ask him do you want to go . 
uhhuh . 
but i think trying to formulate the conditional question that sounds too much . 
okay . 
right right . 
yeah . 
right sure okay . 
to me . 
uhhuh . 
all right but let me let let ' s stay with this a minute . 
but 
because i want to do a little bit of organization . 
before we get more into details . 
the organization is going to be that uh 
the flavor of what ' s going on is going to be that uh 
as we sort of going to this detail indeed keith is going to to worry about the various constructions that people might use . 
uhhuh . 
and johno has committed himself to being the parser wizard . 
so what ' s going to happen is that eventually 
all right . 
like by the time he graduates . 
okay ? 
uh they ' ll be some sort of system which is able to take the discourse in context and have outputs that can feed the rest of belief net . 
i i i assume everybody knows that . 
i just want to you know get closure that that ' ll be the game then . 
uhhuh . 
so the semantics that you ' ll get out of the discourse will be of values that go into the various discourse based decision nodes . 
and now some of those will get fancier like mode of transportation and stuff . 
so it isn ' t by any means uh necessarily a simple thing that you want out . 
so uh if there is and there is mode of transportation 
and it there ' s a sort of also a split if you if you blow this up and look at it in more detail there ' s something that comes from the discourse in terms of what was actually just said . 
what ' s the utterance giving us ? 
yeah . 
and then what ' s the discourse history give us ? 
yeah well that well we ' ll have to decide uh how much of where that goes . 
uhhuh . 
that ' s uh two things then . 
huh . 
uhhuh . 
and it ' s not clear yet . 
i mean it could be those are two separate things . 
it could be that the discourse gadget itself integrates them as 
which would be my guess . 
that you ' d have to do see in order to do reference and stuff like that um you ' ve got to have both the current discourse and the context to say i want to go back there . 
wow what does that mean . 
uhhuh . 
and uh 
uhhuh . 
now . 
uhhuh . 
all right . 
so 
but is is this picture that ' s emerging here just my wish that you have noticed already for symmetry ? 
or is it that we get for each each decision on the very bottom we sort of get the sub e sub d sub u and maybe a sub o o for ontology um meta node ? 
i don ' t know . 
but it might just 
it could be . 
could be . 
so this 
this is this is getting into the thing i want to talk about next . 
which is if that ' s true uh how do we want to combine those ? 
or when it ' s true . 
but this uh would be nice though that you know we only have at most four at the moment um arrows going to each of the uh bottom decisions . 
yeah . 
yeah . 
and four you we can handle ? 
no . 
it ' s too much ? 
yeah . 
well it if it ' s if it ' s four things and each of them has four values it turns out to be a big c p t . 
it ' s not completely 
i mean it ' s it ' s not beyond what the system could solve . 
but it ' s probably beyond what we could actually uh write down or learn . 
right true . 
uh but you know it ' s four to the fourth . 
it ' s pretty big . 
uh 
two fifty six ? 
is that what that 
yeah . 
yeah i mean 
it ' s and i don ' t think it ' s going to i don ' t think it ' ll get worse than that by the way . 
so that ' s a that ' s a good 
huh yeah . 
but but four didn ' t we decide that all of these had true or false ? 
so is it ' s four 
uh for go there . 
but not but not for 
yeah . 
the other one ' s three values for endpoint already . 
yeah i mean you need actually three to the five . 
because uh well i mean if if it has four inputs and then it itself has three values . 
right . 
so 
i mean it can get big fast . 
um for endpoint ? 
no it ' s it ' s 
e it ' s the e v a . 
yeah down here . 
but this one only has two . 
no it still has three . 
no . 
since they will still have three . 
e v a . 
each so you ' re uh uh from each point of view you ' re making the same decision . 
uhhuh . 
so from the point of view of the of the entity 
uhhuh . 
want to view that 
yeah yeah . 
yeah . 
yeah . 
this and also i mean the other places where 
like for example consider endpoint view it has inputs coming from user budget user thrift . 
right . 
so even 
those are not necessarily binary . 
so we ' re we ' re going to have to use some care in the knowledge engineering to not have this explode . 
and in fact i think it doesn ' t in the sense that 
um 
read it 
you know actually with the underlying semantics and stuff i think it isn ' t like you have two hundred and fifty six different uh ways of of thinking about whether this user wants to go to some place . 
all right . 
so we we just have to figure out what the regularities are and and code them . 
but um what i was going to suggest next is maybe we want to work on this a little longer . 
but i do want to also talk about the thing that we started into now of 
uh 
well it ' s all fine to say all these arrows come into the same place . 
what rule of combination is used there ? 
so yes they so these things all affect it . 
uhhuh . 
right . 
how do they affect it ? 
and belief nets have their own beliefs about uh what are good ways to do that . 
so is it it ' s it ' s clearer clear enough what the issue is . 
right . 
right ? 
so do we want to switch that now or we want to do some more of this ? 
basically we just need to sort of 
in order to get some closure on this figure out how we ' re going to get this picture sort of uh completely messy . 
well here here ' s one of the things that that i you 
you no 
i don ' t know how easy it is to do this in the interface . 
but you it would be great if you could actually just display at a given time uh all the things that you pick up 
you click on endpoint . 
okay . 
uhhuh . 
and everything else fades . 
and you just see the links that are relevant to that . 
and i 
does anybody remember the gui on this ? 
uh i would almost say the other way to do that would be to open or make you know n many belief nets . 
and then open them every time you wanted to look at a different one . 
uhhuh . 
it ' s probably pretty easy do it to do it in h t m l . 
because uh 
just 
yeah but 
uh 
h t m l ? 
yeah i have each of these each of the end belief nets be be a page and then you click on the thing . 
and then consider that it ' s respective . 
okay . 
yeah the well the 
but 
anyway so uh it clear that even with this if we put in all the arrows nobody is going to be able to read the diagram . 
yeah . 
all right . 
so we have to figure out some uh uh uh basically display hack or something to do this . 
because 
anyway i i let me suggest that ' s a not a first order consideration . 
we have two first order considerations . 
which is what are the uh influences . 
a . 
and b how do they get combined mathematically ? 
how do we display them is an issue . 
but 
um 
i don ' t yeah i just don ' t think this has been designed to support something like that . 
yeah . 
yeah i i mean it might soon if this is going to be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes . 
right . 
yeah and um i that seems like a perfectly feasible thing to get into . 
but um we have to know what we want first . 
okay so why don ' t you tell us a little bit about decision nodes and what what the choices might be for these ? 
so 
i guess that ' s 
you can technically wear that as you ' re talking . 
yeah it ' s right i guess i can do that . 
darn ! 
put it in your 
yeah . 
i guess this board works fine . 
so um recall the basic problem which is that um you have a belief net and you have like a lot of different nodes all contributing to one node . 
right ? 
so as we discussed specifying this kind of thing is a big pain . 
and it ' s will take a long time to write down . 
because for example if these s have three possibilities each and this has three possibilities then you know you have two hundred and forty three possibilities . 
which is already a lot of numbers to write down . 
so what um helps us in our situation is that these all have values in the same set . 
right ? 
these are all like saying e v or a . 
right ? 
so it ' s not just a generalized situation like 
i mean basically we want to just take a combination of 
we want to view each of these as experts . 
who are each of them is making a decision based on some factors . 
and we want to sort of combine their decisions . 
and create you know um sort of weighted combination . 
huh . 
rover the rover decision . 
the what decision ? 
rover . 
all of their outputs combined to make a decision . 
huh . 
yeah . 
yeah . 
so the problem is to specify the uh so the conditional property of this given all those . 
right ? 
that ' s the way belief nets are defined . 
like each node given its parents . 
right ? 
so um that ' s what we want . 
we want for example p of um 
let ' s call this guy y . 
and let ' s call these x one x two x n . 
right ? 
so we want probability that y equals you know for example um e . 
given that these guys are 
i ' ll just refer to this as like x um hat or something . 
uh the like all of them . 
given that for example the data says you know a v a e or something . 
right ? 
yep . 
so we would like to do this kind of combination . 
all right so 
um 
is that uh 
i yeah i just want to make sure everybody is with us before he goes on . 
i think so yeah . 
it ' s it ' s is is it clear what he wants to compute ? 
right . 
uhhuh . 
so right . 
so basically um what we don ' t want to do is to for every single combination of e and v and a and every single letter e give a number . 
because that ' s obviously not desirable . 
uhhuh . 
what we want to do is find some principled way of um saying what each of these is . 
and we want it to be a valid probability distribution . 
so we want it to um add up to one . 
right ? 
so those are the two things that we uh need . 
huh . 
so what uh i guess what jerry suggested earlier was basically that we you know view these guys as voting . 
and we just take the uh we essentially take um averages . 
right ? 
so for example here two people have voted for a . 
one has voted for v . 
and one has voted for e . 
so we could say that the probabilities are you know probability of being e is one over four because one person voted for e out of four . 
and similarly probability of 
so this is probability of e . 
and then probability of a given all that is um two out of four . 
and probability of v is one out of four . 
right ? 
so that ' s step that ' s the uh yeah that ' s the that ' s the basic uh thing . 
now 
um 
yeah . 
is that all okay ? 
and that one outcome that ' s 
what ? 
it ' s x x one voted for a . 
x two voted for v . 
uhhuh . 
and so forth ? 
right . 
yeah . 
yep . 
yeah . 
that ' s the outcome . 
so this assumes symmetry and equal weights and all this sort of things which may or may not be a good assumption . 
uhhuh . 
so that 
right . 
yeah . 
yeah . 
so step two is um 
right . 
so we ' ve assumed equal weights . 
whereas it might turn out that you know some be that for example what the um the actual the uh verbal content of what the person said like what uh what might be uh somehow more uh important than the uh 
x one matters more than x two or 
right . 
sure so we don ' t want to like give them all equal weight . 
so currently we ' ve been giving them all weight one fourth . 
so we could replace this by uh w one w two w three and w four . 
right ? 
huh . 
and in order for this to be a valid probability distribution for each um x hat we just need that the w s sum to one . 
so they can be for example you know 
you you could have point one point three point two and point four say . 
that ' s one . 
and that ' d be one . 
so that um also seems to work fine . 
and uh 
so i just to make sure i understand this so in this case um we would still compute the average ? 
you ' d compute the weighted average . 
so the probability of e would be uh 
okay so 
so it ' d be so in this case the probability that y equals a would be uh w one times 
point three . 
or a or 
let ' s see . 
one full quarter times point one . 
not one quarter . 
so these numbers have been replaced with point one point three point two and point four . 
no . 
so you can view these as gone . 
okay . 
probability of 
okay . 
yeah . 
yeah . 
okay . 
so 
all right . 
so this is uh step two . 
so the next possibility is that um we ' ve given just a single weight to each expert . 
right ? 
whereas it might be the case that um in certain situations one of the experts is more uh reliable and in certain situations the other expert is more reliable . 
so the way this is handled is by what ' s called a mixture of experts . 
so what you can have is 
you augment these diagrams like this . 
so 
you have a new thing called h . 
okay ? 
this is a hidden variable . 
and what this is is it gets its input from x one x two x three and x four . 
and what it does is it decides which of the experts is to be trusted in this particular situation . 
right ? 
and then these guys all come here . 
okay . 
so this is slightly uh more complicated . 
so what ' s going on is that um this h node looks at these four values of those guys . 
and it decides in given these values which of these isn ' t likely to be more reliable or most reliable ? 
so h produces some you know it produces a number . 
either one two three or four in our situation . 
right ? 
now this guy he looks at the value of h . 
say it ' s two . 
and then he just selects the uh thing . 
that ' s all there is to say i guess about it . 
uhhuh . 
right so you can have a mixture that 
right . 
so so the function of the thing that comes out of h is very different from the function of the other inputs . 
it ' s driving how the other four are interpreted . 
okay . 
yeah . 
yeah . 
so h passes a vector on to the next node ? 
it could . 
it could ? 
a vector of the weights as the 
yeah it could . 
oh . 
sorry . 
well a vector with three zeroes and one one . 
right ? 
oh it ' s basically to tell the bottom node which one of the situations that it ' s in ? 
or which one of the weighting systems 
right so i mean the way you 
i was just if you wanted to pay attention to more than one you could pass a a weighting system though too . 
couldn ' t you ? 
okay . 
um does h have to have another input to tell it alpha beta whatever or is the 
that ' s determined by what the experts are saying ? 
like the type of 
okay . 
huh . 
okay . 
okay . 
i mean it it just seems that like without that that outside input that you ' ve got a situation where you know like if if uh x one says no 
you know a low value coming out of x 
or if x one says no then ignore x one . 
you know ? 
i mean that seems like that ' d be weird . 
yeah well could be things like if x two and x three say yes then ignore x one also . 
right ? 
oh okay . 
okay . 
all right right . 
oh the situations that h has are they built into the net ? 
or 
okay so they they could either be hand coded or learned or 
okay . 
yeah . 
based on training data . 
okay . 
yeah . 
yes . 
so you specify one of these things for every one of those possible situations . 
oh yeah . 
yeah . 
um well i mean to learn them we need data . 
where are we going to get data ? 
well i mean we need data with people intentions . 
right ? 
right right . 
which is slightly tricky . 
right . 
uhhuh . 
uhhuh . 
but what ' s the data about ? 
like are we able to get these nodes from the data ? 
like how thrifty the user is ? 
or do we have access to that ? 
uhhuh . 
oh right . 
oh good . 
yeah . 
okay . 
uhhuh . 
uhhuh . 
okay . 
yeah but that ' s my question . 
like how do we i mean how do we have data about something like um um endpoint sub e ? 
or endpoint sub uh you know s ? 
well basically you would say based on in this dialogue that we have which one of the things that they said uh whether it was the entity relations or whatever was the thing that determined what mode it was . 
huh . 
huh . 
right ? 
so this is what we want to learn . 
yep . 
right . 
huh . 
yeah . 
i don ' t think 
well you have a 
can you bring up the function thing ? 
um where is the thing that allows you to sort of 
that ' s on the added variable . 
isn ' t it ? 
oh function properties . 
is that it ? 
huh i guess not . 
yeah that ' s 
no . 
right . 
okay . 
and um it so either it ' ll allow us to do everything . 
which i think is unlikely . 
i think more likely it ' ll allow us to do very few of these things . 
and in that case we ' ll have to um just write up little things that allow you to um create such c p u ' s on your own in the java base format . 
yeah . 
yeah . 
yeah i was assuming that ' s what we ' d always do . 
because 
yeah i was assuming that ' s what we ' d always do . 
it ' s 
right . 
yeah . 
uh . 
well in terms of java base i think it ' s basically what you see is what you get in 
i don ' t 
yeah . 
i would be surprised if it supports anything more than what we have right here . 
so 
yeah . 
yeah . 
by the way um uh just talking about uh about that general end of things 
uh is there going to be data soon from what people say when they ' re interacting with the system and so on ? 
like i mean what kind of questions are being given being asked ? 
because 
okay . 
yeah yeah . 
okay . 
okay . 
fey you mean . 
okay . 
okay . 
okay . 
okay . 
i ' m just wondering because in terms of you know 
i mean 
uh 
the figure i was thinking about this figure that we talked about . 
fifty constructions or whatever . 
that ' s uh that ' s a whole lot of constructions . 
and um you know i mean one might be fairly pleased with getting a really good analysis of five maybe ten in a summer . 
so i mean i know we ' re going for sort of a rough and ready . 
uhhuh . 
uhhuh . 
okay . 
okay . 
i mean i i i i was uh i was talking about the you know if you wanted to do it really in detail . 
and we don ' t really need all the detail for what we ' re doing right now . 
but anyway in terms of just narrowing that task you know 
which fifty do i do ? 
i want to see what people are using . 
so 
well it will inspire me . 
right sure sure . 
right . 
yeah sure . 
sure . 
yeah . 
okay . 
touche . 
good enough . 
okay . 
so welcome to our next meeting . 
uh today we will have a talk from miguel sanchez concerning his uh work related to ad hoc networks . 
we have here a guest a former icsi member of the n . s . a . group jordi domingo pasqual . 
he is uh assistant professor at u . p . c . 
and maybe jordi you have a few words concerning your work . 
one or two sentence . 
and because we will have tomorrow a talk from him in more detail concerning what ' s going on . 
uh you you want me to say 
yeah only a short introduction . 
oh . 
very short introduction please . 
of course . 
uh well i ' m working in the them broadband 
uh sorry one interruption . 
this is not related to hearing . 
it ' s only for fixing it . 
it ' s not a earphone . 
uh it ' s not a hear 
no . 
so 
it works like like this . 
yeah yeah . 
like this one . 
yeah . 
uh . 
it ' s only a microphone . 
that ' s 
uh . 
yeah . 
that ' s uh much more comfortable . 
okay . 
yeah . 
okay . 
thank you . 
i ' m uh working in the broadband communications group . 
and uh 
uh 
well the research topics at this moment is uh i . p . eighty traffic monitoring and characterization and them uh tool developing tools uh for quality of service uh performance analysis . 
that ' s uh and we have several projects uh both spanish and european projects ongoing . 
uh in this area . 
okay . 
thank you . 
and after the talk of uh miguel i will give you all a few slides concerning the project proposal . 
i will um say something about in which direction it will go . 
and 
uh 
maybe it was my fault that i assumed that the pointer of miguel concerning u . m . t . s . services was deployed to everybody . 
but it was only sent to me . 
so in the meantime everybody got i believe this pointer from me . 
and 
maybe we it ' s a homework in principle for the next meeting to get a little bit familiar with these things . 
worse than no work . 
and um 
so i believe we will not have today a very hard technical discussion . 
maybe more a few topic and items we will focus in the next days until the next meeting . 
and when we are ready with our meeting . 
everything is done . 
then uh we have to read these number . 
and we go around here every member . 
okay . 
so 
okay . 
miguel please . 
thank you . 
well uh i i have prepared uh a really short talk about some of the topics . 
i i have been doing some some research work uh before coming here . 
and uh well mainly i will present . 
uh here you have more or less the sketch of the presentation . 
i will present some ideas and some concepts about what ad hoc networks are . 
about the issues in media access control in wireless networks . 
also about routing in such kind of networks . 
and uh i will make some comments also about uh the current standards of wireless local area networks . 
and finally i will present the blueprint of of my research project or my research uh proposal here . 
so the first thing is uh what an ad hoc network is . 
you know uh an ad hoc network is made of wireless nodes . 
these nodes of course can be mobile nodes . 
and uh in this network there is no network infrastructure . 
so uh the only active thing we have is the mobile nodes . 
and uh 
end to end communication is sometimes uh done by direct communication from one node to the other . 
because they can talk to each other . 
but sometimes it is not possible this direct communication because nodes end uh source or and destination nodes are um are too far away . 
and in this case it can be done communication can be done by uh using multi hub routing . 
so 
an intermediate or a set of intermediate nodes will route or will forward the packet from the sender to the destination . 
so 
uh in a sense what we have in this kind of networks is that uh nodes are as both arced as both uh endpoints and also routers of other neighboring nodes . 
and this makes a uh difference from other kind of network . 
and well regarding the purposes of what can this kind of network be used for uh we can say that well cellular networks are infrastructure based networks . 
in this kind of ad hoc networks we don ' t have anything uh with the exception of the network nodes . 
so this uh network can be useful for uh uh occasions where no available infrastructure is present . 
like for example in in uh after some kind of of uh um catastrophic event . 
or also when even when there is a network available we don ' t want for different reasons to use the available network . 
this later case can be for example the use in military systems . 
where maybe we don ' t want to use the other the enemy network infrastructure for evident reasons . 
yeah . 
huh ? 
but you can also i believe uh to have an ad hoc network where one node is then connecting to the outer world . 
for instance what i have in mind you have a car where you plug in different devices and they talk to each other for instance . 
but one device decided to go to the g . s . m . network or g . p . s . network or whatever kind of things . 
that ' s okay . 
so there ' s a certain kind of task uh for one node within the ad hoc network to provide connectivity to the outer world . 
right ? 
that ' s okay . 
okay . 
that ' s perfect you know . 
yeah . 
this in this case we will say that this node is acting as a as a external gateway from this network to connect to other networks . 
right . 
and of course the underlying uh protocols can can be of course uh i . p . based . 
uh okay . 
here you have several several uh proposed uh scenarios for for used this networks . 
when no network is available . 
okay . 
and another another application for example nasa is is uh studying is uh the use of these networks these ad hoc networks for sending multiple probes uh um uh missions . 
so for example all of you are aware of this uh the last atlas the last successful uh mars mission . 
the cellular vehicle was only one and was uh walking around uh roaming around the base station which in this case was the gateway uh node of this network . 
but it was only one mobile node of course . 
nothing prevents . 
except well maybe the cost to send not only one mobile rover but ten tons of them or or at least uh several of them . 
so uh 
higher area could be covered could be explored . 
and uh of course all the different nodes could also use some kind of ad hoc networking ad hoc routing to extend the distance the maximum distance than uh a single radio transmission will would allow . 
okay ? 
and in the other case or the other area uh of of of application is the so - called network of sensors . 
where we can deploy a set of sensors in a maybe uninhabited area . 
let ' s say for example the forest . 
and we can uh take some information . 
uh for example for for fire fighting we can just launch from a plane several small sensors . 
and uh 
these sensors can be for example uh checking that there is no fire . 
they can have some kind of uh let ' s say infrared technology sensor . 
so we can cover a huge area with only a small set of of sensors and without any other infrastructure . 
yeah ? 
um is that really an ad hoc network ? 
because the sensors are not moving . 
and i think it ' s makes no sense with moving sensors because then you don ' t know where the sensors are . 
yeah . 
so 
well 
you know it ' s an interesting question . 
uh the the main thing about an ad hoc network is not that nodes move . 
it is the way of topology changes can happen . 
the idea that huh any change is possible at any given moment . 
but you can of course ask but if the nodes are not moving what kind of topology changes can we expect . 
yeah . 
that ' s it . 
well uh the thing is that usually in in a in a network of sensors what we have or the idea is to have um an important number of sensors and maybe with a high filer rate . 
yeah . 
maybe the batteries are uh exhausted in some nodes because maybe uh they are not being able to take uh let ' s say any sun to recharge its cells . 
okay . 
uhhuh . 
uh maybe some of them can be uh just uh out of order for other uh environmental conditions . 
so uh the idea is that even when these nodes are not moving they can start and stop working at uh let ' s say higher pace . 
then uh what will happen in a in a regular network uh in a network where you don ' t have or either mobility or uh this uh on off uh rate high rate . 
uhhuh . 
let me go back to your uh uh example . 
huh . 
yeah . 
have in mind some routers are burnt here at icsi or whatever kind of thing . 
what will happen then even in a fixed network ? 
uhhuh . 
so if some sensors are getting out of uh service and whatever kind of thing so the topology has changed even if no node is moving . 
okay . 
uhhuh . 
yeah . 
okay . 
and how to provide the connectivity and the intercommunication things within this network . 
thank you joe . 
yeah . 
i see . 
uhhuh . 
well 
uh you know and finally uh another nonmilitary applications where uh maybe a network is available like for example a room like this . 
where we have in in fact a wired infrastructure . 
but this uh possible application of ad hoc networks could be uh any place any meeting room where we arrive with our computers . 
and uh we just can communicate seamlessly to each other without any kind of access point any kind of uh huh external network . 
because the kind of work we want to do is just only local based . 
it ' s only to chat to each other or to exchange files with the person which is in front of us . 
okay . 
but we don ' t want to product provide uh access to the internet or something . 
okay ? 
and of course the same uh the same scenario could also happen in a place where there is no uh infrastructure available . 
let ' s say a meeting room uh in in the middle of the desert . 
okay ? 
without any other network . 
so 
the point or or the question could be for some of us the idea of saying okay . 
that sounds okay . 
but why not to use a longer transmission range so we can reach any destination in just one hop ? 
this seems to make sense because well uh we are this way avoiding all the routing problem . 
that well we will talk a little bit uh about routing later . 
but uh 
it it seems that probably that the problem is is not an easy one . 
because uh a node ' s moving the route is changing . 
so one can think that routing in this uh scenario is is a complex thing . 
but the problem is if we just uh try to put more power in each transmitter . 
so this uh transmitter can reach any destination in only one hop . 
what we are doing is uh to rising the power needs of each node . 
and also we are reducing the network uh throughput . 
because we are only allowing one one transmission at a time . 
because uh well we cannot allow several transmissions several high - powered transmissions at the same time . 
because one is interfering with the other . 
okay ? 
we are 
uh i think i ' m not telling it yet . 
but we are assuming that we are using a single common channel for all the nodes . 
okay ? 
so that ' s why we cannot allow several transmitters in the same channel at the same time . 
okay ? 
so the idea of having a longer transmission range is not a good one . 
or at least it has the drawbacks um um i was telling you . 
uh let ' s speak a little bit about the media access issues in in wireless networks . 
uh you know the easiest uh way to to show how this works is or at least one of i think one of the easiest is that this drawing or this picture . 
what what we have is a set of nodes each one at a different location . 
at at at a at an at a given moment this uh node this dash node is is transmitting . 
and uh the arrows are representing this transmission . 
and the receiving nodes these three nodes are receiving the transmission . 
and i ' m trying to uh show the area the covered area for of this transmission by means of this uh dashed uh line circle . 
okay ? 
so uh any transmission has a maximum transmission range . 
and uh in the simpler way we can see this like a circle with the center in the transmitter and a certain radius . 
okay ? 
the value of this radius is uh in principle is a fixed value . 
and it depends on the uh power of the transmitter . 
of course uh this is only our uh simplified model . 
and of course this can be uh improved uh a lot . 
okay ? 
and in fact the real behavior is not exactly this one . 
but uh for for what i want to say it ' s it ' s okay . 
it ' s enough . 
okay ? 
so 
what are the differences uh in this in this uh wireless transmission regarding uh to the wireless to the wired ones ? 
what what are the the main differences ? 
well the main differences come from the fact that uh in uh in uh wireless transmission we have a special domain we don ' t have when we are using a wire for transmitting a signal . 
and the point i ' m trying to show in this picture is that if for example this other node wants also to transmit while this one was transmitting if we are using some kind of carry detect scheme like for example c . s . m . a . or something uh uh derivated from it the problem is that this node will hear the the the transmission media . 
it won ' t be able to hear anything . 
so he will conclude that no other transmission is going on . 
and he will start transmitting . 
and if he does what will happen is that this node and this other node will also receive this transmission . 
and this will produce at least at these two nodes a collision or a a a a a bad reception . 
okay ? 
so none of these two simultaneous transmissions will be properly received at this node nor at this other node . 
okay . 
uh this problem is what is called 
oh sorry . 
uh the 
i think this is the previous one . 
this is the german 
uh 
no . 
one 
yes . 
okay . 
this one . 
thank you . 
uh 
this is what is called a hidden terminal problem . 
okay ? 
because well uh this node is not able to hear this other node because of the distance uh between them . 
but uh this problem as you can see in the in the picture is uh really producing at least some reception problem at these two nodes . 
okay . 
so it is it is a problem that we have to address . 
and it is a new problem compared to wired uh media access control . 
and uh 
well some some protocols have been developed to avoid this problem and to try to address this particular behavior of wireless transmissions . 
and the main idea is to use some kind of a reservation mechanism . 
so 
we are um reserving a certain and a specific uh area of space so we can guarantee that nobody is trying to use the same space at the same time . 
okay . 
this is the basic idea . 
uhhuh . 
um 
yeah . 
miguel can you give some examples for such kind of protocols ? 
yeah . 
yeah in fact 
one is really really 
this one . 
this one next slide is 
okay . 
yeah yeah . 
okay . 
okay . 
in uh the the the main idea and and the base of most of this protocols is what this the so - called r . t . s . c . t . s . uh dialogue . 
the idea is that 
uh 
of course this is only intended for unicast transmissions . 
i mean only for when a node wants to transmit something to a neighbor node . 
okay ? 
but not to broadcast uh to all the nodes . 
okay . 
for this for this uh work the transmitter has to send a a a reservation packet called r . t . s . request to send before uh being able to send data . 
and the receiver is expected to return back another packet called c . t . s . clear to send to allow the transmitter to send the data . 
if the transmitter receives successfully the c . t . s . packet from the destination then it will be able to send uh the packet the data packet . 
if not it will uh back off and it will retry uh sometime later . 
okay . 
so the main idea 
and the media is is is still occupied during that period ? 
or 
uh 
yes . 
yes . 
okay . 
the idea is uh if i want to send you something i first of all i need you to answer me to be sure that you are my neighbor now . 
because maybe you are off or maybe you are uh too far away . 
and also because that way miguel for example it may be is not being able to hearing me will hear your c . t . s . and will know that you are about to receive uh data from me . 
okay ? 
so 
in fact forcing the receiver to transmit for a short period of time is also uh used to signal all the uh receiver neighbors that a a reception is taking place . 
okay . 
yeah . 
i didn ' t get it . 
um what happened when i sent an r . t . s . packet ? 
is then the media still occupied for me ? 
or is anybody allowed also to send r . t . s . packets ? 
or everybody 
because if i go to an intermediate node maybe you are communicating to me . 
and i am the intermediate node to the final destination michael . 
and michael send also some r . t . s . packet in the time and and uh uh uh jordi too and whatever . 
yeah . 
then you will never come to a really 
then you ' re always exchanging r . t . s . and non acknowledgement packets for the r . t . s . 
okay . 
two two things . 
so that ' s uh that ' s uh my my problem . 
first of all uh this this mechanism is only a media access controlled mechanism . 
so it is not connected with routing uh anyhow . 
then fine . 
and second point . 
okay . 
uh 
so it ' s only related to the direct neighbor within the scope of the transmissions . 
r . t . s . 
yeah . 
r . t . s . packets can collide to other r . t . s . packets . 
okay . 
so this mechanism is not uh preventing collisions . 
it is preventing only data collisions . 
okay ? 
okay . 
so the 
and and you can say okay . 
but what is the what the benefit is . 
the benefit is that uh r . t . s . packets and c . t . s . packets are short packets . 
really short packets . 
let ' s say uh uh 3 0 bytes or less . 
i assume so . 
yeah . 
while data packets can be much much bigger . 
let ' s say uh one k . five k . s . 
okay ? 
yeah . 
so 
fine . 
a collision in this short packet is only wasting a small amount of time . 
and uh 
if that way we can warranty that there is there are there is no collision uh uh between data packet well this this is this means a a huge uh increase in network throughput . 
because well we we only waste really small time colliding . 
okay . 
okay ? 
but that means in principle that on the mac layer you have always a r . t . s . c . t . s . packet between neighboring nodes . 
yeah . 
and you send afterwards the data . 
but the data will be maybe delayed in the intermediate node because you have always be assured to be uh uh uh r . t . s . and c . t . s . packets are changed before before you can forewarning the data . 
right ? 
yeah . 
it is a reservation mechanism . 
yeah . 
okay . 
so 
if reservation doesn ' t work okay if uh one reservation don ' t succeed then uh this transmission should have to wait . 
now the 
until the reservation 
okay . 
yeah . 
let me 
maybe it ' s better to to uh draw it on the 
oops . 
let me 
so maybe my idea first . 
so this is what node one ? 
this is node two . 
and this is the source . 
yeah . 
and this is node three that is the final destination . 
yeah . 
forget forget about routing . 
yeah ? 
yeah yeah . 
okay . 
but anyway i would like to do that in the ad hoc network . 
this is maybe the this is within the scope of this uh special network . 
that means here that is uh within the transmission power . 
okay . 
so if i send an r . t . s . and get back um a c . t . s . then he is allowed to send data right ? 
uhhuh . 
a c . t . s . 
that ' s okay . 
so in the meantime when he gets this one he also had to send r . t . s . and then c . t . s . 
because this is the next scope of the transmission area . 
uhhuh . 
and then he can send the data right ? 
okay . 
that ' s the case ? 
that ' s it . 
that ' s 
yeah . 
and that ' s what i mean . 
in the meantime he still can get some data here where he try to get certain connectivity on the mac layer . 
uhhuh . 
yeah but uh a node is only is only involved in one transmission at a given time . 
so 
if now two has uh huh answer with the with the c . t . s . it will be waiting until the data that has to come . 
yeah ? 
okay . 
okay ? 
and then he try to forward this data . 
yeah . 
after that . 
but not before . 
so he is definitely first to stop . 
he has to collect all the data . 
yeah . 
yeah you cannot 
could it not be a little bit strange ? 
because if that is starting a file transfer with millions of bytes he have to collect all the bytes before he forwarding to to whatever . 
no no no . 
but we are we are talking only about a data packet . 
huh ? 
one data 
at the mac layer . 
he have to do it for all data packets ? 
yeah . 
okay . 
okay . 
so but in principle when he receives the data packet then he the same applies for the next data packet . 
yeah . 
all the packets . 
all unicast packets . 
but anyway in the meantime he has to forward the packet to the final destination . 
yeah . 
that that true . 
right ? 
that ' s true . 
so it ' s acting in in 
but not in the meantime . 
after receiving you know in fact probably the routing protocol will need to check the address the the let ' s say i . p . address which is inside the data packet . 
okay . 
yeah . 
so 
you cannot usually you cannot uh read the data packet until you the reception is over . 
okay ? 
because usually your network hardware only provides you a copy of a packet after a a successful reception . 
and usually you know that reception is successful if every bit has passed the c . r . c . check . 
okay ? 
you have checked that the that this frame has received uh without errors . 
naja to to 
yeah . 
okay ? 
uhhuh . 
yeah . 
okay . 
so 
um a further question . 
yeah . 
um 
that ' s okay . 
am i right that this um dialogue does not prevent um any disturbance of other nodes in the um sending range of yeah n . one ? 
yeah let me let me put some special representation of what we are doing . 
okay . 
this is the transmitting node . 
this is the receiving node . 
and these two areas of course there ' s something like this are the uh places of the total space where you can hear the here this one is the r . t . s . and this one is the c . t . s . 
uhhuh . 
so any node 
for example this node is a neighbor of the receiving node . 
uhhuh . 
but it is not a neighbor of the transmitting node . 
yeah . 
that ' s it . 
so when this node hears the c . t . s . transmission that is performed by the receiver this will be uh informed that a a reception is taking place in in in it ' s area . 
uhhuh . 
uhhuh . 
okay ? 
so 
in fact this node will avoid any further transmission until uh this reception that will start in in a moment is over . 
but then this node um this transmission is uh aborted . 
okay ? 
and delayed . 
and so there ' s no advantage to uh if it ' s aborted by by any data packets . 
yeah . 
so this um node has to stop each transmission . 
yeah . 
so even the at the moment ongoing transmission . 
uhhuh . 
is that right ? 
yeah . 
so his transmission is aborted . 
yeah but this is typical for mac layer protocols you know . 
not 
no . 
no . 
that ' s 
let me let me let me show you one thing . 
if this node was transmitting before it should uh it should uh transmit an r . t . s . packet in advance okay ? 
uhhuh . 
uhhuh . 
so this node should hear it before . 
yeah . 
yeah . 
that ' s right . 
yeah . 
uhhuh . 
so this node is won ' t be sending the uh uh c . t . s . packet to the transmitter . 
okay . 
yeah . 
yeah . 
uhhuh . 
so this transmission won ' t take place . 
okay . 
yeah . 
yeah . 
it ' s always true that only one node gets a media access for one frame . 
uhhuh . 
uhhuh . 
that ' s the point . 
yeah . 
we always said from data . 
but it ' s really one frame . 
yeah . 
yeah . 
okay . 
and in fact uh there is another detail . 
it is not uh uh uh uh in on the on the slide . 
and it is that both the r . t . s . and the c . t . s . packet uh have a field a control field where the total length of the data packet is shown . 
uhhuh . 
so 
when you hear one uh c . t . s . or one uh r . t . s . packet you know that the frame that they are trying to transmit or that this one is trying to transmit this one is about to receive you know the length . 
you know the bit rate . 
uhhuh . 
so you know that the amount of time you have to wait until you can try to get the control or try to send your own transmission . 
uhhuh . 
okay . 
but this scenario is also uh only working if um both or all nodes have the same range of transmission . 
so the same radius of the sending range . 
huh yeah . 
so otherwise um this one node maybe um would hear his neighbor but not vice versa . 
uh well we are assuming that uh huh all the all the transmissions are bidirectional . 
i mean uh you know it depends . 
it depends mainly on on the antenna gain and the transmission power and the receiver uh threshold . 
uhhuh . 
uhhuh . 
okay ? 
uhhuh . 
but i ' m thinking about this example you gave before . 
maybe maybe you are right . 
so what what we are assuming is that all the nodes behave exactly the same regarding to uh transmission and receiving signals . 
yeah . 
but miguel this is a good point from from dietmar . 
yeah . 
but maybe here is a wall . 
and this guy is behind the wall so his transmission rate is something like that . 
yeah but but 
yeah . 
but the but in this case you know this this idea this uh geometric idea can be can be if you want uh deformed because of some obstacles . 
okay ? 
but this wall is working both ways . 
it is not only making this node not to hear this one it ' s also making this one not to hear this node . 
but one of the 
so 
if they 
because of this wall if they are not neighbors well we can represent this putting this node like here . 
but one of the um senders could be much stronger than the other one . 
okay ? 
no but this is not the scenario we are assuming . 
so 
okay . 
so that was my question . 
yeah . 
uhhuh . 
okay . 
we are assuming all the nodes are exactly the same . 
okay . 
uh so they transmit the same power . 
and they uh have the same uh uh sensitivity . 
uhhuh . 
so they can hear 
okay . 
if if if i can hear you you can hear me . 
uhhuh . 
and and the opposite works also . 
uhhuh . 
okay . 
if you cannot hear me i cannot hear you . 
but 
uhhuh . 
okay . 
it ' s a assumption it ' s it ' s clear . 
but on the other hand um in a real world it isn ' t or 
um 
in a 
in real scenarios uh you have to 
it it is actually 
uh not really . 
but also depends on uh you know for example power relationships and antenna relationships . 
yeah . 
you know uh 
uh that ' s it . 
because 
a car or 
because for example uh one kind of thing 
okay if i use a directional antenna this is making that in one direction . 
yeah . 
uhhuh . 
i ' m getting more uh let ' s say more gain than another . 
yeah . 
and that ' s true . 
okay . 
but that what is also true is that one directional antenna works both ways . 
that 
you ' re not assuming this . 
yeah . 
it provides you more gain when you are transmitting but also when you are receiving . 
so in general in general even when if there uh if there are different antenna gains uh you ' re getting mainly bidirectional channels . 
only when you have an important uh power difference is when um the communication can only work one way . 
yeah . 
okay . 
for example you have one big station with uh a lot of transmission power . 
and then you have a really small mobile uh thing that can hear perfectly the signal from this uh uh bigger station . 
yeah . 
yeah a cellular phone and a car . 
but it has not enough power to transmit something that can be heard here . 
uhhuh . 
yeah . 
so um 
but this this this is not our scenario . 
okay . 
in our scenario all the nodes are exactly the same . 
uhhuh . 
okay . 
they they have the same uh signal uh behavior . 
uhhuh . 
so 
this is not a problem for us . 
at least for the moment . 
maybe later we ' ll see some differences . 
so 
you know the idea is that this mechanism is a reservation mechanism . 
and what we are doing here is try to reserve the area of space we are covering . 
and uh here ' s where our some of our work is done . 
the main idea for for our work is well if we are using this reservation mechanism we are reserving an area of space for a single transmission . 
uh if this area is bigger than what is really needed we are somehow wasting a little bit of space . 
so uh 
our first uh work in this area was to study different mechanisms to try to adjust these transmission values . 
these uh the area the covered area for a single transmission trying to get a minimum value . 
so we can reduce the not used space for other simultaneous transmissions . 
and this will lead us to a a better to a better network throughput to higher number of simultaneous transmissions . 
and we have uh huh worked about this problem uh in two different uh ways . 
one of these ways has been try to find a mechanism to uh calculate an optimal value for the transmission range uh and to get an equal value for all the transmitters . 
so the idea in this first work was to obtain a fixed value for the transmission range . 
and the second uh work uh it is about 
oops . 
it is about uh an algorithm to adapt the transmission power for for every single transmission . 
so uh in this second part of our work we are using a different value for every single transmission . 
so 
first point what we have proposed is a way to obtain the transmission range uh for uh for an escenario where we know the number of nodes . 
and the area of deployment we have a a fixed area where we deploy all the nodes . 
we have a fixed number of nodes . 
and uh we assume that these nodes are moving freely around this this area . 
and uh what we have presented is a mechanism to uh calculate to obtain the uh transmission radius that provides at the same time that provide us the better throughput possible . 
the better possible throughput . 
okay ? 
but without our network getting partitioned . 
which is a problem that we are trying to avoid . 
you know if we have because of node motion we have something like this . 
this is the deployment area of or or node . 
and if we have some nodes here and some nodes here well maybe these nodes in this area cannot reach the nodes on this other area . 
okay ? 
uh so what can we do to avoid this ? 
of course we can choose uh our transmission values longer enough to reach from so the nodes from this area will be able to reach the nodes on this other area . 
okay ? 
but again we can assume that uh if uh nodes are moving uh more or less uh in a random fashion this configuration is not very likely to happen . 
okay ? 
so the point we what we have done is to present a mechanism would which provides uh one uh value for a given uh huh probability . 
okay ? 
so we can say that uh a given uh value are for for the transmission range will be okay for a given number of nodes if we sorry for a certain for a certain probability . 
okay ? 
so the point is uh we cannot say that this is not going to happen . 
what we can say is this is not very likely to happen if nodes move uh uh random . 
yeah but um miguel if uh in the previous slide you mentioned that you uh are working also on adaptive power control . 
okay ? 
yeah . 
yeah . 
is it not possible then if i send something and i could not find any neighbor because one of the cluster below ? 
this is the next . 
yeah 
is it not possible to extend the power until the maximum ? 
and if uh i do not have any connectivity with the maximum of power okay then i ' m lost anyway . 
yeah . 
yeah yeah . 
but this is this is a way that it is it is being explored by other researchers . 
but not not uh by me . 
but uh there is uh one at least one person who is who is doing what they call topology control . 
uhhuh . 
and this is uh related to to uh the control of the transmission power to get uh certain properties uh from your network . 
like for example they are what they are doing uh is uh some people working for b . b . n . 
ram ramanatan is the researcher . 
uhhuh . 
and the article is is uh i think from from this year . 
and uh 
these guys are doing uh what they call uh b . connected networks . 
they are trying all the network nodes to have at least two neighbors . 
okay . 
uhhuh . 
okay ? 
and they are controlling the power to uh this uh huh get this this number of neighbors . 
but this is not what i am doing . 
and uh the kind of power control i am doing uh um is more or less presented here . 
and what we are doing is to transmit uh with the minimum power needed depending on the distance to the destination . 
okay ? 
every transmission is supposed to be done to a certain neighbor node . 
we cull the neighbors to these nodes which are uh closer than a given distance . 
okay ? 
and because we wanted to to compare our algorithm with something we needed to compare it with the no power control . 
which is the usual uh mechanism at this uh media access control level . 
so what we are doing here is to to compare our mechanism against the no power control . 
but again we have to fix 
in order to be able to compare we have to fix a given whatever but a given uh maximum transmission range to compare . 
and uh what we are doing is we are uh taking the advantage that we are we have this r . t . s . c . t . s . dialogue in advance before sending the data to uh agree with the receiver the power level he is willing to get from us . 
okay ? 
so every single transmission in every single transmission we are checking with the receiver the power level we have to use for the data transmission . 
that ' s the main thing . 
and as uh 
and how do you 
sorry miguel . 
how do you check if if the nodes are moving randomly ? 
well uh we are assuming that for at least for uh uh you know uh car and and walking or or people riding a motorcycle the um frame length is so small that only um very very small um space can be can be uh travelled while the transmission is taking place . 
you know . 
in one 
yeah okay . 
maybe that ' s applied for r . t . s . c . t . s . 
but for the real frame ? 
yeah . 
well you just take the 
the frame could also be uh whatever i don ' t know but a few hundred bytes you know that takes a little bit time . 
let ' s let ' s 
no but 
yeah but let ' s say you have one kilobyte . 
okay ? 
one kilobyte is uh eight uh bits . 
okay ? 
uhhuh . 
and uh if you are transmitting at let ' s say uh at one megabit per second this means one microsecond per bit . 
okay ? 
so this only is taking eight milliseconds . 
which is not a lot of time if you are travelling let ' s say at uh one hundred kilometers per second . 
no 
oh per per hour . 
no sorry . 
yeah that ' s right . 
sorry . 
but first of all it took place r . t . s . c . t . s . 
and there could be you mentioned if it ' s still if the medium is still occupied by another one it will be delayed anyway to a randomly time . 
yeah . 
it will be delayed . 
but you will start from scratch again . 
i mean it will be a start with another r . t . s . c . t . s . 
oh . 
so 
okay . 
okay . 
okay . 
i see . 
yeah . 
okay . 
okay ? 
but anyway uh well depending on on the network you now the the the this 
i will have to translate this . 
uh 
it should be something ipsh 
so this should be something like 
uh 
thirty meters per second . 
okay ? 
oh yeah something like that . 
so in in eight milliseconds well the amount of of space you are travelling is not too much . 
it ' s okay . 
for most of of of uh the wireless technologies . 
maybe not for all of them . 
okay . 
but i ' m of course i ' m also uh using a conservative value for the transmission speed . 
now you can get much more speed than speedier interfaces than this one . 
but the thing is uh that we are assuming that for a given transmission we can uh consider the network as if it were built of a set of static nodes . 
okay ? 
motion will be important for routing . 
but for the media access control level we are considering that motion can be is not is not important . 
okay ? 
yeah what i think maybe some uh cases why i go this way with my node and suddenly i go out of the scope of the transmission area . 
because it ' s really a random movement . 
then i still hear 
this is during the data transmission . 
yeah but again again what we are adding with this behavior is uh uh a little bit more probably some some uh small part to the uh bit error rate . 
yeah . 
then 
okay ? 
maybe this frame will won ' t be received properly and should uh have to be uh dropped . 
oh yeah . 
but anyway 
uh even if nodes are completely static uh some problems will happen in the wireless transmission . 
so 
we won ' t have a hundred percent uh perfect uh channel anyway . 
yep . 
right . 
so uh if this problem as you show it probably it ' s it ' s uh you can you can see that it is not very likely to happen . 
because you you you uh have to consider the probability that of happening this 
nee . 
that ' s really right . 
huh . 
but what i would like to say is that besides the r . t . s . c . t . s . behavior you need certain kind of additional mac layer functionality to deal with these packet . 
uhhuh huh . 
for example with transmission or or whatever . 
yeah . 
sure sure . 
for whatever control or whatever kind of things you know . 
in fact in fact you know i i i i i maybe i i i had to to prepare a more detailed uh view . 
i i just was trying to do something soft . 
not to to bore the public . 
but of course there are a lot of other smart uh things that are built in in these protocols . 
right . 
yeah . 
like for example an automatic uh acknowledgement . 
some protocols used uh in the same way as this r . t . s . and c . t . s . packet some of them use an uh acknowledge from the receiver . 
which is also a short packet . 
so you you are getting some kind of link layer uh acknowledgement scheme . 
which can save a lot of data transmissions . 
because uh usually when you send a a a a frame you will want to some kind of acknowledgement back . 
so if this acknowledgement has to go through the process of a new r . t . s . and a new c . t . s . well this takes longer than just a link layer uh extra packet . 
that of course uh is also contemplated in this uh packet length length or included in the r . t . s . and c . t . s . packets . 
so uh you know everybody can wait until this uh acknowledgement is also transmitted by the receiver . 
so 
in fact uh nnn some people proposing this mechanism is is showing a a a big improvement . 
and uh there are a lot of other mechanisms also regarding and a time - out mechanism or the time - out algorithm for these retries when you try to send something and you don ' t succeed uh what what you the amount of time you have to wait until you retry again . 
well uh some people is also proposing different things different uh algorithms with different results . 
so in fact there are a lot of good 
i just was trying to present a you know the main ideas . 
so i i i you know ask uh you feel free to ask uh whatever you want . 
but i i want to insist that it was just an uh a simplified uh version a light version . 
okay ? 
well uh you know finally this algorithm uh as i was telling uh what it ' s doing is to check with the receiver the power level to be used . 
and it is very simple to see that some advantages can some advantage can be obtained . 
because the difference is uh if you don ' t have power control you are using all the time the maximum power . 
if you have power control sometimes you will use less than the maximum power . 
how often do you use less power than the maximum ? 
well this will this will be connected to the motion pattern . 
okay ? 
depending how nodes are moving . 
well maybe all the time all your neighbors are at the maximum distance 
but this probably doesn ' t look like uh something very very uh very likely . 
okay ? 
because well probably what you will have will be some neighbors that are really close . 
huh . 
others that are a little bit far away . 
and finally these neighbors that are in the in the frontier of your of your coverage area . 
okay . 
huh . 
yeah . 
okay this is a question not directly related to these things . 
but maybe that ' s why maybe only a short answer . 
uh do you assume that power control will be issue also in the next years ? 
in other words um is the um success of having more power within the devices in maybe three year four years five years for batteries and and and and sofort so on . 
uh will it be succeeded that you have so much power available that this difficult mechanism who is in the wireless network will be uh out of scope ? 
huh . 
yeah . 
because if i have a device which uh can i use maybe for twenty four hours . 
i do not have in principle really the constraint to uh deal with with uh power savings . 
yeah let let me let me answer you uh with a question . 
uh if for example your car uh you you have uh an endless uh source of of gas do you think it will it will be a problem the amount of gas your your car is is using ? 
okay . 
it won ' t be a problem for your pocket . 
for your wallet . 
but maybe it will be a problem for the environment . 
so i think that the answer to your question is in this line . 
that uh if you have an endless uh source of power well maybe it ' s not a problem for the battery uh lasting . 
but it is a problem because you are using more area than you should . 
and therefore you are preventing other transmissions to take place at the same time . 
and therefore uh the problem is not only connected to to the to the power . 
it is also connected to the to the global network throughput . 
okay ? 
okay . 
so 
but again uh you know uh the the 
if you ask me what what do you think what will happen in the industry 
what i think that will happen is that they will try to get uh huh better hardware than we have now . 
because now the problem with transceivers is that a lot of power is uh consumed at the logic of the transceiver . 
and not uh transmitted to the air . 
it is not power transferred to the air . 
so the problem now is that uh most of the power uh uh uh a wireless network card is consuming is is is drawn by the by the uh logic control of the card . 
yeah . 
all the all the calculations . 
that ' s what i 
all the hardware 
yeah that was the reason i ' m talking about this is uh 
so i am sure that uh that manufacturers will try to to squeeze until the the the last ampere of of this uh let ' s say uh wasted power . 
because what you cannot avoid is uh 
to the part of the of the radio frequency power you have to transmit . 
i mean this is this cannot be avoided . 
but what you can avoid or you can reduce 
and probably 
because now it is the main factor the main consumption factor is the logic inside . 
in the same way at as as it happened with with processors for example . 
now processors are much more uh power efficient than before . 
okay . 
yeah but anyway that was the reason for my question . 
if i save with a lot of difficult mechanism within the air interface and between the base station or access point and the mobile node one percent of the power whereas ninety nine percent is consumed by packet processing . 
and and and and uh uh c . p . u . or whatever . 
uhhuh . 
uh is it worth to have it ? 
if i really with a normal device uh with a battery lifetime of maybe twenty four hours thirty six hours or whatever kind of thing and i think it will be increased . 
as the more mobile nodes are in the world the better the battery will be . 
so that ' s was the reason for my question . 
yeah pero 
yeah yeah yeah . 
uh but 
oh sorry . 
but even if you if you don ' t have to to worry about uh your power source you have to worry about your environment . 
about not using more resources that you don ' t own . 
yeah . 
yeah . 
that are uh shared about among the community . 
yeah i got it . 
yeah . 
yeah . 
okay . 
excuse me . 
okay . 
if i understood correctly the mechanism uh you should uh look for um the minimum uh coverage range . 
yeah . 
in order to maximize the throughput of the network . 
yeah . 
so there the the power control uh algorithm should work in order to use at each instant of time the minimum power need to reach 
the destination . 
the neighbor . 
that because this is the way uh uh more transmissions uh 
may take take place at the same time . 
can take place at the same time . 
yeah yeah yeah yeah . 
so you need the adaptive mechanism to minimize the coverage range . 
yeah . 
that ' s okay . 
and to and to get the maximum network throughput . 
that 
that ' s that ' s the idea . 
however however and 
uh it is always some however . 
uh by applying this uh greedy mechanism in in 
or more than greedy in this case . 
it could be say this stingy mechanism to trying to avoid to use any extra space is also leading to a higher level of interference at the receivers . 
so uh 
at the end of the road we have to uh look for some tradeoffs to avoid too much uh interference at the receivers . 
okay ? 
so uh at the end we are using a little bit more power than these mathematically minimum values . 
okay . 
because if not the uh 
huh 
the frame error rate or the bit error rate uh skyrockets . 
uhhuh . 
okay . 
because of the of high interference levels . 
a lot of simultaneous transmissions also means for each receiver point of view a lot of neighbors or or nodes transmitting at the same time . 
and all the transmitters uh with the exception of the transmitter of my transmitter are my intereferers . 
and are and all of them are producing less quality reception . 
so if they are a lot of them well uh the reception can be can be uh disturbed . 
okay ? 
and but um um this is taking longer than i expected . 
okay . 
let ' s let ' s uh take a a a really a really light uh view at the at the routing in this in this network . 
which is another important area of of research . 
you know in fact there is a a group at the i . t . f . uh called manit . 
this working group is is devoted to uh try to to present or to agree a common protocol for routing i . p . traffic on these uh kind of networks . 
on these ad hoc networks . 
uh and 
at this moment there are i would say a lot of proposals of different protocols uh for uh end to end traffic . 
and also for multicast traffic . 
on these networks . 
and uh well some day in the future uh a protocol should be chosen . 
but for the moment uh we have several of them on the table . 
and uh any protocol has some advantages and some disadvantages . 
the basic the basic problem we have to solve in in these uh routing protocols is the fast uh the fast pace at what uh topology changes can happen . 
so 
the problem here is that now uh one node is my neighbor . 
and next second it is not . 
so any route that was going through this neighbor now is is not possible . 
and should change . 
and the problem is that well 
uh 
if you let me a personal comment i think that one error on the group is not to agree a set of mobility patterns to to do the the tests . 
because here well mobility is making these uh neighborhood relationships to appear or to disappear . 
so uh it should be interesting if we agree uh a common a common set of motion patterns to perform the tests . 
because if not well it ' s difficult to to perform comparisons uh between one protocol and another . 
a different one . 
but anyway now what we have is is two basic approaches to this this problem . 
uh mainly what they call the practive protocols . 
which are um extensions of of uh um back door and link end state routing protocols . 
distance vectors . 
sorry and and link end state protocols . 
uh which are usually table driven . 
so you have a process trying to to maintain up - to - date a set of routing tables and the nodes . 
and uh every routing decision is uh just uh looking up the table . 
and sending to the proper neighbor node . 
and uh the other the other set of protocols are using a reactive uh approach . 
and these protocols are trying to work on demand . 
so they are trying to solve on only these routers that are needed . 
so when i want to send uh a packet to a a given destination first of all i have to figure out the proper route for this packet . 
and then uh i ' m using soft routing . 
i ' m i ' m including on the on the uh header of this packet the set of uh nodes that should be forwarding this node to the destination . 
uh of course uh these uh two approaches can be can be uh somehow mixed . 
and some hybrid proposals are also on the on the paper . 
and uh 
these proposals are are trying to get the advantages of both uh mechanisms . 
uh sometimes making a kind of combination of of them . 
uh let ' s say for example using uh practive approach for the closer set of nodes . 
let ' s say for the neighbors and maybe the next level . 
and using a reactive approach . 
i mean as our routing approach for nodes that are closer than this practive area . 
okay . 
and uh well 
some multicast protocols have been proposed for this scenario too . 
and well they have to deal with the same problems that they ' re uh end to end routing protocols . 
huh . 
what do you mean by multicast protocols ? 
yeah . 
routing . 
routing protocols intended for multicast . 
okay yeah . 
okay . 
so for for uh for sending one to any . 
yeah . 
huh ? 
uh well the main the main problems that some of the solutions uh are exhibiting is uh the lack of uh scalability . 
uh mainly the source routing protocols have a problem when you when you scale from or scale scale badly from tens of nodes to to thousands of nodes . 
because well you cannot have uh uh let ' s say uh an endless uh header length . 
you have a limited a limited header length . 
and maybe we will have to explain a little bit for those who are not familiar with source routing . 
so 
you can have the destinations you would like to or the in the i . p . addresses of the intermediate nodes you still know . 
yeah . 
even if it ' s not the direct neighbor . 
but one of uh where you really want that the packet went through put it in the i . p . header . 
uhhuh . 
so and 
this one is going then to this guy and so on and so on . 
until finally it ' s reached destination . 
so there are 
and that ' s what i mean you cannot put it thousand intermediate nodes in for example . 
okay . 
but to put a thousand i . p . addresses in the header so that the packet is uh forwarded accordingly to . 
so there ' s more than one i . p . address in the header . 
yeah yeah yeah yeah . 
and 
okay i see . 
something like this . 
so you your packet should look like like this way . 
do they have to 
yeah . 
do they have to be in order ? 
so you are looking first for node two and then for node three and so on . 
yeah . 
yeah . 
it ' s uh 
you ' ll know to remove it ' s from the header in principle and and so on until it uh reaches the final destination . 
okay . 
okay . 
so this this uh header well it ' s it ' s a problem . 
of course there are also some some solutions . 
like uh uh employing some kind of of uh hierarchical source routing . 
so you don ' t have to put all the all the route 
this one for instance . 
that may that the different parts could be one to number four . 
uhhuh . 
uhhuh . 
maybe two b . or three b . . 
yeah but nevertheless this guy is a is an gateway in the router for for this packet you know . 
and they remove itself from the header . 
okay . 
yeah . 
it must be not the whole path you know . 
another problem uh is uh trying to provide some quality of service in these networks . 
because well them uh change is is the only thing you know for sure here 
so uh providing quality of service is also is quite a challenge in in this network . 
but again uh there are some proposals . 
um miguel are you familiar with these kind of proposals ? 
not really . 
not really because i don ' t trust 
you know 
uh i ' m sure that the proposals are okay . 
but uh i don ' t i don ' t think that you cannot you you i don ' t think you can warranty too much in these networks . 
so i see this like a you know a a topic i ' m not convinced about . 
i don ' t trust you can really provide quality of service . 
but of course 
that depends on the service level you want to be . 
definitely not a guarantee level . 
but maybe something like a control load level or something like that seems to be for me possible . 
yeah . 
right ? 
you know uh if you are curious uh i can i can i can provide you the some of the proposals . 
yeah . 
huh . 
which include 
yeah we can discuss later off line . 
yeah . 
okay . 
and uh finally the other the other thing which is also under research or under study is uh to have some kind of a power aware routing . 
there are some proposals too . 
so that way you could 
routing function could be connected with uh global or local power consumption . 
so for example you could ask to nnn the network to transmit your packet with the lowest uh global uh consumption . 
or with your lowest local consumption for example . 
okay ? 
i mean would the option for me to to use less power when sending a packet is to send it to the closest neighbor . 
okay assuming that i ' m i ' m also using or having some kind of power control thing . 
so that way transmitting to the closer close to my closer node is uh something that requires less effort than sending to a more distant node . 
maybe the closer node is not a good uh it is not in the good direction to the to reach the destination . 
but it is for sure the the less expensive uh thing for me . 
okay ? 
but probably this uh this is not something really useful . 
and that what can be really useful is to reduce the global power consumption in the routing function . 
so 
because in this way 
well maybe one node is is being forced to use more power . 
but but if we take a look at the whole thing well we can ask for a a low consumption route . 
well the same way 
yeah but the 
as we are asking for example when we want uh some packet to be shipped in the real life we can go and say well we will we are happy with this u . p . s . ground system . 
what we want is two day delivery service or twenty four hours service and we are willing to pay more or less for this service . 
yeah but it ' s really happened also in the riot case you know . 
if i get the wrong route with the r . c . m . p . redirects it ' s in principle then the same . 
yeah . 
yeah . 
that ' s okay . 
yeah yeah . 
so these are more or less uh some open problems . 
and uh well just a quick comment about probably 
all of use are now aware of the availability of this uh standard the i . triple e . eight hundred and two point eleven . 
uh in fact it is it is powering you know uh the evolution of the of the of networking industry in the wireless area . 
and in the beginning the first adaptors uh 
oops . 
were only one and two megabytes per second . 
but now we you you can buy for for the same price for even the same price uh the new eleven megabytes per second version . 
i ' ve been use it for for a while . 
and it can tell you it works pretty well . 
and uh the thing is that these devices have two different modes of operation . 
one of them and probably the most popular is uh what we call the infrastructure mode . 
where you have a set of mobile nodes . 
and then you have one or more access points . 
these access points are uh in fact providing the uh required connectivity from the mobiles to the network to the wired network . 
and from there to the internet usually . 
yeah in principle the base station . 
yeah yeah we can call it a base station . 
yeah . 
yeah . 
and uh the other mode of operation which should be appropriate for example for this meeting room example uh doesn ' t require any any access point . 
and in this second case communication happens uh um from one computer to the other at the link layer . 
okay ? 
so if i want to connect to uh let ' s say miguel ' s uh michael ' s uh i i will send him a packet . 
and he will receive it and that ' s it . 
okay we can build on top of this some uh routing algorithm . 
some ad hoc routing algorithm . 
but this is out of the scope of the of the standard . 
uhhuh . 
and 
and miguel should i should ask you one question . 
yeah . 
and uh uh in version one and two you you have different technologies . 
you know frequency hopping uh two modes and and and also infrared . 
yeah . 
yeah . 
does it still apply for for the uh ? 
for the 
no . 
eleven b . is only for for uh radio . 
and it ' s only for uh direct sequences spread spectrum . 
okay d . s . s . 
okay . 
okay . 
but in fact there is an ongoing new version i think it ' s version a . . 
but it is not uh commercially available . 
which will use uh orthogonal frequency division multiplexing . 
okay . 
and will get probably twenty five megabits per second . 
uh but again the will move to five gigahertz . 
uh five point five gigahertz . 
uh gigahertz uh area of a expect uh spectrum . 
but now uh current devices are split at 
you know that the old the old wavelan are nine hundred megahertz version . 
and the new ones are the the eleven megabits uh are uh two point four uh i . s . m . band . 
megahertz . 
yeah . 
uhhuh . 
however uh some old uh wavelans are also but not the older ones the oldest ones are also uh two point four 
uh gigahertz . 
uh gigahertz . 
yeah . 
in the r . s . m . band . 
and the good thing is that now especially with the new version all you 
you you you are you start to see uh compatible products in the market . 
because uh maybe because it ' s the let ' s say second version . 
but also because i think it ' s the only way for this industry to take off . 
because uh previous versions if you buy let ' s say wavelan you are tied to wavelan the rest of your life . 
but now you can you can have interoperable products from several vendors . 
which is i think what in the past will power the ethernet uh revolution . 
you can buy any any compatible product . 
and and you know it will work with the other brand . 
yeah . 
and one additional question from myself . 
but maybe also short . 
because time it running fast . 
uh i have heard that uh wireless lan and bluetooth will have some problems . 
uh that they influence each other . 
in front ? 
do you have additional information about this topic ? 
yeah . 
huh . 
you know 
in the beginning uh what the 
i think that to put things in perspective what we need to know is what bluetooth is and what bluetooth is for . 
and uh bluetooth is mainly for cutting this cable . 
you know the other day i was joking about that our wireless microphones were not in fact wireless . 
because it had this wire . 
so the point is that uh bluetooth is mainly a technology for cutting these kind of cables . 
you know oh short short distance cables . 
yeah that ' s right . 
yeah . 
yeah . 
uh carrying usually really uh sh nnn 
nnn 
slow signals . 
or let ' s say boys and something like this . 
yeah but nevertheless you have the range of ten meters or of one hundred meters . 
yeah . 
yeah but you know uh in fact 
okay . 
uh the initial version had only the the range of ten meters . 
and i guess that somebody at a certain meeting said okay why don ' t we have a an extended range version . 
so we could reuse the same technology for other purposes . 
different than the original ones . 
so them uh i have the feeling that this is this is what is uh introducing some confusion in the in the bluetooth . 
uh or in the way people is is looking at bluetooth . 
because they can say okay hundred meters is is is an acceptable distance . 
let ' s say for communicating inside a building inside a a small office . 
so uh some people i think is being tempted to think that bluetooth could provide them uh some kind of local connectivity . 
but uh for for data for computing uses . 
uh however i think that the that the when you have tried uh current uh standard uh working devices you you 
working at at eleven megabits per second you cannot you cannot switch to another thing to another slower thing . 
but uh even when they are using the same the same uh um area of a a spectrum . 
because bluetooth is also intended to work in two point four uh gigabits . 
yeah . 
uh the technologies are different . 
you know uh bluetooth uh is using a frequency hopping system . 
and uh 
huh 
both uh dialing sequence and frequency hopping spread the spectrum techniques are also intended to provide uh interference uh less uh data transmission . 
so the idea is that these two techniques are intended not to interfere with any other thing . 
so even when i haven ' t tried and i cannot tell you for sure i think that the only problem one network will encounter uh in the presence of the other is a little bit of more noise . 
and this will produce a little bit less throughput . 
but nothing more . 
i don ' t expect any any more problem . 
even the the the own bluetooth specification is also 
uh huh 
assuming that another bluetooth or several bluetooth networks will be could be in the same area of space 
and they are using the same hopping technology frequency hopping technology . 
but again this technology is uh trying to avoid the other networks by choosing different hopping patterns . 
so uh if several bluetooth networks can can uh coexist without a problem i don ' t see any problem will will happen if if we want to to make coexist one uh bluetooth with another wireless uh local area network technology . 
well that ' s a good news okay ? 
yeah i think so . 
but anyway um based on your uh uh initial scenario i believe because bluetooth is on one chip 
yeah . 
like you have now your u . c . b . buss or whatever connectivity you will have your bluetooth connectivity . 
five bucks . 
and that means your mouse and and and 
five bucks chip . 
yeah and and and whatever kind of of uh things connected to your laptop and also your microphone and whatever you will will have is bluetooth - based . 
uhhuh huh . 
yeah or will be bluetooth - based . 
will be . 
yeah and this is this is uh within maybe an uh wireless lan . 
will be . 
so despite the fact that they are considered for different scenarios they are still 
in fact in fact bluetooth is also designed . 
within one one area . 
yeah . 
to be compatible with existing digital european cordless telephones . 
so hopefully we will be able to use some of our old devices or maybe our our cordless phone base station at home with a computer . 
so i think some really nice applications will will appear . 
okay we ' ll when i i will have some problems in the future with my wireless lan and bluetooth connectivity . 
i will come to you . 
you will solve it okay ? 
i ' ll try to . 
okay please go on . 
so let me let me just uh finish you know . 
okay . 
uh well this is something i more or less i told you . 
and uh you know the point or or or 
what the the spark of of my of my work here or at least of what i was proposing to work here is the fact that these two uh two modes of operation i was telling you here that you have to choose at the driver level if your network adaptor is working in an access point based environment or in ad in an ad hoc environment i see this as a as a limitation . 
because i think that uh when you have to choose among two options well huh maybe you are saying no to some of the benefits the other option different than the one you are choosing could provide you . 
and i envision an an an an escenario where uh 
oops . 
well yeah . 
let ' s go . 
where we can have a kind of uh dual mode uh wireless network adaptor . 
so if we are not able to reach any access point but we are able to reach another network node well maybe this network node could do me the favor to reach or to forward my packets to the access point . 
so the main idea the driving force here is to uh try to obtain uh let ' s say hybrid mode . 
which allows an adaptor to work either in the access point or in the uh in the ad hoc mode in a seamless way . 
and to include in every single node driver 
this forwarding or helper uh forwarding mechanism that will allow to extend the wireless coverage without a need of buying a lot of access points . 
and putting even an access point inside the restroom okay ? 
of course this idea huh can sound can sound a little bit not very appealing for the manufacturers . 
at least for the manufacturers of access point . 
because well they probably are very happy of selling a lot of them . 
but maybe for cars . 
yeah if your car is the infrastructure for instance . 
yeah . 
yeah . 
okay . 
so this is the i think this is near the end this is the last . 
so 
one possible extension of the same idea and something uh i ' ve been thinking for awhile is the idea that well why can ' t do we extend this same concept to cell array systems ? 
why can ' t we for example think about some huh new mechanisms that users could get uh connectivity by means of other users and no directly to the base station ? 
or when we have several technologies uh in overlapped in a certain area why can ' t we use the closest and the cheapest maybe technology ? 
or maybe the less power consumption technology without the user to worry about if he is now using this or the other technology . 
and on the other hand what are the billing implications of this behavior ? 
because it is clear that well when i ' m only uh talking to the to the base station of my provider well billing is more or less straightforward . 
but what happens if i ' m working uh let ' s say uh across a mall and at a given moment i ' m using the small base station of a cordless phone that is inside the shop i ' m at the window of ? 
well in this case i ' m using a resource which is not owned by my provider . 
i ' m using a let ' s say a private property . 
maybe i have to pay to this private property . 
or maybe my carrier will have to pay or to refund some money to this guy . 
you know this something uh i ' m putting on the table . 
i ' m not sure about uh if this can be really of interest or not . 
but it ' s an idea . 
and i ' ll be happy to discuss it with you . 
and i uh i think my presentation is over . 
so 
uhhuh . 
okay . 
many thanks miguel . 
are there any questions ? 
oh you are welcome . 
maybe we have also the time to discuss with miguel off line the things if there is some uh question concerning uh his talk or maybe other questions . 
maybe one last question from my side . 
because i bring it up uh concerning the proposal some kind of active routing mechanism . 
uhhuh . 
it ' s going in a quite different direction as as as as the traditional things discussed in the i . t . f . 
and i currently do not have any idea whether active routing is really a topic uh within the i . t . f . 
do you have certain kind of experience or do you know certain activities uh in that area ? 
nnn no to both to both questions . 
okay . 
i don ' t have previous experience . 
i don ' t uh know if uh where it will it would fix . 
however uh you know i ' m just doing this presentation . 
uh somehow a review of my previous work . 
i know yeah . 
so uh this uh doesn ' t mean that 
i ' m i ' m probably getting involved a little bit more in this active routing thing . 
uhhuh . 
so uh i i maybe i will be able to hopefully i will be able to to give you a better answer in the future . 
oh okay . 
one more time many thanks miguel . 
so 
oh thanks michael for your computer . 
no problem . 
so i will deploy a little bit information here from the uh project proposal . 
should i power off it ? 
um just log out . 
okay . 
uh no . 
log out . 
oh okay sorry sorry . 
so i have only 
four . 
oh . 
jordi is only a short period of time here . 
which is which is proper 
so he will get the colored one . 
michael . 
uh thank you thank you very much . 
okay . 
michael . 
and take a look to 
which is the proper answer . 
uh 
that ' s the proper answer . 
this one ? 
yeah . 
okay . 
yeah . 
thank you . 
kill the computer . 
uh so i started uh for for advertising the project proposal here to provide a few slides . 
i think first of all wilbert is not here . 
second um the um link here was uh enabling u . m . t . s . services and application . 
uh i assume was not read yesterday night . 
so i suggest we go roughly to the slides here . 
and um 
the the problem is that in principle we have different scopes . 
and motivation of the project proposal from my point of view is that we will have the um wireless access networks for the next generation will be more flexible . 
there ' s a for uh current uh uh uh for for fast changes within this network . 
and that means if you go to slide number three that we have um the possibility to to um having normal features in the mobile access network . 
and 
and um 
and um also based on that it belongs normally to one single provider domain that it is possible to to uh use novel things . 
and and and new protocols and new technologies within this network . 
on the other hand in the internet backbone uh we it is impossible . 
and we see it on several examples . 
like this m . p . l . s . 
there ' s quality of service support and multicast . 
and all this kind of thing . 
that based on the success of the internet backbone it ' s become uh very unflexible to uh for the provision of these things . 
so if we are going to offer building blocks and provide novel solutions for the next generation of wireless access networks taking into account without modifying the end to end scope then i think it ' s really beneficial work . 
also for the use of interactive multimedia application . 
so as it is described in the uh project proposal . 
um the point is that um to start with um a bigger cluster of uh of potential partners to do this really really really big work . 
seems not to be feasible in the next time . 
because if you have settled everything and discussed everything and and and and uh without any money in the background and a lot of money in the background 
that is not uh feasible from my point of view . 
nevertheless i discussed with a lot of partners these things . 
and today uh michael and me we were on the u . c . b . to discuss with a guy who is a professor who is probably interested in the application stuff . 
they are going in that direction . 
they have a small project funded by n . s . a . 
n . s . f . 
um for this intelligent classroom is a little bit exaggerated i believe . 
but going in that direction . 
so there are a lot of interest . 
but without really hard money in the background it is very hard to come to the initial steps . 
and uh juan peire one of the uh members of this n . s . a . group has uh identified a certain kind of start money i would like to say . 
so maybe if you start with a small cluster of um the constraints of this funding . 
and that means uh six universities and and institutions . 
uh three in u . s . a . and three in europe . 
and of course they are uh including the n . s . a . group . 
and maybe that seems to be very reasonably for me . 
but then we have to align the project proposal in that sense . 
because then we cannot do do anything as it is described in the in the bigger scope . 
so the point is um to reduce the overall picture which i described in a few words to the fact that we have really some work packages where we can focus on it . 
still fitting into the big picture . 
yeah . 
and so that will be the task of the next weeks . 
and uh 
i hope that everybody is doing his homework concerning for instance . 
uh alternative to the intelligent classroom maybe that we can start here only with the n . s . a . group . 
within this big picture . 
um with some work . 
that we put the pieces together . 
because i believe many are very flexible here . 
accounting also the future coming uh joining people of the n . s . a . group to do some work here . 
and if we are starting with a very very very small cluster with a common activity have maybe some starting funding for bigger uh radius of the of the the the uh project proposal with the mind that maybe at the final stage it will becoming a european proposal with this uh the the whole funding . 
that ' s uh my point and my picture i have in mind . 
and i will go definitely back to germany the tenth of december . 
that is fixed now . 
and i hope we can use these remaining weeks to have really progress in uh for the proposal in that sense what i mentioned before . 
uhhuh . 
because then i will make the advertising that is still worth to stay here . 
and i hope then siemens will say okay for me to stay longer here . 
and then i will come back maybe in the mid of end of january . 
so that ' s uh it ' s a comment to the proposal . 
so i think everybody should consider carefully based on this statement i made uh next steps . 
and of course everybody has little bit other work to do . 
but it should be should be always an ongoing process until i will leave until the tenth of december . 
you mentioned um six partners of this um work . 
okay . 
so you know already what partners are included . 
okay i didn ' t have a look at uh slides . 
um 
yeah . 
i will distribute all the things electronically . 
okay . 
to all the 
okay take a look to slide of number two . 
just i ' m just curious . 
yeah . 
you see uh uh university of mannheim . 
university 
also these are the official ones . 
yeah sure . 
you see that in the icsi u . s . on the u . s . a . side i believe that the home companies and universities are still contributing . 
uhhuh . 
yeah yeah . 
yeah ? 
but these are then the official ones . 
and i would like to have them 
and all of them had agreed ? 
or 
they say they are very interested in it . 
okay . 
yeah ? 
uh a few words the university of mannheim is at location where joerg widmer is uh working on it . 
and i got the statement 
uh they are very interested in that . 
they did a lot in the area of um intelligent classroom . 
but nevertheless they did a lot in networking stuff . 
and university of uppsala sweden . 
that ' s the reason i invited uh christian tschudin the professor who did ten years work in in active routing . 
and uh okay the universidad nacional de 
yeah . 
spanish . 
maybe we have a better expert to pronounce it . 
universidad nacional de educacion a distancia . 
uned . 
i always said uned . 
in spain . 
uh this is this university of juan peire . 
yeah . 
and he is also the one who had recognized uh 
who is ? 
one 
pair . 
pair . 
perez . 
not parez peire . 
p . e . i . r . e . 
paez . 
paez paez . 
paez . 
uh peire . 
no no no . 
paez . 
not not paez . 
not 
peire . 
p . e . i . r . e . . 
you never heard from him ? 
no . 
i don ' t know . 
you can i you can mail him later on the 
i don ' t know who he is . 
okay . 
then of course the whole n . s . a . group . 
and also of the coordinator of all the things . 
then georgia tech i have good relationship to uh the long lasting uh cooperation with georgia tech . 
and they did a lot in this area also related to networking stuff as well as to the intelligent classroom stuff and the u . c . b . 
we still focusing on maybe we can have uh more professors involved . 
which are working also on the networking stuff as well as on the application stuff . 
so that the u . c . b . is clustered as one uh partner . 
but nevertheless with different departments . 
uhhuh huh . 
yeah . 
so 
but take a look to the slides i will uh deploy it um uh electronically . 
where your slides are available ? 
sorry ? 
where the slides are available ? 
i will send it electronically . 
when ? 
after the meeting . 
uh . 
you will send it sorry . 
i will . 
future . 
sorry . 
and maybe you take a look to the uh last two slides . 
um um 
maybe the g . p . r . s . picture is still uh available . 
so you have in principle here now the mapping of the different areas um within g . p . s . 
and in principle the same applies for u . m . t . s . 
there is no so much different . 
um you always have the s . g . s . n . and u . m . t . s . 
they are called three g . s . g . s . n . . 
and you have the protocol stack . 
um in on the slide number five to see what uh is going on . 
and you see the difference . 
the amazing thing is that you have i . p . over i . p . 
as you take a look to the the uh g . g . s . n . you have two i . p . layer functionality and and all those things . 
and you have the g . p . s . tunnel uh protocol g . t . p . between the g . and the s . and the g . t . s . n . 
and and so on . 
so uh i believe they are very very difficult protocols stuck between the uh between the um um involved nodes . 
and making it necessary in principle to deal with our four building blocks in um yeah i believe in a difficult way . 
if uh we have in mind quality of service routing and and uh uh mobility aspects and and all this kinds of things for i . p . layer functionality . 
so that ' s in principle uh an overview of the protocol stack . 
and the involved nodes . 
and i will provide more and more information . 
but um uh i have to also figure out everything from the scratch . 
i am not a total expert for for the future wireless networks . 
okay . 
then i would like to thanks everybody . 
and if there ' s no additional question comment or or other remarks i would like to start with reading uh these numbers . 
okay we have 
okay thank you . 
now please let don ' t switch off power . 
i have to call adam . 
so 
so i suggest now we will have in a few minutes we will have the coffee break tea cake whatever will will be offered . 
and then we will have a we can have a discussion . 
okay . 
welcome to our next meeting . 
um i have couple of points we should discussed . 
one is related to the proposal . 
michael please can you close the door ? 
yep . 
thank you . 
and um 
furthermore as most of you know i will leave in tenth of december . 
i think we should discuss how we proceed in the meantime . 
because i get i would like to say different signals from siemens . 
i believe in the meantime it ' s a higher probability that i will return . 
but based on the uh procedure to get a j . one visa and the i . p . six six it will be i would like to say earliest stage will be end of january . 
so that means we have to get over six weeks . 
and 
then furthermore i would like to know the status of everybody . 
i know for sure okay um miguel you will have your plans for this uh ongoing process uh concerning your work . 
okay from you it ' s definitely clear in principle . 
okay for michael what are your current plans ? 
and dietmar maybe you then also . 
what we have discussed in principle concerning the ongoing process with u . u . s . a . i . a . and also this uh your current work . 
and from my point it seems to be clear that i will go back . 
definitely at tenth of december . 
and as i mentioned before probably will be more than fifty percent i would like to say that i will be come back to get the freedom to launch here the project in the sense in whatever kind of form and get in principle paid by another project within siemens . 
so the point is how long i will stay . 
i believe a couple of months definitely . 
and based on the success i think that ' s always an ongoing process to go back to uh to germany for a couple of weeks . 
and then come here and and go on with with this work . 
and 
so that is my current opinion concerning how siemens deal with with my uh ongoing effort . 
and furthermore i would like to first of all thanks to uh dietmar . 
because he started to use a testbed . 
oh . 
uh 
in principle in his spare time . 
yeah . 
yeah . 
uh i will 
so so the first uh uh box this morning . 
i will set up definitely in my spare time in the evenings and the weekends the second box . 
and i ' m looking for two other volunteers who are setting the third and the fourth box . 
but what are the box ? 
a box is a p . c . 
p . c . ' s . 
p . c . ' s . 
but what 
equipped with with we should equipped it with with linux . 
or maybe too with free b . s . d . 
well the first 
i doubt i don ' t know . 
stop . 
and we ' ll 
the first thing the most uh complicated is to fit them with the removal removable um hard disk . 
and now we have an expert . 
but it ' s 
yeah . 
so the first computer i had to 
um 
the 
oh . 
what ' s the right word ? 
i had to put everything out . 
to to put the removable hard disk in . 
yeah to 
so that you can pull uh the plug in the removable hard disk to the i . d . bus . 
and and it ' s 
okay . 
yeah it ' s 
and and okay maybe it ' s a little bit 
but but it ' s not not um very uh difficult or something like that . 
uhhuh . 
so you just have to 
and 
why you are laughing ? 
i 
i don ' t know . 
i i i didn ' t see him . 
so i don ' t know what he did . 
i know in the meantime it ' s running . 
uh ! 
and i will definitely set up the next one . 
so wilbert will set up the second computer . 
yeah . 
though my idea maybe you uh can equip it with 
i don ' t know what your time whether the time constraint allows you to set up one with with free b . s . d . for instance . 
you know i i can i can build uh any computer uh you installing whatever it ' s needed . 
yeah . 
okay . 
uhhuh . 
i mean i will enjoy doing it . 
do you find the time ? 
so 
that ' s okay for me . 
huh . 
maybe also to uh support your 
no promises . 
no promises ? 
no . 
and even maybe to to uh put your i . g . m . p . stuff on it . 
uh 
no promises . 
no promises . 
no . 
uh he ' s very hard to sell . 
so it ' s about one hour to put this uh hard disk in . 
and a further hour to uh well two or three hours to install the operating systems . 
nee because then the network is still running then . 
could we wait until the network is running ? 
because currently it ' s not possible uh based on certain fire wall constraints . 
yeah . 
at the moment . 
i believe david is uh currently working on that to set up the fire wall . 
and he ' s not an expert for that . 
and when i get the signal i will ask one more time . 
nah but nevertheless thanks to dietmar that he . 
did the networks have internet connectivity ? 
yes . 
we have uh for for secure socket . 
and uh for web access the fire wall is open . 
that ' s all . 
and but currently it ' s not working right ? 
right . 
um on friday when i installed um uh linux the first time i got access to the local network here um but not to any machines outside of uh i . c . s . i . 
and till monday there ' s no access at all to any machines . 
also not to inside machines . 
but then 
uh 
so i think it ' s related to the work um they ' ve done on sunday here . 
and i sent 
but normally you should have access to all the internet to outside . 
yes . 
yeah . 
you have internet outside access . 
full . 
but no telnet and not r . login or whatever kind of things you know . 
a restricted in . 
not . 
huh ? 
not a no f . t . p . 
yeah f . t . p . yes . 
but no telnet . 
huh . 
uh because you can 
the the the point is that we will use it as it is uh described several times that we will use it as a local network in principle . 
but it doesn ' t make sense to use certain kinds of uh media transportation to put some stuff you need from your p . c . or your l . s . to this uh uh uh to this testbed . 
you know . 
uhhuh . 
so 
you download it if that must be possible from the network . 
but normally it should be used as um uh for demonstrations or to figure out if you have a scenario where you have to use more than uh one box which you have on your desktop . 
because that is the primary uh uh reason for this testbed . 
so definitely you have to have web access to download the necessary files . 
uhhuh huh . 
so and then furthermore one more thanks to claudia . 
he did a lot of work . 
right . 
and i could only pass her some advices and some discussions with her concerning the web pages . 
uh the messages . 
oh . 
and now we are in principle in the state we have to do it with a project area . 
but they ' re also some contributions from you guys requested . 
um 
and the alumni page in principle we have to 
you know but it ' s primarily my job i believe uh to set up so that it is uh adjusted really to the people who are worth to be alumnis . 
alumnis . 
yeah . 
is it alumni alumni ? 
i ' m 
alumni . 
alumni . 
i ' m not sure how to pronounce this word . 
aber das wird jetzt geaendert . 
huh ? 
das wird geaendert . 
and um 
but um 
i think everybody should take a look to the web pages and inform claudia if something uh has to be improved or if there ' s some comments . 
uhhuh . 
or 
uh 
he ' s laughing all the time . 
why ? 
uh because it is you know that ' s very important . 
maybe not for us . 
but maybe for our successors . 
and maybe somebody will come back once a day or send some students or some colleagues or whatever . 
so my point of view i will i will documented everything when i will leave here in the sense that potential successor as a group leader can hook in with these things and that these web pages will be updated every time when it is necessary . 
we tried to do it so that it must be at least updated only when really major changes happen . 
so that means somebody ' s leaving the group . 
uh somebody is joining the group . 
a new project is started . 
but uh the effort should be minimized as possible . 
and so please take a look to the web pages . 
and 
i have announced in the project area the major headlines . 
and especially wilbert maybe you can write something about yours ? 
i call it i believe multicast and then development deployment uh for for source specific 
maybe a few lines . 
maybe a picture . 
and something like that should be added to u . s . a . i . a . 
okay that ' s my stuff . 
and 
um 
then the next point is then this active routing stuff . 
um 
i would like to discuss it before . 
but you were busy . 
yeah . 
and so . 
okay . 
um 
i believe it must be adjusted to the current activities a little bit more . 
uhhuh . 
and um 
i i think it doesn ' t 
it is not worth to discuss it now . 
because nobody raised it before . 
yeah . 
i think so . 
and uh so let us have a bilateral discussion afterwards . 
i would what i would like to have is that um your contributions is related to certain kind of things happened here . 
and that means really to the project proposal itself and also maybe to the u . s . a . i . a . architecture . 
in that sense that at certain stages because it ' s a general architecture certain stages maybe to future mobile core networks that it is related to these kind of things . 
um having uh i what i have in mind is that things should not be started from the end system . 
that ' s my principle concern . 
because that will never be happen from my point of view . 
it should be started as the edge device . 
so that it certain kind of mechanism whatever is enabled between the ingress edge device and the outgress edge device . 
because it will be at the certain stage i . p . based in the future generation telecommunication networks before its goal . 
uhhuh . 
that ' s okay . 
fuel it to the over the internet . 
and between these both boxes i can assume uh because the mobility happens there as a normal natural thing . 
and the forwarding process and the routing process should be no more separated from my point of view . 
and to have there a certain kind of intelligent mechanism that the packets can be used to set up the routes because they have all the information . 
they know where they have to go because i . p . addresses are still there and within the packet . 
uhhuh huh . 
i mean how can this use uh within this area and how this area is then aligned to the more traditional routing within the internet backbone itself ? 
that ' s my question . 
and i think that is good a research area . 
then i think there ' s a lot of 
i ' m not a expert at all for this . 
but i i i believe there ' s a lot of potential for that . 
and we should discuss it maybe bilateral afterwards . 
okay . 
okay . 
yeah ? 
so one more time everybody should take a look to the web pages . 
and from claudia at the general remarks . 
and should write based on the uh headlines in the project proposal the um things what still happened the things what they have still in mind . 
uh so that we can update these last you know present the last major part of the web pages . 
the pages are already on the web ? 
okay . 
yeah yeah . 
yes . 
yeah . 
it is . 
you can now access it normally with maybe w . w . w . i . c . s . i . berkeley edu . 
so there are some gaps . 
okay . 
huh . 
and 
so 
okay . 
yeah so there are some gaps left . 
and 
i don ' t know . 
you maybe you can also read through the all the text which is on the web pages . 
because i ' d like to change the text a bit . 
because sometimes it ' s too long . 
sometimes it ' s too short . 
maybe the english is not that good . 
so 
um 
but anyways . 
so i tried to do this today . 
and if you could do it afterwards it would be really nice . 
because i ' m quite sure that i can ' t find every like orthographic mistake in it or something . 
uh there there there are couple of comments i i have about the web pages . 
good . 
one is is the uh i think it ' s joe ' s uh graphic i think it should be better . 
yeah yeah yeah . 
yeah . 
the graphics are too bad . 
maybe you are working at it . 
i know . 
you are definitely right . 
it was in a good shape but it uh then we disturbed . 
okay . 
and then maybe the the i . c . s . i . logo could be could be could be 
i can ' t change something with a logo . 
uh 
no . 
it is just 
uh 
maybe we can we can uh translate the white color into transparent color . 
so it will get more natural . 
yeah . 
okay . 
good . 
yeah i 
it ' s just a suggestion . 
another thing is i ' d want to get a link on the logo so that you can come from the logo to the icsi web home page back . 
to the home page . 
okay . 
that ' s that ' s okay . 
so 
that ' s these are some things i have to do . 
yeah . 
and if you have something which i should put on the web page for you 
so 
yeah some pictures will be nice . 
a few sentences will be nice . 
and 
yeah it depends on how much time you have . 
and then the page for about 
so some information for people who are new comers or 
i don ' t know a good word for it . 
should we use uh new comers ? 
or 
so with somebody who is new arriving here or wants to to uh send an application . 
newbies . 
huh ? 
newbies . 
newbies ? 
yeah okay . 
so there i have to add some information . 
i don ' t know i i tried to set up everything by today for this page . 
because i ' ve started with this . 
um if you have any kind of ideas what was important for you then just let 
because i have some points like um i don ' t know yeah like pacific bell . 
like uh long - distance carriers . 
then like uh cars and car insurances . 
health insurances . 
so health insurance is something i can only say for german people . 
uhhuh huh . 
so maybe 
i don ' t know if this is different in spain . 
that would be fine too to have some information or in nnn holland . 
okay . 
i don ' t know . 
i will take a look and i will tell you something . 
yeah . 
uhhuh . 
so how maybe how you did it or whatsoever . 
okay . 
i will send you some because i have something in mind . 
so 
yeah . 
then what else did i have ? 
then 
another point ' s like uh what about the bank . 
uh so transferring your money from europe over here what is the cheapest way or what could you recommend or something ? 
um 
another point . 
yeah and then there ' s there ' s another point like going out in berkeley or what to do in berkeley or in the neighborhood . 
this a lot of this stuff is not networking group n . s . a . uh restricted . 
no . 
i know . 
yeah but nobody do that you know . 
i know . 
but there ' s nothing like this on the on the icsi page as far as i know . 
so 
that ' s the point . 
we discussed it still a couple of weeks or months ago . 
uh the point is normally it is an i . c . s . i . task anyway . 
uhhuh . 
but 
yeah but at least then it should be huh i think be uh i . c . s . i . part and not network restricted . 
right . 
well they have uh a a white booklet you know probably 
yeah that is from nineteen ninety one or nineteen ninety two you know . 
yeah but it ' s not in the 
this is not on the web . 
and this is not on the web . 
no . 
no no . 
and the the the 
i i just i 
people 
normally that ' s was my my uh 
in fact the pacific bell phone was not working for example . 
when i tried the the phone on this booklet it was not working . 
huh . 
but the thing is that maybe this could be on a starting point or or if digest 
yeah . 
i don ' t know . 
maybe i talk with jane about this . 
if we can use this information i don ' t know somewhere on the icsi home page too . 
move it on the normal icsi i . c . s . i . 
yeah . 
maybe . 
maybe every group has somewhere hidden uh a uh deep outgoing 
we can do that . 
yeah but the point is that nobody feel responsible for that . 
and if it ' s 
yeah but uh but my point is that it should not be under the networking group thing . 
it ' s a common 
yes . 
uh yes . 
uh but 
i see there your point . 
okay . 
that ' s right . 
but if it is under the networking points the group leader is responsible to get up to date information . 
i believe we are the group where the people are uh changing much more faster to join the group and to leave the group as other groups . 
uhhuh . 
and so the most problem as as of uh it ' s likely that uh the people here in this group needs this information um much more uh often as as other groups . 
but 
but that could still be applicable if you put it under the icsi site if you take the responsibility for that . 
yes . 
i see 
yeah i talk to jane about this . 
uh 
yeah . 
so i think i think both arguments are not an are arguments against having this under the normal i . c . s . i . page . 
but we we can do that . 
or only the networking uh page . 
but the problem is are you allowed to change anything on the general icsi server ? 
yeah . 
no . 
this is why i have to talk to jane . 
yeah . 
yeah that ' s 
yeah . 
so you may need just a link from the main icsi page to the n . s . a . page . 
that ' s a 
we have the we have the directory structure of the real unix tree in compliance and in accordance with what you with the structure of the web pages . 
and um that means uh the group leader normally do not have access to the general web pages . 
he has access to the n . s . a . pages . 
and um 
but i think that ' s an administration problem and that everybody agrees that the information page must be on the general on the highest level . 
okay . 
i have no problem with that . 
but uh 
but 
but i think we discuss if still 
your argument is uh i think it we have to have the right to change it . 
yeah . 
so if there ' s anything changing in insurances or something something like that that we have access to this page further on to to make any changes . 
yeah . 
yeah but this is not a problem at all . 
i i mean if you are coming from germany and you know that there is something changed with the health insurance then you send jane an email like could you please change this blah blah blah . 
yeah but it ' s much more complicated . 
yeah but that ' s that ' s effort . 
that ' s the whole problem that nobody wants to do it . 
yeah . 
yeah . 
yeah okay . 
you know how it you know the process here within the n . s . a . group . 
you know . 
yes . 
and and that was a reason i we finally decided here that we put it information on the n . s . a . page . 
we have this discussed still a couple of months ago ago . 
i think the best solution is really to put a link on the i . c . s . i . page to this stuff . 
yeah . 
yep . 
and the stuff itself is uh located at our server . 
in our directory . 
yeah . 
in our directory . 
yeah . 
yeah . 
yeah we can do that . 
yes also fine . 
we then create a link and then we have to ask with jane . 
yeah . 
okay . 
another point is i want i want to would like to add another button something which is called like events or i don ' t know yeah i guess i call it events . 
huh . 
like where we could uh announce talks which are you know future talks for the future . 
or and where we could also have a link on for instance the two workshops which have going on uh last summer . 
so hannes ' workshop and then the workshop from oliver . 
that there might be a link behind these workshops and or former talks we have . 
so like from people who have been here before . 
and he wants to uh publish their slides or an article or whatsoever behind there . 
so that we have like a button for events which are where workshops can be announced or old workshops could could be um shown or whatever . 
uhhuh . 
of course that is a living thing . 
i think it ' s a good idea . 
not only that the workshop was a talk announce because they are still announce it is a broader sense . 
uh but i think the idea from claudia is very good that the slides from the talks here if it ' s worth to have it on the web anyway um should be published in that way that the people can access it . 
uhhuh . 
for instance i have my u . s . a . i . a . slides . 
maybe if some things and is going on maybe you have some multicast slides concerning your work at i . g . m . p . 
yeah . 
that ' s okay too . 
and uh 
and if we have some talks from exterm and we had some in the past we can also put the slides on on these things . 
because then they ' re still still a growing context for us opportunity for the people you know there . 
oh . 
this guy did something there . 
maybe i can contact him and ask him would you like to do something contribute whatever . 
uhhuh huh . 
uh so . 
that ' s and i think it ' s a great idea from claudia to to have this event page . 
because it ' s not a big deal . 
you know . 
no it ' s easy to to add it . 
it ' s it ' s 
i mean . 
yeah . 
and then it ' s 
nah okay . 
if there are no events then there are no events . 
yeah yeah . 
but we still have a few which happened in the last year . 
and okay . 
then it is a growing thing . 
but it ' s done automatically that the group leader or the group uh put some things uh also on the web . 
something in the center pipe . 
yeah ? 
everybody agree ? 
um i don ' t know . 
okay . 
maybe it could be a good thing if we have such an event button that um somewhere beneath this button or wherever that there ' s a date when the last update was . 
so that you know it ' s worth to click this button to see there ' s a new um announcement or not . 
yeah okay . 
so otherwise you are often clicking this button . 
and you get your old information or even an uh empty page . 
maybe there ' s 
yeah but this will be then down on the button of the page anyways . 
yeah maybe we can have updated on you know the button itself . 
so 
yeah . 
something like that . 
and then updated and the current date when when something happened . 
last updated . 
yeah . 
i don ' t know how we deal with that . 
yep . 
is it another thing we have to ? 
yep . 
so it ' s just a suggestion . 
i don ' t know how easy it is to to implement something like that . 
yeah . 
huh . 
okay . 
okay you 
well . 
let ' s consider update event button . 
okay . 
so and then the next point and i believe yeah so not the last one is one that i would like to know the status as far it is possible from everybody concerning his future intention here at i . c . s . i . or whether when he will leave whether he can or will he consider currently uh contribute here to the proposal . 
because you know i ' ve i ' m facing the problem if i go back to siemens . 
and i say okay . 
there ' s a potential . 
there are potential contacts . 
currently maybe no money . 
but if we go in one direction it it is worth to know if people can still go on in that area of that kind of work then they are back in their university or their company or whatever . 
and even if it ' s nur part - time jobs and and if it ' s come to a real proposal that maybe the people can hook in uh one more time . 
because i need this information definitely uh to inform the uh the siemens management that it ' s worth to send me back here . 
so maybe wilbert you can start . 
you will leave end of january definitely . 
and currently you see no chance as far as i know uh to stay longer here . 
and either you will go back to k . p . n . or you will stay here and find then a job opportunity another company . 
is that right ? 
yes . 
yeah . 
can you give us more details of concerning the status ? 
no . 
no ? 
no . 
pending . 
pending . 
yeah . 
see for me it ' s the same . 
i can also say uh 
for me everything has completely changed . 
so now i go back and i don ' t anything what to do . 
so it ' s like i have to sort everything out when i ' m back in germany . 
yes . 
but you have no 
but i won ' t go back to the university . 
yeah . 
so 
i don ' t think so . 
so you are looking for a job . 
that ' s probably then okay . 
in principle i would like to say you are lost for the n . s . a . group . 
then it ' s like 
yeah . 
because ffft that ' s uh it would be a a wonder if uh it hook in at the same area you know . 
yeah . 
no no no . 
yeah . 
uh but that ' s also for me . 
yeah . 
i ' m kind of lost for the n . s . a . group . 
yeah . 
yeah . 
i think so yeah . 
lost is maybe a bit like 
and oh also also 
ja . 
from the work contributions you know . 
well 
but i think even also k . p . n . is lost for the uh for the i . c . s . i . 
yeah . 
yeah . 
uh do you know whether they have 
there ' s a lot of uh budget cuts going on . 
and nothing is possible anymore . 
so 
um so from your side the statement is um that uh independently of your person uh the k . p . n . is not they ' re not willing to send us another guy here to i . c . s . i . anyway . 
yes . 
absolutely . 
and if they are interested in uh a certain kind of project then it must be related to a certain kind of really service or a certain kind of end system or real product or whatever kind of thing with respect to u . m . t . s . 
it it will be different thing . 
right ? 
it will be a it will be a start - up . 
and i know they ' re they ' re working on a a few of them in this area . 
but it ' s outside of i . c . s . i . 
huh . 
so 
k . p . n . and and i . c . s . i . in principle . 
yeah . 
after you will leave here that is . 
yeah and then what do you intend to do in the last two months beside of course looking for 
holidays . 
yeah . 
um i am working now on on something . 
uh an open source router . 
this is that from from mark right ? 
no . 
in 
not ? 
well it ' s a little bit out of mark . 
i ' m 
right now i ' m interested and i ' m looking into it . 
and i ' m working started yesterday actually working on it . 
to do the uh to do an implementation of the protocol that was designed by mark um on an open source router that ' s different from the one that of mark ' s project . 
uhhuh . 
yeah do you finish that and do you believe that you can finish that until end of january ? 
i hope so . 
it sounded sounded to me a little bit little bit hard hard hard time constraint right ? 
that would be cool . 
yeah . 
it ' s 
hard work . 
yeah . 
that ' s right . 
but i ' m working on it . 
uhhuh . 
okay . 
miguel maybe you can say also . 
oh i ' ll be i ' ll be here until the end of july . 
and uh 
well uh 
even later if uh there is some interesting work uh going on . 
well i i will be able to to do some work from spain too . 
uhhuh . 
so that ' s my future uh forecast . 
uhhuh . 
and uh do you have some students which could be join if there is 
yeah . 
i assume there is a certain activity . 
maybe if you will leave in july 
yeah well you know uh the problem the i think that we have a a problem or a difference in spain at least compared with the americans . 
and is that our students are uh are not getting involved in research until they have uh finished their studies . 
so uh it ' s something a little bit uh strange . 
but it is this this is the 
what ? 
they are not 
sorry ? 
they are not involved in in research ? 
yeah . 
you know 
what they are doing then ? 
i ' m sorry . 
lectures . 
huh ? 
you know they 
ach so ach so 
okay . 
you you have to to pass the different tests . 
and you have to study the different subjects . 
and until you have finished with this uh well okay you can do it by by your own . 
uhhuh . 
but but the thing is that you ' re not supposed to do it . 
and usually students are pretty busy for not doing other things . 
uhhuh . 
uh 
and there ' s no final master ' s thesis or something like that what they have to perform ? 
uh yeah them nnn not really . 
you know there is . 
there is . 
uhhuh . 
but uh it is not a research work . 
usually it ' s an application work . 
so you build a web site your own e . commerce site uh whatever . 
uhhuh . 
or a program or 
why i didn ' t study in spain ? 
but 
but it is not uh something your teacher provides you some research papers and you let ' s say build a simulator or try to . 
huh . 
uhhuh . 
uhhuh . 
are certain tasks ? 
okay . 
and so 
so 
we have uh other students are which are uh huh people that has a grant . 
and they are they are starting as uh researchers . 
ah but this is only connected to your own funding . 
so if you if you have projects you can have uh people working with you . 
uhhuh . 
if you don ' t have a research project well you cannot pay them . 
so usually you don ' t have anybody . 
so it ' s kind of uh dependent on the funding we have in some projects . 
so 
it ' s not sure . 
no . 
not really sure . 
there . 
we ' re not talking about to send the students here to i . c . s . i . 
i ' m talking if there is an activity at least with the n . s . a . group that certain kind of activities also in the university could apply for the master works of diplomas thesis uh whatever kind of thing that 
yeah . 
we we 
i think we could we could find uh some uh work force . 
okay ? 
uhhuh . 
because well you you can uh redirect you know the the work as uh let ' s say as a subject work of something that you can you can try to uh 
in some subjects in fact uh the the the uh topics are more open . 
so you can introduce some research topics too . 
so 
but the main thing is that there is a uh this big difference . 
because uh students are not supposed to do research uh work until they have finished their their grade . 
uhhuh . 
you can change that . 
yeah . 
sure . 
uh maybe you 
sure . 
i think it ' s pretty healthy for a student to to have a project uh where you have to write actually some part of research . 
or 
yeah i think so too . 
but uh you know it also depends on the subjects . 
because sometimes subjects are fixed . 
sure . 
so you cannot you cannot uh uh give any any stuff you want . 
okay . 
you have to to provide a certain a certain prime for the subject too . 
of course . 
but you know sometimes especially in the in the latest uh uh courses uh things are probably more open . 
and well it it is something that can be changed . 
uhhuh . 
okay . 
thank you . 
claudia i still mentioned have you other things ? 
for me as i said before i will be funded by a uh by the ministry of uh the german government for research in the project so - called invinet . 
that seems to be sure . 
and i got absolutely freedom to do what i would like to do . 
and i would like to go on with the q . s . in advance mechanism . 
and uh 
in the relation of u . s . a . i . a . i . also have the activities with georgia tech . 
they have now a p . h . d . 
it is settled . 
and my other next uh generation of contract is also going in that sense so the topic is still going going on . 
and when i will come back here i would like to use these things too to maybe come to a closer a bigger project um outside of this goal with contributions here from uh first of all from the n . s . a . group and then from from other partners . 
but this i have definitely uh discussed with my management . 
and this will happened i believe in december . 
maybe and in the beginning of january . 
and i will keep informed to the management of i . c . s . i . anyway . 
but also i assume that my suggestions that we have a weekly phone conference and email exchange during that time . 
so that we can inform each other concerning what are the questions what are the problems what is the status and so on . 
uh 
but i think we will uh detail these things then in one of the last meetings . 
so 
how is your status and and your ideas and your plans and your future and 
yeah . 
well . 
i will 
you ' re addicted to the testbeds you run on the hour . 
no no no no no . 
so that ' s 
so i will stay here till the end of february . 
and 
afterwards um at berlin i ' m yeah funded by an institution of the german government . 
so 
they are paying me . 
and i have to do research for them of course . 
i have to um well uh reach some goals and so on . 
but on the other hand there will be some time left i think to do some work on this area i started here . 
and for me myself i ' m also very interested in in continue this work . 
and so that will be manageable . 
and um 
on the other hand there are also uh some students or 
well . 
at the moment it ' s quite difficult to find students uh who are doing their master ' s thesis and so on . 
because there are not a lot of students uh which are in this state in germany now . 
but um 
about two years ago the numbers of students were um studying computer science uh started to increase again . 
and so in one or two years we will have uh many students uh which are performing their master ' s thesis . 
and so i think there will also be uh many students which are joining in this work . 
so hopefully uh i will found will find some students which are joining in . 
and um 
so hopefully this work will be go on . 
uhhuh . 
okay . 
sounded good to me . 
and michael ? 
so i won ' t change the topic then . 
i ' m here until end of may . 
and after that i presumably going to a siemens project with some department of gee mens . 
but related to that topic what i have done here . 
so 
it ' s some of pre stage to that . 
so it might be more related or loosely related . 
so it ' s at least it ' s in the same topic . 
and progress it ' s going on . 
but it ' s not that fast going on as i would have like it . 
uhhuh . 
oh . 
i would like to have it . 
sorry . 
well . 
but oder ? 
yeah then what is the current status anyway ? 
um i ' m currently i ' m looking into quality of service routing . 
this is . 
and i had discussions with a post doc from the u . u . c . b . 
well . 
we want to we started to collect information to write the paper about quality of serving routing for m . p . l . s . in an m . p . l . s . domain . 
uhhuh . 
so you have um distributed routing at the edges . 
and one aspect is that the information is outdated so that you know to always have the exact information of your links dates and so on . 
it what we have plans of that . 
and trying to look at some routing policies or routing algorithms . 
uhhuh . 
now as i see in principle uh fff that ' s a really raw view . 
m . p . l . s . offers certain kind of success of active routing . 
because in principle the forwarding pass is a little bit decoupled from this from the routing pass . 
yeah . 
and this was in principle . 
okay . 
it ' s it ' s not really the subject . 
it it 
but in a broader sense it could be seen in that sense . 
it yeah . 
i think uh there are in a certain degree some alignment with with both of you guys . 
yeah . 
right ? 
so at least from the definition of christian tschudin m . p . l . s . is a subset of of active active routing . 
so it ' s very it ' s static ? 
it ' s no active ? 
but it ' s sort of active because they have these program statements . 
yeah . 
yeah . 
maybe it ' s a separation in principle that i do not use the normal traditional uh data forwarding pass and update in principle only the routing information uh to to to use it . 
but 
yeah . 
yeah . 
well they are they are using the the the same idea of labelling packets with a with a content descriptor or something . 
yeah . 
yeah . 
yeah . 
that ' s right . 
yeah . 
so what i mean is at a certain degree yeah that has to be figured out . 
yeah . 
there ' s a connection point . 
there is uh there are some linkage between them in both of your your work . 
uhhuh . 
yeah . 
so 
my last point uh in principle is the proposal itself . 
um 
i know in the past it was always if i ' m not writing something nothing going to happen . 
so i believe wilbert you are going out of these activity . 
you have to use your time to finish your work as you uh have in mind until your end of february . 
or is that right ? 
january . 
yes . 
end of january . 
sorry . 
so you will not you will not find any time to contribute anymore to this activity . 
no . 
okay . 
then from miguel ' s side i expect more detailed vision . 
we can do it as i mentioned before bilateral afterwards uh concerning your work and how you think it could be beneficial contribution to the activity maybe based on the generic uh uh u . s . a . i . a . architecture . 
later . 
i will write as long as i have time here uh on the proposal itself . 
and in the near term future i will distribute a list of the small cluster of people . 
i tried to access juan peire several times . 
he didn ' t answer because he still had mentioned that there ' s some minor funding that i think would help . 
for instance to have initial meeting either here or in europe or or wherever . 
i ' ve uh contact one more time the professor . 
what is his name ? 
rao ? 
or 
uh landay mentioned uh 
landay ? 
rao right ? 
yeah . 
because he ' s a professor in uh responsible for the infrastructure at u . c . b . and he has some projects which are related to um these these uh activities . 
landay . 
uh . 
i would name it intelligent classroom . 
i don ' t know whether i can succeed to get an appointment then . 
but i will distribute a list contact list and the interests of each partner . 
so that everybody can see and everybody knows yeah i have in mind . 
maybe it ' s a small n . s . a . group activity itself with no linkage to the outer world . 
maybe it ' s a n . s . a . group activity with a linkage to the outer world based on the uh universities at home or the companies at home . 
there ' s some linkage . 
and the third stage is let ' s say there ' s a n . s . a . group activity in this area uh with the supported um home entities and with certain kind of linkage here to the companies or or universities here in this area . 
the last one i think it ' s uh the best one . 
but you see the question is always where ' s the money . 
and i say oh poo . 
currently i don ' t know . 
the second question is how long i stay here . 
and say ooo i don ' t know . 
so 
everybody ' s waiting . 
yeah ? 
and the only um activity could come from the n . s . a . group itself . 
but i think it ' s a a work in process and that it will take some time and uh everything must be just settled a little bit more . 
so but anyway i would like to get contributions from the people here of the n . s . a . group concerning proposals . 
this is a living thing . 
and 
it ' s a pity that multicast is in principle removed . 
and we do not have any expert from multicast anymore . 
and uh that ' s makes very hard i believe . 
because that is a major at least twenty five percent of the whole network uh stuff . 
and um 
but neverless we have to live with this situation . 
right . 
you are laughing again ? 
right . 
right . 
so maybe we have to rewrite something . 
have new ideas going forward more in certain kind of really telecommunication network and the routing and q . s . stuff . 
and remove in principle the multicast stuff . 
which in principle a pity because i think that ' s a really really good uh uh huh source of research work for the future telecommunication core networks . 
because they are still not able to deal with multicast . 
they still have there that tunnel generations and all those kind of things . 
and i i believe that would be very beneficial to use it for the really uh mobile scenarios in in that network . 
so but anyway we have to live with a real situation . 
and that means we have to drop multicast from the proposal . 
any comments ? 
oh not really you know . 
uh i i i i think that well in the future somebody will come to the n . s . a . group . 
uh 
then we can extend the proposal one more time with multicast . 
uh 
so 
no i mean that 
okay . 
i i i think that it cannot uh be uh considered the first type task to do . 
because nobody is is knowledgeable about multicasting . 
but i think that uh any of us could address these things in the future . 
or maybe a new person could address this in the future . 
so 
if 
i mean what i think is that uh it it makes no sense to me to reduce uh uh uh uh something which is more or less complete . 
because we don ' t have the person . 
i think that the the way to to go is probably the opposite to try to find something which has a meaning by itself . 
and then try to get the resources to to to do this . 
oh maybe you understand me in the wrong way . 
uh 
i do not mean to drop it to remove the text from the proposal . 
okay . 
okay . 
i mean activities planning activities . 
sorry . 
yeah . 
that ' s okay . 
work packages . 
sorry sorry . 
heh . 
yeah . 
now i 
so 
no no . 
because that ' s uh that ' s why i mentioned that it is important thing . 
but currently there ' s only one new group member sven buchholz who will figure out the thing huh how to say um the taking into account the end system or the limited end system capabilities with respect to mobility and the network itself . 
where it should be where should be uh the adaptation process performed to deal with the different devices for ubiquitous access to the network ? 
should it be in the end system itself ? 
should be in the edge device ? 
it should it be in the core ? 
should it be on the server ? 
these are the questions he would like to figure out . 
and to uh to have in principle the pro and cons of uh different of all these different approaches . 
so that ' s the only new member . 
who is that ? 
sven buchholz . 
he was here . 
i invited him and discussed with him his potential work i . 
quite sure . 
oh he was here one day . 
yeah . 
yeah . 
huh . 
but he showed up the next day . 
several days . 
but only for administration stuff . 
yeah . 
but for the technical discussion he was here one day . 
yeah . 
yeah . 
i ' m do not remember whether whether you were 
that must be three weeks ago . 
because i i just met him when i arrived . 
yeah i do remember him . 
yeah . 
but i didn ' t talk with him about uh about the research topic . 
uhhuh . 
so i didn ' t know what he was going to do . 
yeah he will come mid of january i believe . 
yeah . 
uhhuh . 
as far as i know . 
so but this is the only guy you know . 
but that is not reflected in that sense that we remove the text . 
what i mean is is uh the that we what ' s kind of activity we are going more in detail in describing the network packages and and detailed uh uh descriptions more detailed descriptions . 
okay . 
so 
any other question ? 
any other comment ? 
oh . 
then we should start with reading the numbers . 
one more time . 
oh again ? 
we have to do that ? 
oh . 
yes . 
we have to do it . 
i don ' t know . 
so that means we have to read the transcript script number and then the numbers . 
and if there ' s a new line a short break . 
and afterwards we have to 
uh that device is switched on . 
so please do not switch off the devices . 
and i will call herr janin and that adam . 
so i will start . 
so i i had a question for adam . 
have we started already ? 
well we started recording but yeah . 
yeah . 
is jane around ? 
or 
i saw her earlier . 
uh 
she can just walk in i guess or 
i think 
yeah . 
right . 
she ' ll probably come up . 
since we ' re starting late i figured we ' d better just start . 
yeah great idea . 
i was going to ask adam to uh say if he thought anymore about the demo stuff . 
because it occurred to me that this is late may and the darpa meeting is in mid july . 
uh but i don ' t remember what we 
i know that we were going to do something with the transcriber interface is one thing . 
but i thought there was a second thing . 
anybody remember ? 
well we were going to do a mock up like question answering or something i thought . 
that was totally separate from the interface . 
do you remember ? 
remember like asking questions and retrieving but in a pre stored fashion . 
uhhuh . 
right . 
that was the thing we talked about i think before the transcriber 
come on in . 
yeah . 
all right so anyway you have to sort out that out . 
and get somebody going on it . 
because we ' re got a got a month left basically . 
so 
you like these . 
right ? 
okay good . 
okay . 
um 
okay so what are we else we got ? 
you got you just wrote a bunch of stuff . 
no that was all um previously here . 
oh . 
i was writing the digits and then i realized i could xerox them . 
oh . 
oh . 
because i didn ' t want people to turn their heads from these microphones . 
so 
we all by the way have the same digit form for the record . 
so 
that ' s cool . 
yeah . 
so the choice is uh which which do we want more the the the comparison uh of everybody saying them at the same time or the comparison of people saying the same digits at different times that 
it ' s just because i didn ' t have any more digit sheets . 
i know that . 
so 
but you know which opportunity should we 
yeah . 
unison . 
i mean it actually it might be good to have them separately and have the same exact strings . 
unison . 
i mean we could use them for normalizing or something . 
but it of course goes more quickly doing them in unison . 
i guess we ' ll see . 
i don ' t know . 
i guess it ' s dependent on 
see how long we go . 
how long we go and how good the snack is out there . 
yeah huh get some advance intelligence . 
but anyway they won ' t be identical as somebody is saying zero in some sometimes you know saying o and so it ' s not not identical . 
right . 
right . 
yeah we ' d have to train . 
we ' d be like a chorus . 
okay . 
yeah we ' d have to get get some experience . 
greek chorus . 
yeah . 
yes . 
yeah . 
really boring chorus . 
um do we have an agenda ? 
adam usually tries to put those together but he ' s ill . 
i ' ve got a couple of things to talk about . 
so 
yeah . 
uh what what might those be ? 
uh i b m stuff and um just getting uh meeting information organized . 
meeting info organized . 
okay . 
um 
are you implying that it ' s currently disorganized ? 
in my mind . 
is there stuff that ' s happened about um uh the s r i recognizer et cetera ? 
those things that were happening before with 
you guys were doing a bunch of experiments with different front ends and then with 
well 
is is that still sort of where it was uh the other day ? 
we ' re improving . 
we ' re improving . 
yeah . 
now the the you saw the note that the p l p now is getting basically the same as the m f c c . 
right . 
right ? 
right . 
yeah actually it looks like it ' s getting better . 
oh . 
so but but it ' s not 
just with with age kind of . 
with age yeah . 
yeah yeah . 
but uh that ' s not directly related to me . 
doesn ' t mean we can ' t talk about it . 
um it seems it looks i haven ' t the it ' s the experiment is still not complete . 
but 
um it looks like the vocal tract length normalization is working beautifully actually . 
uhhuh . 
using the warp factors that we computed for the s r i system and just applying them to the icsi front end . 
that ' s pretty funny . 
yeah . 
so you just need to copy over to this one . 
okay . 
just had to take the reciprocal of the number because they have different meanings in the two systems . 
okay . 
uh ! 
yeah well that ' s always good to do . 
yeah . 
okay . 
okay 
uh 
but one issue actually that just came up in discussion with liz and and don was um as far as meeting recognition is concerned um we would really like to uh move uh to uh doing the recognition on automatic segmentations . 
yeah . 
because in all our previous experiments we had the uh you know we were essentially cheating by having the um you know the the hand segmentations as the basis of the recognition . 
uhhuh . 
and so now with thilo ' s segmenter working so well i think we should consider doing a 
huh so . 
come on . 
yeah we but 
think you think we should increase the error rate ? 
uh doing 
anyway yeah . 
good . 
yeah . 
yeah . 
yeah . 
yeah . 
that ' s what i wanted to do anyway . 
yeah . 
yeah . 
so we should just get together and 
yeah . 
and even the good thing is that since you um have high recall even if you have low precision because you ' re over generating that ' s good . 
because we could train noise models in the recognizer for these kinds of uh transients and things that come from the microphones . 
yeah . 
right . 
yeah . 
but i know that if we run recognition unconstrained on a whole waveform we do very poorly because we ' re we ' re getting insertions in places what that you may well be cutting out . 
well 
yeah . 
uhhuh . 
so we do need some kind of pre segmentation . 
we should we should consider doing some extra things like um you know retraining or adapting the the models for background noise to the to this environment for instance . 
huh 
yeah . 
yeah . 
and yeah using thilo ' s you know posteriors or some kind of or 
so 
right now they ' re they ' re discrete . 
yes or no for a speaker to consider those particular speaker background models . 
yeah . 
so 
right . 
there ' s lots of interesting things that could be done . 
yeah . 
yeah we should do that . 
so 
good . 
so uh why don ' t we uh do the i b m stuff ? 
you had some thing about that ? 
yeah so um talked with brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before . 
right . 
and so 
the uh chuck chunks . 
yeah . 
huh 
the chuck chunks . 
right . 
and so he talked it over with the transcriber . 
and the transcriber thought that the easiest thing for them would be if there was a beep and then the a number a digit and then a beep uh at the beginning of each one . 
yeah . 
yeah . 
and that would help keep them from getting lost . 
and um so adam wrote a little script to generate those style uh beeps . 
and so we ' re 
where ' d you get the digits from ? 
i came up here and just recorded the numbers one through ten . 
they sound really good . 
so 
that ' s a great idea . 
does it sound okay ? 
yeah . 
so um yeah we just used those . 
and do you splice them into the waveform ? 
or 
yeah he then he i recorded actually i recorded one through ten three times at three different speeds and then he picked . 
right . 
uhhuh . 
he liked the fastest one so he just cut those out and spliced them in between uh two beeps . 
it will be funny . 
it sounds like a radio announcer ' s voice really . 
uh 
does it ? 
yeah yeah . 
it will be funny when you ' re really reading digits and then there are the chunks with with your digits in . 
yeah with my 
oh right . 
oh that ' s right . 
yeah . 
that ' ll throw them . 
now actually 
huh ? 
we ' re are we handling 
uh maybe we should have you record a b c for those or something . 
huh maybe . 
and she said it wasn ' t going to the transcriber said it wouldn ' t be a problem because they can actually make a template uh that has beep number beep . 
okay . 
so for them it ' ll be very quick . 
yeah . 
to to put those in there when they ' re transcribing . 
so um we we ' re going to send them one more sample meeting . 
uh and thilo has run his segmentation . 
adam ' s going to generate the chunked file . 
and then um i ' ll give it to brian and they can try that out . 
and when we get that back we ' ll see if that sort of fixes the problem we had with uh too many beeps in the last transcription . 
okay do do what do you have any idea of the turn around on on those steps you just said ? 
great . 
uh 
uh our our on our side ? 
or including i b m ' s ? 
including i b m ' s . 
well i don ' t know . 
the last one seemed like it took a couple of weeks . 
okay . 
um maybe even three . 
uh that ' s just the i b m side . 
our side is quick . 
i mean i i don ' t know how long does your 
it should be finished today or something yeah . 
well i meant the overall thing . 
the reason i ' m asking is because uh jane and i have just been talking and she ' s just been doing uh a you know further hiring of transcribers . 
yeah . 
uhhuh . 
uhhuh . 
and so we don ' t sort of really know exactly what they ' ll be doing how long they ' ll be doing it and so forth . 
because right now she has no choice but to operate in the mode that we already have working . 
right . 
and uh 
so it ' d be it ' d be good to sort of get that resolved uh soon as we could . 
yeah . 
and then 
i yeah i i hope we can get a better estimate from this one that we send them . 
uhhuh . 
so um 
i i don ' t know yet how long that ' ll take . 
yeah um 
i mean in particular i would i would really hope that when we do this darpa meeting in july that we sort of have we ' re we ' re into production mode somehow . 
uhhuh . 
you know that we we actually have a stream going and we know how how well it does and how and how it operates . 
yeah . 
i think that would that would certainly be a a very good thing to know . 
right right . 
okay . 
uh 
maybe before we do the meeting info organize thing maybe you could say relevant stuff about where we are in transcriptions . 
okay so um we uh the transcribers have continued to work past what i ' m calling set one . 
which was the the set that i ' ve been uh okay talking about up to this point . 
but uh they ' ve gotten five meetings done in that set . 
right now they ' re in the process of being edited . 
um the um 
let ' s see . 
i hired two transcribers today i ' m thinking of hiring another one . 
which will because we ' ve had a lot of attrition . 
and that will bring our total to 
they die off after they do this for a while . 
yeah . 
burn out . 
yeah . 
well you know it ' s it ' s various things . 
so one of them had a baby um you know one of them really wasn ' t planning 
oh that was an unforeseen side effect of 
uh one of them um had never planned to work past january . 
i mean it ' s all these various things . 
because we you know we presented it as possibly a month project back in january . 
and and and and um 
so it makes sense . 
uh through attrition we we ' ve we ' re down to to two but they ' re really solid . 
we ' re really lucky the two that we kept . 
and um well i don ' t mean i don ' t mean anything against the others what i mean is we ' ve got a good cause a good core no we had a good core . 
well they won ' t hear this since they ' re going they won ' t be transcribing this meeting . 
yeah but still i mean i it ' s just a matter of we we ' re we ' ve got uh 
no backs . 
two of the ones who who um had been putting in a lot of hours up to this point and they ' re continuing to put in a a lot of hours . 
which is wonderful and excellent work . 
and so then in addition um i hired two more today and i ' m planning to hire a third one with this within this coming week . 
but but the plan is just as uh morgan was saying we discussed this and the plan right now is to keep the staff on the on the leaner side . 
you know ? 
rather than hiring like eight to ten right now . 
uhhuh . 
because if the i b m thing comes through really quickly then um we wouldn ' t want to have to uh you know lay people off and stuff . 
so 
and this way it ' ll i mean i got really a lot of response for for my notice . 
and i think i could hire additional people if i wish to . 
yeah and the other thing is i mean in the unlikely event 
and since we ' re so far from this it ' s a little hard to plan this way . 
in the unlikely event that we actually find that we have uh transcribers on staff who are twiddling their thumbs . 
because you know there ' s you know all the stuff that that was sitting there has been transcribed and they ' re and they ' re faster the the pipeline is faster than uh than the generation . 
um 
uh in in the day event that that day actually dawns uh i i bet we could find some other stuff for them to do . 
so i i think that uh uh as we were talking if we if we hire twelve then we could you know run into a problem later . 
oh yes . 
i mean we also just couldn ' t sustain that forever . 
but but um for all sorts of reasons . 
but if we hire you know we have five on staff five or six on staff at any given time then it ' s a small enough number so we can be flexible either way . 
good . 
okay . 
good . 
it ' d be great too if um we can we might need some help again getting the tighter boundaries . 
or some hand to experiment with um you know to have a ground truth for this segmentation work . 
which i guess you have some already that was really helpful and we could probably use more . 
huh yeah that was a thing i i planned working on is uh to use the the transcriptions which are done by now and to to use them as uh 
oh . 
oh the new ones . 
yeah . 
with the tighter boundaries yeah . 
yeah . 
and to use them for for training a or for whatever yeah . 
to to create some speech nonspeech labels out of them . 
and yeah but that that ' s a thing was what i ' m just looking into . 
okay . 
the the the pre segmentations are so much are so extremely helpful . 
now there was uh i guess 
so a couple weeks ago i needed some new ones and it happened to be during the time that he was on vacation . 
for just very few days you were away . 
yeah . 
but it happened to be during that time i needed one . 
so i so i started them on the non - pre - segmented and then switched them over to yours . 
and um they um you know they always appreciate that when they have that available . 
and he ' s uh usually uh uh um um 
so they really appreciate it . 
but i was going to say that they do adjust it once in a while . 
you know once in a while there ' s something like 
yeah sure . 
um and actually you talked to them . 
didn ' t you ? 
did you have you 
yeah . 
i talked to helen . 
and and and she was 
and so i asked her 
i mean they ' re very perceptive . 
i really want to have this meeting of the transcribers . 
i haven ' t done it yet but i want to do that . 
and she ' s out of town um for a couple of weeks but i want to do that when she returns . 
um because she was saying you know in a in a span of very short period we asked it seems like the ones that need to be adjusted are these these these things . 
and she was saying the short utterances uh the um 
huh 
huh 
yeah . 
you know i mean you ' re you ' re aware of this . 
yeah . 
but but actually it ' s so correct for so much of the time that it ' s an enormous time saver . 
and it just gets tweaked a little around the boundaries . 
that ' s great . 
so 
um yeah i think it ' d be interesting to combine these . 
yeah . 
is there actually a record of where they change ? 
i mean you can compare do a diff on the 
just so that we knew 
you could do it . 
it ' s it ' s complicated in that um hhh hhh 
yeah . 
actually when when they create new yeah new segments or something it will be uh not that easy . 
but huh i think one could do that . 
i mean if we keep a old copy of the old time marks j . 
yeah . 
just so that if we run it we know whether we ' re which ones were cheating . 
yeah . 
yeah . 
and 
that would be great yeah to know that . 
there is a there is one problem with that and that is when they start part way through then what i do is i merge what they ' ve done with the pre segmented version . 
which one would be good . 
yeah . 
so it ' s not a pure it ' s not a pure condition . 
what you ' d really like is that they started with pre segmented and were pre segmented all the way through . 
uhhuh . 
and um i uh the 
it wasn ' t possible for about four of the recent ones . 
but it will be possible in the future . 
yeah . 
because we we ' re um 
huh that ' s great . 
it would . 
yeah . 
yeah as long as we have a record i guess of the original automatic one we can always find out how well we would do from the recognition side by using those boundaries . 
yeah . 
yeah . 
um 
you know a completely non cheating version . 
yeah . 
yeah . 
also if you need someone to record this meeting i mean i ' m happy to for the transcribers 
i could do it or chuck or adam . 
thank you . 
okay . 
so uh you were saying something about organizing the meeting info ? 
yeah so um uh jane and adam and i had a meeting where we talked about the reorganization of the directory structure for all of the meeting 
did you record it ? 
no . 
for all the meeting recorder data . 
we should have . 
um and so we ' ve got a plan for what we ' re going to do there . 
and then jane also prepared a um started getting all of the the meetings organized so she prepared a a spreadsheet which i spent the last couple of days adding to . 
so i went through all of the data that we have collected so far and have . 
been putting it into uh a spreadsheet with start time the date the old meeting name the new meeting name the number of speakers the duration of the meeting comments you know what its transcription status is all that kind of stuff . 
and so the idea is that we can take this and then export it as h t m l and put it on the meeting recorder web page . 
oh great . 
so we can keep people updated about what ' s going on . 
um i ' ve got to get some more information from jane . 
because i have some some gaps here that i need to get her to fill in . 
but so far um as of monday the fourteenth um we ' ve had a total number of sixty two hours of meetings that we have collected . 
and um 
uh some other interesting things average number of speakers per meeting is six . 
um 
and i ' m going to have on here the total amount that ' s been transcribed so far . 
but i ' ve got a bunch of 
uh that ' s what i have to talk to jane about figuring out exactly which ones have have been completed and so forth . 
but um this ' ll be a nice thing that we can put up on the the web site and people can be informed of the status of various different ones . 
and it ' ll also list uh like under the status if it ' s at i b m or if it ' s at icsi uh or if it ' s completed or which ones we ' re excluding . 
and and there ' s a place for comments so we can um say why we ' re excluding things and so forth . 
so 
now would the ones that um are already transcribed we we have enough there that 
you know we ' ve already done some studies and so forth . 
and 
um shouldn ' t we go through and do the business of of having the um uh participants approve it uh for approve the transcriptions for distribution and so forth ? 
um interesting idea . 
in principle i i would say yes although i still am doing some the final pass editing . 
trying to convert it over to the master file as the being the channelized version . 
and it ' s yeah it seems like i get into that a certain way and then something else intervenes and i have to stop . 
cleaning up the things like the uh uh places where the transcriber was uncertain . 
and and doing spot checking here and there . 
so um uh i guess it would make sense to wait until that ' s done . 
um but but 
well let me put in another sort of a milestone kind of as as i did with the uh uh the the pipeline . 
yeah . 
um we are going to have this darpa meeting in the middle of july . 
and i think it it ' d be 
yes . 
given that we ' ve been we ' ve given a couple public talks about it already spaced by months and months i think it ' d be pretty bad if we continued to say none of this is available . 
um 
it ' ll certainly be done by then yeah . 
right so we can we we want to be able to say here is a subset that is available right now . 
uhhuh . 
that ' s right . 
and that ' s has been through the legal issues and so forth . 
that ' s right . 
so 
yeah that ' s right so that 
okay ? 
okay . 
so by before july . 
and they don ' t have to approve you know an edited version they can just give their approval to whatever version . 
well maybe 
well in principle yes but i mean if if if somebody actually did get into some legal issue with it then 
yeah but i mean the editing will continue presumably if if errors are found they will be fixed . 
but they won ' t change the the content of the meetings . 
content really . 
well see this is the this is the issue subtleties . 
so 
well if jane is clarifying question question then you know how can they agree to it before they know her final version ? 
the other thing too is there can be subtleties where a person uses this word instead of that word which could ' ve been transcribed in the other way . 
yeah . 
thing 
and and they wouldn ' t have been slanderous if it had been this other word . 
you know ? 
it you know there is a point at which i agree it becomes ridiculous . 
because you know you could do this final thing and then a year from now somebody could say you know that should be a period and not a question mark . 
right ? 
and you don ' t you there ' s no way that we ' re going to go back and ask everybody do you approve this uh you know this document now . 
so 
so i think what it is is that the the the the thing that they sign i i haven ' t looked at it in a while but it has to be open enough that it sort of says okay from now on you know now that i ' ve read this you can use do anything you want with these data . 
uhhuh . 
and uh but i think we want to 
so assuming that it ' s in that kind of wording which i don ' t remember um i think we just want to have enough confidence ourselves that it ' s so close to the final form it ' s going to be in a year from now that they ' re 
uhhuh . 
i agree . 
huh i totally agree . 
uh . 
it ' s just uh a question of uh if if the person is using the transcript as the way of them judging what they said and whether it was slanderous then it seems like it ' s it ' s it needs to be more correct than if we could count on them re listening to the meeting . 
because it becomes uh in a way a a uh a legal document . 
if they ' ve agreed to that . 
well i forget how we 
right i forget how we ended up on this . 
but i remember my taking the position of not making it so so easy for everybody to observe everything . 
and adam was taking the position of of having it be really straightforward for people to check every aspect of it including the audio . 
and i don ' t remember who won adam or me . 
but 
well if it ' s only the transcript though i mean this this is my point that that 
uh the 
uh that ' s why i ' m bringing this up again because i can ' t remember how we ended up . 
then it becomes 
that it was the 
he wanted to do a web interface that would make it 
well if it ' s just the audio 
that would give you access to the transcript and the audio . 
well . 
that ' s what adam wanted . 
uhhuh . 
and i don ' t remember how we ended up . 
i mean with the web interface it ' s interesting because you could allow the person who signs to be informed when their transcript changes . 
or something like that . 
and i mean i would say no like i don ' t want to know . 
but some people might be really interested . 
and then in other words they would be informed if there was some significant change other than typos and things like that . 
you decided you were whispering satanic incantations under your breath when you were 
i don ' t know what happened to the small heads thing . 
but i um i ' m just saying that like you know you can sort of say that any things that are deemed 
they disappeared from view . 
anyway i mean i agree that at some point people probably won ' t care about typos but they would care about significant meaning changes . 
and then they could be asked for their consent i guess if if those change . 
because assuming we we don ' t really distribute things that have any significant changes from what they sign anyway . 
that ' s 
how about having them approve the audio and not the transcripts ? 
oh my god ! 
uh 
that would be simpler . 
if we could count on them listening . 
but no one will listen to the hours and hours of 
talk . 
well that ' s okay . 
we just have to give them a chance to listen to it and if they don ' t that ' s their problem . 
that ' s 
huh huh . 
you you 
that ' s like 
unfortunately uh in in the thing that they signed it says transcripts . 
no i ' m serious ! 
you ' ll be you ' ll be provided the transcripts when they ' re available . 
really ? 
yeah . 
i i think 
huh 
huh 
yeah . 
that ' s a lot to ask for people that have been in a lot of meetings . 
yeah . 
yeah . 
anyway haven ' t we we ' ve gone down this path a number of times i know this can lead to extended conversations and and not really get anywhere . 
so let let me just suggest that uh off line that uh the people involved figure it out and take care of it before it ' s july . 
yes . 
okay so so that in july we can tell people yes we have this and you can use it . 
yes . 
it ' s done ready available . 
good . 
uh 
so let ' s see . 
what else we got ? 
uh don did did a report about his project in class . 
and uh an oral and written written version . 
well . 
so that was stuff he was doing with you . 
i mean it ' s i guess one thing we ' re learning is that the amount 
yeah . 
we have eight meetings there . 
because we couldn ' t use the non native all non native meetings . 
and it ' s well probably below threshold on enough data for us for the things we ' re looking at . 
because the prosodic features are very noisy and so you you need a lot of data in order to model them . 
um so we ' re starting to see some patterns . 
and we ' re hoping that maybe with i don ' t know double or triple the data with twenty meetings or so that we would start to get better results . 
but we did find that some of the features that i jane would know about that are expressing sort of the distance of um boundaries from peaks in the utterance and some local um range pitch range effects like how close people are to their floor are showing up in these classifiers . 
which are also being given some word features that are cheating because they ' re true words . 
um so these are based on forced alignment . 
word features like um word frequency . 
and whether or not something ' s a backchannel and so forth . 
so we ' re starting to see i think some interesting patterns . 
so the dominant features including everything were those those quasi cheating things . 
right ? 
where these are 
sometimes not . 
i think it depends what you ' re looking at actually . 
yeah sometimes positions in sentences obviously or in spurts was helpful . 
right . 
i don ' t know if that ' s cheating too . 
um 
spurts wouldn ' t be . 
right ? 
spurts is not cheating except that of course you know the real words . 
but roughly speaking the recognized words are going to give you a similar type of position . 
right . 
right would they give you the same number of words though ? 
it ' s either early or late . 
right . 
not exactly but 
but somewhat ? 
yeah it should be . 
on the average . 
well we don ' t know . 
and actually that ' s one of the things we ' re interested in doing is a sort of 
have you tried using just time as opposed to number of words ? 
uhhuh . 
so 
i think uh 
just time position like when the word starts ? 
yeah . 
well no i mean time time position relative to the beginning of the spurt . 
uh 
i don ' t know if that was in the 
you know 
start . 
yeah . 
uh we didn ' t try it . 
yeah there ' s all these things to do . 
but it ' s 
like there ' s a lot of different features you could just pull out . 
yeah . 
i mean that wouldn ' t be cheating because you can detect pause pretty well within the time . 
right . 
right . 
how about time position normalized by 
and it depends on speaking rate . 
yeah yeah . 
speaking rate yeah . 
yeah that ' s actually why i didn ' t use it at first . 
yeah . 
yeah . 
but we one of the interesting things was 
uhhuh . 
i guess you reported on some punctuation type ? 
finding sentence boundaries finding disfluency boundaries . 
yeah . 
and then i had done some work on finding from the foreground speech whether or not someone was likely to interrupt . 
so where you know if i ' m talking now and someone and and andreas is about to interrupt me is he going to choose a certain place in my speech either prosodically or word based . 
and there the prosodic features actually showed up . 
and a neat thing 
even though the word features were available . 
and a neat thing there too is i tried some putting the speaker 
so i gave everybody a short version of their name . 
so the real names are in there . 
which we couldn ' t use . 
uh we should use i d ' s or something . 
and those don ' t show up . 
so that means that overall um it wasn ' t just modeling morgan or it wasn ' t just modeling a single person . 
uhhuh . 
um 
but was sort of trying to uh get a general idea . 
the model the tree classifier was trying to find general locations that were applicable to different speakers . 
even though there are huge speaker effects . 
so 
the but the main limitation now is i because we ' re only looking at things that happen every ten words or every twenty words we need more more data and more data per speaker . 
so 
it ' d also be interesting to look at the e d u meetings . 
because we did include meeting type as a feature . 
so 
whether you were in a meeting recorder meeting or a robustness meeting did matter to interrupts . 
because there are just fewer interrupts in the robustness meetings . 
uhhuh . 
and so the classifier learns more about morgan than it does about sort of the average person . 
uhhuh . 
which is not bad . 
it ' d probably do better than um but it wasn ' t generalizing . 
so it ' s 
yeah . 
and i think don um well we have a long list of things he ' s starting to look at now over the summer . 
where we can 
and he ' ll be able to report on more things in the future . 
but it was great that we could at least go from the you know jane ' s transcripts and the uh recognizer output and get it to this point . 
and i think it ' s something mari can probably use in her preliminary report . 
like yeah we ' re at the point where we ' re training these classifiers . 
and we ' re just reporting very preliminary but suggestive results that some features both word and prosodic work . 
the other thing that was interesting to me is that the pitch features are better than in switchboard . 
and i think that really is from the close talking mikes . 
because the pitch processing that was done has much cleaner behavior than than the switchboard telephone bandwidth . 
better in what sense ? 
um well first of all the pitch tracks are have less um halvings and doublings than than switchboard . 
and there ' s a lot less dropout . 
so if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information . 
uhhuh . 
uhhuh . 
in other words the pitch tracker just didn ' t get a high enough probability of voicing for words . 
for for you know five 
huh . 
there are much fewer than in switchboard . 
so the missing we had a big missing data problem in switchboard . 
and so the features weren ' t as reliable . 
because they were often just not available . 
so that ' s actually good . 
could it have to do with the the lower frequency cut off on the switchboard ? 
maybe i mean the we had telephone bandwidth for switchboard . 
and we had the annoying sort of telephone handset movement problem that i think may also affect it . 
huh . 
so we ' re just getting better signals in in this data . 
which is nice . 
so 
yeah . 
anyway don ' s been doing a great job . 
and we hope to continue with um andreas ' s help and also some of thilo ' s help on this . 
great . 
to to try to get a non cheating version of how all this would work . 
yeah sure . 
yeah . 
has has uh we just i think just talked about this the other day but has has anybody had a chance to try changing uh insertion penalty sort of things with the with the uh uh using the tandem system input for the 
oh yeah i tried that . 
it didn ' t um help dramatically . 
were they out of balance ? 
the 
i didn ' t i didn ' t notice . 
there were a little 
the relative number of 
i think there were a higher number of deletions actually . 
oh . 
deletions ? 
so you uh so actually it it preferred to have a positive uh negative insertion penalty . 
which means that um 
uhhuh . 
but you know it didn ' t change the 
by adjusting that the um 
okay . 
yeah the error changed by probably one percent or so . 
but you know given that that word error rate is so high that ' s not a 
okay so that 
so that ' s so that ' s not the problem . 
that ' s not the problem . 
yeah . 
no . 
but uh we just um 
uh 
you know chuck and i talked and the next thing to do is probably to tune the um the size of the gaussian system um to to this to this feature vector which we haven ' t done at all . 
we just used the same configuration as we used for the for the standard system . 
huh . 
and for instance uh dan dan just sent me a message saying that c m u used um something like ten gaussians per cluster . 
you know each each mixture has ten gaussians . 
uhhuh . 
huh we ' re using sixty four . 
and and we ' re using sixty four . 
right ? 
so that ' s obviously a big difference . 
yeah . 
and it might be way off . 
and give very poorly trained uh you know gaussians that way . 
huh . 
uh and poorly trained mixture weights . 
so so we have 
the turn around time on the training when we train only the a male system with uh you know our small training set is less than twenty four hours . 
so we can run lots of uh basically just brute force . 
try a whole bunch of different um settings . 
okay . 
and uh with the new machines it ' ll be even better . 
so 
yeah we get twelve of those . 
huh ? 
yeah . 
but the p l p features work um uh you know continue to improve the 
okay . 
um 
as i said before the uh using dan ' s uh uh vocal tract normalization option works very well . 
uhhuh . 
so um i ran one experiment where we ' re just did the vocal tract normalization only in the test data . 
so i didn ' t bother to retrain the models at all . 
and it improved by one percent . 
which is about what we get with uh with you know just actually doing both training and test normalization um with um the uh uh with the standard system . 
so in a few hours we ' ll have the numbers for the for retraining everything with vocal tract length normalization . 
and so that might even improve it further . 
great . 
so it looks like the p l p features do very well now with after having figured out all these little tricks to to get it to work . 
yeah . 
so 
wait so you mean you improve one percent over a system that doesn ' t have any v t l in it already ? 
good . 
exactly yeah . 
okay . 
yeah . 
okay so then then we ' ll have our baseline to to compare the currently hideous uh uh new thing with . 
right 
but 
right and and what that suggests also is of course that the current switchboard m l p isn ' t trained on very good features . 
yeah . 
uh because it was trained on whatever you know was used uh last time you did hub five stuff . 
which didn ' t have any of the 
right but all of these effects were like a couple percent . 
uh 
right ? 
i mean the 
well but if you add them all up you have uh almost five percent difference now . 
add all of them 
i thought one was one point five percent and one was point eight . 
yeah and now we have another percent with the v t l . 
that ' s three point three . 
um actually and it ' s 
right it was it was there was 
um 
what ' s actually interesting is that with 
um well you maybe another half percent if you do the v t l in training . 
and then interestingly if you optimize you get more of a win out of rescoring the um uh the n best lists . 
uh and optimizing the weights . 
um uh than 
than you do with the standard ? 
yeah . 
yeah but the part that ' s actually adjustment of the front end per se as opposed to doing putting v t l n in or something is it was a couple percent . 
so 
right . 
right it was it was there was there was one thing that was one and a half percent and one that was point eight . 
so and and 
let me see if i remember what they were . 
one of them was uh the change to uh because it did it all at once to uh from bark scale to mel scale . 
uhhuh . 
which i really feel like saying in quotes . 
because they ' re essentially the same scale . 
yeah why did that 
but the but but but any individual particular implementation of those things puts things in a particular place . 
uhhuh . 
so that ' s why i wanted to look 
i still haven ' t looked at it yet . 
i i want to look at exactly where the filters were in the two . 
uhhuh . 
and it it ' s probably something like there ' s one fewer or one more filter in the sub one kilohertz band . 
and for whatever reason with this particular experiment it was better . 
uhhuh . 
one way or the other . 
huh . 
um it could be there ' s something more fundamental . 
but it you know i i don ' t know it yet . 
and the other and the other that was like one and a half or something . 
and then there was point eight percent . 
which was 
what was the other thing ? 
well that was combined with the triangular . 
right ? 
yeah those those two were together . 
yeah right . 
we weren ' t able to separate them out . 
because it was just done in one thing . 
but then there was a point eight percent which was something else . 
do you remember the 
the low frequency cut off . 
oh yeah so that was that was uh that one i can claim credit for uh in terms of screwing it up in the first place . 
so that someone until someone else fixed it . 
which is that um i never put 
when 
we had some problems before with offsets . 
this this went back to uh i think wall street journal . 
so we we had uh 
huh . 
everybody else who was doing wall street knew that there were big d c offsets in in these data in those data . 
and and and nobody happened to mention it to us . 
huh . 
and we were getting these like really terrible results . 
like two three times the error everybody else was getting . 
and then in casual conversation someone mentioned uh well i guess you know of course you ' re taking care of the offsets . 
i said what offsets . 
uhhuh . 
uhhuh . 
and at that point you know we were pretty new to the data . 
and we ' d never really like looked at it on a screen . 
and then when we just put it on the screen and wroop ! 
there ' s this big d c offset . 
uhhuh . 
so um in p l 
there was a like a hum or or when they recorded it ? 
no it ' s just it it ' s it ' s not at all uncommon for for recorded electronics to have different um d c offsets . 
or just 
huh . 
it ' s it ' s you know no big deal . 
it ' s you know you could have ten twenty maybe thirty millivolts whatever . 
and it ' s consistently in there . 
the thing is most people ' s front ends have pre emphasis with it with zero at zero frequency . 
so that it ' s irrelevant . 
uh but with p l p we didn ' t actually have that . 
we had we had the equivalent of pre emphasis in a a uh fletcher munson style weighting that occurs in the middle of p l p . 
but it doesn ' t actually have a zero at zero frequency . 
huh . 
like uh uh typical simple pre emphasis does . 
we had something more fancy . 
it was later on . 
it didn ' t have that . 
so at that point i oh we better have a have a high pass filter . 
just you know just take care of the problem . 
so i put in a high pass filter at uh i think ninety ninety hertz or so uh for a sixteen kilohertz sampling rate . 
and i never put anything in to adjust it for different different sampling rates . 
and so well so you know the code doesn ' t know anything about that . 
and so this is all at eight kilohertz . 
and so it was at forty five hertz instead of at instead of at ninety . 
huh . 
so um 
i don ' t know if dan fixed it or or uh what he 
well he made it a parameter . 
he made it a parameter . 
so yeah i guess if he did it right he did fix it . 
and then and then it ' s taking care of sampling rate . 
which is great . 
what what is the parameter ? 
he had a 
is it uh just the lower cut off that you want ? 
it ' s called uh h h . p . f . 
h 
yeah does h . p . f . on on his feature . 
and but h . p . f . you know when you put a number after it uses that as the hertz value of the cut off . 
uhhuh . 
yeah . 
oh okay . 
so 
i mean frankly we never did that with the rasta filter either . 
so the rasta filter is actually doing a different thing in the modulation spectral domain depending on what sampling rate you ' re doing . 
uhhuh . 
which is another old old bug of mine . 
uhhuh . 
but um 
um so that that was the problem there was we we we had always intended to cut off below a hundred hertz . 
uhhuh . 
and it just wasn ' t doing it . 
so now it is . 
so that that helped us by like eight tenths of a percent . 
it still wasn ' t a big deal . 
okay . 
well but um well uh again after completing the current experiments we ' ll we can add up all the uh differences . 
oh yeah . 
but but i guess my my point was that that um the hybrid system thing that we did was uh primitive in many ways . 
and and 
right . 
and i think i agree with you that if we fixed lots of different things and they would all add up we would probably have a a a competitive system . 
but i think not that much of it is due to the front end per se . 
i think maybe a couple percent of it is as far as i can see from this . 
uhhuh . 
uh unless you call well if you call v t l the front en front end that ' s uh a little more . 
but that ' s sort of more both kind of . 
one experiment we should we ' ll probably need to do though when um at some point is since we ' re using that same the net that was trained on p l p without all these things in it for the tandem system we may want to go back and retrain . 
right . 
but 
well that ' s what i meant in fact yeah . 
yeah yeah . 
for the tandem you know . 
so we can see if it what effect it has on the tandem processing . 
so so the thing is is do we expect 
uhhuh . 
uh at this point i ' m i mean you know i ' m wondering is it can we expect uh a tandem system to do better than a properly trained you know a gaussian system trained directly on the features with you know the right choice of parameters ? 
well that ' s what we ' re seeing in other areas yes . 
right ? 
so it ' s so 
um um 
so we but but we may not i mean if it doesn ' t perform as well we may not know why . 
right ? 
because we need to do the exact experiment . 
right . 
i mean the reason to think it should is because you ' re putting in the same information and you ' re transforming it to be more discriminative . 
so um 
now the thing is in some databases i wouldn ' t expect it to necessarily give you much . 
and and part of what i view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do . 
not just the standard front end . 
but other things like with multiple streams and so forth . 
uhhuh . 
and allows you to feed them to the other system with this through this funnel . 
um so i think i think that ' s the real power of it . 
i wouldn ' t expect huge huge improvements . 
um but it should at least be roughly the same and maybe a little better . 
uhhuh . 
if it ' s you know like way way worse then you know 
right . 
so morgan another thing that andreas and i were talking about was 
so in the first experiment that he did we just took the whole fifty six uh outputs . 
and that ' s um basically compared to a thirty nine input feature vector from either m f c c or p l p . 
uhhuh . 
uhhuh . 
but one thing we could do is 
let let let me just ask you something . 
when you say take the fifty six outputs these are the final nonlinearity outputs ? 
yeah through the regular tandem outputs . 
and they ' re and 
through the k l t ? 
through the k l t . 
okay . 
all that kind of stuff . 
and so so then you do you use all fifty six of the k l t ? 
or 
that ' s what we did . 
right ? 
okay . 
so one thing we were wondering is if we did principal components and say took out just thirteen and then did deltas and double deltas on that 
yes . 
yes . 
so we treated the first thirteen as though they were standard features . 
yeah . 
i mean did dan do experiments like that to 
uh talk with stephane . 
he did some things like that . 
it was either him or carmen . 
i forget . 
huh . 
uhhuh . 
i mean these were all different databases and different you know in h t k and all that . 
yeah . 
so it it may not apply . 
but my recollection of it was that it didn ' t make it better but it didn ' t make it worse . 
huh . 
but again given all these differences maybe it ' s more important in your case that you not take a lot of these low variance uh components . 
because in a sense the net ' s already got quite a bit of context in those features . 
yeah . 
so if we did deltas and double deltas on top of those we ' re getting sort of even more . 
which could be good or not . 
yeah . 
yeah . 
yeah worth trying . 
but there the main point is that um you know it took us a while but we have the procedure for coupling the two systems debugged now . 
and i mean there ' s still conceivably some bug somewhere in the way we ' re feeding the tandem features . 
uh either generating them or feeding them to this to the s r i system . 
uhhuh . 
yeah . 
but 
there might be . 
it ' s 
because that ' s a pretty big difference . 
yeah . 
but 
and i ' m wondering how we can how we can debug that . 
yeah . 
i mean how 
um 
huh . 
i ' m actually quite sure that the feeding the features into the system and training it up . 
what if 
that that i think that ' s this that ' s essentially the same as we use with the with the p l p features . 
and that ' s obviously working great . 
so um 
yeah there could be a bug in in the somewhere before that . 
there we could 
the another degree of freedom is how do you generate the k l t transform ? 
uhhuh . 
that ' s 
right ? 
we 
right . 
well and another one is the normalization of the inputs to the net . 
yeah . 
these nets are trained with particular normalization . 
and when that gets screwed up it it can really hurt it . 
i ' m doing what eric 
eric coached me through then that part of it . 
so i ' m pretty confident in that . 
okay . 
i mean the only slight difference is that i use normalization values that um andreas calculated . 
from the original p l p . 
right . 
which is right . 
yeah . 
right . 
so i i do 
oh we actually don ' t do that normalization for the p l p . 
do we ? 
for the just the straight p l p features . 
no the the s r i system does it . 
s r i system does that right . 
yeah . 
right . 
well you might 
so that ' s that ' s another 
so there ' s there is there is room for bugs that we might not have discovered . 
yeah . 
yeah . 
uhhuh . 
yeah i i would actually double check with stephane at this point . 
but 
because he ' s probably the one here 
i mean he and dan are the ones who are at this point most experienced with the tandem . 
uhhuh . 
thing and there may there may be some little bit here and there that is not not being handled right . 
yeah it ' s hard with features . 
because you don ' t know what they should look like . 
i mean you can ' t just like print the the values out in ascii and you know look at them see if they ' re 
not unless you had a lot of time . 
well 
and 
uh and also they ' re not i mean as i understand it you you don ' t have a way to optimize the features for the final word error . 
right ? 
right . 
i mean these are just discriminative . 
but they ' re not um optimized for the final 
they ' re optimized for phone discrimination . 
right so it there ' s always this question of whether you might do better with those features if there was a way to train it for the word error metric that you ' re actually that you ' re actually 
not for 
that ' s right . 
well the other 
yeah the 
huh 
well you actually are . 
but but it but in an indirect way . 
well right it ' s indirect so you don ' t know 
so what and you may not be in this case . 
come to think of it . 
because uh you ' re just taking something that ' s trained up elsewhere . 
so what what you what you do in the full procedure is you um uh have an embedded training . 
so in fact you the the net is trained on uh uh a uh viterbi alignment of the training data that comes from your full system . 
and so that ' s where the feedback comes all around so that it is actually discriminant . 
you can prove that it ' s it ' s a 
uh 
if you believe in the viterbi assumption that uh getting the best path uh is almost equivalent to getting the best uh total probability um then you actually do improve that by uh by training up on local local uh local frames . 
but um we aren ' t actually doing that here . 
because we did we did that for a hybrid system . 
and now we ' re plugging it into another system . 
and so it isn ' t it wouldn ' t quite apply here . 
so another huge experiment we could do would be to take the tandem features uh do s r i forced alignments using those features and then re do the net with those . 
do 
uhhuh . 
huh uh exactly exactly . 
yeah . 
so that you can optimize it for the word error . 
yeah another thing is since you ' re not using the net for recognition per se but just for this transformation it ' s probably bigger than it needs to be . 
but 
yeah . 
so that would save a lot of time . 
and there ' s a mismatch in the phone sets . 
huh . 
so you ' re using a a a larger phone set than what 
yeah actually all those things could could could could uh could affect it as well . 
yeah yeah . 
the other thing uh just to mention that stephane this was an innovation of stephane ' s which was a pretty neat one . 
uh and might particularly apply here given all these things we ' re mentioning . 
um stephane ' s idea was that um discriminant uh approaches are great . 
even the local ones given you know these potential outer loops which you know you can convince yourself turn into the global ones . 
um however there ' s times when it is not good . 
uh when something about the test set is different enough from the training set that that uh the discrimination that you ' re learning is is is not a good one . 
uhhuh . 
so uh his idea was to take as the input feature vector to the uh gaussian mixture system uh a concatenation of the neural net outputs and the regular features . 
oh we already talked about that . 
yeah that 
yeah . 
uhhuh . 
didn ' t you did you do that already ? 
yeah . 
or 
no but we we when when we when i first started corresponding with dan about how to go about this i think that was one of the things that we definitely went there . 
oh that makes a lot of sense . 
huh . 
yeah . 
yeah i mean i ' m sure that stephane wasn ' t the first to think of it . 
yeah . 
but actually stephane did it . 
and and and it helped a lot . 
uhhuh and does it help ? 
yeah . 
oh okay . 
so that ' s that that ' s our current best best system in the uh uh in the aurora thing . 
oh okay . 
yeah that makes sense . 
yeah . 
and do you do a k l t transform on the on the combined feature vector ? 
as you should never do worse . 
i i uh missed what you said . 
do you you do a k l t transform on the combined feature vector ? 
yeah . 
okay . 
well actually i uh you should check with him . 
because he tried several different combinations . 
because you end up with this huge feature vector so that might be a problem unless you do some form of dimensionality reduction . 
yeah i uh 
what i don ' t remember is which came out best . 
so he did one where he put put the whole thing into one k l t . 
and another one since the the p l p things are already orthogonalized he left them alone and and just did a k l t on the on the on the net outputs . 
uhhuh . 
and then concatenated that . 
huh . 
and i don ' t remember which was better . 
did he did he try to 
so he always ended up with a feature vector that was twice as long as either one of the 
no i don ' t know i i don ' t know . 
you have to check with him . 
yeah . 
okay actually i have to run . 
i ' m into big ideas these days . 
yeah . 
uh 
we need to close up . 
because i need to save the data and um get a call . 
not to mention the fact that we ' re missing snacks . 
yeah . 
right . 
did people want to do the digits ? 
uh 
or um do them together ? 
um 
i i i think given that we ' re in a hurry for snacks maybe we should do them together . 
i don ' t know . 
should we just 
okay . 
i mean are we trying to do them in synchrony ? 
that might be fun . 
adam ' s not here so he ' s not here to tell me no . 
well it ' s it ' s it ' s not you know it ' s not going to work out . 
but we could we could just uh uh see if we find a rhythm . 
you know . 
sure . 
what 
uh o s or zeroes ? 
we want to agree on that ? 
maybe just whatever people would naturally do . 
i don ' t know . 
oh but if we were a singing group we would want to decide . 
right ? 
be harmony . 
yeah yeah . 
mine ' s identical to yours . 
we might 
is that correct ? 
sorry so i set up . 
and we didn ' t have enough digit forms . 
oh i see . 
so i xeroxed the same one seven times . 
so these are excellent . 
oh i see . 
why don ' t we do 
anyone have a problem with saying zero ? 
no . 
is zero okay ? 
yeah . 
okay . 
one and a two and three . 
okay let ' s be done with this . 
okay . 
okay . 
this is ami who 
and this is tilman and ralf . 
hi . 
uhhuh nice to meet you . 
hi . 
hi . 
okay . 
so we ' re going to try to finish by five so people who want to can go hear nancy chang ' s talk uh downstairs . 
huh . 
and you guys are giving talks on tomorrow and wednesday lunch times . 
yes . 
huh . 
right ? 
that ' s great . 
okay so do do you know what we ' re going to do ? 
i thought two things . 
uh we ' ll introduce ourselves and what we do . 
and um we already talked with andreas thilo and david . 
and some lines of code were already written today . 
and almost tested . 
and just going to say we have um again the recognizer to parser thing where we ' re working on . 
and that should be no problem . 
and then that can be sort of developed uh as needed when we get enter the tourism domain . 
them we have talked this morning with the with tilman about the generator . 
and um there one of our diligent workers has to sort of volunteer to look over tilman ' s shoulder while he is changing the grammars to english . 
uhhuh . 
because we have we face two ways . 
either we do a syllable concatenating um grammar for the english generation which is sort of starting from scratch and doing it the easy way . 
or we simply adopt the uh um more in depth um style that is implemented in the german system . 
and um are then able not only to produce strings but also the syntactic parse . 
uh not parse not 
the syntactic tree that is underneath in the syntactic structure . 
which is the way we decided we were going to go because a it ' s easier in the beginning . 
uhhuh . 
and um it does require some some knowledge of of those grammars and and and some linguistic background . 
but um it shouldn ' t be a problem for anyone . 
okay so that sounds good . 
johno are you going to have some time to do that uh with these guys ? 
sure . 
because you ' re the grammar maven . 
okay . 
i mean it makes sense . 
doesn ' t it ? 
yeah . 
yeah good . 
okay . 
so i think that ' s probably the the right way to do that . 
and 
yeah so i i actually want to to find out about it too . 
but i may not have time to get in . 
the the ultimate goal is that before they leave we we can run through the entire system input through output on at least one or two sample things . 
and um and by virtue of doing that then in this case johno will have acquired the knowledge of how to extend it . 
ad infinitum . 
when needed if needed when wanted and so forth . 
okay that sounds great . 
and um also um ralf has hooked up with david and you ' re going to continue either all through tonight or tomorrow on whatever to get the uh parser interface working . 
huh . 
they are thinning out and thickening out lattices . 
and doing this kind of stuff to see what works best . 
huh . 
yep . 
great . 
so you guys enjoy your weekend ? 
yes very much so . 
yeah very much . 
okay before before you got put to work ? 
yeah . 
great . 
okay so that ' s 
sort of one branch is to get us caught up on what ' s going on . 
also of course it would be really nice to know what the plans are in addition to what ' s sort of already in code . 
yes . 
and we can 
i don ' t know . 
was there uh a time when we were set up to do that ? 
it probably will work better if we do it later in the week after we actually understand uh better what ' s going on . 
yes . 
huh . 
yeah . 
so when do you guys leave ? 
um we ' re here through sunday . 
oh . 
so 
oh okay . 
all through friday would be fine . 
so 
okay so 
so we ' ll find a time later in the week to uh get together and talk about your understanding of what smartkom plans are . 
uhhuh . 
and how we can change them . 
yes sure . 
uh 
should we already set a date for that ? 
might be beneficial while we ' re all here . 
okay . 
um what what does not work for me is thursday afternoon . 
i can do earlier in the day on thursday or um most of the time on friday . 
not all . 
thursday morning sounds fine ? 
but johno ? 
uhhuh . 
what are your constraints ? 
um thursday afternoon doesn ' t work for me but 
neither does thursday morning ? 
no ? 
uh thursday morning should be fine . 
eleven ? 
okay . 
eleven on thursday ? 
i was just thinking i i will have leavened by eleven . 
right right . 
this is then out of deference to our non morning people . 
uhhuh . 
okay . 
so at eleven ? 
huh ? 
thursday around eleven ? 
okay . 
yeah . 
and actually we can invite um andreas as well . 
uh he will be in washington though . 
oh that ' s true . 
he ' s off off on his trip already . 
but um david is here and he ' s actually knows everything about the smartkom recognizer . 
thilo . 
okay well yeah . 
maybe we ' ll see if david could make it . 
that would be good . 
okay so 
facing to to what we ' ve sort of been doing here 
um 
well for one thing we ' re also using this room to collect data . 
yeah obviously . 
um um not this type of data . 
no not meeting data but sort of sort uh our version of a wizard experiment such 
oh okay . 
not like the ones in munich but pretty close to it . 
uhhuh . 
the major difference to the munich ones is that we do it via the telephone . 
okay . 
even though all the recording is done here . 
and so it ' s a sort of a computer call system that gives you tourist information . 
uhhuh . 
tells you how to get places . 
and it breaks halfway through the experiment and a human operator comes on . 
and part of that is sort of trying to find out whether people change their linguistic verbal behavior when first thinking they speak to a machine and then to a human . 
yeah . 
and we ' re setting it up so that we can we hope to implant certain intentions in people . 
for example um we have first looked at a simple sentence that how do i get to the powder tower . 
okay so you have the castle of heidelberg . 
okay . 
and there is a tower and it ' s called powder tower . 
oh okay . 
yeah . 
and um so what will you parse out of that sentence ? 
probably something that we specified in m three l . 
huh . 
that is action go to whatever domain object whatever powder tower . 
and maybe some model will tell us some g p s module in the mobile scenario where the person is at the moment . 
and um we ' ve sort of gone through that once before in the deep mail project . 
and we noticed that first of all what are 
i should ' ve brought some slides . 
but what our 
so here ' s the tower . 
think of this as a two dimensional representation of the tower . 
and our system led people here to a point where they were facing a wall in front of the tower . 
there is no entrance there but it just happens to be the closest point of the road network to the geometric center . 
because that ' s how the algorithm works . 
so we took out that part of the road network as a hack . 
and then it found actually the way to the entrance . 
which was now the closest point of the road network to 
yeah . 
okay geometric center . 
but what we actually observed in heidelberg is that most people when they want to go there they actually don ' t want to enter . 
because it ' s not really interesting . 
they want to go to a completely different point where they can look at it and take a picture . 
oh okay . 
huh . 
yeah . 
and so what uh uh a you 
let ' s say a simple parse from a from an utterance won ' t really give us is what the person actually wants . 
does he want to go there to see it ? 
does he want to go there now ? 
later ? 
how does the person want to go there ? 
is that person more likely to want to walk there ? 
walk a scenic route ? 
and so forth . 
there are all kinds of decisions that we have identified in terms of getting to places and in terms of finding information about things . 
and we are constructing and then we ' ve identified more or less the extra linguistic parameters that may play a role . 
information related to the user and information related to the situation . 
and we also want to look closely on the linguistic information that 
what we can get from the utterance . 
that ' s part of why we implant these intentions in the data collection to see whether people actually phrase things differently . 
whether they want to enter in order to buy something or whether they just want to go there to look at it . 
and um so the idea is to construct uh um suitable interfaces and a belief net for a module that actually tries to guess what the underlying intention was . 
and then enrich or augment the m three l structures with what it thought what more it sort of got out of that utterance . 
so if it can make a good suggestion hey . 
you know that person doesn ' t want to enter . 
that person just wants to take a picture because he just bought film . 
or that person wants to enter because he discussed the admission fee before . 
or that person wants to enter because he wants to buy something . 
and that you usually do inside of buildings and so forth . 
these uh these types of uh these bits of additional information are going to be embedded into the m three l structure in an sort of subfield that we have reserved . 
and if the action planner does something with it great . 
if not you know then that ' s also something um that we can ' t really 
at least we want to offer the extra information we don ' t really um we ' re not too worried . 
uhhuh . 
huh . 
i mean ultimately if you have if you can offer that information somebody ' s going to do something with it sooner or later . 
that ' s sort of part of our belief . 
what was he saying ? 
um for example right now i know the g i s from email is not able to calculate these viewpoints . 
so that ' s a functionality that doesn ' t exist yet to do that dynamically . 
uhhuh . 
but if we can offer it that distinction maybe somebody will go ahead and implement it . 
surely nobody ' s going to go ahead and implement it if it ' s never going to be used . 
so 
what have i forgotten about ? 
oh yeah ! 
well uh 
how we do it ? 
yeah that ' s the 
no no . 
it ' s a good time to pause . 
i i see questions on peoples ' faces . 
so why don ' t 
let ' s let ' s let ' s hear . 
oh . 
well the obvious one would be if if you envision this as a module within smartkom where exactly would that sit ? 
um so far i ' ve thought of it as sort of adding it onto the modeler knowledge module . 
that ' s the 
huh . 
okay yeah . 
so this is one that already adds additional information to the 
makes perfect sense . 
yes . 
huh uh . 
but it could sit anywhere in the attention recognition . 
i mean basically this is what attention recognition literally sort of can 
well it ' s supposed to do . 
huh . 
yeah . 
that ' s what it should do . 
right . 
yeah . 
yeah . 
yeah . 
huh . 
yeah . 
well from my understanding of what the people at phillips were originally trying to do doesn ' t seem to quite fit into smartkom currently . 
so what they ' re really doing right now is only selecting among the alternatives the hypotheses that they ' re given enriched by the domain knowledge and the um discourse modeler and so on . 
yeah . 
yeah . 
so if if this is additional information that could be merged in by them . 
and then it would be available to action planning and and others . 
yeah . 
the 
let ' s let ' s 
that 
okay that was one question . 
is there other other things that 
because we want to not pass over any you know questions or concerns that you have . 
well there ' re there ' re two levels of of giving an answer and i guess on both levels i don ' t have any um further questions . 
huh . 
huh . 
uh the the two levels will be as far as i ' m concerned as uh standing here for the generation module . 
huh . 
and the other is is my understanding of what smartkom uh is supposed to be . 
right . 
and i i think that fits in perfectly . 
so well let me let me expand on that a little bit from the point of view of the generation . 
huh . 
yeah . 
so the idea is that we ' ve actually got this all laid out and we could show it to you 
um robert didn ' t bring it today but there ' s a a belief net which is 
there ' s a first cut at a belief net that that doesn ' t it isn ' t fully uh instantiated . 
and in particular some of the the combination rules and ways of getting the the conditional probabilities aren ' t there . 
but we believe that we have laid out the fundamental decisions in this little space . 
uhhuh . 
and the things that influence them . 
so one of the decisions is what we call this a v e thing . 
do you want to um access view or enter a thing ? 
huh . 
so that ' s a discrete decision . 
uhhuh . 
there are only three possibilities and the uh 
what one would like is for this uh knowledge modeling module to add which of those it is and give it to the planner . 
uhhuh . 
but uh the current design suggests that if it seems to be an important decision and if the belief net is equivocal so that it doesn ' t say that one of these is much more probable than the other then an option is to go back and ask for the information you want . 
uhhuh . 
all right ? 
now there are two ways one can go imagine doing that . 
for the debugging we ' ll probably just have a a drop down menu . 
and the while you ' re debugging you will just 
okay . 
but for a full system then one might very well formulate a query . 
give it to the dialogue planner and say this you know are you know you are you planning to enter . 
uhhuh . 
or whatever it whatever that might be . 
so that ' s under that model . 
then there would be a uh um a loop in which this thing would formulate a query . 
yes . 
presumably give it to you . 
that would get expressed and then hopefully you know you ' d get an answer back . 
yep . 
and that would of course the answer would have to be parsed . 
huh . 
right ? 
yep . 
and 
okay so that uh 
yes . 
we probably won ' t do this early on because the current focus is more on the decision making and stuff like that . 
yep . 
but while we ' re on the subject i just wanted to give you a sort of head ' s up that it could be that some months from now we said okay we ' re now ready to try to close that loop in terms of querying about some of these decisions . 
uhhuh . 
uhhuh . 
huh . 
yep . 
so my suggestion then is that you um look into the currently ongoing discussion about how the action plans are supposed to look like . 
and they ' re currently um agreeing or or in the process of agreeing on an x m l ification of um something like a state transition network of how dialogues would proceed . 
and the these um transition networks uh will be what the action planner interprets in a sense . 
huh . 
did you know this robert ? 
uh michael is doing that . 
right ? 
well uh marcus lerkult is actually implementing that stuff . 
and marcus and michael together are um leading the discussion there . 
okay . 
yeah . 
so we we have to get in on that . 
uhhuh . 
yep . 
because um partly those are like x schemas . 
huh . 
definitely . 
the transition diagrams . 
huh . 
and it may be that that um we should early on make sure that they have the flexibility that we need . 
huh . 
but they uh 
have i understood this right ? 
they they govern more or less the the dialogue behavior or the action . 
uhhuh . 
it ' s not really what you do with the content of the dialogue but it ' s 
so i mean there is this this this nice 
uh no . 
it ' s it ' s also a quantrant uh uh 
is it 
so there ' s so there the word action okay is is what ' s ambiguous here . 
i think . 
huh . 
yes . 
so um one thing is there ' s an actual planner that tells the person in the tourist domain now . 
tells the person how to go . 
okay . 
first go here . 
first go there . 
uhhuh . 
uh you know take a bus . 
whatever it is . 
so that ' s that form of planning and action and a route planner and g i s all sort of stuff . 
uh but i think that isn ' t what you mean . 
no . 
no in smartkom terminology that ' s um called a function that ' s modeled by a function modeler . 
and it ' s that ' s completely um encapsulated from the dialogue system . 
that ' s simply a functionality that you give data as in a query . 
and then you get back from that huh a functioning model um which might be a planner or a v c r or whatever . 
um some result and that ' s then then used . 
well okay . 
so that ' s what i thought . 
so action action here means uh speech uh you know dialogue act . 
yeah yeah . 
huh . 
yeah in that in that sense . 
yes . 
yeah . 
dialogue act . 
yeah . 
um i think i think it ' s not going to i think that ' s not going to be good enough . 
i i what uh what i meant by that . 
so i think the idea of having a you know transition diagram for the grammar of conversations is a good idea . 
uhhuh . 
okay . 
and i think that we do definitely have to get in on it and find out okay . 
but i think that um 
when so when you get to the tourist domain it ' s not just an information retrieval system . 
uhhuh . 
right ? 
clearly . 
so this this is where i think this 
yes . 
people are going to have to think this through a bit more carefully . 
uhhuh . 
so if it ' s only like in in the in the film and t v thing 
okay you can do this . 
and you just get information and give it to people . 
but what happens when you actually get them moving and so forth and so on 
yep . 
uh your i i think the notion of this as a self contained uh module . 
you know the functional module that that interacts with with where the tourism stuff is going probably is too restrictive . 
yep . 
now i don ' t know how much people have thought ahead to the tourist domain in this . 
probably not enough . 
i mean an another uh more basic point there is that the current um tasks and therefore the concepts in this ac 
what ' s called the action plan and what ' s really the dialogue manager . 
yeah . 
um is based on slots that have to be filled . 
and the um kind of values in these slots would be fixed things like the a time or a movie title or something like this . 
uhhuh . 
right . 
whereas in the a um tourist domain it might be an entire route . 
indeed . 
set based or even very complex structured information in these slots . 
right . 
and i ' m not sure if if complex slots of that type are really um being taken into consideration . 
okay . 
could you could you put a message into the right place to see if we can at least ask that question ? 
so that ' s that ' s really something we 
yep . 
uhhuh . 
i mean nothing ' s being completely settled there . 
yep . 
so this is really an ongoing discussion . 
uhhuh . 
yeah and um it might actually 
and that ' s 
okay . 
uh also because um again in deep map we have faced and implemented those problems once already . 
maybe we can even shuffle some know how from there to to markus and michael . 
uhhuh . 
yes . 
huh . 
yep . 
and um huh you don ' t know 
okay 
i ' ll i ' ll talk to michael . 
it ' s what i do anyway . 
who how far is the uh the the m three l specification for for the natural language input gone on the the uh 
i haven ' t seen anything for the uh tourist path domain . 
yeah it ' s it ' s not defined yet . 
and um you are probably also involved in that . 
um yeah . 
right ? 
uh together with the usual gang . 
um petra and jan . 
yeah there ' s a meeting next next week i think . 
okay because that ' s those are the 
i think the the true key issues is how does the whatever comes out of the language input pipeline look like ? 
and then what the action planner does with it ? 
and how that is uh specified ? 
i didn ' t think of the internal working of the uh the action planner and the language uh the function model as sort of relevant . 
because what what they take is sort of this this fixed representation of a of an intention . 
and that can be as detailed or as crude as you want it to be . 
uhhuh . 
but um the internal workings of of the 
whether you know there ' re dialogue action planners that work with belief nets that are action planners that work with you know state automata . 
so that shouldn ' t really matter too much . 
i mean it does matter . 
because it does have to keep track of you 
we are on part six of a route that consists of eight steps and so forth . 
yeah there there i think there are a lot of reasons why it matters . 
right . 
okay ? 
so that 
uh 
for example the it ' s the action planner is going to take some spec and make some suggestions about what the user should do . 
what the user says after that is going to be very much caught up with what the action planner told it . 
yes . 
if the if the parser and the language end doesn ' t know what the person ' s been told 
okay . 
it ' s you ' re making your life much more difficult than it has to be . 
yeah . 
right ? 
so if someone says the best to uh go there is by taxi . 
let ' s say . 
now the planner comes out and says you want to get there fast . 
take a taxi . 
okay . 
and the language end doesn ' t know that . 
okay there ' s all sorts of dialogues that won ' t make any sense which would be just fine . 
huh 
uh 
yeah . 
that would 
but that i think that that uh point has been realized . 
and it ' s it ' s not really um been defined yet . 
but there ' s going to be some kind of feedback and input from uh the action planner into all the analysis modules telling them what to expect and what the current state of the discourse is . 
huh . 
beyond what ' s currently being implemented which is just word lists . 
yeah but this is not the this is not just the state of the discourse . 
uhhuh . 
of of special interest . 
this is actually the state of the plan . 
that ' s why 
uhhuh . 
yes yes uhhuh yeah . 
okay so it 
and 
uh it ' s great if people are already taking that into account . 
but one would have have to see see the details . 
the specifics aren ' t really there yet . 
yes . 
yeah . 
so there ' s work to do there . 
so anyway robert that ' s why i was thinking that . 
uhhuh . 
um 
i think you ' re going to need 
we talked about this several times that that the the input end is going to need a fair amount of feedback from the planning end . 
huh . 
in in one of these things which are are much more continuous than the just the dialogue over movies and stuff . 
yeah . 
huh . 
and even on on a more basic level the the action planner actually needs to be able to have um an expressive power that can deal with these structures . 
huh ? 
and not just um say um um the dialogue um will consist of ten possible states and these states really are fixed in in a certain sense . 
would there be any chance of getting the terminology changed so that the dialogue planner was called a dialogue planner ? 
you have to 
because there ' s this other thing the there ' s this other thing in in the tourist domain which is going to be a route planner . 
that ' d be nice . 
or it ' s really going to be an action planner . 
and it 
it ought to be called a a dialogue manager . 
because that ' s what everybody else calls it . 
i would think . 
yeah . 
huh . 
huh ? 
yeah . 
so so what would happen if we sent a note saying gee we ' ve talked about this and couldn ' t we change this uh the whole word ? 
i have no idea how complicated these things are . 
probably close to impossible . 
depends on who you talk to how . 
we ' ll see . 
i ' ll go check . 
cause i completely agree . 
huh . 
yeah . 
and i think this is just for historical reasons within uh the preparation phase of the project . 
and not because somebody actually believes it ought to be action planner . 
so if there is resistance against changing it that ' s just because oh we don ' t want to change things . 
that that not deep reason 
okay . 
anyway 
if if that persists then we ' re going to need another term for the thing that actually does the planning of the uh routes and whatever we are doing for the tourist . 
that ' s external services . 
yeah but that ' s not uh 
that has all the wrong connotations . 
it ' s it sounds like it ' s you know stand alone . 
it doesn ' t interact . 
it doesn ' t 
that ' s why i ' m saying . 
i think you can ' t 
it ' s fine for looking up when you know when the show ' s on t v . 
you go to 
but i i i i think it ' s really really wrong headed for something that you that has a lot of state . 
it ' s going to interact in a complicated way with the uh understanding parts . 
yeah . 
yeah i think just the the spatial planner and the route planner . 
i showed you once the action between them among them in the deep map system . 
right . 
so a printout of the communication between those two fills up . 
i don ' t know how many pages . 
and that ' s just part of how do i get to one place . 
huh . 
it ' s really insane . 
and uh 
but um so this is um definitely a good point to get uh michael into the discussion . 
or to enter his discussion actually . 
that ' s the way around . 
yeah marcus 
markus . 
is he new in the in the 
where ' s 
yeah he ' s he started um i think january . 
yeah . 
and he ' s going to be responsible for the implementation of this action planner . 
dialogue manager . 
is he going to continue with the old uh thing ? 
no . 
no he ' s completely going to rewrite everything in java . 
okay . 
okay so that ' s interesting . 
yes i was just that ' s my next question . 
huh . 
whether we ' re we ' re going to stick to prolog or not . 
no . 
no that ' s going to be phased out . 
yeah . 
okay . 
but i do think the the function modeling concept has a certain makes sense in a in a certain light . 
yeah . 
because the action planner should not be or the dialogue manager in that case should not um have to worry about whether it ' s interfacing with um something that does route planning in this way or that way . 
uhhuh . 
i totally agree . 
sure . 
huh ? 
it 
yeah i i agree . 
there is there ' s a logic to dialogue which which is is separable . 
yeah . 
and it cant sort of formulate its what it wants in a in a rather abstract uh way . 
you know find me a good route for this . 
uhhuh . 
it doesn ' t really have to worry how route planner a or how route planner b actually wants it . 
so this is seemed like a good idea . 
in the beginning . 
it ' s tricky . 
it ' s tricky because one could well imagine 
i think it will turn out to be the case that uh this thing we ' re talking about the extended uh knowledge modeler will fill in some parameters about what the person wants . 
one could well imagine that the next thing that ' s trying to fill out the detailed uh route planning let ' s say will also have questions that it would like to ask the user . 
you could well imagine you get to a point where it ' s got a a choice to make and it just doesn ' t know something . 
and so you would like it also be able to uh formulate a query . 
uhhuh . 
and to run that back through uh the dialogue manager and to the output module and back around . 
huh . 
and a good design would would allow that to happen . 
a lot of 
yeah . 
huh . 
if if you know if if you can ' t make it happen then you you do your best . 
yeah . 
but that doesn ' t necessarily contradict um an architecture where there really is a a well defined interface . 
i totally agree . 
and and 
but but what it 
but what the point is 
in that case the dialogue manager is sort of event driven . 
so the dialogue manager may think it ' s in a dialogue state of one sort . 
and this one of these planning modules comes along and says hey right now we need to ask a question . 
uhhuh . 
so that forces the dialogue manager to change state . 
yes . 
okay . 
it could be 
sure . 
yeah i i think that ' s that ' s the um concept that people have . 
yeah yeah it it 
okay . 
yep . 
and and the the underlying idea of course is that there is something like kernel modules with kernel functionality that you can plug uh certain applications like tourist information or um the home scenario with uh controlling a v c r and so on . 
and then extend it to an arbitrary number of applications eventually . 
so wouldn ' t 
that ' s an additional reason to have this well defined interface . 
oh yeah yeah . 
and keep these things like uh tourist information external . 
and then call it external services . 
huh . 
but of course the the more complex 
yeah there is another philosophical issue that i think you know you can evade . 
yep . 
but at least it makes sense to me that sooner or later uh a service is going to come and describe itself to you . 
and that ' s sort of what srini is working on in in in the daml uh project where um you you find a g i s about that gives you information on berkeley . 
yeah . 
and it ' s it ' s going to be there and tell you what it can do and how it wants to do things . 
and so you can actually interface to such a system without ever having met it before . 
and the function modeler and a self description of the um external service haggle it out . 
huh . 
and you can use the same language core understanding core to interface with planner a planner b planner c and so forth . 
huh . 
huh . 
which is you know uh uh utopian 
completely utopian at the moment . 
but slowly you know getting into the realm of the uh contingent . 
huh . 
but we are facing of course much more um realistic problems . 
and language input for example is of course uh crucial you know also when you do the sort of deep understanding analysis that we envision . 
um then of course the uh um you know 
what is it ? 
poverty of the stimulus . 
yet the uh the less we get of that the better . 
and um so we we ' re thinking for example how much syntactic analysis actually happens already in the parser ? 
huh . 
and whether one could interface to that potentially . 
yeah . 
are there currently is uh 
no syntactic analysis . 
but in the next release there will be some . 
huh . 
how ' s it 
unless 
and it ' s 
um uh 
you can access this 
so uh we we looked at the current pattern matching thing . 
huh . 
and as you say it ' s just a surface pattern matcher . 
uh so what are what are the plans roughly ? 
um it ' s to to integrate and syntactic analysis . 
and um add some more features like segmentation . 
so then an more than one utterance is there um there ' s often uh pause between it . 
and a segmentation occurs . 
so the um 
um 
so the idea is to uh have a a particular 
yeah . 
do you have a particular parser in mind ? 
is it uh 
i mean have you thought through 
is it an h p s g parser ? 
is it a whatever ? 
no no it ' s uh i think it ' s it ' s totally complicated for 
it ' s just one one person . 
okay . 
and so i have to keep the 
oh you have to do it . 
you have to do it . 
yeah . 
yeah . 
uh and so things must be simpler . 
i see . 
so 
but uh miel syntactic analysis with um finite state transducers . 
but the people at d f 
yeah . 
people at d f k i have written a fair number of parsers . 
other you know people over the years uh have written various parsers at d f k i . 
none of them are suitable ? 
i i i i ' m asking . 
i don ' t know . 
yeah uh the problem is that it has to be very fast . 
because um if you want to for more than one path anywhere 
okay . 
what ' s in the latches from the speech recognizer ? 
uhhuh . 
so it ' s speed is crucial . 
uh 
and they are not fast enough . 
uhhuh . 
and they also have to be very robust because of um speech recognition errors . 
and 
okay . 
so um so there was a chunk parser in verbmobil that was one of the uh branchers . 
you know they i 
there were these various uh competing uh syntax modules . 
and i know one of them was a chunk parser . 
and i don ' t remember who did that . 
i think it ' s that 
alan ? 
might 
at tubingen i thought . 
yeah i i don ' t remember . 
was do you know something about that ? 
tubingen was at least involved in putting the chunks together . 
in at 
i can ' t quite recall whether they actually produced the chunks in the first place . 
oh . 
uh i see . 
yeah that ' s right . 
or 
there 
oh from from stuttgart . 
that ' s right . 
they they had there were this was done with a two phase thing where the chunk parser itself was pretty stupid . 
yeah also 
and then there was a kind of trying to fit them together that used more context . 
right . 
yeah . 
right . 
well you and and especially you did some some . 
um um 
was a learning based approach which learned from a big corpus of of trees . 
right . 
uhhuh . 
right . 
and yes the it the chunk parser was a finite state machine that um mark light originally worked on in while he was in tubingen . 
and then somebody else in tubingen picked that up so it was done in tubingen . 
yeah . 
definitely . 
but is that the kind of thing 
it sounds like the kind of thing that you were thinking of . 
yeah . 
yeah i guess it ' s similar . 
yeah . 
that ' s in this direction . 
yes . 
what ? 
yeah it ' s in in this direction . 
huh . 
the 
from michael strube i ' ve heard very good stuff about the chunk parser that is done by forwiss . 
uh which is in embassy doing the parsing . 
uhhuh . 
so this is sort of came as a surprise to me that you know embassy is featuring a nice parser . 
but it ' s what i hear one could also look at that and see whether there is some synergy possible . 
uhhuh yeah . 
it would be very interesting . 
uhhuh . 
huh yeah . 
and they ' re doing chunk parsing . 
and it ' s uh 
i i can give you the names of the people who do it there . 
but um 
then there is of course more ways of parsing things . 
of course . 
but but uh given the constraints that you want it to be small and fast and so forth my guess is you ' re probably into some kind of chunk parsing . 
and uh i ' m not a big believer in this um statistical you know cleaning up . 
uh 
it that seems to me kind of a last resort if uh you can ' t do it any other way . 
uh 
but i don ' t know . 
it may may be that ' s what you guys finally decide do . 
huh . 
uh 
and have you looked 
uh just again for context 
uhhuh . 
there is this this one that they did at s r i some years ago . 
fastus ? 
um 
a 
yeah i ' ve i ' ve looked at it . 
but but it ' s no not much uh information available . 
uh . 
i found 
but it ' s also finite state transducers i thought . 
it is . 
yeah . 
i mean it ' s it was pretty ambitious . 
and 
and of course it was english oriented . 
um 
yeah and and purely finite state transducers are not so good for german since there ' s um 
right . 
yeah i guess that ' s the point is is all the morphology and stuff . 
the word order is is uh not fixed . 
and english is all all word order . 
and it makes a lot more sense . 
yeah . 
and 
yeah okay . 
good point . 
so in in in german you ' ve got uh most of this done with 
uhhuh also it ' s uh it ' s um yes uh the um choice between uh this processing and that processing and my template matcher . 
right . 
right . 
so what about 
um 
did 
like morfix ? 
you ' ve got stemmers ? 
or is that something that 
um yeah but it ' s all in the in the lexicon . 
but did you have that ? 
so it ' s 
yeah the information is available . 
okay . 
i see . 
so but 
so you just connect to the lexicon . 
so 
yeah . 
and uh 
at least for german you have all all of the uh the stemming information . 
yeah we can 
oh yeah . 
we have knowledge bases from from verbmobil system we can use . 
yep . 
and so 
right . 
but it it it doesn ' t look like you ' re using it 
i didn ' t see it being used in the current template uh parser . 
i i didn ' t see any uh 
of course we actually only looked at the english . 
it 
did we look at the german ? 
um 
i don ' t remember . 
so 
yeah but but it ' s used for for stem forms . 
well i think i think there ' s some misunderstanding here . 
oh okay . 
it ' s morphix is not used online . 
so the lexicon might be derived by morphix . 
what ? 
but what what ' s happening online is just um um a a retrieval from the lexicon which would give all the stemming information . 
right . 
right . 
huh . 
so it would be a full foreign lexicon . 
and that ' s what you have . 
yeah . 
yep . 
okay . 
what 
uh i didn ' t 
we threw out all the forms . 
huh ? 
we threw out all the forms . 
because you know english . 
well 
oh okay . 
so it yeah i thought i ' d 
uhhuh . 
so in german then you actually do case matching and things like in the in the pattern matcher or not ? 
um not yet but it ' s planned to do that . 
okay . 
because i i didn ' t i didn ' t think i saw it . 
have we looked at the german ? 
yeah . 
oh i 
yeah . 
that ' s getting it from the lexicon is just fine . 
yeah yeah yeah . 
sure . 
oh yes . 
right . 
no problem with that . 
um 
yeah and here ' s the case where the english and the german might really be significantly different . 
in terms of if you ' re trying to build some fast parser and so forth . 
and 
you really might want to do it in a significantly different way . 
i don ' t know . 
so you ' ve you guys have looked at this ? 
also ? 
in terms of you know if you ' re doing this for english as well as german . 
um do you think now that it would be this doing it similarly ? 
um yeah . 
it ' s um i think it ' s um 
yes it ' s it ' s um possible to to do list processing . 
and maybe this is um more adequate for english . 
and in german um set processing is used . 
set . 
maybe yeah 
some extensions uh have to be made for for a english version . 
huh . 
okay . 
interesting . 
not easy . 
well there ' s i ' m sure there ' s going to be more discussion on that after your talk . 
uhhuh . 
right . 
yeah . 
we ' re just going to foreshadow what we saw that 
right . 
and um 
now actually 
um 
are you guys free at five ? 
or do you have to go somewhere at five o ' clock tonight ? 
in ten minutes ? 
uh . 
no . 
uh uh i think we ' re expect 
oder there was an talk ? 
yeah there there ' s the um practice talk . 
uh huh yeah . 
great . 
so you ' re going to that . 
yeah that that ' s what we were planning to do . 
that ' s good because that will uh tell you a fair amount about the form of semantic construction grammar that we ' re using . 
yeah . 
so so i i think that probably as good an introduction as you ' ll get . 
uhhuh . 
uh . 
uh to the form of of uh conceptual grammar that that we have in mind for this . 
huh uh . 
it won ' t talk particularly about how that relates to what uh robert was saying at the beginning . 
but let me give you a very short version of this . 
so we talked about the fact that there ' re going to be a certain number of decisions that you want the knowledge modeler to make that will be then fed to the function module that does uh route planning . 
it ' s called the route planner or something . 
uhhuh . 
so there are these decisions . 
and then one half of this we talked about at little bit is how if you had the right information . 
if you knew something about what was said . 
and about the something about was the agent a tourist or a native or a business person ? 
or uh young or old . 
whatever . 
that information . 
and also about the 
uh what we ' re calling the entity . 
is it a castle ? 
is it a bank ? 
is it a town square ? 
is it a statue ? 
whatever . 
so all that kind of information could be combined into decision networks and give you decisions . 
but the other half of the problem is how would you get that kind of information from the parsed input ? 
so um 
so what you might try to do is just build more templates saying uh 
we ' re trying to build a 
you know build a template that uh somehow would capture the fact that he wants to take a picture . 
huh . 
okay ? 
and and we could you could do this . 
and it ' s a small enough domain that probably you you know 
huh . 
okay . 
you could do this . 
but uh from our point of view this is also a research project . 
and there are a couple of people not here for various reasons who are doing doctoral dissertations on this . 
uhhuh . 
and the idea that we ' re really after is a very deep semantics based on cognitive linguistics . 
and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity . 
so a typical one in this formulation is a container . 
so this is a static thing . 
and the notion is that all sorts of physical situations are characterized in terms of containers . 
going in and out the portals and 
huh . 
okay . 
but also importantly for lakoff and these guys is all sorts of metaphorical things are also characterized this way . 
you get in trouble and you know et cetera . 
huh . 
and so 
so what we ' re really trying to do is to map from the discourse to the conceptual semantics level . 
and from there to the appropriate decisions . 
so another one of these primitive what are called image schemas is uh goal seeking . 
uhhuh . 
so this a notion of a source path goal trajector possibly obstacles . 
uhhuh . 
and the idea is this is another conceptual primitive . 
and that all sorts of things particularly in the tourist domain can be represented in terms of uh source path and goal . 
uhhuh . 
so the idea would be could we build an analyzer that would take an utterance . 
and say aha . 
this utterance is talking about an attempt to reach a goal . 
the goal is this . 
the the uh traveler is that . 
uh 
the where we are at now is is this 
they ' ve mentioned possible obstacles et cetera . 
so the and this is again attempt to get very wide coverage . 
so if you can do this then the notion would be that across a very large range of domains you could use this deep conceptual basis as the interface . 
uhhuh . 
uhhuh . 
and then 
uh 
the processing of that both on the input end recognizing that certain words in a language talk about containers or goals et cetera . 
and on the output end given this kind of information you can then uh make decisions about what actions to take . 
provides they claim a very powerful general notion of deep semantics . 
so that ' s what we ' re really doing . 
uhhuh . 
and 
nancy is going to 
her talk is going to be not about using this in applications but about modeling how children might learn this kind of uh deep semantic grammar . 
uhhuh . 
yep yep . 
and how do you envision um the the um this deep semantic to be worked with ? 
would it be highly ambiguous if 
and then there would be another module that takes that um highly underspecified deep semantic construction ? 
and map it onto the current context to find out what the person really was talking about in that context ? 
well that ' s that ' s that ' s where the belief net comes in . 
or or a 
so the idea is 
let ' s take this business about going to the powder tower . 
uhhuh . 
so part of what you ' ll get out of this will be the fact 
if it works right 
okay that this is an agent that wants to go to this place . 
and that ' s their goal . 
and there will be additional situational information . 
uhhuh . 
oh okay . 
uh okay . 
part of it comes from the ontology . 
the tower is this kind of object . 
uhhuh . 
yeah okay . 
part of it comes from the user model . 
uhhuh . 
and the idea of the belief net is it combines the information from the dialogue which comes across in this general way . 
uhhuh . 
you know this is a this is a goal seeking behavior along with specific information from the ontology about the kinds of objects involved . 
yeah . 
okay . 
yeah . 
yep yep yep yep . 
and about the situation about is it raining . 
i don ' t know . 
whatever it is . 
and so that ' s the belief net that we ' ve laid out . 
uhhuh . 
and so the coupling to the situation comes in this model from at at at the belief net combining evidence from the dialogue with the ontology with the situation . 
yeah . 
huh . 
but nancy isn ' t going to talk about that . 
yeah . 
just about the um 
oh yeah . 
i see . 
yeah yeah really . 
first steps . 
right . 
the the construction grammar . 
and she ' s going to start . 
in a minute . 
in a minute . 
uh okay . 
okay . 
is it in 
then your place in five five a ? 
all right . 
i was saying hynek will be here next week . 
uh wednesday through friday . 
uh through saturday . 
and um 
i won ' t be here thursday and friday . 
but my suggestion is that uh at least for this meeting people should go ahead . 
uh because hynek will be here . 
and 
you know we don ' t have any czech accent yet . 
uh as far as i know . 
so 
okay . 
there we go . 
um 
so other than reading digits what ' s our agenda ? 
i don ' t really have uh anything new . 
been working on meeting recorder stuff . 
so 
okay . 
um 
do you think that would be the case for next week also ? 
or is is uh 
what ' s your projection on 
um 
because the one thing the one thing that seems to me we really should try if you hadn ' t tried it before because it hadn ' t occurred to me . 
it was sort of an obvious thing . 
is um adjusting the uh the scaling and uh insertion penalty sort of stuff . 
i did play with that actually a little bit . 
um what happens is uh when you get to the noisy stuff you start getting lots of insertions . 
right . 
and um 
so i ' ve tried playing around a little bit with um the insertion penalties and things like that . 
yeah . 
um 
i mean it it didn ' t make a whole lot of difference . 
like for the well matched case it seemed like it was pretty good . 
um i could do more playing with that though . 
and uh 
and see . 
but you were looking at mel cepstrum . 
yes . 
right . 
oh you ' re talking about for for our features . 
right . 
so i mean it ' s not the direction that you were working with that we were saying what ' s the uh what ' s the best you can do with with mel cepstrum . 
huh . 
but they raised a very valid point . 
which i guess 
so to first order i mean you have other things you were going to do . 
but to first order i would say that the conclusion is that if you um do uh some monkeying around with uh the exact h t k training and with uh you know how many states and so forth that it it doesn ' t particularly improve the performance . 
in other words that even though it sounds pretty dumb just applying the same number of states to everything more or less no matter what language isn ' t so bad . 
right ? 
and i guess you hadn ' t gotten to all the experiments you wanted to do with number of gaussians . 
right . 
but um 
let ' s just 
if we had to if we had to draw a conclusion on the information we have so far we ' d say something like that . 
right ? 
uhhuh . 
uh so the next question to ask which is i think the one that that that andreas was addressing himself to in the lunch meeting is um we ' re not supposed to adjust the back end . 
but anybody using the system would . 
yeah . 
so 
if you were just adjusting the back end how much better would you do uh in noise ? 
uh because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum . 
uhhuh . 
but um they ' re probably not at all set right for these things . 
particularly these things that look over uh larger time windows in one way or another with with l d a and k l t and neural nets and all these things . 
in the past we ' ve always found that we had to increase the insertion penalty to to correspond to such things . 
so 
i think that ' s uh that ' s kind of a first order thing that that we should try . 
so for 
so the experiment is to um run our front end like normal with the default uh insertion penalties and so forth . 
and then tweak that a little bit . 
and see how much of a difference it makes . 
so by our front end i mean take you know the aurora two take some version that stephane has that is you know our current best version of something . 
if we were 
uhhuh . 
um 
i mean don ' t want to do this over a hundred different things that they ' ve tried . 
but you know for some version that you say is a good one . 
you know ? 
um 
how how much uh does it improve if you actually adjust that ? 
okay . 
but it is interesting . 
you say you you have for the noisy 
how about for the for the mismatched or or or or the or the medium mismatched conditions ? 
have you 
when you adjusted those numbers for mel cepstrum did it 
uh i i don ' t remember off the top of my head . 
um 
yeah i didn ' t even write them down . 
i i i don ' t remember . 
i would need to 
well i did write down 
um 
so when i was doing i just wrote down some numbers for the well matched case . 
yeah . 
um 
looking at the i wrote down what the deletions substitutions and insertions were . 
uh 
for different numbers of states per phone . 
yeah . 
um but uh that that ' s all i wrote down . 
okay . 
so 
i i would 
yeah . 
i would need to do that . 
okay . 
so 
i can do that for next week . 
yeah . 
and um 
yeah . 
also uh uh sometimes if you run behind on some of these things maybe we can get someone else to do it . 
and you can supervise or something . 
but 
but i think it would be it ' d be good to know that . 
okay . 
i just need to get um front end uh stuff from you . 
huh . 
or you point me to some files that you ' ve already calculated . 
yeah . 
all right . 
okay . 
uh 
i probably will have time to do that and time to play a little bit with the silence model . 
uhhuh . 
so maybe i can have that for next week when hynek ' s here . 
yeah . 
uhhuh . 
yeah . 
because i mean the the other 
that in fact might have been part of what uh the difference was . 
at least part of it that that we were seeing . 
remember we were seeing the s r i system was so much better than the tandem system . 
huh . 
part of it might just be that the s r i system they they they always adjust these things to be sort of optimized . 
is there 
and 
i wonder if there ' s anything that we could do to the front end that would affect the insertion . 
yes . 
i think you can . 
what could you do ? 
well um 
uh 
part of what ' s going on um is the uh the range of values . 
so if you have something that has a much smaller range or a much larger range and taking the appropriate root . 
oh ! 
uhhuh . 
you know ? 
if something is kind of like the equivalent of a bunch of probabilities multiplied together you can take a root of some sort . 
if it ' s like seven probabilities together you can take the seventh root of it or something . 
or if it ' s in the log domain divide it by seven . 
uhhuh . 
but 
but 
um 
that has a similar effect . 
because it changes the scale of the numbers of the differences between different candidates from the acoustic model . 
oh . 
right . 
as opposed to what ' s coming from the language model . 
so that 
right . 
so in effect that ' s changing the value of your insertion penalty . 
yeah . 
i mean it ' s more directly like the the language scaling or the uh the model scaling or acoustic scaling . 
that ' s interesting . 
but you know that those things have kind of a similar effect to the insertion penalty . 
uhhuh . 
anyway they ' re a slightly different way of of handling it . 
right . 
so um 
so if we know what the insertion penalty is then we can get an idea about what range our number should be in . 
so that they match with that . 
i think so . 
yeah . 
yeah . 
so that ' s why i think 
that ' s another reason other than curiosity as to why it would in fact be kind of neat to find out if we ' re way off . 
uhhuh . 
i mean the other thing is aren ' t we seeing 
i ' m sure you ' ve already looked at this . 
in these noisy cases are we are seeing lots of insertions . 
right ? 
the insertion number is quite high ? 
i know the v a d takes care of part of that . 
yeah . 
yeah . 
but 
i ' ve seen that with the mel cepstrum . 
yeah . 
i don ' t i don ' t know about the aurora front end . 
but 
i think it ' s much more balanced with uh when the front end is more robust . 
yeah . 
i could look at it at this . 
yeah . 
yeah . 
what ' s a typical number ? 
uhhuh . 
i don ' t i don ' t know . 
do we 
oh you oh you don ' t know . 
okay . 
i don ' t have this in 
i ' m sure it ' s more balanced . 
but it it it wouldn ' t surprise me if there ' s still 
uhhuh . 
i mean in in the the the old systems we used to do i i uh i remember numbers kind of like insertions being half the number of deletions as being and both numbers being tend to be on the small side comparing to to uh substitutions . 
uhhuh . 
uhhuh . 
well this 
the whole problem with insertions was what i think um we talked about when the guy from o g i came down that one time . 
and 
and that was when people were saying well we should have a uh uh voice activity detector . 
right . 
that because all that stuff that we ' re getting the silence that ' s getting through is causing insertions . 
so 
right . 
huh . 
i ' ll bet you there ' s still a lot of insertions . 
uhhuh . 
yeah . 
and it may be less of a critical thing . 
i mean the fact that some get by may be less of a critical thing if you uh get things in the right range . 
uhhuh . 
so i mean the insertions is is a symptom . 
it ' s a symptom that there ' s something uh wrong with the range . 
right . 
but there ' s uh your your your substitutions tend to go up as well . 
so uh i i i think that 
uhhuh . 
uh the most obvious thing is just the insertions . 
but 
uh 
um 
if you ' re operating in the wrong range i mean that ' s why just in general if you change what these these penalties and scaling factors are you reach some point that ' s a that ' s a minimum . 
so 
um 
um 
we do have to do well over a range of different conditions . 
some of which are noisier than others . 
um 
but um i think we may get a better handle on that if we if we see 
um i mean we 
it ' s if we actually could pick a a a more stable value for the range of these features it um uh could 
uh 
even though it ' s it ' s it ' s true that in a real situation you can in fact adjust the these these scaling factors in the back end and it ' s artificial here that we ' re not adjusting those you certainly don ' t want to be adjusting those all the time . 
huh . 
and if you have a nice front end that ' s in roughly the right range . 
i remember after we got our stuff more or less together in the previous systems we built that we tended to set those scaling factors at kind of a standard level . 
and we would rarely adjust them again . 
even though you could get a 
uhhuh . 
for an evaluation you can get an extra point or something if you tweaked it a little bit . 
but 
once we knew what roughly the right operating range was it was pretty stable . 
and uh we might just not even be in the right operating range . 
so would the 
uh would a good idea be to try to map it into the same range that you get in the well matched case ? 
so if we computed what the range was in well matched and then when we get our noisy conditions out we try to make it have the same range as 
no you don ' t want to change it for different conditions . 
no . 
no . 
i i i what what i ' m saying 
oh i wasn ' t suggesting change it for different conditions . 
i was just saying that when we pick a range we we want to pick a range that we map our numbers into . 
we should probably pick it based on the range that we get in the well matched case . 
yeah . 
otherwise i mean what range are we going to choose ? 
to to map everything into . 
well it depends how much we want to do gamesmanship and how much we want to do 
i mean if 
it to me actually even if you want to be play on the gamesmanship side it can be kind of tricky . 
so i mean what you would do is set the set the scaling factors uh so that you got the best number for this point four five times the you know and so on . 
uhhuh . 
but they might change that . 
those weightings . 
yeah . 
um 
so 
uh 
i just sort of think we need to explore the space . 
uhhuh . 
just take a look at it a little bit . 
okay . 
and we we we may just find that that we ' re way off . 
uhhuh . 
maybe we ' re not . 
you know . 
as for these other things it may turn out that uh it ' s kind of reasonable . 
but then 
i mean andreas gave a very reasonable response . 
and he ' s probably not going to be the only one who ' s going to say this in the future . 
of you know 
people people within this tight knit community who are doing this evaluation are accepting uh more or less that these are the rules . 
yeah . 
but people outside of it who look in at the broader picture are certainly going to say well wait a minute you ' re doing all this standing on your head uh on the front end . 
when all you could do is just adjust this in the back end with one one knob . 
uhhuh . 
and 
so we have to at least i think determine that that ' s not true . 
which would be okay . 
or determine that it is true . 
in which case we want to adjust that . 
and then continue with with what we ' re doing . 
right . 
and as you say as you point out finding ways to then compensate for that in the front end also then becomes a priority for this particular test . 
and saying you don ' t have to do that . 
uhhuh . 
so 
okay . 
so uh 
what ' s new with you ? 
uh 
so there ' s nothing new . 
uh what ' s old with you that ' s developed ? 
um . 
i ' m sorry ? 
you 
okay . 
what ' s old with you that has developed over the last week or two ? 
huh . 
well so we ' ve been mainly working on the report . 
and and 
yeah . 
mainly working on what ? 
on the report of the work that was already done . 
oh . 
um 
how about that 
uhhuh . 
that ' s all . 
anything new on the thing that uh you were working on with the uh 
i don ' t have results yet . 
no results . 
yeah . 
what was that ? 
the the 
uh 
voicing thing . 
voicing detector . 
i mean what ' s what ' s going on now ? 
what are you doing ? 
uh to try to found nnn robust feature for detect between voice and unvoice . 
and we we try to use the variance of the difference between the f f t spectrum and mel filter bank spectrum . 
yeah . 
uh also the another parameter is relates with the auto correlation function . 
uhhuh . 
r energy and the variance also of the auto correlation function . 
uhhuh . 
so that ' s 
yeah that ' s what you were describing i guess a week or two ago . 
so 
yeah . 
but we don ' t have we don ' t have result of the for aurora yet . 
uhhuh . 
we need to train the neural network . 
and 
so you ' re training neural networks now ? 
no . 
not yet . 
so what what ' s going on ? 
well we work in the report too . 
because we have a lot of result . 
uhhuh . 
they are very dispersed . 
and was necessary to to look in all the directory to to to give some more structure . 
so so 
yeah . 
if i can summarize basically what ' s going on is that you ' re going over a lot of material that you have generated in furious fashion . 
generating many results and doing many experiments . 
and trying to pull it together into some coherent form to be able to see see what happens . 
huh huh . 
uh 
yeah basically we ' ve stopped uh experimenting . 
yes ? 
i mean we ' re just writing some kind of technical report . 
and 
is this a report that ' s for aurora ? 
or is it just like a tech report for icsi ? 
no . 
or 
yeah . 
for icsi . 
uh . 
i see . 
yeah . 
just summary of the experiment and the conclusion . 
and 
something like that . 
yeah . 
uhhuh . 
okay . 
so my suggestion though is that you you not necessarily finish that . 
but that you put it all together so that it ' s you ' ve got you ' ve got a clearer structure to it . 
you know what things are . 
you have things documented . 
you ' ve looked things up that you needed to look up . 
so that you know so that such a thing can be written . 
uhhuh . 
and um 
when when when do you leave again ? 
uh in july . 
first of july . 
first of july . 
okay . 
and that you figure on actually finishing it in in june . 
because you know you ' re going to have another bunch of results to fit in there anyway . 
uhhuh . 
uhhuh . 
and right now it ' s kind of important that we actually go forward with experiments . 
it ' s not 
so so i i think it ' s good to pause and to gather everything together and make sure it ' s in good shape . 
so that other people can get access to it . 
and so that it can go into a report in june . 
but i think to to really work on on fine tuning the report at this point is is probably bad timing i i think . 
uhhuh . 
yeah . 
well we didn ' t 
we just planned to work on it one week on this report . 
not no more anyway . 
um 
but you you may really want to add other things later anyway . 
yeah . 
uhhuh . 
because you 
huh . 
there ' s more to go ? 
yeah . 
well 
so i don ' t know there are small things that we started to to do . 
but 
are you discovering anything uh that makes you scratch your head as you write this report ? 
like why did we do that . 
or why didn ' t we do this . 
uh 
or 
yeah . 
yeah . 
and 
actually there were some tables that were also with partial results . 
we just noticed that . 
while gathering the result that for some conditions we didn ' t have everything . 
huh . 
but anyway . 
um 
yeah yeah . 
we have yeah extracted actually the noises from the speechdat car . 
and so 
we can train neural network with speech and these noises . 
um 
it ' s difficult to say what it will give . 
because when we look at the aurora the t i digits experiments um they have these three conditions that have different noises . 
and apparently this system perform as well on the seen noises on the unseen noises and on the seen noises . 
but 
i think this is something we have to try anyway . 
so 
adding the noises from from the speechdat car . 
um 
that ' s 
that ' s uh 
that ' s permitted ? 
uh 
well 
o g i does did that . 
um 
at some point they did that for for the voice activity detector . 
uh for a v a d . 
right ? 
um 
could you say it again . 
what what exactly did they do ? 
they used some parts of the um italian database to train the voice activity detector i think . 
it 
yeah i guess the thing is 
yeah . 
i guess that ' s a matter of interpretation . 
the rules as i understand it is that in principle the italian and the spanish and the english 
no . 
italian and the finnish and the english were development data . 
yeah . 
and spanish yeah . 
on which you could adjust things . 
and the and the german and danish were the evaluation data . 
uhhuh . 
and then when they finally actually evaluated things they used everything . 
yeah . 
that ' s right . 
so 
uh 
uh 
and it is true that the performance uh on the german was 
i mean even though the improvement wasn ' t so good the the raw performance was really pretty good . 
uhhuh . 
so 
and uh 
it it doesn ' t appear that there ' s strong evidence that even though things were somewhat tuned on those three or four languages that that going to a different language really hurt you . 
and the noises were not exactly the same . 
right ? 
because it was taken from a different 
uh 
i mean they were different drives . 
different cars . 
i mean it was it was actual different cars and so on . 
yeah . 
yeah . 
so 
um it ' s somewhat tuned . 
it ' s tuned more than you know a a a a 
uhhuh . 
you ' d really like to have something that needed no particular noise at all . 
maybe just some white noise or something like that at most . 
uhhuh . 
but that ' s not really what this contest is . 
so 
um i guess it ' s okay . 
uhhuh . 
i think it ' s 
that ' s something i ' d like to understand before we actually use something from it . 
because it would 
it ' s probably something that huh the you know the uh experiment designers didn ' t really think about . 
because i think most people aren ' t doing trained systems or you know uh systems that are like ours where you actually use the data to build models . 
i mean they just doing signal processing . 
yeah . 
so 
well it ' s true . 
except that uh that ' s what we used in aurora one . 
and then they designed the things for aurora two knowing that we were doing that . 
yeah . 
that ' s true . 
um 
and they didn ' t forbid us . 
right ? 
to build models on the data ? 
no . 
but i think i think that it it 
it probably would be the case that if say we trained on italian uh data and then uh we tested on danish data and it did terribly uh that that it would look bad . 
and i think someone would notice . 
and would say well look this is not generalizing . 
uhhuh . 
i would hope i would hope they would . 
um 
but uh 
it ' s true . 
you know maybe there ' s parameters that other people have used . 
you know that they have tuned in some way for other things . 
so it ' s it ' s uh 
we should we should 
maybe that ' s maybe a topic . 
especially if you talk with him when i ' m not here . 
that ' s a topic you should discuss with hynek . 
to you know double check it ' s okay . 
uhhuh . 
do we know anything about the speakers for each of the uh training utterances ? 
what do you mean ? 
do you have speaker information ? 
we we 
social security number . 
that would be good . 
like we have male female . 
bank pin . 
huh . 
just male female ? 
at least . 
huh . 
what kind of information do you mean ? 
well i was thinking about things like you know gender uh you know gender specific nets and uh vocal tract length normalization . 
uhhuh . 
things like that . 
i i don ' t i didn ' t know what information we have about the speakers that we could try to take advantage of . 
uhhuh . 
huh . 
uh 
right . 
i mean again if you had the whole system you were optimizing that would be easy to see . 
but if you ' re supposedly just using a fixed back end and you ' re just coming up with a feature vector i ' m not sure 
i mean having the two nets suppose you detected that it was male it was female you come up with different 
well you could put them both in as separate streams or something . 
uh 
uhhuh . 
maybe . 
i don ' t know . 
i was just wondering if there was other information we could exploit . 
uhhuh . 
huh . 
yeah it ' s an interesting thought . 
maybe having something along the 
i mean you can ' t really do vocal tract normalization . 
but something that had some of that effect . 
yeah . 
being applied to the data in some way . 
uhhuh . 
um 
do you have something simple in mind for i mean vocal tract length normalization ? 
uh no i hadn ' t i hadn ' t thought it was thought too much about it really . 
it just something that popped into my head just now . 
and so i i 
i mean you could maybe use the ideas a similar idea to what they do in vocal tract length normalization . 
you know you have some sort of a uh general speech model . 
you know maybe just a mixture of gaussians that you evaluate every utterance against . 
and then you see where each you know utterance like the likelihood of each utterance you divide the the range of the likelihoods up into discrete bins . 
and then each bin ' s got some knob uh setting . 
yeah but just listen to yourself . 
i mean that uh really doesn ' t sound like a real time thing with less than two hundred milliseconds uh latency that and where you ' re not adjusting the statistical engine at all . 
yeah . 
yeah . 
uhhuh . 
yeah . 
that ' s true . 
right . 
you know that just 
huh . 
could be expensive . 
i mean . 
yeah . 
no 
well not just expensive . 
i i i don ' t see how you could possibly do it . 
you can ' t look at the whole utterance and do anything you know you can only 
oh ! 
right ? 
right . 
each frame comes in and it ' s got to go out the other end . 
right . 
so uh 
so whatever it was it would have to be uh sort of on a per frame basis . 
yeah . 
uhhuh . 
yeah . 
i mean you can do 
um 
yeah . 
fairly quickly you can do male female male female stuff . 
yeah . 
but as far as 
i mean like i thought b b n did a thing with uh uh vocal tract normalization a ways back . 
maybe other people did too . 
with with uh uh trying to identify third formant average third formant using that as an indicator of 
i don ' t know . 
so 
you know third formant 
if you imagine that to first order what happens with uh changing vocal tract is that uh the formants get moved out by some proportion . 
uhhuh . 
so if you had a first formant that was one hundred hertz before if the fifty if the vocal tract is fifty percent shorter then it would be out at seven fifty hertz . 
and so on . 
so that ' s a move of two hundred fifty hertz . 
whereas the third formant which might have started off at twenty five hundred hertz you know might be out to thirty seven fifty . 
you know so it ' s at 
so 
although you frequently get less distinct higher formants it ' s still third formant ' s kind of a reasonable compromise . 
and 
uhhuh . 
so i think uh if i recall correctly they did something like that . 
huh . 
and and 
but um that doesn ' t work for just having one frame or something . 
yeah . 
you know that ' s more like looking at third formant over over a turn or something like that . 
uhhuh . 
uhhuh . 
and 
right . 
um 
so 
but on the other hand male female is a is a is a much simpler categorization than figuring out a a factor to uh squish or expand the the spectrum . 
uhhuh . 
so um 
you could imagine that 
i mean just like we ' re saying voiced unvoiced is good to know . 
uh male female is good to know also . 
uhhuh . 
um 
but you ' d have to figure out a way to to to uh incorporate it on the fly . 
uh i mean i guess as you say one thing you could do is simply uh have the the male and female output vectors you know nets trained only on males and trained only on females . 
or 
or uh 
you know . 
but 
um 
i don ' t know if that would really help . 
because you already have males and females . 
and it ' s uhhuh putting into one net . 
so 
is it 
is it balanced ? 
um in terms of gender . 
the data ? 
do you know ? 
huh . 
almost . 
yeah . 
huh . 
uhhuh . 
huh . 
okay . 
you ' re you were saying before . 
uh yeah . 
so this noise 
um 
yeah the m s g 
um 
huh 
there is something perhaps i could spend some days to look at this thing . 
because it seems that when we train networks on let ' s say on timit with m s g features they they look as good as networks trained on p l p . 
but 
um 
when they are used on on the speechdat car data it ' s not the case . 
oh well . 
the m s g features are much worse . 
and so maybe they ' re um less more sensitive to different recording conditions . 
shouldn ' t be . 
or 
they should be less so . 
yeah . 
but 
right ? 
huh . 
but let me ask you this . 
what what ' s the um 
do you recall if the insertions were were higher with m s g ? 
i don ' t know . 
i cannot tell . 
but 
it ' s it 
the the error rate is higher . 
yeah but you should always look at insertions deletions and substitutions . 
so i 
yeah . 
uhhuh . 
so 
uhhuh . 
so uh 
m s g is very very 
uh p l p is very much like mel cepstrum . 
m s g is very different from both of them . 
uhhuh . 
so if it ' s very different then this is the sort of thing 
i mean i ' m really glad andreas brought this point up . 
i sort of had forgotten to discuss it . 
um 
you always have to look at how this uh these adjustments uh affect things . 
and even though we ' re not allowed to do that again we maybe could reflect that back to our use of the features . 
so if it if in fact uh 
uhhuh . 
the problem might be that the range of the m s g features is quite different than the range of the p l p or mel cepstrum . 
uhhuh . 
and you might want to change that . 
uhhuh . 
but 
yeah . 
but it ' s it ' s after 
well it ' s tandem features . 
so 
huh 
yeah . 
yeah . 
we we have estimation of posteriors with p l p and with m s g as input . 
yeah . 
so i 
well . 
i don ' t know . 
that means they ' re between zero and one . 
uhhuh . 
but it it it it doesn ' t necessarily 
you know they could be 
um 
doesn ' t tell you what the variance of the things is . 
huh . 
uhhuh . 
right ? 
because if you ' re taking the log of these things it could be 
uh 
knowing what the sum of the probabilities are doesn ' t tell you what the sum of the logs are . 
uhhuh . 
yeah . 
so 
yeah . 
so we should look at the likelihood . 
or or 
what 
or 
well 
at the log perhaps . 
and 
yeah . 
uhhuh . 
yeah . 
or what you know what you ' re uh the thing you ' re actually looking at . 
uhhuh . 
so your your 
the values that are are actually being fed into h t k . 
uhhuh . 
what do they look like ? 
but 
and so the uh for the tandem system the values that come out of the net don ' t go through the sigmoid . 
right ? 
they ' re sort of the pre nonlinearity values ? 
right . 
yes . 
so they ' re kind of like log probabilities is what i was saying . 
and those 
okay . 
and that ' s what goes into h t k ? 
uh almost . 
but then you actually do a k l t on them . 
okay . 
um 
they aren ' t normalized after that . 
are they ? 
huh no . 
they are not . 
no . 
no . 
okay . 
so um 
right . 
so the question is yeah whatever they are at that point um are they something for which taking a square root or cube root or fourth root or something like that is is going to be a good or a bad thing . 
so 
uhhuh . 
uh and that ' s something that 
nothing nothing else after that is going to 
uh things are going to scale it . 
uh you know subtract things from it . 
scale it from it . 
but nothing will have that same effect . 
um 
so 
um 
anyway uh 
yeah . 
because if if the log probs that are coming out of the m s g are really big the standard insertion penalty is going to have very little effect . 
well the 
right . 
compared to you know a smaller set of log probs . 
yeah . 
no again you don ' t really look at that . 
it ' s something that 
and then it ' s going through this transformation that ' s probably pretty close to 
it ' s uh whatever the k l t is doing . 
but it ' s probably pretty close to what a a a discrete cosine transformation is doing . 
yeah . 
but still it ' s it ' s not going to probably radically change the scale of things . 
i would think . 
and uh 
yeah . 
it may be entirely off . 
and and it may be at the very least it may be quite different for m s g than it is for mel cepstrum or p l p . 
so that would be 
so the first thing i ' d look at without adjusting anything would just be to go back to the experiment and look at the uh substitutions insertions and deletions . 
and if the if 
the uh 
if there ' s a fairly large effect of the difference say uh uh the ratio between insertions and deletions for the two cases then that would be uh an indicator that it might might be in that direction . 
uhhuh . 
uhhuh . 
anything else ? 
yeah but 
my my point was more that it it works sometimes . 
and 
yeah . 
but sometimes it doesn ' t work . 
so 
well . 
and it works on t i digits . 
and on speechdat car it doesn ' t work . 
and 
yeah . 
uhhuh . 
yeah . 
well . 
but you know some problems are harder than others . 
uhhuh . 
yeah . 
and 
and uh sometimes you know there ' s enough evidence for something to work . 
and then it ' s harder . 
it breaks . 
you know ? 
so it ' s 
uhhuh . 
but it but um it it could be that when you say it works maybe we could be doing much better . 
even in t i digits . 
right ? 
yeah . 
so 
yeah sure . 
uh 
huh . 
yeah . 
yeah . 
well . 
there is also the spectral subtraction . 
which 
um 
i think maybe we should uh try to integrate it in in our system . 
yeah . 
huh . 
uhhuh . 
right . 
but 
i think that would involve to to huh use a big a already a big bunch of the system of ericsson . 
because he has spectral subtraction . 
then it ' s followed by um other kind of processing that ' s are dependent on the uh if it ' s speech or or silence . 
uhhuh . 
and there is this kind of spectral flattening after if it ' s silence . 
and 
and i i think it ' s important um to reduce this musical noise and this this increase of variance during silence portions . 
so 
well . 
this was this would involve to take almost everything from from the this proposal . 
and 
and then just add some kind of on line normalization in in the neural network . 
huh . 
okay . 
well this ' ll be i think something for discussion with hynek next week . 
yeah . 
uhhuh . 
yeah . 
okay . 
right . 
so 
how are uh uh how are things going with what you ' re doing ? 
oh . 
well um 
i took a lot of time just getting my taxes out of the way . 
multi national taxes . 
so i ' m i ' m starting to write code now for my work . 
but i don ' t have any results yet . 
um it would be good for me to talk to hynek i think when he ' s here . 
yeah . 
do you know what his schedule will be like ? 
uh he ' ll be around for three days . 
uh we ' ll have a lot of time . 
okay . 
so 
so uh 
okay . 
um 
i ' ll uh 
you know he ' s 
he ' ll 
he ' ll be talking with everybody in this room . 
so 
but you said you won ' t you won ' t be here next thursday ? 
not thursday and friday . 
yeah . 
because i will be at faculty retreat . 
huh . 
so 
i ' ll try to connect with him and people as as i can on on wednesday . 
but 
um 
oh how ' d taxes go ? 
taxes go okay ? 
huh yeah . 
yeah . 
that ' s just that ' s that ' s one of the big advantages of not making much money is the taxes are easier . 
yeah . 
unless you ' re getting money in two countries . 
i think you are . 
they both want their cut . 
aren ' t you ? 
huh . 
huh yeah . 
right ? 
yeah . 
yeah . 
huh . 
canada canada wants a cut ? 
uhhuh . 
have to do so you you have to do two returns ? 
huh uh for two thousand i did . 
yeah . 
oh oh . 
yeah . 
for 
that ' s right . 
but not for this next year ? 
two thousand . 
yeah . 
probably not this next year i guess . 
yeah . 
um 
yeah . 
uh i ' ll i ' ll still have a bit of canadian income . 
but it ' ll be less complicated . 
because i will not be a considered a resident of canada anymore . 
so i won ' t have to declare my american income on my canadian return . 
okay . 
all right . 
uh 
barry ? 
do you want to say something about your stuff here ? 
oh . 
um 
right . 
i just um continuing looking at uh uh phonetic events . 
and uh this tuesday going to be uh meeting with john ohala with chuck to talk some more about these uh um phonetic events . 
um came up with uh a plan of attack . 
uh going to execute . 
and 
um 
yeah . 
it ' s that ' s pretty much it . 
oh well . 
um why don ' t you say something about what it is ? 
oh . 
you oh you want you want details . 
huh 
okay . 
well we ' re all gathered here together . 
i thought we ' d you know 
i was hoping i could wave my hands . 
um 
so 
um 
so once 
i i was thinking getting getting us a set of acoustic events to um to be able to distinguish between uh phones and words and stuff . 
and um 
once we 
we would figure out a set of these events that can be you know um hand labeled or or derived uh from the hand labeled phone targets . 
um we could take these events and um do some cheating experiments . 
um where we feed um these events into an s r i system um uh and evaluate its performance on a switchboard task . 
hey barry ? 
uh yeah . 
can you give an example of an event ? 
yeah . 
sure . 
um i i can give you an example of twenty odd events . 
um 
so in this paper um it ' s talking about phoneme recognition using acoustic events . 
so things like frication or uh nasality . 
whose paper is it ? 
um 
this is a paper by hubener and cardson benson berndsen . 
yeah . 
huh . 
from uh university of hamburg and bielefeld . 
uhhuh . 
okay . 
um 
yeah i think the 
just to expand a little bit on the idea of acoustic event . 
uhhuh . 
there ' s um in my mind anyways there ' s a difference between um acoustic features and acoustic events . 
and i think of acoustic features as being um things that linguists talk about . 
like um 
so stuff that ' s not based on data . 
stuff that ' s not based on data necessarily . 
yeah . 
oh okay . 
right . 
yeah . 
yeah . 
that ' s not based on you know acoustic data . 
okay . 
so they talk about features for phones . 
like uh its height . 
its tenseness . 
yeah . 
laxness . 
things like that . 
uhhuh . 
which may or may not be all that easy to measure in the acoustic signal . 
versus an acoustic event which is just something in the acoustic signal that is fairly easy to measure . 
um so it ' s um it ' s a little different . 
in at least in my mind . 
i mean when we did the spam work i mean there we had we had this notion of an uh auditory auditory event . 
good that ' s great . 
and uh 
um 
called them avents . 
uhhuh . 
uh uh uh with an a at the front . 
uh 
and the the the idea was something that occurred that is important to a bunch of neurons somewhere . 
so 
uhhuh . 
um a sudden change or a relatively rapid change in some spectral characteristic will will do sort of this . 
i mean there ' s certainly a bunch of a bunch of places where you know that neurons are going to fire because something novel has happened . 
that was that was the main thing that we were focusing on there . 
but there ' s certainly other things beyond what we talked about there that aren ' t just sort of rapid changes . 
but 
it ' s kind of like the difference between top down and bottom up . 
yeah . 
i think of the acoustic you know phonetic features as being top down . 
you know you look at the phone . 
and you say this phone is supposed to be you know have this feature this feature and this feature . 
whether those features show up in the acoustic signal is sort of irrelevant . 
whereas an acoustic event goes the other way . 
here ' s the signal . 
here ' s some event . 
uhhuh . 
what 
and then that you know that may map to this phone sometimes . 
and sometimes it may not . 
it just maybe depends on the context . 
things like that . 
and so it ' s sort of a different way of looking . 
uhhuh . 
uhhuh . 
yeah . 
so 
yeah . 
okay . 
uhhuh . 
um 
using these these events um you know we can we can perform these these uh cheating experiments . 
see how how how good they are um in um in terms of phoneme recognition or word recognition . 
and 
um 
and then from that point on i would uh design robust event detectors um in a similar um spirit that saul has done uh with his graphical models and this this probabilistic and or model that he uses . 
um 
uh try to extend it to um to account for other other phenomena like um c m r co modulation release . 
and 
um 
and maybe also investigate ways to to modify the structure of these models um in a data driven way . 
uh similar to the way that uh jeff jeff uh bilmes did his work . 
um 
and while i ' m i ' m doing these um event detectors you know i can measure my progress by comparing um the error rates in clean and noisy conditions to something like uh neural nets . 
um 
and 
so 
so once we have these these uh event detectors um we could put them together and and feed the outputs of the event detectors into into the s r i um h m m h m m system . 
and 
um 
and test it on on switchboard or um maybe even aurora stuff . 
and 
that ' s pretty much the the big picture of of um the plan . 
by the way 
um 
there ' s uh a couple people who are going to be here . 
i forget if i already told you this . 
but a couple people who are going to be here for six months . 
uhhuh . 
uh 
uh there ' s a professor kollmeier uh from germany . 
who ' s uh uh quite big in the uh hearing aid signal processing area . 
and um michael kleinschmidt who ' s worked with him . 
who also looks at auditory properties inspired by various uh brain function things . 
huh . 
so 
um 
um i think they ' ll be interesting to talk to in this sort of issue . 
as these detectors are are uh developing . 
huh . 
okay . 
so he looks at interesting interesting things in in the different ways of looking at spectra in order to to get various speech properties out . 
so 
okay . 
okay . 
well 
short meeting . 
but that ' s okay . 
and uh 
we might as well do our digits . 
and like i say i i encourage you to go ahead and meet uh next week with uh uh hynek . 
all right . 
i ' ll i ' ll start . 
it ' s uh one thirty five . 
so i the the problem is that i actually don ' t know how these held meetings are held . 
if they are very informal and sort of just people are say what ' s going on . 
yeah . 
and 
yeah that ' s usually what we do . 
we just sort of go around and people say what ' s going on what ' s the latest uh 
okay . 
yeah . 
okay . 
so i guess that what may be a reasonable is if i uh first make a report on what ' s happening in aurora in general at least what from my perspective . 
yeah . 
that would be great . 
uh 
and and uh so i i think that carmen and stephane reported on uh amsterdam meeting . 
which was kind of interesting . 
because it was for the first time we realized we are not friends really but we are competitors . 
because until then it was sort of like everything was like wonderful . 
and 
yeah . 
it seemed like there were still some issues . 
yeah . 
right ? 
that they were trying to decide . 
there is a plenty of there ' re plenty of issues . 
like the voice activity detector 
well and what happened was that they realized that if two leading proposals which was french telecom alcatel and us both had uh voice activity detector . 
right . 
and i said well a big surprise i mean we could have told you that four months ago except we didn ' t because nobody else was bringing it up . 
obviously french telecom didn ' t volunteer this information either . 
right . 
because we were working on mainly on voice activity detector for past uh several months . 
because that ' s buying us the most uh thing . 
and everybody said well but this is not fair we didn ' t know that . 
and of course uh the it ' s not working on features really . 
right . 
and i agreed . 
i said well yeah . 
you are absolutely right . 
i mean if i wish that you provided better end point at speech because uh 
or at least that if we could modify the recognizer uh to account for these long silences . 
because otherwise uh that that that wasn ' t a correct thing . 
and so then everybody else says well we should we need to do a new evaluation without voice activity detector . 
or we have to do something about it . 
right . 
and in principle i uh i we agreed . 
uhhuh . 
we said uh yeah . 
because uh 
but in that case uh we would like to change the uh the algorithm . 
because uh if we are working on different data we probably will use a different set of tricks . 
right . 
but unfortunately nobody ever officially can somehow acknowledge that this can be done . 
because french telecom was saying no no no now everybody has access to our code . 
so everybody is going to copy what we did . 
yeah . 
well our argument was everybody has access to our code and everybody always had access to our code . 
we never uh uh denied that . 
we thought that people are honest that if you copy something and if it is protected protected by patent then you negotiate or something . 
yeah . 
right . 
right ? 
i mean if you find our technique useful we are very happy . 
right . 
uhhuh . 
but and french telecom was saying no no no . 
there is a lot of little tricks which uh sort of uh cannot be protected and you guys will take them which probably is also true . 
i mean you know it might be that people will take uh uh the algorithms apart and use the blocks from that . 
but i somehow think that it wouldn ' t be so bad as long as people are happy uh uh uh honest about it . 
yeah . 
and i think they have to be honest in the long run because winning proposal again uh what will be available is will be a code . 
uhhuh . 
so the uh the people can go to code and say well listen this is what you stole from me . 
right . 
you know ? 
right . 
so let ' s deal with that . 
so i don ' t see the problem . 
the biggest problem of course is that that alcatel french telecom claims well we fulfilled the conditions . 
we are the best . 
uh we are the standard . 
and and other people don ' t feel that . 
because they so they now decided that that is the whole thing will be done on well endpointed data . 
essentially that somebody will endpoint the data based on clean speech . 
because most of this uh the speechdat car has the also close speaking mike and endpoints will be provided . 
uhhuh . 
uh . 
and uh we will run again . 
still not clear if we are going to run the if we are allowed to run uh uh new algorithms . 
but i assume so . 
because uh we would fight for that really . 
uh but since uh 
at least our experience is that only endpointing a a mel cepstrum gets uh gets you twenty one percent improvement overall and twenty seven improvement on speechdat car . 
huh . 
then obvious the database uh i mean the the the uh the baseline will go up . 
right . 
and nobody can then achieve fifty percent improvement . 
so they agreed that uh there will be a twenty five percent improvement required on on uh bad badly mismatched 
but wait a minute . 
i thought the endpointing really only helped in the noisy cases . 
it uh 
oh but you still have that with the m f c c . 
okay . 
yeah . 
yeah . 
yeah but you have the same i mean m f c c basically has an enormous number of uh insertions . 
right . 
yeah . 
yeah . 
yeah . 
and so so now they want to say we we will require fifty percent improvement only for well matched condition and only twenty five percent for the serial cases . 
huh . 
yeah and uh and they almost agreed on that except that it wasn ' t a hundred percent agreed . 
and so last time uh during the meeting i just uh brought up the issue . 
i said well you know uh quite frankly i ' m surprised how lightly you are making these decisions . 
because this is a major decision . 
for two years we are fighting for fifty percent improvement . 
and suddenly you are saying oh no we we will do something less . 
but maybe we should discuss that . 
and everybody said oh we discussed that and you were not a there . 
and i said well a lot of other people were not there because not everybody participates at these teleconferencing things . 
then they said oh no no no because uh everybody is invited . 
however there is only ten or fifteen lines so people can ' t even you know participate . 
so uh they agreed and so they said okay we will discuss that . 
immediately nokia uh raised the question . 
and they said oh yeah we agree this is not good to to uh dissolve the uh uh the uh the criterion . 
uhhuh . 
so now officially nokia is uh uh complaining and said they they are looking for support . 
uh i think qualcomm is uh saying too we shouldn ' t abandon the fifty percent yet . 
we should at least try once again one more round . 
uhhuh . 
uhhuh . 
so this is where we are . 
huh . 
i hope that i hope that this is going to be adopted . 
next wednesday we are going to have uh another uh teleconferencing call so we ' ll see what uh where it goes . 
so what about the issue of um the weights on the for the different systems ? 
the well matched and medium mismatched and 
yeah . 
that ' s what that ' s a very good uh point . 
because david says well you know we we can manipulate this number by choosing the right weights anyways . 
uhhuh . 
so while you are right but uh you know but 
uh yeah . 
if you of course if you put a zero uh weight zero on a mismatched condition or highly mismatched then then you are done . 
uhhuh . 
but weights were also already decided uh half a year ago . 
and they ' re the staying the same ? 
so 
well of course people will not like it . 
uhhuh . 
now what is happening now is that i i think that people try to match the criterion to solution . 
they have solution . 
now they want to make sure their criterion is 
right . 
and i think that this is not the right way . 
yeah . 
uh it may be that that 
eventually it may may it may have to happen . 
uhhuh . 
but it ' s should happen at a point where everybody feels comfortable that we did all what we could . 
uhhuh . 
and i don ' t think we did . 
basically i think that that this test was a little bit bogus because of the data . 
and uh essentially there were these arbitrary decisions made and and everything . 
so so so this is this is where it is . 
so what we are doing at o g i now is uh uh uh working basically on our parts which we i think a little bit neglected . 
like noise separation . 
uh so we are looking in ways is in uh which uh with which we can provide better initial estimate of the mel spectrum basically . 
which would be a uh more robust to noise . 
and so far not much uh success . 
huh . 
we tried uh things which uh a long time ago bill byrne suggested . 
instead of using fourier spectrum from fourier transform use the spectrum from l p c model . 
their argument there was the l p c model fits the peaks of the spectrum so it may be naturally more robust in noise . 
and i thought well that makes sense but so far we can ' t get much much out of it . 
huh . 
uh we may try some standard techniques like spectral subtraction and 
you haven ' t tried that yet ? 
not not not much . 
huh . 
or even i was thinking about uh looking back into these totally ad hoc techniques . 
like for instance uh dennis klatt was suggesting uh the one way to uh deal with noisy speech is to add noise to everything . 
huh . 
so i mean uh uh add moderate amount of noise to all data . 
oh ! 
i see . 
so that makes uh any additive noise less less effective . 
right ? 
right . 
because you already uh had the noise uh in a 
and it was working at the time . 
it was kind of like one of these things you know but 
if you think about it it ' s actually pretty ingenious . 
so well you know just take a take a spectrum and and and add of the constant c to every every value . 
well you ' re you ' re basically 
yeah . 
so you ' re making all your training data more uniform . 
exactly . 
and if if then if this data becomes noisy it it becomes effectively becomes less noisy basically . 
huh . 
but of course you cannot add too much noise because then you ' ll then you ' re clean recognition goes down . 
but i mean it ' s yet to be seen how much . 
it ' s a very simple technique . 
uhhuh . 
yes indeed it ' s a very simple technique . 
you just take your spectrum and and use whatever is coming from f f t add constant . 
huh . 
you know ? 
onto power spectrum . 
that that 
or the other thing is of course if you have a spectrum what you can start doing you can leave start leaving out the the parts which are uh uh low in energy . 
and then perhaps uh one could try to find a a all pole model to such a spectrum . 
because a all pole model will still try to to to put the the continuation basically of the of the model into these parts where the issue set to zero . 
so that ' s what we want to try . 
i have a visitor from brno . 
he ' s a kind of like young faculty . 
pretty hard working so he so he ' s so he ' s looking into that . 
huh . 
and then most of the effort is uh now also aimed at this trap recognition . 
this uh this is this recognition from temporal patterns . 
huh ! 
what is that ? 
uh you don ' t know about traps ! 
huh . 
the traps sound familiar i but i don ' t 
yeah . 
i mean 
this is familiar like sort of because we gave you the name . 
but what it is is that normally what you do is that you recognize uh speech based on a shortened spectrum . 
uhhuh . 
uhhuh . 
essentially l l p c mel cepstrum uh everything starts with a spectral slice . 
uh so if you so given the spectrogram you essentially are sliding sliding the spectrogram along the uh frequency axis . 
uhhuh . 
and you keep shifting this thing and you have a spectrogram . 
uhhuh . 
so you can say well you can also take the time trajectory of the energy at a given frequency . 
uhhuh . 
and what you get is then that you get a vector . 
and this vector can be a a assigned to some phoneme . 
namely you can say it i will i will say that this vector will uh will will describe the phoneme which is in the center of the vector . 
and you can try to classify based on that . 
huh . 
and you so you 
so it ' s a very different vector very different properties . 
we don ' t know much about it . 
huh . 
but the truth is 
but you have many of those vectors per phoneme . 
well so you get many decisions . 
right ? 
uhhuh . 
and then you can start thinking about how to combine these decisions . 
huh . 
exactly that ' s what yeah that ' s what it is . 
huh . 
because if you run this uh recognition you get you still get about twenty percent error . 
uh twenty percent correct . 
huh . 
you know ? 
on on like for the frame by frame basis . 
so uh uh so it ' s much better than chance . 
how wide are the uh frequency bands ? 
that ' s another thing . 
well currently we start i mean we start always with critical band spectrum . 
for various reasons . 
but uh the latest uh observation uh is that you you you are you can get quite a big advantage of using two critical bands at the same time . 
are they adjacent ? 
or are they 
adjacent adjacent . 
okay . 
and the reasons there are some reasons for that . 
because there are some reasons i can i could talk about will have to tell you about things like masking experiments which uh uh uh uh yield critical bands . 
and also experiments with release of masking which actually tell you that something is happening across critical bands across bands . 
and 
well how do you how do you uh convert this uh energy over time in a particular frequency band into a vector of numbers ? 
it ' s uh uh uh i mean time t zero is one number time 
yeah but what ' s the number ? 
is it just the 
it ' s a spectral energy logarithmic spectral energy . 
it ' s just the amount of energy in that band from in that time interval . 
yeah . 
yes yes . 
yes yes . 
okay . 
and that ' s what that ' s what i ' m saying then . 
so this is a this is a starting vector . 
it ' s just like shortened spectrum or something . 
uhhuh . 
but now we are trying to understand what this vector actually represents . 
for instance a question is like how correlated are the elements of this vector . 
turns out they are quite correlated because i mean especially the neighboring ones . 
yeah . 
right ? 
they they represent the same almost the same configuration of the vocal tract . 
yeah . 
uhhuh . 
so there ' s a very high correlation . 
so the classifiers which use the diagonal covariance matrix don ' t like it . 
so we ' re thinking about de correlating them . 
huh . 
then the question is uh can you describe elements of this vector by gaussian distributions or to what extent . 
because uh 
and and and so on and so on . 
so we are learning quite a lot about that . 
huh . 
and then another issue is how many vectors we should be using . 
i mean the so the minimum is one . 
uhhuh . 
but i mean is the is the critical band the right uh uh dimension ? 
so we somehow made arbitrary decision yes . 
then but then now we are thinking a lot how to uh how to use at least the neighboring band because that seems to be happening . 
this i somehow start to believe that ' s what ' s happening in recognition . 
because a lot of experiments point to the fact that people can split the signal into critical bands . 
but then oh uh uh 
so you can you are quite capable of processing a signal uh uh independently in individual critical bands . 
that ' s what masking experiments tell you . 
but at the same time you most likely pay attention to at least neighboring bands . 
when you are making any decisions you compare what ' s happening in in this band to what ' s happening to the band to to to the to the neighboring bands . 
and that ' s how you make uh decisions . 
that ' s why the articulatory events which uh fletcher talks about they are about two critical bands . 
you need at least two basically . 
you need some relative relative relation . 
huh . 
huh . 
absolute number doesn ' t tell you the right thing . 
you need to you need to compare it to something else what ' s happening . 
but it ' s what ' s happening in the in the close neighborhood . 
so if you are making decision what ' s happening at one kilohertz you want to know what ' s happening at nine hundred hertz and it and maybe at eleven hundred hertz . 
but you don ' t much care what ' s happening at three kilohertz . 
so it ' s really 
it ' s sort of like saying that what ' s happening at one kilohertz depends on what ' s happening around it . 
it ' s sort of relative to it . 
to some extent it that is also true . 
uhhuh . 
yeah . 
but it ' s but for but for instance uh uh what what uh humans are very much capable of doing is that if if they are exactly the same thing happening in two neighboring critical bands recognition can discard it . 
huh . 
is what ' s happening ? 
hey ! 
hey ! 
okay we need us another another voice here . 
hey stephane . 
yeah ? 
i think so . 
yep . 
yeah ? 
sure . 
go ahead . 
and so so so for instance if you if you if you add the noise that normally masks masks the uh the the signal . 
uhhuh . 
right ? 
and you can show that in that if the if you add the noise outside the critical band that doesn ' t affect the the decisions you ' re making about a signal within a critical band . 
huh . 
unless this noise is modulated . 
if the noise is modulated with the same modulation frequency as the noise in a critical band the amount of masking is less . 
huh . 
the moment you moment you provide the noise in neighboring critical bands . 
so the masking curve normally it looks like sort of 
i start from from here . 
so you you have uh no noise then you you you are expanding the critical band so the amount of maching is increasing . 
and when you hit a certain point which is a critical band then the amount of masking is the same . 
huh . 
so that ' s the famous experiment of fletcher a long time ago . 
like that ' s where people started thinking wow this is interesting . 
yeah . 
so 
but if you if you if you modulate the noise the masking goes up and the moment you start hitting the another critical band the masking goes down . 
so essentially essentially that ' s a very clear indication that that that cognition can take uh uh into consideration what ' s happening in the neighboring bands . 
but if you go too far in a in a if you if the noise is very broad you are not increasing much more . 
so so if you if you are far away from the signal uh from the signal uh the frequency at which the signal is then the even the when the noise is co modulated it it ' s not helping you much . 
uhhuh . 
yeah . 
uhhuh . 
so 
huh . 
so things like this we are kind of playing with with with the hope that perhaps we could eventually use this in a in a real recognizer . 
uhhuh . 
like uh partially of course we promised to do this under the the the aurora uh program . 
but you probably won ' t have anything before the next time we have to evaluate . 
right ? 
probably not . 
yeah . 
well maybe most likely we will not have anything which would comply with the rules . 
uh . 
like because uh uh 
latency and things . 
latency currently chops the require uh significant uh latency amount of processing . 
uhhuh . 
because uh we don ' t know any better yet than to use the neural net classifiers uh and uh and uh traps . 
yeah . 
uhhuh . 
though the the work which uh everybody is looking at now aims at trying to find out what to do with these vectors so that a simple gaussian classifier would be happier with it . 
huh . 
uhhuh . 
or to what extent a gaussian classifier should be unhappy uh 
that and how to gaussian ize the vectors . 
and 
huh . 
so this is uh what ' s happening . 
then sunil is uh uh uh asked me for one month ' s vacation . 
and since he did not take any vacation for two years i had no i didn ' t have a heart to tell him no . 
so he ' s in india . 
wow ! 
and uh 
is he getting married or something ? 
uh well uh he may be looking for a girl for for i don ' t i don ' t i don ' t ask . 
i know that when last time narayanan did that he came back engaged . 
right . 
well i mean i ' ve known other friends who they they go to they go back home to india for a month they come back married . 
yeah . 
i know . 
i know i know . 
you know huh ? 
and then of course then what happened with narayanan was that he start pushing me that he needs to get a p h d because they wouldn ' t give him his wife . 
and she ' s very pretty and he loves her . 
and so so we had to really 
so he finally had some incentive to finish . 
oh yeah . 
huh ? 
we had well i had a incentive because he he always had this plan except he never told me . 
oh . 
sort of figured that that was a uh that he uh he told me the day when we did very well at our nist evaluations of speaker recognition the technology and he was involved there . 
we were after presentation we were driving home and he told me . 
when he knew you were happy . 
huh ? 
yeah . 
so i i said well yeah okay so he took another another three quarter of the year but uh he was out . 
so i wouldn ' t surprise me if he has a plan like that though though uh pratibha still needs to get out first . 
huh . 
because pratibha is there a a year earlier . 
huh . 
and and satya needs to get out very first because he ' s he already has uh four years served . 
though one year he was getting masters . 
so 
so 
huh . 
so have the um 
when is the next uh evaluation ? 
june or something ? 
which ? 
speaker recognition ? 
no for uh aurora . 
uh there we don ' t know about evaluation . 
next meeting is in june . 
huh . 
and uh uh but like getting get together . 
oh okay . 
are people supposed to rerun their systems ? 
nobody said that yet . 
or 
i assume so . 
huh . 
uh yes uh but nobody even set up yet the date for uh delivering uh endpointed data . 
wow . 
and this uh that that sort of stuff . 
but i uh 
yeah . 
what i think would be of course extremely useful if we can come to our next meeting and say well you know we did get fifty percent improvement . 
if if you are interested we eventually can tell you how but uh we can get fifty percent improvement . 
uhhuh . 
because people will will be saying it ' s impossible . 
huh . 
do you know what the new baseline is ? 
oh i guess if you don ' t have 
twenty two twenty twenty two percent better than the old baseline . 
using your uh voice activity detector ? 
yes . 
yes . 
but i assume that it will be similar i don ' t i i don ' t see the reason why it shouldn ' t be . 
similar yeah . 
uhhuh . 
i i don ' t see reason why it should be worse . 
yeah . 
because if it is worse then we will raise the objection . 
we say well you know how come . 
because uh if we just use our voice activity detector which we don ' t claim even that it ' s wonderful it ' s just like one of them . 
uhhuh . 
yeah . 
we get this sort of improvement . 
how come that we don ' t see it on on on on your endpointed data ? 
yeah . 
i guess it could be even better . 
because the voice activity detector that i choosed is something that cheating it ' s using the alignment of the speech recognition system . 
i think so . 
yeah . 
yeah uh 
and only the alignment on the clean channel and then mapped this alignment to the noisy channel . 
and on clean speech data . 
oh okay . 
yeah . 
well david told me 
david told me yesterday or harry actually he told harry from qualcomm . 
and harry uh brought up the suggestion we should still go for fifty percent . 
he says are you aware that your system does only thirty percent uh comparing to to endpointed baselines . 
yeah . 
so they must have run already something . 
huh . 
so 
and harry said yeah . 
but i mean we think that we we didn ' t say the last word yet that we have other other things which we can try . 
huh . 
so so there ' s a lot of discussion now about this uh new criterion . 
uhhuh . 
because nokia was objecting with uh qualcomm ' s we basically supported that we said yes . 
uhhuh . 
now everybody else is saying well you guys might must be out of your mind . 
uh the guenter hirsch who doesn ' t speak for ericsson anymore because he is not with ericsson . 
and ericsson may not may withdraw from the whole aurora activity because they have so many troubles now . 
wow ! 
ericsson ' s laying off twenty percent of people . 
wow ! 
where ' s uh guenter going ? 
well guenter is already he got the job uh already was working on it for past two years or three years . 
uhhuh . 
he got a job uh at some some fachschule the technical college not too far from aachen . 
huh ! 
so it ' s like professor university professor . 
uhhuh . 
you know not quite a university not quite a sort of it ' s not aachen university but it ' s a good school and he he ' s happy . 
uhhuh . 
huh ! 
and he well he was hoping to work uh with ericsson like on uh like consulting basis . 
uhhuh . 
but right now he says says it doesn ' t look like that anybody is even thinking about speech recognition . 
wow ! 
they think about survival . 
yeah . 
huh . 
so 
so but this is being now discussed right now . 
and it ' s possible that uh that that it may get through that we will still stick to fifty percent . 
uhhuh . 
but that means that nobody will probably get this this improvement . 
yet with the current system . 
which essentially i think that we should be happy with . 
because that that would mean that at least people may be forced to look into alternative solutions . 
uhhuh . 
uhhuh . 
and 
but maybe i i mean we are not too far from from fifty percent from the new baseline . 
uh but not 
which would mean like sixty percent over the current baseline which is 
yeah . 
yes yes . 
we we getting we getting there right . 
well . 
we are around fifty fifty five . 
yeah . 
so 
yeah . 
uhhuh . 
is it like sort of is 
how did you come up with this number ? 
if you improve twenty by twenty percent the the the all baselines it ' s just a quick computation ? 
yeah . 
i don ' t know exactly if it ' s 
uhhuh . 
i think it ' s about right . 
yeah because it it depends on the weightings . 
and 
yeah yeah . 
yeah . 
but 
uhhuh . 
huh . 
how ' s your documentation or whatever 
it what was it you guys were working on last week ? 
yeah . 
finally we we ' ve not finished with this . 
we stopped . 
more or less it ' s finished . 
yeah . 
to need a little more time to improve the english and maybe to fill in something some small detail something like that . 
uhhuh . 
huh . 
but it ' s more or less ready . 
yeah . 
well we have a document that explain a big part of the experiments . 
necessary to to include the the bibliography . 
but 
uhhuh . 
it ' s not yeah finished yet . 
uhhuh . 
so have you been running some new experiments ? 
i i thought i saw some jobs of yours running on some of the machine . 
yeah . 
right . 
we ' ve done some strange things like removing c zero or c one from the the vector of parameters . 
and we noticed that c one is almost not useful at all . 
you can remove it from the vector it doesn ' t hurt . 
really ? 
that has no effect ? 
um 
uh is this in the baseline ? 
or in uh 
in the 
no . 
in the proposal . 
in 
uh huh uh huh . 
so we were just discussing since you mentioned that in it 
uhhuh . 
driving in the car with morgan this morning we were discussing a good experiment for for beginning graduate student who wants to run a lot of who wants to get a lot of numbers on something . 
uhhuh . 
which is like imagine that you will you will start putting every any coefficient which you are using in your vector in some general power . 
in some what ? 
general power . 
like sort of you take a power of two or take a square root or something . 
uhhuh . 
uhhuh . 
uhhuh . 
so suppose that you are working with a c c one . 
so if you put it in a square root that effectively makes your model half as efficient . 
because uh your uh gaussian mixture model . 
right ? 
computes the mean . 
uhhuh . 
and and uh 
but it ' s the mean is an exponent of the whatever the the this gaussian function . 
you ' re compressing the range . 
right ? 
of that 
so you ' re compressing the range of this coefficient so it ' s becoming less efficient . 
right ? 
uhhuh . 
so 
so 
morgan was and he was he was saying well this might be the alternative way how to play with a with a fudge factor . 
you know ? 
uh in the 
oh . 
you know just compress the whole vector . 
yeah . 
and i said well in that case why don ' t we just start compressing individual elements like when when 
because in old days we were doing when when people still were doing template matching and euclidean distances we were doing this liftering of parameters . 
right ? 
uhhuh . 
because we observed that uh higher parameters were more important than lower for recognition . 
and basically the the c c one contributes mainly slope . 
right . 
and it ' s highly affected by uh frequency response of the of the recording equipment and that sort of thing . 
uhhuh . 
uhhuh . 
so 
so we were coming with all these various lifters . 
uhhuh . 
uh bell labs had he this uh uh raised cosine lifter which still i think is built into h h t k for reasons unknown to anybody . 
but but uh we had exponential lifter or triangle lifter basic number of lifters . 
huh . 
and but so they may be a way to to fiddle with the with the 
insertions ? 
insertions deletions or the the giving a relative uh basically modifying relative importance of the various parameters . 
uhhuh . 
the only of course problem is that there ' s an infinite number of combinations . 
oh . 
uhhuh . 
and if the if you if 
you need like a some kind of a 
yeah you need a lot of graduate students and a lot of computing power . 
you need to have a genetic algorithm that basically tries random permutations of these things . 
i know . 
exactly . 
oh . 
if you were at bell labs or i 
i shouldn ' t be saying this in on on a mike . 
right ? 
or uh i b m . 
that ' s what maybe that ' s what somebody would be doing . 
yeah . 
huh . 
oh i mean i mean the places which have a lot of computing power . 
uhhuh . 
so because it is really it ' s a it ' s a it ' s it will be a reasonable search . 
yeah . 
uh 
but i wonder if there isn ' t some way of doing this uh search like when we are searching say for best discriminants . 
you know actually i don ' t know that this wouldn ' t be all that bad . 
i mean you you compute the features once . 
yeah . 
right ? 
yeah . 
and then these exponents are just applied to that . 
absolutely . 
and everything is fixed . 
so 
everything is fixed . 
and is this something that you would adjust for training ? 
each each 
or only recognition ? 
for both you would have to do . 
you would do it on both . 
yeah . 
so you ' d actually 
you have to do both . 
because essentially you are saying uh this feature is not important . 
uhhuh . 
or less important . 
so that ' s a that ' s a painful one . 
yeah . 
so for each uh set of exponents that you would try it would require a training and a recognition . 
yeah . 
but but wait a minute . 
you may not need to uh uh retrain the model . 
you just may may need to uh give uh less weight to to uh a uh a component of the model which represents this particular feature . 
you don ' t have to retrain it . 
oh . 
so if you 
instead of altering the feature vectors themselves you you modify the the the gaussians in the models . 
you just multiply . 
yeah . 
yep . 
you modify the gaussian in the model . 
but in the in the test data you would have to put it in the power . 
but in a training what you in a training uh in trained model all you would have to do is to multiply a model by appropriate constant . 
uhhuh . 
but why if you ' re if you ' re if you ' re altering the model why in the test data why would you have to muck with the uh cepstral coefficients ? 
because in uh test in uh test data you don ' t have a model . 
you have uh only data . 
but in a in a 
no but you ' re running your data through that same model . 
that is true . 
but i mean so what you want to do you want to say if uh you if you observe something like stephane observes that c one is not important you can do two things . 
uhhuh . 
uhhuh . 
if you have a trained trained recognizer in the model you know the the the the component which i i mean dimension 
uhhuh . 
all of the all of the mean and variances that correspond to c one you put them to zero . 
to the you you know it . 
yeah . 
but what i ' m proposing now if it is important but not as important you multiply it by point one in a model . 
but but but 
but what are you multiplying ? 
because those are means . 
right ? 
i mean you ' re 
you ' re multiplying the standard deviation ? 
so it ' s 
i think that you multiply the 
i would i would have to look in the in the math . 
i mean how how does the model uh 
i think you 
yeah i think you ' d have to modify the standard deviation or something so that you make it wider or narrower . 
yeah . 
because 
yeah . 
yeah . 
yeah . 
effectively that ' s that that ' s uh i 
exactly . 
that ' s what you do . 
that ' s what you do you you you modify the standard deviation as it was trained . 
yeah . 
effectively you you know in in front of the of the model you put a constant . 
yeah effectively what you ' re doing is you is you are modifying the the the deviation . 
right ? 
oop . 
the spread . 
sorry . 
right ? 
yeah . 
the spread . 
so 
it ' s the same same mean . 
and and and 
right ? 
so by making the standard deviation narrower uh your scores get worse for 
yeah . 
unless it ' s exactly right on the mean . 
your 
no . 
by making it narrower 
right ? 
i mean there ' s you ' re you ' re allowing for less variance . 
uh your 
uhhuh . 
yes . 
so you making this particular dimension less important . 
because see what you are fitting is the multidimensional gaussian . 
right ? 
uhhuh . 
it ' s a it has it has uh thirty nine dimensions or thirteen dimensions if you ignore deltas and double deltas . 
uhhuh . 
uhhuh . 
so in order if you in order to make dimension which which stephane sees uh less important uh uh i mean not not useful less important what you do is that this particular component in the model you can multiply by you can you can basically de weight it in the model . 
but you can ' t do it in a in a test data . 
because you don ' t have a model for i mean uh when the test comes . 
but what you can do is that you put this particular component in and and you compress it . 
that becomes uh gets less variance subsequently becomes less important . 
couldn ' t you just do that to the test data and not do anything with your training data ? 
that would be very bad . 
because uh your your model was trained uh expecting uh 
that wouldn ' t work . 
because your model was trained expecting a certain variance on c one . 
uhhuh . 
and because the model thinks c one is important . 
after you train the model you sort of you could do you could do still what i was proposing initially . 
that during the training you you compress c one that becomes then it becomes less important in a training . 
uhhuh . 
but if you have if you want to run extensive experiment without retraining the model you don ' t have to retrain the model . 
you train it on the original vector . 
but after you when you are doing this parametric study of importance of c one you will de weight the c one component in the model . 
and you will put in the you will compress the this component in a in the test data by the same amount . 
could you also if you wanted to 
if you wanted to try an experiment uh by leaving out say c one couldn ' t you in your test data uh modify the all of the c one values to be um way outside of the normal range of the gaussian for c one that was trained in the model ? 
so that effectively the c one never really contributes to the score ? 
uhhuh . 
do you know what i ' m 
no . 
that would be a severe mismatch . 
right ? 
what you are proposing ? 
yeah . 
no you don ' t want that . 
because that would then your model would be unlikely . 
your likelihood would be low . 
right ? 
uhhuh . 
because you would be providing severe mismatch . 
but what if you set if to the mean of the model then ? 
and it was a you set all c ones coming in through your test data you you change whatever value that was there to the mean that your model had . 
no that would be very good match . 
right ? 
yeah . 
that you would 
which 
well yeah but we have several means . 
so 
i see what you are saying . 
right ? 
saying . 
but 
uh no no i don ' t think that it would be the same . 
let me uh 
if you set it to a mean that would 
no you can ' t do that . 
oh that ' s true . 
you you chuck you can ' t do that . 
right ? 
yeah because you you have 
wait . 
which 
yeah . 
because that would be a really fiddling with the data . 
you can ' t do that . 
huh huh . 
uhhuh . 
uhhuh . 
but what you can do i ' m confident you 
well i ' m reasonably confident and i putting it on the record . 
right ? 
i mean people will listen to it for for centuries now . 
is what you can do is you train the model uh with the with the original data . 
uhhuh . 
then you decide that you want to see how important c c one is . 
so what you will do is that a component in the model for c one you will divide it by by two . 
and you will compress your test data by square root . 
uhhuh . 
then you will still have a perfect match . 
except that this component of c one will be half as important in a in a overall score . 
uhhuh . 
uhhuh . 
then you divide it by four and you take a square fourth root . 
then if you think that some component is more is more important then it then then uh uh it is based on training then you uh multiply this particular component in the model by by by 
you ' re talking about the standard deviation ? 
yeah . 
yeah . 
yeah multiply this component uh it by number larger than one . 
uhhuh . 
and you put your data in power higher than one . 
then it becomes more important in the overall score i believe . 
but don ' t you have to do something to the mean also ? 
yeah . 
but at the 
no . 
no . 
no . 
yeah . 
but i think it ' s uh the the variance is on on the denominator in the in the gaussian equation . 
so i think it ' s maybe it ' s the contrary . 
if you want to decrease the importance of a parameter you have to increase it ' s variance . 
yes . 
right . 
yes . 
multiply . 
exactly . 
yeah . 
so you so so you may want to do it other way around . 
huh . 
that ' s right . 
okay . 
yeah . 
uhhuh . 
right . 
but if your 
if your um original data for c one had a mean of two . 
uhhuh . 
and now you ' re you ' re you ' re changing that by squaring it . 
now your mean of your c one original data has is four . 
but your model still has a mean of two . 
so even though you ' ve expended the range your mean doesn ' t match anymore . 
uhhuh . 
do you see what i mean ? 
let ' s see . 
i think what i see what could be done is you don ' t change your features which are computed once for all . 
uhhuh . 
but you just tune the model . 
so you have your features . 
you train your your model on these features . 
uhhuh . 
and then if you want to decrease the importance of c one you just take the variance of the c one component in the in the model and increase it if you want to decrease the importance of c one or decrease it 
yeah . 
yeah . 
right . 
yeah . 
you would have to modify the mean in the model . 
i you i agree with you . 
yeah . 
yeah . 
yeah so 
but i mean but it ' s it ' s it ' s do able . 
well . 
right ? 
i mean it ' s predictable . 
uh yeah . 
it ' s predictable yeah . 
yeah . 
yeah it ' s predictable . 
yeah . 
huh . 
but as a simple thing you could just just muck with the variance . 
just adjust the model . 
yeah . 
to get uh this uh this the effect i think that you ' re talking about . 
uhhuh . 
right ? 
it might be . 
could increase the variance to decrease the importance . 
uhhuh . 
uhhuh . 
yeah because if you had a huge variance you ' re dividing by a large number you get a very small contribution . 
yeah . 
it becomes more flat . 
doesn ' t matter 
and 
right . 
yeah . 
yeah . 
yeah . 
huh . 
yeah the sharper the variance the more more important to get that one right . 
uhhuh . 
yeah you know actually this reminds me of something that happened uh when i was at b b n . 
we were playing with putting um pitch into the mandarin recognizer . 
uhhuh . 
and this particular pitch algorithm um when it didn ' t think there was any voicing was spitting out zeros . 
so we were getting uh when we did clustering we were getting groups uh of features 
pretty new outliers interesting outliers . 
yeah with with a mean of zero and basically zero variance . 
right ? 
variance . 
so when when anytime any one of those vectors came in that had a zero in it we got a great score . 
i mean it was just you know incredibly high score and so that was throwing everything off . 
uhhuh . 
so if you have very small variance you get really good scores when you get something that matches . 
yeah . 
so so that ' s a way yeah yeah 
uhhuh . 
that ' s a way to increase the yeah 
yeah that ' s interesting . 
so in fact that would be 
that doesn ' t require any retraining . 
yeah . 
no . 
no no . 
that ' s right . 
so it ' s just 
so that means 
tuning the models and testing actually . 
yeah . 
it ' s just recognitions . 
yeah . 
yeah . 
you you have a step where you you modify the models make a copy of your models with whatever variance modifications you make and rerun recognition . 
it would be quick . 
yeah . 
uhhuh . 
yeah . 
yeah . 
yeah . 
and then do a whole bunch of those . 
yeah . 
uhhuh . 
that could be set up fairly easily i think . 
and you have a whole bunch of 
you know 
chuck is getting himself in trouble . 
that ' s an interesting idea actually . 
for testing the 
yeah . 
huh ! 
didn ' t you say you got these uh h t k ' s set up on the new linux boxes ? 
that ' s right . 
in fact and and they ' re just right now they ' re installing uh increasing the memory on that uh the linux box . 
yeah . 
hey ! 
and chuck is sort of really fishing for how to keep his computer busy . 
right . 
yeah . 
right ? 
absinthe . 
absinthe . 
well you know that ' s 
we ' ve got five processors on that . 
that ' s yeah that ' s a good thing . 
oh yeah . 
and two gigs of memory . 
that ' s right . 
because then you just write the do and then you pretend that you are working while you are sort of you you can go fishing . 
yeah . 
yeah . 
exactly . 
pretend yeah . 
yeah . 
go fishing . 
see how many cycles we used ? 
yeah . 
then you are sort of in this mode like all of those arpa people are . 
yeah . 
right ? 
uh since it is on the record i can ' t say uh which company it was . 
but it was reported to me that uh somebody visited a company . 
and during a during a discussion there was this guy who was always hitting the carriage returns uh on a computer . 
uhhuh . 
so after two hours uh the visitor said why are you hitting this carriage return . 
and he said well you know we are being paid by a computer i mean we are we have a government contract . 
and they pay us by by amount of computer time we use . 
it was in old days when there were uh of p d p eights and that sort of thing . 
oh my gosh ! 
so he had to make it look like 
because so they had a they literally had to monitor at the time at the time on a computer how much time is being spent i or on on this particular project . 
yeah . 
how 
idle time . 
yeah . 
yeah . 
nobody was looking even at what was coming out . 
have you ever seen those little 
um 
it ' s it ' s this thing that ' s the shape of a bird and it has a red ball and its beak dips into the water . 
yeah i know . 
right . 
so if you could hook that up so it hit the keyboard 
yeah . 
yeah . 
yeah . 
yeah . 
that ' s an interesting experiment . 
it would be similar similar to 
i knew some people who were uh that was in old communist uh czechoslovakia . 
right ? 
so we were watching for american airplanes coming to spy on on uh on us at the time . 
uhhuh . 
uhhuh . 
so there were three guys uh uh stationed in the middle of the woods on one lonely uh watching tower pretty much spending a year and a half there because there was this service . 
right ? 
ugh ! 
and so they very quickly they made friends with local girls and local people in the village . 
and 
yeah . 
and so but they there was one plane flying over always uh uh above . 
and so that was the only work which they had . 
they like four in the afternoon they had to report there was a plane from prague to brno basically flying there . 
yeah . 
so they very first thing was that they would always run back and and at four o ' clock and and quickly make a call this plane is uh uh passing . 
then a second thing was that they they took the line from this post to uh uh a local pub . 
and they were calling from the pub . 
and they but third thing which they made when they screwed up they finally they had to the the the pub owner to make these phone calls because they didn ' t even bother to be there anymore . 
and one day there was there was no plane . 
at least they were sort of smart enough that they looked if the plane is flying there . 
right ? 
yeah . 
and pub owner says oh my four o ' clock okay quickly pick up the phone call that there ' s a plane flying . 
there was no plane for some reason . 
and there wasn ' t ? 
it was downed . 
or and 
so they got in trouble . 
but but uh 
huh ! 
well that ' s that ' s a really 
so so yeah . 
that wouldn ' t be too difficult to try . 
maybe i could set that up . 
yeah . 
yeah . 
and we ' ll just 
well at least go test the test the uh assumption about c one i mean to begin with . 
but then of course one can then think about some predictable result to change all of them . 
uhhuh . 
it ' s just like we used to do these uh these uh um the the uh distance measures . 
it might be that uh 
yeah so the first set of uh variance weighting vectors would be just you know one modifying one and leaving the others the same . 
yeah . 
yeah . 
yeah . 
yeah . 
yeah . 
yeah . 
maybe . 
and and do that for each one . 
because you see i mean what is happening here in a in a in a in such a model is that it ' s tells you yeah what has a low variance uh is uh is uh is more reliable . 
that would be one set of experiment 
right ? 
how do we 
yeah when the data matches that then you get really 
yeah . 
yeah . 
yeah . 
yeah . 
yeah . 
yeah . 
right . 
how do we know especially when it comes to noise ? 
but there could just naturally be low variance . 
yeah . 
because i like i ' ve noticed in the higher cepstral coefficients the numbers seem to get smaller . 
right ? 
so 
they 
i mean just naturally . 
yeah . 
yeah that ' s 
they have smaller means also . 
yeah . 
uh 
exactly . 
and so it seems like they ' re already sort of compressed . 
uhhuh . 
the range of values . 
yeah that ' s why uh people used these lifters were inverse variance weighting lifters basically that makes uh uh euclidean distance more like uh mahalanobis distance with a diagonal co variance when you knew what all the variances were over the old data . 
uhhuh . 
uhhuh . 
huh . 
what they would do is that they would weight each coefficient by inverse of the variance . 
turns out that uh the variance decreases at least at fast i believe as the index of the cepstral coefficients . 
uhhuh . 
i think you can show that uh uh analytically . 
huh . 
so typically what happens is that you you need to weight the uh weight the higher coefficients more than uh the lower coefficients . 
uhhuh . 
huh . 
huh . 
so 
yeah 
when yeah is 
when we talked about aurora still i wanted to make a plea uh encourage for uh more communication between between uh uh different uh parts of the distributed uh uh center . 
uh even when there is absolutely nothing to to to say but the weather is good in in in berkeley . 
i ' m sure that it ' s being appreciated in oregon and maybe it will generate a similar responses down here . 
like uh 
we can set up a webcam maybe . 
yeah . 
yeah . 
what you know nowadays 
yeah . 
it ' s up actually do able almost . 
is the um 
if we mail to aurora inhouse does that go up to you guys also ? 
i don ' t think so . 
no . 
no . 
okay . 
so what is it 
so we should do that . 
yeah we 
we should definitely set up . 
yeah . 
do we have a mailing list that includes uh the o g i people ? 
yeah . 
uh no . 
we don ' t have . 
oh ! 
uhhuh . 
maybe we should set that up . 
that would make it much easier . 
yeah . 
yeah . 
yeah that would make it easier . 
so maybe just call it aurora or something that would 
yeah . 
yeah . 
and then we also can send the the to the same address . 
right ? 
and it goes to everybody ? 
uhhuh . 
uhhuh . 
yeah . 
okay . 
maybe we can set that up . 
because what ' s happening naturally in research i know is that people essentially start working on something and they don ' t want to be much bothered . 
right ? 
but what the the then the danger is in a group like this is that two people are working on the same thing and of course both of them come with the very good solution but it could have been done somehow in half of the effort or something . 
uhhuh . 
oh there ' s another thing which i wanted to uh uh report . 
lucash i think uh wrote the software for this aurora two system . 
reasonably uh uh good one because he ' s doing it for intel . 
but i trust that we have uh rights to uh use it uh or distribute it and everything . 
because intel ' s intentions originally was to distribute it free of charge anyways . 
huh ! 
and so so uh we we will make sure that at least you can see the software and if if if if it is of any use . 
just uh 
uhhuh . 
it might be a reasonable point for perhaps uh start converging . 
uhhuh . 
because morgan ' s point is that he is an experienced guy . 
he says well you know it ' s very difficult to collaborate if you are working with supposedly the same thing in quotes except which is not is not the same . 
uhhuh . 
which which uh uh one is using that set of hurdles another one set is using another set of hurdles . 
so and and then it ' s difficult to compare . 
what about harry ? 
uh we received a mail last week and you are starting to to do some experiments . 
he got the he got the software . 
yeah they sent the release . 
and use this intel version . 
yeah . 
yeah . 
yeah . 
yeah . 
huh . 
yeah because intel paid us uh 
should i say on a microphone ? 
uh some amount of money not much . 
not much i can say on a microphone . 
much less then we should have gotten for this amount of work . 
and they wanted uh to to have software so that they can also play with it which means that it has to be in a certain environment . 
huh . 
they use actually some intel libraries but in the process lucash just rewrote the whole thing because he figured rather than trying to make sense uh of uh including icsi software uh not for training on the nets . 
huh . 
oh . 
but i think he rewrote the the the or maybe somehow reused over the parts of the thing so that so that the whole thing including m l p trained m l p is one piece of uh software . 
uhhuh . 
wow ! 
is it useful ? 
yeah . 
yeah . 
i mean i remember when we were trying to put together all the icsi software for the submission . 
or 
that ' s what he was saying . 
right . 
he said that it was like it was like just so many libraries and nobody knew what was used when . 
and and so that ' s where he started and that ' s where he realized that it needs to be needs to be uh uh at least cleaned up . 
yeah . 
uhhuh . 
and so i think it this is available . 
huh . 
yeah . 
so 
well the the only thing i would check is if he does he use intel math libraries . 
because if it ' s the case it ' s maybe not so easy to use it on another architecture . 
uh 
not maybe maybe not in a first maybe not in a first approximation . 
uh yeah . 
because i think he started first just with a plain c c or c plus plus or something before 
uhhuh . 
i i can check on that . 
yeah . 
yeah . 
okay . 
huh . 
and uh in otherwise the intel libraries i think they are available free of freely . 
but they may be running only on on uh on uh windows . 
yeah . 
yeah . 
or on on the 
on intel architecture maybe . 
yeah on intel architecture may not run in sun . 
i ' m 
yeah . 
yeah . 
yeah . 
that is that that is possible . 
that ' s why intel of course is distributing it . 
well 
right ? 
or that ' s 
yeah . 
well there are at least there are optimized version for their architecture . 
yeah . 
i don ' t know . 
i never checked carefully these sorts of 
i know there was some issues that initially of course we do all the development on linux . 
but we use we don ' t have we have only three uh uh uh uh suns . 
and we have them only because they have a spert board in . 
otherwise otherwise we almost exclusively are working with uh p c ' s now with intel . 
in that way intel succeeded with us because they gave us too many good machines for very little money or nothing . 
yeah . 
so so so we run everything on intel . 
wow ! 
huh . 
and 
does anybody have anything else ? 
to 
shall we read some digits ? 
yeah . 
yes . 
i have to take my glasses 
so 
hynek i don ' t know if you ' ve ever done this . 
the way that it works is each person goes around in turn and uh you say the transcript number and then you read the digits the the strings of numbers as individual digits . 
no . 
uhhuh . 
so you don ' t say eight hundred and fifty you say eight five oh and so forth . 
okay . 
okay . 
um 
so can maybe can i maybe start then ? 
sure . 
so you think we ' re going now . 
yes ? 
okay good . 
all right . 
going again . 
uh so we ' re going to go around as before and uh do do our digits . 
uh yeah you don ' t actually need to say the name . 
that ' ll probably be bleeped out . 
okay . 
so 
that ' s if these are anonymized . 
but yeah 
oh okay . 
uh i mean not that there ' s anything defamatory about uh eight five seven or or anything . 
but 
uh anyway . 
okay . 
uh so here ' s what i have for i i was just jotting down things i think that we should do today . 
uh this is what i have for an agenda so far . 
um we should talk a little bit about the plans for the uh the field trip next week . 
uh a number of us are doing a field trip to uh uh o g i . 
and uh mostly first though about the logistics for it . 
then maybe later on in the meeting we should talk about what we actually you know might accomplish . 
uh 
okay . 
uh in and kind of go around see what people have been doing talk about that a progress report um essentially . 
um and then uh another topic i had was that uh uh uh dave here had uh said uh give me something to do . 
and i i have i have uh failed so far in doing that . 
and so maybe we can discuss that a little bit . 
if we find some holes in some things that that someone could use some help with he ' s he ' s volunteering to help . 
i ' ve got to move a bunch of furniture . 
okay always count on a serious comment from that corner . 
so um 
uh and uh then uh talk a little bit about about disks and resource resource issues that that ' s starting to get worked out . 
and then anything else anybody has that isn ' t in that list ? 
uh 
i was just wondering does this mean the battery ' s dying and i should change it ? 
uh i think that means the battery ' s okay . 
d do you 
let me see . 
oh okay . 
so 
yeah that ' s good . 
yeah . 
you ' re all right . 
because it ' s full . 
yeah . 
yeah . 
all right . 
yeah . 
it looks full of electrons . 
okay . 
plenty of electrons left there . 
okay . 
so um 
uh 
okay . 
so uh i wanted to start this with this mundane thing . 
um 
uh i i it was it was kind of my bright idea to have us take a plane that leaves at seven twenty in the morning . 
um . 
oh yeah that ' s right . 
uh this is uh the reason i did it uh was because otherwise for those of us who have to come back the same day it is really not much of a of a visit . 
uh 
so um the issue is how how how would we ever accomplish that ? 
uh 
what what what part of town do you live in ? 
um i live in um the corner of campus . 
the um southeast corner . 
okay . 
okay so would it be easier 
those of you who are not you know used to this area it can be very tricky to get to the airport at at uh you know six thirty . 
um so would it be easier for you if you came here and i drove you ? 
yeah ? 
yeah perhaps yeah . 
yeah yeah okay . 
yeah . 
yeah sure . 
okay so if if everybody can get here at six . 
at six . 
yeah i ' m afraid we need to do that to get there on time . 
six okay . 
yeah so . 
oh boy ! 
anyway . 
so 
will that be enough time ? 
yeah . 
yeah so i ' ll just pull up in front at six and just be out front . 
and uh and yeah that ' ll be plenty of time . 
it ' ll take it it it won ' t be bad traffic that time of day . 
and and uh 
i guess once you get past the bridge that that would be the worst . 
going to oakland . 
yeah oakland . 
oakland . 
yeah . 
bridge . 
once you get past the turnoff to the bay bridge . 
oh the turnoff to the bridge . 
yeah . 
won ' t even do that . 
i mean just go down martin luther king . 
yeah . 
yeah . 
okay . 
and then martin luther king to nine eighty to eight eighty . 
uhhuh . 
yeah . 
and it ' s it ' d take us tops uh thirty minutes to get there . 
oh i 
so that leaves us fifty minutes before the plane . 
it ' ll just 
yeah . 
so 
great . 
okay . 
so that ' ll 
it ' s i mean it ' s still not going to be really easy . 
but well particularly for for uh for barry and me . 
we ' re not we ' re not staying overnight . 
so we don ' t need to bring anything particularly except for uh a pad of paper . 
and so and uh you two have to bring a little bit . 
okay . 
but uh you know don ' t don ' t bring a footlocker and we ' ll be okay . 
so 
you ' re staying overnight . 
so just 
i figured you wouldn ' t need a great big suitcase . 
oh yeah yeah . 
yeah . 
that ' s sort of one night . 
so 
anyway . 
so six a m in front . 
okay . 
six a m in front . 
okay . 
uh i ' ll be here . 
uh i ' ll i ' ll i ' ll i ' ll give you my phone number . 
if i ' m not here for a few after a few minutes then 
wake you up . 
nah i ' ll be fine . 
i just uh it for me it just means getting up a half an hour earlier than i usually do . 
not not not a lot . 
okay wednesday . 
so 
okay . 
that was the real real important stuff . 
um i i i figured maybe wait on the potential goals for the meeting uh until we talk about what ' s been going on . 
so uh what ' s been going on ? 
why don ' t we start start over here . 
um well preparation of the french test data actually . 
okay . 
so it means that um 
well it is uh a digit french database of microphone speech . 
downsampled to eight kilohertz . 
i ' ve added noise to one part with the actually the aurora two noises . 
and so this is a training part . 
and then the remaining part i use for testing and with other kind of noises . 
so we can . 
so this is almost ready . 
i ' m preparing the the h t k baseline for this task . 
and yeah . 
okay . 
uh 
so the h t k base lines so this is using mel cepstra and so on . 
or 
yeah . 
yeah okay . 
and again i guess the the plan is uh to uh then given this 
what ' s the plan again ? 
the plan with these data ? 
with 
so so does just remind me of what what you were going to do with the what what what what ' s 
you just described what you ' ve been doing . 
yeah . 
so if you could remind me of what you ' re going to be doing . 
oh this is 
uh yeah . 
yeah yeah . 
tell him about the cube . 
the cube . 
i should tell him about the cube . 
yeah . 
oh cube yeah . 
yeah . 
uh we actually we want to huh uh uh analyze three dimensions . 
fill in the cube . 
the feature dimension the training data dimension and the test data dimension . 
um 
well what we want to do is first we have number for each uh task . 
so we have the um t i digit task the italian task the french task and the finnish task . 
yeah . 
so we have numbers with uh systems i mean i mean neural networks trained on the task data . 
and then to have systems with neural networks trained on uh data from the same language if possible with well using a more generic database which is phonetically phonetically balanced . 
and um . 
yeah so 
so we had talked i guess we had talked at one point about maybe the language i d corpus . 
is that a possibility for that ? 
uh yeah but uh these corpus there is a call home and a call friend also . 
the call friend is for language identification . 
well anyway these corpus are all telephone speech . 
so um this could be a a problem for why ? 
because uh uh the the speech dat databases are not telephone speech . 
they are downsampled to eight kilohertz . 
but but they are not uh with telephone bandwidth . 
yeah . 
that ' s really funny . 
isn ' t it ? 
i mean because th this whole thing is for developing new standards for the telephone . 
telephone . 
yeah . 
yeah but the the idea is to compute the feature before the before sending them to the 
well you do not send speech you send features computed on the the device . 
uhhuh . 
yeah i know . 
but the reason 
or well . 
oh i see . 
so your point is that it ' s it ' s it ' s uh the features are computed locally and so they aren ' t necessarily telephone bandwidth uh or telephone distortions . 
so you 
yeah . 
yeah . 
did you happen to find out anything about the o g i multilingual database ? 
yeah that ' s that ' s that ' s what i meant . 
yeah it ' s 
i said there ' s there ' s there ' s an o g i language i d not the not the uh 
the callfriend is a is a uh l d c thing right ? 
yeah there are also two other databases . 
one they call the multi language database and another one is a twenty two language something like that . 
but it ' s also telephone speech . 
oh they are ? 
okay . 
uh 
well nnn 
but i ' m not sure 
so 
i mean the bandwidth shouldn ' t be such an issue . 
right ? 
because this is downsampled and and filtered . 
right ? 
so it ' s just the fact that it ' s not telephone . 
and there are so many other differences between these different databases . 
i mean some of this stuff ' s recorded in the car . 
and some of it ' s 
i mean there ' s there ' s many different acoustic differences . 
yeah . 
so i ' m not sure if i mean unless we ' re going to include a bunch of car recordings in the in the training database i ' m not sure if it ' s completely rules it out . 
if our if we if our major goal is to have phonetic context and you figure that there ' s going to be a mismatch in acoustic conditions does it make it much worse to sort of add another mismatch if you will ? 
uh i i guess the question is how important is it to for us to get multiple languages uh in there . 
yeah but uhhuh um 
yeah . 
well actually for the moment if we do not want to use these phone databases we we already have uh english spanish and french uh with microphone speech . 
uh 
uhhuh . 
yeah . 
so 
so that ' s what you ' re thinking of using is sort of the the equivalent of the multiple ? 
well . 
yeah . 
for the multilingual part we were thinking of using these three databases . 
and for the difference in phonetic context that you provide that . 
well this 
uh actually these three databases are um generic databases . 
yeah . 
so for for uh italian which is close to spanish french and uh t i digits we have both uh digits training data and also more general training data . 
so huh 
well we also have this broadcast news that we were talking about taking off the disk which is is microphone data for for english . 
yeah . 
yeah perhaps yeah there is also timit . 
we could use timit . 
yeah . 
right . 
yeah so there ' s plenty of stuff around . 
okay so anyway the basic plan is to uh test this cube . 
yeah . 
yes . 
to fill in the cube . 
to fill fill it in . 
yeah . 
okay . 
yeah and perhaps um we were thinking that perhaps the cross language issue is not uh so big of a issue . 
well we perhaps we should not focus too much on that cross language stuff . 
i mean uh training training a net on a language and testing for another language . 
uhhuh . 
but that ' s 
perhaps the most important is to have neural networks trained on the target languages but uh with a general database general databases . 
so that well the the guy who has to develop an application with one language can use the net trained on that language or a generic net . 
uh it it depends how you mean using the net . 
but not trained on a 
so if you ' re talking about for producing these discriminative features that we ' re talking about you can ' t do that . 
huh . 
because because the what they ' re asking for is is a feature set . 
right ? 
and so uh we ' re the ones who have been weird by by doing this training . 
yeah . 
but if we say no you have to have a different feature set for each language i think this is going to be very bad . 
oh . 
so 
you think so . 
oh . 
that ' s 
huh . 
oh yeah . 
yeah i mean in principle i mean conceptually it ' s sort of like they want a well they want a replacement for mel cepstra . 
huh . 
so we say okay this is the year two thousand . 
we ' ve got something much better than mel cepstra . 
it ' s you know gobbledy gook . 
okay and so we give them these gobbledy gook features . 
but these gobbledy gook features are supposed to be good for any language . 
huh 
because you don ' t know who ' s going to call . 
and you know i mean so it ' s it ' s it ' s uh 
uh how do you know what language it is ? 
somebody picks up the phone . 
so this is their image . 
well i chh 
someone picks up the phone right ? 
and and he he picks up the 
yeah but the the application is 
there is a target language for the application . 
so if a 
yeah 
well 
well 
but no but you you pick up the phone . 
yeah . 
you talk on the phone . 
and it sends features out . 
okay . 
so the phone doesn ' t know what a what what your language is . 
yeah . 
if 
yeah . 
if it ' s in the phone . 
but 
well it that that could be at the server ' s side . 
but that ' s the image that they have . 
and well huh yeah . 
it could be . 
but that ' s the image they have . 
right ? 
so that ' s that ' s 
i mean one could argue all over the place about how things really will be in ten years . 
but the particular image that the cellular industry has right now is that it ' s distributed speech recognition where the uh uh probabilistic part and and semantics and so forth are all on the servers and you compute features of the uh on the phone . 
so that ' s that ' s what we ' re involved in . 
we might might or might not agree that that ' s the way it will be in ten years . 
but that ' s that ' s that ' s what they ' re asking for . 
so so i think that it is an important issue whether it works cross language . 
now it ' s the o g i uh folks ' perspective right now that probably that ' s not the biggest deal . 
and that the biggest deal is the um acoustic environment mismatch . 
and they may very well be right . 
but i i was hoping we could just do a test and determine if that was true . 
if that ' s true we don ' t need to worry so much . 
maybe maybe we have a couple languages in the training set and that gives us enough breadth uh uh that that that the rest doesn ' t matter . 
um the other thing is uh this notion of training to uh which i i guess they ' re starting to look at up there training to something more like articulatory features . 
uh and if you have something that ' s just good for distinguishing different articulatory features that should just be good across you know a wide range of languages . 
yeah . 
uh but 
yeah so i don ' t i know unfortunately i don ' t i see what you ' re where you ' re coming from i think . 
but i don ' t think we can ignore it . 
so we we really have to do test with a real cross language . 
i mean for instance training on english and testing on italian . 
or or we can train or else uh can we train a net on uh a range of languages and which can include the test the test the target language . 
test on an unseen . 
or 
yeah . 
so um 
there ' s there ' s uh 
this is complex . 
so ultimately uh as i was saying i think it doesn ' t fit within their image that you switch nets based on language . 
yeah . 
now can you include uh the the target language ? 
um from a purist ' s standpoint it ' d be nice not to . 
because then you can say when 
because surely someone is going to say at some point okay so you put in the german and the finnish . 
huh . 
uh now what do you do uh when somebody has portuguese ? 
you know ? 
um and uh however you aren ' t it isn ' t actually a constraint in this evaluation . 
so i would say if it looks like there ' s a big difference to put it in then we ' d make note of it and then we probably put in the other . 
because we have so many other problems in trying to get things to work well here that that you know it ' s not so bad as long as we we note it and say look we did do this . 
huh ? 
and so ideally what you ' d want to do is you ' d want to run it with and without the target language and the training set for a wide range of languages . 
uh 
yeah . 
yeah perhaps . 
yeah . 
yeah . 
yeah . 
and that way you can say well you know we ' re going to build it for what we think are the most common ones . 
but if that somebody uses it with a different language you know here ' s what ' s you ' re here ' s what ' s likely to happen . 
yeah because the truth is is that it ' s it ' s not like there are i mean although there are thousands of languages uh from uh uh the point of view of cellular companies there aren ' t . 
there ' s you know there ' s fifty or something . 
right . 
you know . 
so 
uh and they aren ' t you know with the exception of finnish which i guess it ' s pretty different from most most things . 
uh it ' s it ' s uh most of them are like at least some of the others . 
so our guess that spanish is like italian and and so on . 
i guess finnish is a is is a little bit like hungarian supposedly . 
right ? 
or is 
i think 
i don ' t know anything about finnish . 
well i oh well i know that uh i mean i ' m not a linguist but i guess hungarian and finnish and one of the one of the languages from the former soviet union are in this sort of same family . 
but they ' re just these you know uh countries that are pretty far apart from one another have i guess people rode in on horses and brought their 
huh . 
huh . 
okay . 
the 
yeah . 
your turn . 
oh my turn . 
oh okay . 
um let ' s see i i spent the last week uh looking over stephane ' s shoulder and and understanding some of the data . 
i reinstalled um um h t k the free version . 
so um everybody ' s now using three point o . 
which is the same version that uh o g i is using . 
oh good . 
yeah . 
so 
without without any licensing big deals or anything like that . 
and um so we ' ve been talking about this this uh cube thing . 
and it ' s beginning more and more looking like the uh the borge cube thing . 
it ' s really gargantuan . 
um 
but i ' m am i 
so are are you going to be assimilated ? 
resistance is futile . 
exactly . 
um yeah so i ' ve been looking at uh uh timit stuff . 
um the the stuff that we ' ve been working on with timit trying to get a um a labels file so we can uh train up a train up a net on timit and test um the difference between this net trained on timit and a net trained on digits alone . 
uhhuh . 
um and seeing if if it hurts or helps . 
and again when just to clarify when you ' re talking about training up a net you ' re talking about training up a net for a tandem approach ? 
anyway 
yeah yeah . 
um 
and and the inputs are p l p and delta and that sort of thing . 
uhhuh . 
well the inputs are one dimension of the cube . 
or 
which um we ' ve talked about it being uh p l p um m f c cs um j rasta j rasta l d a . 
huh . 
yeah but your initial things you ' re making one choice there . 
yeah . 
right ? 
which is p l p or something ? 
right . 
yeah . 
um i i haven ' t i haven ' t decided on on the initial thing . 
probably probably something like p l p . 
yeah . 
huh . 
um 
so so you take p l p and you you uh do it uh you you uh use h t k with it with the transformed features using a neural net that ' s trained . 
and the training could either be from digits itself or from timit . 
and that ' s the 
right . 
and and and then the testing would be these other things which which which might be foreign language . 
right . 
i see . 
right . 
i i i get in the picture about the cube . 
yeah 
okay . 
maybe . 
okay . 
okay . 
uhhuh . 
um 
i mean those listening to this will not have a picture either . 
so um i guess i ' m i ' m not any worse off . 
but 
but at some point somebody should just show me the cube . 
it sounds 
i i get i think i get the general idea of it . 
yeah yeah . 
yeah . 
so when you said that you were getting the labels for timit um are what do you mean by that ? 
uhhuh . 
oh i ' m just i ' m just uh transforming them from the um the standard timit transcriptions into into a nice long huge p file to do training . 
huh . 
were the digits um hand labeled for phones ? 
um the the digits 
or were they those labels automatically derived ? 
oh yeah . 
those were those were automatically derived by by dan using um embedded embedded training and alignment . 
huh . 
uh but which dan ? 
uh ellis . 
okay . 
right . 
okay . 
yeah so . 
i was just wondering because that test you ' re 
uhhuh . 
i i think you ' re doing this test because you want to determine whether or not uh having general speech performs as well as having specific speech . 
that ' s right . 
well especially when you go over the different languages again . 
because you ' d the different languages have different words for the different digits . 
uhhuh . 
and i was 
so it ' s 
yeah . 
so i was just wondering if the fact that timit you ' re using the hand labeled stuff from timit might be confuse the results that you get . 
i i think it would . 
but but on the other hand it might be better . 
right but if it ' s better it may be better because it was hand labeled . 
oh yeah . 
but still probably use it . 
yeah okay . 
i mean 
you know i i i guess i ' m sounding cavalier . 
but i mean i think the point is you have uh a bunch of labels and and they ' re hand uh hand marked . 
uh i guess actually timit was not entirely hand marked . 
it was automatically first and then hand hand corrected . 
but but um uh it it um it might be a better source . 
oh okay . 
so it ' s 
you ' re right . 
it would be another interesting scientific question to ask is it because it ' s a broad source or because it was you know carefully ? 
uh and that ' s something you could ask . 
uhhuh . 
but given limited time i think the main thing is if it ' s a better thing for going across languages on this training tandem system . 
yeah . 
then it ' s probably 
right . 
what about the differences in the phone sets ? 
uh between languages ? 
no between timit and the the digits . 
oh . 
um right . 
well there ' s a mapping from the sixty one phonemes in timit to to fifty six the icsi fifty six . 
sixty one . 
oh okay . 
i see . 
and then the digits phonemes um there ' s about twenty twenty two or twenty four of them . 
is that right ? 
out of that fifty six ? 
yep . 
out of that fifty six . 
oh okay . 
yeah . 
so 
it ' s it ' s definitely broader . 
yeah . 
but actually the issue of uh phoneme mappings will arise when we will do use several languages . 
yeah . 
because you well some phonemes are not uh in every languages . 
so we plan to develop a subset of the phonemes uh that includes uh all the phonemes of our training languages . 
and use a network with kind of one hundred outputs or something like that . 
uhhuh . 
uhhuh . 
you mean a superset sort of . 
uh yeah . 
superset . 
yeah yeah . 
yeah . 
yeah . 
i i looks the sampa phone . 
yeah . 
sampa phone for english uh american english and the the the language who have more phone are the english . 
huh . 
of the these language . 
but for example in spain the spanish have several phone that doesn ' t appear in the english and we thought to complete . 
but for that it needs we must do a lot of work because we need to generate new transcription for the database that we have . 
uhhuh . 
uhhuh . 
other than the language is there a reason not to use the timit phone set ? 
because it ' s larger . 
as opposed to the icsi phone set . 
oh . 
you mean why map the sixty one to the fifty six ? 
yeah . 
i don ' t know . 
i have 
um i forget if that happened starting with you or was it or if it was eric afterwards who did that . 
but i think basically there were several of the phones that were just hardly ever there . 
yeah . 
and i think some of them they were making distinctions between silence at the end and silence at the beginning . 
oh . 
when really they ' re both silence . 
i i think it was things like that that got it mapped down to fifty six . 
okay . 
yeah especially in a system like ours which is a discriminative system . 
you know you ' re really asking this net to learn . 
yeah . 
yeah . 
it ' s it ' s kind of hard . 
there ' s not much difference really . 
and the ones that are gone i think are i think there was they also in timit had like a glottal stop . 
which was basically a short period of silence . 
uhhuh . 
and so 
well we have that now too right ? 
i don ' t know . 
yeah . 
it ' s actually pretty common that a lot of the recognition systems people use have things like like say thirty nine phone symbols . 
so 
right ? 
uh and then they get the variety by by bringing in the context the phonetic context . 
uh so we actually have an unusually large number in in what we tend to use here . 
um 
so actually maybe now you ' ve got me sort of intrigued . 
what there ' s 
can you describe what what ' s on the cube ? 
yeah . 
i mean 
i i think that ' s a good idea . 
yeah yeah . 
to to talk about the whole cube . 
yeah yeah . 
and maybe we could sections in the cube for people to work on . 
yeah . 
yeah . 
um 
okay . 
okay . 
uh do you want to do it ? 
so even even though the meeting recorder doesn ' t doesn ' t uh 
and since you ' re not running a video camera we won ' t get this . 
but if you use a board it ' ll help us anyway . 
okay . 
uh point out one of the limitations of this medium . 
okay . 
but you ' ve got the wireless on . 
right ? 
yeah . 
i have the wireless . 
yeah . 
so you can walk around . 
okay . 
can can you walk around too ? 
no . 
okay . 
well . 
uh he can ' t actually . 
um 
but 
he ' s tethered . 
basically the the cube will have three dimensions . 
the first dimension is the the features that we ' re going to use . 
and the second dimension um is the training corpus . 
and that ' s the training on the discriminant neural net . 
um 
and 
the last dimension happens to be 
yeah and again 
yeah so the the training for h t k is always that ' s always set up for the individual test . 
right ? 
that there ' s some training data and some test data . 
so that ' s different than this . 
right right . 
this is this is for for a n n only . 
and yeah the training for the h t k models is always uh fixed for whatever language you ' re testing on . 
right . 
and then there ' s the testing corpus . 
so then i think it ' s probably instructive to go and and and show you the features that we were talking about . 
um 
so let ' s see . 
help me out with 
p l p . 
with what ? 
p l p . 
p l p ? 
okay . 
m s g . 
m s g . 
uh j rasta . 
j rasta . 
and j rasta l d a . 
j rasta l d a . 
um 
multi band . 
multi band . 
so there would be multi band before um before our network i mean . 
yeah . 
just the multi band features right ? 
and 
yeah . 
yeah . 
so something like uh t c t within bands . 
uh uh . 
and well 
and then multi band after networks meaning . 
that we would have uh neural networks uh discriminant neural networks for each band . 
uh yeah . 
and using the the outputs of these networks or the linear outputs or something like that . 
uh 
yeah . 
what about mel cepstrum ? 
oh um 
or is that 
you don ' t include that because it ' s part of the base or something ? 
well you do have a baseline system that ' s that ' s mel cepstra . 
yeah databases . 
yeah . 
right ? 
so 
uhhuh . 
but uh 
well 
not for the the a n n . 
i mean 
okay . 
so yeah . 
we could we could add m f c c also . 
we could add 
probably should . 
i mean at least at least conceptually you know it doesn ' t meant you actually have to do it . 
yeah . 
yeah . 
but 
conceptually it makes sense as a as a base line . 
it ' d be an interesting test just to have just to do m f c c with the neural net . 
without the 
yeah . 
and everything else the same . 
compare that with just m f c c without the the net . 
yeah . 
uhhuh . 
i think i think dan did some of that . 
oh . 
um in his previous aurora experiments . 
and with the net it ' s it ' s wonderful . 
without the net it ' s just baseline . 
um i think o g i folks have been doing that too . 
because i think that for a bunch of their experiments they used uh mel cepstra actually . 
yeah . 
yeah . 
um of course that ' s there and this is here and so on . 
okay . 
okay . 
um for the training corpus corpus um we have um the the digits from the various languages . 
um english . 
spanish . 
um french . 
what else do we have ? 
and the finnish . 
finnish . 
and italian . 
where did where did that come from ? 
uh no italian no . 
digits ? 
italian no . 
oh . 
oh italian . 
italian yes . 
italian . 
italian . 
is that was that distributed with aurora ? 
or 
one l or two l s ? 
the newer one . 
where did that 
so english uh finnish and italian are aurora . 
yeah . 
and spanish and french is something that we can use in addition to aurora . 
uh well 
yeah . 
so carmen brought the spanish . 
and stephane brought the french . 
okay . 
and 
um 
oh yeah . 
is it french french or belgian french ? 
and 
there ' s a 
it ' s uh french french . 
french french . 
like mexican spain and spain . 
yeah . 
or swiss . 
i think that is more important . 
swiss german . 
mexican spain . 
yeah . 
because more people 
yeah . 
probably so . 
yeah . 
yeah . 
yeah herve always insists that belgian is is absolutely pure french . 
has nothing to do with 
but he says those those those parisians talk funny . 
yeah yeah yeah . 
they have an accent . 
yeah they 
they do yeah . 
yeah but then he likes belgian fries too . 
so 
okay . 
and then we have uh um broader broader corpus um like timit . 
timit so far . 
and spanish too . 
right ? 
spanish . 
oh spanish stories ? 
albayzin is the name . 
what about t i digits ? 
um t i digits 
uh all these aurora data data is from is derived from t i digits . 
uhhuh . 
oh oh okay . 
um basically they they corrupted it with uh different kinds of noises at different s n r levels . 
uh . 
i see . 
yeah . 
and i think stephane was saying there ' s there ' s some broader material in the french also . 
yeah . 
we we could use 
yeah . 
okay . 
the french data . 
spanish stories ? 
no . 
no . 
not spanish stories . 
no . 
spanish . 
no 
spanish something . 
yeah . 
okay . 
did the aurora people actually corrupt it themselves ? 
or just specify the signal and the signal - t 0 - noise ratio ? 
they they corrupted it um themselves . 
okay . 
but they also included the the noise files for us . 
right ? 
or 
yeah . 
so we can go ahead and corrupt other things . 
i ' m just curious carmen . 
i mean i couldn ' t tell if you were joking or 
is it is it mexican spanish ? 
or is it 
no no no no . 
oh no no . 
no no no no . 
it ' s it ' s spanish from spain spanish . 
spanish from spain . 
yeah okay . 
from spain . 
all right . 
spanish from spain . 
we ' re really covered there . 
okay . 
and the french from france . 
okay . 
yeah . 
no the french is yeah from uh paris . 
oh . 
from paris . 
okay . 
yeah . 
okay . 
and timit ' s from lots of different places . 
from t i . 
it ' s from texas . 
so maybe it ' s 
from the deep south . 
so it ' s not really from the u s either . 
is that okay ? 
yeah . 
yeah . 
okay . 
and um 
within the training corporas um we ' re uh thinking about um training with noise . 
so 
incorporating the same kinds of noises that um aurora is incorporating in their um in their training corpus . 
um i don ' t think we ' re given the uh the unseen noise conditions though . 
right ? 
i think what they were saying was that um for this next test there ' s going to be some of the cases where they have the same type of noise as you were given before hand and some cases where you ' re not . 
like 
uhhuh . 
uhhuh . 
okay . 
so presumably that ' ll be part of the topic of analysis of the the test results is how well you do when it ' s matching noise and how well you do where it ' s not . 
right . 
i think that ' s right . 
so i guess we can ' t train on on the the unseen noise conditions . 
well not if it ' s not seen . 
right . 
if not if it ' s unseen . 
yeah . 
yeah . 
i mean it does seem to me that a lot of times when you train with something that ' s at least a little bit noisy it can it can help you out in other kinds of noise . 
even if it ' s not matching . 
just because there ' s some more variance that you ' ve built into things . 
but but uh 
uhhuh . 
uh exactly how well it will work will depend on how near it is to what you had ahead of time . 
so okay so that ' s your training corpus . 
uhhuh . 
and then your testing corpus ? 
um the testing corporas are um just um the same ones as aurora testing . 
and that includes um the english um italian finnish . 
finnish . 
uh we ' re going to get german . 
right ? 
at the final test will have german . 
well so 
yeah . 
the final test on a guess is supposed to be german and danish . 
uh yeah . 
right ? 
right . 
the 
yeah . 
the spanish perhaps . 
spanish . 
we will have 
oh yeah . 
we can we can test on spanish . 
yeah . 
but the the aurora spanish i mean . 
oh yeah . 
uhhuh . 
oh there ' s a there ' s spanish testing in the aurora ? 
uh not yet . 
but uh uh 
yeah . 
it ' s preparing . 
they are preparing it . 
and well 
they are preparing . 
according to hynek it will be we will have this at the end of november . 
or um 
okay . 
so uh 
yeah . 
something like seven things in each uh each column . 
so that ' s uh three hundred and forty three uh different systems that are going to be developed . 
there ' s three of you . 
uh 
so that ' s 
yeah one hundred each about . 
hundred and hundred and fourteen each . 
what what about noise conditions ? 
what ? 
don ' t we need to put in the column for noise conditions ? 
are you just trying to be difficult ? 
no . 
i just don ' t understand . 
well 
uh 
i ' m just kidding . 
when when i put these testings on there i ' m 
yeah . 
there ' s three three tests . 
um 
type a type b and type c . 
and they ' re all they ' re all going to be tested um with one training of the h t k system . 
um there ' s a script that tests all three different types of noise conditions . 
test a is like a matched noise . 
test b is a is a slightly mismatched . 
and test c is a um mismatched channel . 
and do we do all our training on clean data ? 
um 
also we can clean that 
no no . 
no . 
we ' re we ' re going to be um training on the noise files that we do have . 
so 
um 
yeah . 
so i guess the question is how long does it take to do a a training ? 
i mean it ' s not totally crazy . 
i mean these are a lot of these are built in things . 
and we know we have programs that compute p l p . 
we have m s g . 
we have j 
you know a lot of these things will just kind of happen . 
won ' t take uh a huge amount of development . 
it ' s just trying it out . 
so we actually can do quite a few experiments . 
but how how long does it take do we think for one of these trainings ? 
uhhuh . 
that ' s a good question . 
what about combinations of things ? 
oh yeah . 
that ' s right . 
i mean because 
so for instance i think the major advantage of m s g 
oh . 
yeah . 
och ! 
good point . 
major advantage of m s g i see that we ' ve seen in the past is combined with p l p . 
yeah . 
um 
now this is turning into a four dimensional cube ? 
or you just add it to the features . 
no . 
well you just select multiple things on the one dimension . 
here . 
just 
oh yeah . 
okay . 
yeah . 
so i mean 
you don ' t want to 
uh 
let ' s see . 
seven choose two would be uh twenty one different combinations . 
um 
it ' s not a complete set of combinations though . 
probably 
right ? 
what ? 
it ' s not a complete set of combinations though . 
no . 
right ? 
yeah . 
i hope not . 
yeah . 
there ' s 
that would be 
uh 
yeah . 
so p l p and m s g i think we definitely want to try . 
because we ' ve had a lot of good experience with putting those together . 
uhhuh . 
um 
yeah . 
when you do that you ' re increasing the size of the inputs to the net . 
do you have to reduce the hidden layer or something ? 
well so 
i mean 
so it doesn ' t increase the number of trainings . 
no no . 
i ' m i ' m just wondering about number of parameters in the net . 
do you have to worry about keeping that the same ? 
or 
uh i don ' t think so . 
there ' s a computation limit though . 
isn ' t there ? 
yeah . 
i mean it ' s just more 
excuse me ? 
isn ' t there like a limit on the computation load or latency or something like that for aurora task ? 
oh yeah . 
we haven ' t talked about any of that at all . 
have we ? 
no . 
yeah . 
so there ' s not really a limit . 
what it is is that there ' s there ' s uh it ' s just penalty . 
you know ? 
that that if you ' re using uh a megabyte then they ' ll say that ' s very nice . 
but of course it will never go on a cheap cell phone . 
um 
okay . 
and 
uh i think the computation isn ' t so much of a problem . 
i think it ' s more the memory . 
uh and expensive cell phones expensive hand helds and so forth are going to have lots of memory . 
so it ' s just that uh these people see the the cheap cell phones as being still the biggest market . 
so 
uhhuh . 
um 
but yeah . 
i was just realizing that actually it doesn ' t explode out . 
um 
it ' s not really two to the seventh . 
but it ' s but but it doesn ' t really explode out the number of trainings . 
because these were all trained individually . 
right ? 
so 
uh if you have all of these nets trained some place then uh you can combine their outputs and do the k l transformation and so forth . 
and and uh 
uhhuh . 
so what it it blows out is the number of uh testings . 
and you know and the number of times you do that last part . 
but that last part i think is so has got to be pretty quick . 
so 
uh 
right . 
i mean it ' s just running the data through . 
oh . 
well you got to do the k l transformation . 
but what about a net that ' s trained on multiple languages though ? 
eight 
but 
is that just separate nets for each language then combined ? 
necessary to put in . 
or is that actually one net trained on ? 
uh probably one net . 
good question . 
well . 
uh 
one would think one net . 
so 
but we ' ve i don ' t think we ' ve tested that . 
right ? 
so in the broader training corpus we can we can use uh the three or a combination of of two two languages . 
database three . 
in one net . 
yeah . 
uhhuh . 
yeah . 
so i guess the first thing is if if we know how much a how long a a training takes . 
if we can train up all these these combinations uh then we can start working on testing of them individually and in combination . 
right ? 
because the putting them in combination i think is not as much computationally as the training of the nets in the first place . 
uhhuh . 
right ? 
yeah . 
so you do have to compute the k l transformation . 
uh 
which is a little bit . 
but it ' s not too much . 
it ' s not too much . 
no . 
yeah . 
so it ' s 
but yeah . 
but there is the testing also which implies training uh the h t k models . 
the the model . 
and well 
the h t k model . 
uh right . 
it ' s 
right . 
yeah . 
so if you do have lots of combinations it ' s 
but it ' s it ' s it ' s not so long . 
it 
yeah . 
how long does it take for an uh h t k training ? 
it ' s around six hours i think . 
it depends on the 
for training and testing . 
yeah . 
more than six hours . 
more . 
for the italian . 
yes . 
maybe one day . 
one day . 
for h t k ? 
yeah . 
really ? 
well . 
running on what ? 
uh m f c c . 
no . 
i ' m sorry . 
running on what machine ? 
uh ravioli . 
uh 
i don ' t know what ravioli is . 
is it is it an ultra five ? 
or is it a 
huh . 
um who is that ? 
i don ' t know . 
i don ' t know . 
i don ' t know . 
i don ' t know what a ravioli is . 
i don ' t know . 
i don ' t know . 
we can check really quickly . 
yeah . 
i guess . 
i think it ' s not so long . 
because well the t i digits test data is about uh many hours . 
uh uh thirty hours of speech i think . 
it ' s a few hours . 
something like that . 
huh . 
yeah right . 
and it 
well . 
so 
i mean 
clearly there ' s no way we can even begin to do any significant amount here unless we use multiple machines . 
it ' s six hours . 
right ? 
so we 
i mean there ' s plenty of machines here . 
and they ' re they ' re often not in in a great great deal of use . 
so i mean i think it ' s it ' s key that that the that you look at uh you know what machines are fast what machines are used a lot . 
uh are we still using p make ? 
is that 
oh . 
i don ' t know how how we would p make this though . 
um 
well you have a 
i mean once you get the basic thing set up you have just all the uh all these combinations . 
yeah . 
right ? 
uhhuh . 
um 
it ' s let ' s say it ' s six hours or eight hours or something for the training of h t k . 
how long is it for training of of uh the neural net ? 
the neural net ? 
um 
i would say two days . 
depends on the corpuses right ? 
it depends . 
yeah . 
it also depends on the net . 
depends on the corpus . 
yeah . 
how big is the net ? 
for albayzin i trained on neural network . 
uh was um one day also . 
uh 
but on what machine ? 
on a spert board . 
uh 
i i think the neural net spert . 
you did a you did it on a spert board . 
okay . 
yes . 
again we do have a bunch of spert boards . 
yeah . 
and i think there ' s i think you folks are probably the ones using them right now . 
is it faster to do it on the spert ? 
or 
uh don ' t know . 
used to be . 
it ' s it ' s still a little faster on the sperts . 
is it ? 
yeah . 
yeah . 
adam adam did some testing . 
or either adam or or dan did some testing . 
and they found that the spert board ' s still still faster . 
and the benefits is that you know you run out of spert and then you can do other things on your your computer . 
uhhuh . 
uhhuh . 
and you don ' t 
uhhuh . 
yeah . 
so you could be 
we have quite a few spert boards . 
you could set up uh you know ten different jobs or something to run on spert different spert boards . 
and and have ten other jobs running on different computers . 
so it ' s got to take that sort of thing . 
or or we ' re not going to get through any significant number of these . 
yeah . 
uh 
so this is 
yeah i mean 
i kind of like this because what it 
no . 
what i like about it is 
okay . 
we we we do have a problem . 
that we have very limited time . 
you know . 
so with very limited time we actually have really quite a quite a bit of computational resource available . 
if you you know get a look across the institute and how little things are being used . 
and uh 
on the other hand almost anything that really you know is is new where we ' re saying well let ' s look at like we were talking before about uh uh voiced - unvoiced - silence detection features and all those sort that ' s 
yeah . 
i think it ' s a great thing to go to . 
but if it ' s new then we have this development and and and learning process to to go through on top of just the the all the all the work . 
so i i i don ' t see how we ' d do it . 
so what i like about this is you basically have listed all the things that we already know how to do . 
and and all the kinds of data that we at this point already have . 
yeah . 
and uh you ' re just saying let ' s look at the outer product of all of these things . 
and see if we can calculate them . 
am i am i interpreting this correctly ? 
is this sort of what what you ' re thinking of doing in the short term ? 
huh . 
okay . 
yeah . 
so so then i think it ' s just the the missing piece is that you need to uh you know you know talk to talk to uh chuck talk to uh adam . 
uh sort out about uh what ' s the best way to really you know attack this as a as a as a mass problem in terms of using many machines . 
uh 
and uh then you know set it up in terms of scripts and so forth and uh in in kind some kind of structured way . 
uh 
um and you know when we go to uh o g i next week uh we can then present to them you know what it is that we ' re doing . 
and uh we can pull things out of this list that we think they are doing sufficiently . 
huh . 
that you know we ' re not we won ' t be contributing that much . 
uhhuh . 
um 
and uh 
then uh like we ' re there . 
how big are the nets you ' re using ? 
um for the for nets trained on digits um we have been using uh four hundred order hidden units . 
and um for the broader class nets we ' re we ' re going to increase that . 
because the um the digits nets only correspond to about twenty phonemes . 
uhhuh . 
so 
broader class ? 
um the broader broader training corpus nets . 
like timit . 
um we ' re going to 
oh . 
it ' s not actually broader class . 
it ' s actually finer class . 
but you mean you mean more classes . 
right . 
right . 
yeah . 
more classes . 
right right . 
yeah . 
more classes . 
yeah . 
that ' s what i mean . 
yeah . 
uhhuh . 
and 
yeah . 
carmen did you do you have something else to add ? 
we you haven ' t talked too much . 
and 
i begin to work with the italian database to nnn to with the front end and with the h t k program and the . 
and i trained uh with the spanish two neural network with p l p and with lograsta p l p . 
i don ' t know exactly what is better if if lograsta or j rasta . 
well um j rasta has the potential to do better . 
but it doesn ' t always . 
it ' s j rasta is more complicated . 
it ' s it ' s uh instead of doing rasta with a log you ' re doing rasta with a log like function that varies depending on a j parameter . 
uh which is supposed to be sensitive to the amount of noise there is . 
so it ' s sort of like the right transformation to do the filtering in is dependent on how much noise there is . 
huh huh . 
and so in j rasta you attempt to do that . 
it ' s a little complicated . 
because once you do that you end up in some funny domain . 
and you end up having to do a transformation afterwards . 
which requires some tables . 
and uh 
so it ' s it ' s it ' s a little messier . 
huh huh . 
uh there ' s more ways that it can go wrong . 
uh but if if if you ' re careful with it it can do better . 
it ' s a bit i ' ll do better . 
so it ' s 
so 
um and i think to to to recognize the italian digits with the neural spanish neural network . 
and also to train another neural network with the spanish digits . 
the database of spanish digits . 
and i working that . 
yeah . 
but to prepare the the database are difficult . 
was for me it was a difficult work last week with the labels . 
because the the program with the label obtained that i have the albayzin is different to the label to train the neural network . 
and that is another work that we must to do to to change . 
i didn ' t understand . 
uh for example albayzin database was labeled automatically with h t k . 
it ' s not hand . 
it ' s not labels by hand . 
oh . 
labeled . 
i ' m sorry . 
labels . 
i have a i had a problem with the pronunciation . 
i ' m sorry . 
i ' m sorry . 
the labels . 
i ' m sorry . 
the labels . 
yeah . 
okay . 
so 
okay . 
oh also that 
so let ' s start over . 
so timit ' s hand labeled . 
yes . 
and and you ' re saying about the spanish ? 
the spanish labels . 
that was in different format . 
oh i see . 
that the format for the them the program to train the neural network . 
i necessary to convert . 
and 
well 
so you ' re just having a problem converting the labels . 
it ' s it ' s 
yeah . 
yeah . 
but 
yes . 
because they have one program feacalc . 
but no . 
labecut but don ' t doesn ' t uh include the h t k format to convert . 
uhhuh . 
and 
huh . 
i don ' t know what . 
i ask even i ask to dan ellis what i can do that . 
and they he say me that he doesn ' t any any any form to to do that . 
and at the end i think that with labecut i can transfer to ascii format . 
and h t k is an ascii format . 
and i do another uh one program to put ascii format of h t k to ascii format to exceed . 
uhhuh . 
and they used labcut to to pass . 
okay . 
yeah . 
actually that was complicated . 
so you 
but well i know how we can did that do that . 
sure . 
so it ' s just usual kind of uh sometimes say housekeeping . 
right ? 
to get these get these things sorted out . 
yeah . 
so it seems like there ' s there ' s some peculiarities of the uh of each of these dimensions that are getting sorted out . 
and then um if if you work on getting the uh assembly lines together and then the the pieces sort of get ready to go into the assembly line . 
and gradually can start you know start turning the crank more or less . 
and uh uh 
we have a lot more computational capability here than they do at o g i . 
so i think that if 
what ' s what ' s great about this is it sets it up in a very systematic way . 
so that uh once these all of these you know mundane but real problems get sorted out we can just start turning the crank . 
uhhuh . 
and and push all of us through . 
and then finally figure out what ' s best . 
yeah . 
um 
i i was thinking two things . 
uh the first thing was um 
we we actually had thought of this as sort of like um not not in stages but more along the the time axis . 
just kind of like one stream at a time . 
uhhuh . 
je - je - je - je - je check out the results . 
and and go that way . 
oh yeah yeah . 
sure . 
no i ' m just saying i ' m just thinking of it like loops . 
right ? 
and so if you had three nested loops that you have a choice for this a choice for this and a choice for that . 
uhhuh . 
yeah . 
right ? 
and you ' re going through them all . 
uhhuh . 
that that ' s what i meant . 
right . 
right . 
and uh the thing is that once you get a better handle on how much you can realistically do uh um concurrently on different machines different sperts and so forth uh and you see how long it takes on what machine and so forth you can stand back from it and say okay if we look at all these combinations we ' re talking about and combinations of combinations and so forth you ' ll probably find you can ' t do it all . 
uhhuh . 
okay . 
okay . 
so then at that point uh we should sort out which ones do we throw away . 
which of the combinations across you know what are the most likely ones . 
uhhuh . 
and 
and uh 
i still think we could do a lot of them . 
i mean it wouldn ' t surprise me if we could do a hundred of them or something . 
but probably when you include all the combinations you ' re actually talking about a thousand of them or something . 
and that ' s probably more than we can do . 
uh 
but a hundred is a lot . 
and and uh um 
okay . 
yeah . 
yeah . 
and the the second thing was about scratch space . 
and i think you sent an email about um scratch space for for people to work on . 
and i know that uh stephane ' s working from an n t machine . 
so his his home directory exists somewhere else . 
his his stuff is somewhere else . 
yeah . 
yeah . 
i mean my point 
i i want to 
yeah . 
thanks for bring it back to that . 
my i want to clarify my point about that that that chuck repeated in his note . 
um 
we ' re over the next year or two we ' re going to be upgrading the networks in this place . 
uhhuh . 
but right now they ' re still all pretty much all ten megabit lines . 
and we have reached the this the machines are getting faster and faster . 
so it actually has reached the point where it ' s a significant drag on the time for something to move the data from one place to another . 
uhhuh . 
so you you don ' t especially in something with repetitive computation where you ' re going over it multiple times you do don ' t want to have the the data that you ' re working on distant from where it ' s being where the computation ' s being done if you can help it . 
uhhuh . 
uh 
now we are getting more disk for the central file server . 
which since it ' s not a computational server would seem to be a contradiction to what i just said . 
but the idea is that uh suppose you ' re working with uh this big bunch of multi multi lingual databases . 
um 
you put them all in the central at the central file server . 
uhhuh . 
then when you ' re working with something and accessing it many times you copy the piece of it that you ' re working with over to some place that ' s close to where the computation is and then do all the work there . 
and then that way you you won ' t have the the network you won ' t be clogging the network for yourself and others . 
huh . 
that ' s the idea . 
so uh it ' s going to take us 
it may be too late for this uh precise crunch we ' re in now . 
but uh 
we ' re 
uh 
it ' s going to take us a couple weeks at least to get the uh uh the amount of disk we ' re going to be getting we ' re actually going to get . 
uh i think four more uh thirty six gigabyte drives . 
and uh put them on another another disk rack 
we ran out of space on the disk rack that we had . 
so we ' re getting another disk rack and four more drives to share between uh primarily between this project and the meetings meetings project . 
um 
but uh 
we ' ve put another i guess there ' s another eighteen gigabytes that ' s that ' s in there now to help us with the immediate crunch . 
but uh 
are you saying 
so i don ' t know where you ' re 
stephane where you ' re doing your computations ? 
if so you ' re on n t machine . 
so you ' re using some external machine too . 
yeah . 
it 
uh 
well 
to 
it ' s nutmeg and mustard i think . 
it uh 
do you know these yet ? 
i don ' t know what kind . 
nuh uh . 
yeah okay . 
uh 
are these are these uh computational servers or something ? 
i ' m i ' ve been kind of out of it . 
yeah . 
i think yeah . 
i think so . 
huh . 
unfortunately these days my idea of running of doing computation is running a spread sheet . 
so 
huh . 
uh 
haven ' t been haven ' t been doing much computing personally . 
so 
um 
yeah . 
so those are computational servers . 
so i guess the other question is what disk there space there is there on the computational servers . 
right . 
yeah i ' m not sure what ' s available on 
is it 
you said nutmeg . 
and what was the other one ? 
mustard . 
mustard . 
okay . 
yeah . 
huh . 
well you ' re the you ' re the disk czar now . 
so 
right right . 
well i ' ll check on that . 
yeah . 
yeah so basically uh chuck will be the one who will be sorting out what disk needs to be where and so on . 
and i ' ll be the one who says okay spend the money . 
which i mean 
these days uh if you ' re talking about scratch space it doesn ' t increase the uh need for backup . 
and uh i think it ' s not that big a 
and the the disks themselves are not that expensive . 
right now it ' s 
what you can do when you ' re on that machine is uh just go to the slash scratch directory and do a d f minus k . 
and it ' ll tell you if there ' s space available . 
yeah . 
uh and if there is then uh 
but wasn ' t it uh 
i think dave was saying that he preferred that people didn ' t put stuff in slash scratch . 
it ' s more putting in x a or x b or 
well there ' s different there um there ' s 
right ? 
right . 
so there ' s the slash x whatever disks and then there ' s slash scratch . 
and both of those two kinds are not backed up . 
and if it ' s called slash scratch it means it ' s probably an internal disk to the machine . 
um 
and so that ' s the kind of thing where like if um okay if you don ' t have an n t but you have a a a unix workstation and they attach an external disk it ' ll be called slash x something uh if it ' s not backed up . 
and it ' ll be slash d something if it is backed up . 
and if it ' s inside the machine on the desk it ' s called slash scratch . 
but the problem is if you ever get a new machine they take your machine away . 
it ' s easy to unhook the external disks . 
put them back on the new machine . 
but then your slash scratch is gone . 
so you don ' t want to put anything in slash scratch that you want to keep around for a long period of time . 
but if it ' s a copy of say some data that ' s on a server you can put it on slash scratch . 
because um first of all it ' s not backed up . 
and second it doesn ' t matter if that machine disappears and you get a new machine . 
because you just recopy it to slash scratch . 
so that ' s why i was saying you could check slash scratch on those on on um mustard and and nutmeg to see if if there ' s space that you could use there . 
i see . 
you could also use slash x whatever disks on mustard and nutmeg . 
yeah yeah . 
um 
yeah . 
and we do have 
i mean 
yeah . 
so so you 
yeah it ' s better to have things local if you ' re going to run over them lots of times so you don ' t have to go to the network . 
right . 
so so especially if you ' re right if you ' re if you ' re taking some piece of the training corpus which usually resides in where chuck is putting it all on the on the uh file server uh then yeah it ' s fine if it ' s not backed up . 
because if it gets wiped out or something i mean it is backed up on the other disk . 
so 
uhhuh . 
yeah . 
okay . 
yeah so one of the things that i need to i ' ve started looking at 
uh is this the appropriate time to talk about the disk space stuff ? 
sure . 
i ' ve started looking at um disk space . 
dan david um put a new um drive onto abbott that ' s an x disk . 
which means it ' s not backed up . 
so 
um i ' ve been going through and copying data that is you know some kind of corpus stuff usually that that we ' ve got on a c d rom or something onto that new disk to free up space on other disks . 
and um so far um i ' ve copied a couple of carmen ' s um databases over there . 
we haven ' t deleted them off of the slash d c disk that they ' re on right now in abbott . 
um 
uh but we i would like to go through sit down with you about some of these other ones and see if we can move them onto um this new disk also . 
yeah okay . 
there ' s there ' s a lot more space there . 
and it ' ll free up more space for doing the experiments and things . 
so anything that that you don ' t need backed up we can put on this new disk . 
um but if it ' s experiments and you ' re creating files and things that you ' re going to need you probably want to have those on a disk that ' s backed up just in case something goes wrong . 
so 
um 
so far i ' ve i ' ve copied a couple of things . 
but i haven ' t deleted anything off of the old disk to make room yet . 
um 
and i haven ' t looked at the any of the aurora stuff . 
except for the spanish . 
so i i guess i ' ll need to get together with you and see what data we can move onto the new disk . 
yeah okay . 
um 
yeah . 
i i just 
another question occurred to me is is what were you folks planning to do about normalization ? 
um 
well we were thinking about using this systematically for all the experiments . 
um 
this being ? 
so 
but 
uh 
so that this could be another dimension . 
but we think perhaps we can use the the best uh um uh normalization scheme as o g i is using . 
so with parameters that they use there . 
yeah . 
i think that ' s a good idea . 
i mean it ' s we we seem to have enough dimensions as it is . 
so probably if we sort of take their 
yeah yeah yeah . 
probably the online line normalization . 
because then it it ' s if we do anything else we ' re going to end up having to do online normalization too . 
so we may as well just do online normalization . 
uhhuh . 
so 
so that it ' s plausible for the final thing . 
good . 
um 
so i guess 
yeah the other topic 
i maybe we ' re already there or almost there is goals for the for next week ' s meeting . 
uh it seems to me that we want to do is flush out what you put on the board here . 
uh 
you know maybe have it be somewhat visual little bit . 
okay . 
like a like a slide ? 
uh 
so we can say what we ' re doing . 
yeah . 
okay . 
and um also if you have sorted out um this information about how long roughly how long it takes to do on what and you know what we can how many of these trainings uh uh and testings and so forth that we can realistically do uh then one of the big goals of going there next week would be to to actually settle on which of them we ' re going to do . 
and uh when we come back we can charge in and do it . 
um 
anything else that 
actually started out this this field trip started off with with uh stephane talking to hynek . 
so you may have you may have had other goals uh for going up . 
and anything else you can think of would be we should think about accomplishing ? 
i mean i ' m just saying this because maybe there ' s things we need to do in preparation . 
oh i think basically this is this is 
uh yeah . 
okay . 
okay . 
uh 
all right . 
and uh and the other the the last topic i had here was um uh dave ' s fine offer to to uh do something on this . 
i mean he ' s doing he ' s working on other things . 
but to to do something on this project . 
so the question is where where could we uh uh most use dave ' s help ? 
um 
yeah . 
i was thinking perhaps if um additionally to all these experiments which is not really research . 
well i mean it ' s uh running programs . 
yeah . 
and um trying to have a closer look at the perhaps the um speech uh noise detection or uh voiced - sound - unvoiced - sound detection . 
and which could be important in for noise noise . 
i think that would be a i think that ' s a big big deal . 
because the you know the thing that sunil was talking about uh with the labels uh labeling the database when it got to the noisy stuff . 
the that that really throws things off . 
you know having the noise all of a sudden your your um speech detector . 
i mean the the um 
what was it ? 
um . 
what was happening with his thing ? 
he was running through these models very quickly . 
he was getting lots of uh uh insertions is what it was . 
in his recognitions . 
the only problem 
i mean maybe that ' s the right thing . 
the only problem i have with it is exactly the same reason why you thought it ' d be a good thing to do . 
um i i think that 
let ' s fall back to that . 
but i think the first responsibility is sort of to figure out if there ' s something that uh an an additional 
uh 
that ' s a good thing you remove the mike . 
go ahead . 
good . 
uh 
uh 
what an additional clever person could help with when we ' re really in a crunch for time . 
right ? 
because dave ' s going to be around for a long time . 
all right ? 
yeah . 
he ' s he ' s going to be here for years . 
yeah . 
and so um 
over years if he ' s if he ' s interested in you know voiced - unvoiced - silence he could do a lot . 
but if there if in fact there ' s something else that he could be doing would help us when we ' re we ' re sort of uh strapped for time . 
we have we we ' ve you know only uh another another month or two to you know with the holidays in the middle of it um to to get a lot done . 
if we can think of something some piece of this that ' s going to be 
the very fact that it is sort of just work and and it ' s running programs and so forth is exactly why it ' s possible that it some piece of could be handed to someone to do . 
because it ' s not 
uh yeah . 
so that that ' s the question . 
and we don ' t have to solve it right this second . 
but if we could think of some some piece that ' s that ' s well defined that he could help with . 
he ' s expressing a willingness to do that . 
what about training up a um a multilingual net ? 
uh 
yes . 
yeah . 
maybe to huh put together the the label the labels between timit and spanish or something like that . 
yeah . 
so defining the superset . 
yes . 
and uh joining the data . 
and huh 
yeah . 
yeah . 
uh 
yeah . 
that ' s something that needs to be done . 
in any event . 
yeah . 
so what we were just saying is that that um i was arguing for if possible coming up with something that that really was development and wasn ' t research . 
because we we ' re we have a time crunch . 
and so uh if there ' s something that would would save some time that someone else could do on some other piece then we should think of that first . 
see the thing with voiced - unvoiced - silence is i really think that that it ' s to do to do a a a a poor job is is pretty quick . 
uh 
or you know a so so job . 
you can you can you can throw in a couple 
we know what what kinds of features help with it . 
huh . 
you can throw something in . 
you can do pretty well . 
but i remember in fact when you were working on that . 
and you worked on for few months as i recall . 
and you got to say ninety three percent . 
and getting to ninety four really really hard . 
uhhuh . 
another year . 
yeah . 
yeah . 
so 
um 
and the other tricky thing is since we are 
uh even though we ' re not we don ' t have a strict prohibition on memory size and and computational complexity uh clearly there ' s some limitation to it . 
so if we have to if we say we have to have a pitch detector say if we if we ' re trying to incorporate pitch information or at least some kind of harmonic harmonicity or something this is another whole thing . 
take a while to develop . 
anyway it ' s a very very interesting topic . 
i mean one i think one of the a lot of people would say and i think dan would also uh that one of the things wrong with current speech recognition is that we we really do throw away all the harmonicity information . 
uh we try to get spectral envelopes . 
reason for doing that is that most of the information about the phonetic identity is in the spectral envelopes are not in the harmonic detail . 
but the harmonic detail does tell you something . 
like the fact that there is harmonic detail is is real important . 
so 
um 
so uh 
so i think 
yeah . 
so that so the the other suggestion just came up was well what about having him work on the uh multi lingual superset kind of thing . 
uh coming up with that and then you know training it training a net on that say um from from uh from timit or something . 
is that or uh for multiple databases . 
what what would you what would you think it would 
what would this task consist of ? 
yeah it would consist in uh 
well . 
um creating the the superset . 
and uh modifying the labels for matching the superset . 
uh 
uh creating a superset from looking at the multiple languages . 
well creating the mappings actually . 
and then creating changing labels on timit ? 
yeah . 
or on or on multiple language multiple languages ? 
no . 
yeah yeah . 
the multiple language . 
with the three languages . 
maybe for the other language . 
because timit have more phone . 
yeah . 
uh . 
so you ' d have to create a mapping from each language to the superset . 
yeah . 
from each language to the superset . 
uhhuh . 
yeah . 
yeah . 
there ' s 
um 
carmen was talking about this sampa thing . 
and it ' s um it ' s an effort by linguists to come up with um a machine readable i p a um sort of thing . 
right . 
and um they they have a web site that stephane was showing us that has um has all the english phonemes and their sampa correspondent um phoneme . 
yeah . 
and then um they have spanish . 
they have german . 
they have all all sorts of languages um mapping mapping to the sampa phonemes . 
which 
yeah . 
the the transcription though for albayzin is the transcription are of sampa the same uh how you say symbol that sampa appear . 
sampa ? 
what does sampa mean ? 
uhhuh . 
huh . 
but i don ' t know if timit how is timit . 
so i mean 
what 
i ' m sorry . 
go ahead . 
i was going to say does that mean i p a is not really international ? 
no it ' s it ' s saying 
it uses special diacritics and stuff which you can ' t do with ascii characters . 
can ' t print on ascii . 
yeah . 
oh i see . 
so the sampa ' s just mapping those . 
got it . 
what uh 
has o g i done anything about this issue ? 
do they have do they have any kind of superset that they already have ? 
i don ' t think so . 
well they they they ' re going actually the the other way defining phoneme clusters apparently . 
well 
aha . 
that ' s right . 
uh and that ' s an interesting way to go too . 
so they just throw the speech from all different languages together . 
then cluster it into sixty or fifty or whatever clusters ? 
i think they ' ve not done it uh doing uh multiple language yet . 
but what they did is to training uh english nets with all the phonemes . 
and then training it in english nets with uh kind of seventeen i think it was seventeen uh broad classes . 
automatically derived . 
uhhuh . 
yeah . 
automatically derived broad classes or 
yeah i think so . 
uhhuh . 
uh 
and yeah . 
and the result was that apparently when testing on cross language it was better . 
i think so . 
but hynek didn ' t add didn ' t have all the results when he showed me that . 
so well . 
but 
so that does make an interesting question though . 
is there ' s some way that we should tie into that with this . 
um . 
right ? 
i mean if if in fact that is a better thing to do should we leverage that rather than doing um our own ? 
right ? 
so if if if they 
i mean we have we have the the trainings with our own categories . 
and now we ' re saying well how do we handle cross language . 
and one way is to come up with a superset . 
but they are they ' re trying coming up with clustered . 
and do we think there ' s something wrong with that ? 
i think that there ' s something wrong 
okay . 
well because 
what 
well for the moment we are testing on digits . 
and perhaps using broad phoneme classes . 
it ' s it ' s okay for classifying the digits . 
but as soon as you will have more words . 
well words can differ with only a single phoneme and which could be the same uh class . 
well . 
i see . 
so 
right . 
although you are not using this for the 
so i ' m offering 
you ' re using this for the feature generation now . 
not the 
yeah but you will ask the net to put one for the phoneme class . 
yeah . 
and so . 
yeah . 
so you ' re saying that there may not be enough information coming out of the net to help you discriminate the words ? 
well . 
yeah . 
yeah . 
huh . 
fact most confusions are within the phone phone classes right ? 
i think uh larry was saying like obstruents are only confused with other obstruents et cetera et cetera . 
yeah . 
huh . 
yeah . 
yeah . 
yeah . 
this is another 
yeah . 
another point . 
yeah . 
so so maybe we could look at articulatory type stuff . 
but that ' s what i thought they were going to 
right ? 
did they not do that ? 
or 
i don ' t think so . 
well . 
they were talking about perhaps . 
so 
but they 
i 
they ' re talking about it . 
but that ' s sort of a question whether they did . 
yeah . 
because that ' s that ' s the other route to go . 
instead of this you know 
uhhuh . 
superclass . 
instead of the the the the superclass thing . 
which is to take 
so suppose you don ' t really mark 
to really mark articulatory features you really want to look at the acoustics and and see where everything is . 
and we ' re not going to do that . 
so 
uh the second class way of doing it is to look at the uh phones that are labeled . 
and translate them into acoustic uh articulatory uh uh features . 
so it won ' t really be right . 
you won ' t really have these overlapping things and so forth . 
so the targets of the net are these 
but 
articulatory feature . 
articulatory features ? 
right . 
but that implies that you can have more than one on at a time ? 
that ' s right . 
uh . 
you either do that or you have multiple nets . 
okay . 
i see . 
uh 
and um 
i don ' t know if our software this if the versions of the quicknet that we ' re using allows for that . 
do you know ? 
allows for ? 
multiple targets being one . 
oh . 
um 
we have gotten soft targets to to work . 
okay . 
so that that ' ll work . 
yeah . 
yeah . 
okay . 
so um 
that ' s another thing that could be done . 
is that we could we could uh just translate instead of translating to a superset just translate to articulatory features some set of articulatory features and train them with that . 
um 
now the fact even though it ' s a smaller number it ' s still fine . 
because you have the the uh combinations . 
so in fact it has every you know it had has has every distinction in it that you would have the other way . 
yeah . 
but it should go across languages better . 
we could do an interesting cheating experiment with that too . 
we could i don ' t know if you had uh the phone labels you could replace them by their articulatory features . 
and then feed in a vector with those uh things turned on based on what they ' re supposed to be for each phone . 
to see if it if you get a big win . 
do you know what i ' m saying ? 
no . 
so 
um 
i mean if your net is going to be outputting uh a vector of basically of 
well it ' s going to have probabilities . 
but let ' s say that they were ones and zeros . 
then and you know for each 
um 
i don ' t know if you know this for your testing data . 
but if you know for your test data you know what the string of phones is and and you have them aligned then you can just instead of going through the net just create the vector for each phone and feed that in . 
to see if that data helps . 
uh uh what made me think about this is i was talking with hynek and he said that there was a guy at a t and t who spent eighteen months working on a single feature . 
and because they had done some cheating experiments 
this was the guy that we were just talking that we saw on campus . 
so this was larry saul who did this did this . 
oh okay . 
he used sonorants . 
right . 
okay . 
was what he was doing . 
right . 
yeah . 
and they they had done a cheating experiment or something right ? 
he he he didn ' t mention that part . 
and determined that 
but 
well hynek said that that i guess before they had him work on this they had done some experiment where if they could get that one feature right it dramatically improved the result . 
i see . 
okay . 
so i was thinking you know it made me think about this . 
that if it ' d be an interesting experiment just to see you know if you did get all of those right . 
should be . 
because if you get all of them in there that defines all of the phones . 
so that ' s that ' s equivalent to saying that you ' ve got got all the phones right . 
right . 
so if that doesn ' t help there ' s 
yeah . 
although yeah it would be make an interesting cheating experiment . 
because we are using it in this funny way . 
where we ' re converting it into features . 
yeah . 
and then you also don ' t know what error they ' ve got on the h t k side . 
you know ? 
yeah . 
it sort of gives you your the best you could hope for kind of . 
huh . 
huh . 
i see . 
the soft training of the nets still requires the vector to sum to one though . 
to sum up to one . 
right ? 
so you can ' t really feed it like two articulatory features that are on at the same time with ones . 
because it ' ll kind of normalize them down to one half or something like that for instance . 
but perhaps you have the choice of the final 
right . 
nonlinearity ? 
uh 
nonlinearity . 
yeah . 
um 
is it always softmax ? 
it ' s 
or 
no . 
it ' s actually sigmoid x . 
yeah . 
for the 
so if you choose sigmoid it ' s it ' s okay ? 
you 
did we just run out of disk ? 
um 
i think i think apparently the uh 
or 
why don ' t you just choose linear ? 
what ' s that ? 
right ? 
linear outputs ? 
linear outputs ? 
isn ' t that what you ' ll want ? 
um 
if you ' re going to do a k l transform on it . 
right right . 
right . 
but during the training we would train on sigmoid x . 
oh you 
yeah . 
and then at the end just chop off the final nonlinearity . 
huh . 
so we ' re we ' re we ' re off the air ? 
or 
about to be off the air . 
uh all right . 
so i uh uh wanted to mention a couple little bits of news . 
um hynek is supposed to come for a couple days next week . 
don ' t know which days yet . 
so hopefully he ' ll have some intensive time to to work with people . 
um the second thing is that um we ' re starting to talk about maybe having sunil come here uh for some chunk of the summer . 
so that may or may not happen . 
but if he does since actually pratibha is going to be off at i b m um the uh effort will pretty much shift here . 
because sunil will be here and other people are working on other things i think . 
so so 
uh that ' s my news . 
all right . 
cool . 
i need a new office mate . 
oh okay . 
there you go . 
right . 
it will be sometime in summer . 
july or august or 
yeah i mean it may not happen . 
i mean he wants uh i think he wants some experience someplace else and he ' s he ' s uh thinking of going someplace . 
uhhuh . 
but it ' s i mean pratibha is getting her experience going to i b m and he may come here . 
so 
but i don ' t know maybe june . 
maybe earlier . 
but uh 
anyway hynek will be here next week and maybe he ' ll know more about it . 
oh yeah . 
well the news more specifically for aurora . 
um 
so i guess there was again a conference call but uh they are not decide on everything yet . 
for the v a d they probably they will do something like having some kind of idealized v a d that they could run on the channel zero of the speechdat car . 
and then take the same um end points and apply them on channel one . 
uhhuh . 
so it ' s 
oh so take a real v a d but apply it to to to the clean clean data . 
uh 
yeah to the clean and take the end points for the noisy . 
huh . 
okay . 
but i am not sure this is decided yet . 
um 
and and when they ' re talking about it do you have the impression that they ' re talking about a particular v a d which everybody would use ? 
or or just that everybody would use the same procedure ? 
well probably uh the same v a d for everybody . 
uhhuh . 
um 
so they would just provide that as part of the data . 
maybe . 
but this is still 
yeah . 
sounds like they ' re still arguing . 
yeah . 
yeah they ' re still not decided . 
yeah . 
yeah . 
um i don ' t know what 
yeah . 
nothing much . 
yeah . 
probably the um these weight things they will apply the same kind of weighting scheme for t i digits than for the speechdat car . 
so it would be weighting of 
um 
it would be an average of improvements rather than an average of word error rates which would make the more clean parts of t i digits more important than they are right now . 
uhhuh . 
okay . 
uh but it sounds like none of this is really decided that this is how things are leaning . 
this 
and 
they they i think they will tend to go this way but huh . 
uh 
if we have the result for the tandem with um m s g also 
so it was 
yeah there is no there is no surprise . 
well so there is nor significant improvement . 
um yeah basically that ' s all . 
we ' ve started to work on some kind of report for the work so we ' ve not much more results . 
uhhuh . 
yeah you have a uh you have a lunch talk sometime in 
huh . 
uhhuh . 
it ' s next week yeah . 
when is it ? 
next week ? 
oh okay . 
how about the um the thing that you guys were working on before ? 
the uh uh voiced unvoiced . 
uh 
oh yes . 
but no . 
this week i ' m i am begin to to write the report on 
oh . 
i stopped it . 
you stopped working on it . 
interfered . 
i see . 
yeah . 
okay . 
uh 
so it sounds like basically things are slowing down a bit ? 
and and and trying to collate results ? 
and get something from it ? 
uhhuh . 
yeah . 
yeah . 
um . 
yeah . 
right now sunil seems is in india actually . 
right . 
uh so there is no progress apparently from their side neither . 
right . 
um and 
but that sort of puts it on us to do it . 
but kind of puts it on us to put more in then really . 
i ' m sorry ? 
yeah . 
i mean uh who ' s who ' s was uh looking at the combination of uh spectral subtraction approaches with what we had for instance ? 
sunil was working on this . 
okay . 
um he sent a bunch of a bunch of results . 
uh 
but i don ' t know what ' s the status of this . 
i guess it was just the result that he sent . 
so um 
what was that again ? 
he just used the spectral subtraction and the l d a filters i guess huh . 
uhhuh . 
and it was not better than what we had before . 
and 
then he tried to put the online normalization and it did not improve further . 
putting the online normalization . 
so 
um . 
yeah . 
huh . 
huh . 
okay . 
well 
huh . 
yeah . 
i uh i so i guess nothing has ever happened about uh making a standardized uh place where the software sits so that people can work with it and upgrade it ? 
no . 
well i i sent mails to start the the process and i guess we should have to 
well we know most what we have to to put in in this . 
and 
yeah . 
so i guess yeah we 
okay . 
well uh let ' s let ' s come back to this uh later . 
um okay . 
um chuck did you get a chance to do anymore stuff with the uh h t k ? 
no i didn ' t . 
um are you talking about 
or 
uh no . 
this week i haven ' t . 
i ' ve been my whole time ' s been taken up with uh meeting recorder stuff . 
okay . 
uh disk crash and uh covering things . 
okay . 
this may be a very short meeting . 
uh um 
anything from your side ? 
uh continuing readings we come uh we ' re doing some background reading on phonetics . 
uhhuh . 
okay . 
yeah . 
dave ? 
well um one thing in in the paper avendano and his collaborators wrote is that is that um they tried doing channel normalization on the reverberant in speech by um subtracting the mean of the log spectral magnitude over a two second window . 
but they didn ' t do anything with the phase and they said perhaps that limited their approach that it did not try to normalize the phase in any way . 
so i ' m i ' m going to start thinking about um ways that the that the phase could be used . 
um . 
if if the um channel and the reverberation is multiplicative in the frequency domain with the speech spectrum then the phases should be additive . 
so um perhaps just subtracting the mean of the phase would would help . 
um but i don ' t know i i get the impression that they tried to do some things with the phase and they weren ' t successful . 
okay . 
oh you know there is one other thing . 
um stephane showed me a paper yesterday um where uh for the italian system they had done a series of experiments playing around with the um the number of iterations that i talked about last week . 
and um so there was a whole series of those that they had done . 
uhhuh . 
they didn ' t i don ' t think reported timing for those . 
but um it turns out that the one that they ' re actually using was not the best uh in in their series of experiments which i uh maybe it ' s because they uh wanted to use the same number of iterations across all different languages and this was only done on italian or something . 
sure . 
who ' s they they ? 
uh i don ' t know who did it . 
do you know stephane ? 
who did that ? 
um 
i don ' t know . 
but it ' s the company who prepared the italian database . 
so it was 
is it alcatel ? 
or 
i think so . 
i 
huh . 
i don ' t know . 
so um you know there wasn ' t a huge difference in terms of the performance across all the different experiments that they did . 
um but it varied a little bit . 
and uh so i guess the main thing that i take out of that is that i think that for our purposes here we could definitely you know decrease the number of iterations that we do . 
and um 
at least while we ' re you know working on uh all different of kinds of variations and that would let us you know pump through a lot more experiments . 
so um i still have to to send everybody a pointer about uh how to run the um h t k system on the linux boxes and about changing these number of iterations so that so that you can do that . 
um so the the other thing that that i was thinking about maybe trying out next is 
um 
oh ! 
the other the other experiment that they had in that paper was uh uh playing with the number of gaussians per state . 
and so 
uh 
uhhuh . 
i think it ' s was playing with the number of states per word . 
they had sixteen seventeen eighteen . 
yeah because it was around between sixteen and twenty . 
or 
okay . 
i should look at that more carefully because i wonder what they did about 
yeah . 
oh okay . 
i was thinking it was gaussians but it ' s states . 
so and 
okay . 
yeah apparently um they had better results when they increased the number of states . 
from from eighteen to twenty or 
uhhuh . 
yeah . 
so the thing i was thinking about was uh you know the number of insertions really goes up when you start adding all the noise in . 
and maybe the thing to do next would be to try to um uh make the silence model more powerful . 
you know increasing the number of gaussians to the number of states different different things like that . 
so that ' s probably the next little thing i ' ll play with when i get a chance . 
um 
let ' s see . 
um why don ' t why don ' t we uh if there aren ' t any other major things why don ' t we do the digits and then then uh turn the mikes off . 
uh we should be going . 
so next week we ' ll have uh both birger and uh mike michael . 
michael kleinschmidt . 
uhhuh . 
and birger kollmeier will join us . 
um 
and you ' re you ' re probably going to go up in a couple three weeks or so ? 
when when are you thinking of going up to uh o g i ? 
yeah like uh not next week . 
but maybe the week after . 
okay . 
good so at least we ' ll have one meeting with with you still around . 
uhhuh . 
and and 
that ' s good . 
um 
yeah well maybe we can start with this . 
huh . 
all today huh ? 
yeah . 
oh . 
um 
yeah so there was this conference call this morning . 
um 
and the only topic on the agenda was just to discuss . 
and to come at uh to get a decision about this latency problem . 
no this i ' m sorry this is a conference call between different aurora people ? 
uh yeah it ' s the conference call between the aurora uh group . 
or just 
it ' s the main conference call . 
okay . 
uh yeah there were like two hours of discussions . 
and then suddenly uh people were tired i guess . 
and they decided on a number . 
two hundred and twenty . 
um 
included including everything . 
uh it means that it ' s like eighty milliseconds less than before . 
um 
and what are we sitting at currently ? 
so currently uh we have system that has two hundred and thirty . 
yeah . 
so that ' s fine . 
two thirty . 
yeah . 
so that ' s the system that ' s described on the second point of this document . 
so it ' s 
we have to reduce it by ten milliseconds somehow . 
yeah but that ' s 
yeah . 
that ' s not a problem i i guess . 
okay . 
um 
it ' s it ' s primary primarily determined by the v a d at this point . 
right ? 
yeah . 
yeah at this point . 
so we can make the v a d a little shorter . 
yeah . 
that ' s 
yeah uhhuh . 
yeah we probably should do that pretty soon so that we don ' t get used to it being a certain way . 
uhhuh . 
yeah . 
um 
was hari on the on the phone ? 
yeah sure . 
okay . 
well it was mainly a discussion between hari and david . 
who was like 
yeah . 
uh 
okay . 
huh 
uh yeah so the second thing is the system that we have currently . 
oh yes we have like a system that gives sixty two percent improvement . 
but if you want to stick to the this latency 
well it has a latency of two thirty . 
but if you want also to stick to the number of features that limit it to sixty then we go a little bit down . 
but it ' s still sixty one percent . 
uh and if we drop the tandem network then we have fifty seven percent . 
uh but the two two thirty includes the tandem network ? 
yeah . 
okay . 
and is the tandem network uh small enough that it will fit on the terminal size ? 
uh no i don ' t think so . 
in terms of 
no . 
no . 
okay . 
it ' s still in terms of computation if we use like their way of computing the the maps the the mips i think it fits . 
uhhuh . 
uhhuh . 
but it ' s uh mainly a problem of memory . 
right . 
um 
and i don ' t know how much this can be discussed or not . 
because it ' s it could be in rom . 
so it ' s maybe not that expensive . 
but 
how much memory how many 
i i uh i i don ' t remember exactly . 
but uh 
yeah i i i have to check that . 
yeah i ' d like to see that . 
because maybe i could think a little bit about it . 
because maybe we could make it a little smaller . 
or i mean it ' d be it ' d be neat if we could fit it all . 
uhhuh . 
uh i ' d like to see how far off we are . 
uhhuh . 
but i guess it ' s still within their rules to have have it on the uh uh server side . 
yeah yeah . 
right ? 
okay . 
huh . 
and this is still 
uh well you ' re saying here 
i i should just let you go on . 
yeah there were small tricks to make this tandem network work . 
uh huh 
and one of the trick was to um use some kind of hierarchical structure . 
where the silence probability is not computed by the final tandem network but by the v a d network . 
um 
so apparently it looks better when uh we use the silence probability from the v a d network . 
and we re scale the other probabilities by one minus the silence probability . 
huh . 
um 
so it ' s some kind of hierarchical thing uh that sunil also tried um on spine . 
and apparently it helps a little bit also . 
huh . 
and 
yeah the reason why why we did that with the silence probability was that um 
could uh uh 
i ' m i ' m really sorry . 
can you repeat what you were saying about the silence probability ? 
uhhuh . 
i only 
yeah . 
my mind was some 
so there is the tandem network that estimates the phone probabilities . 
yeah . 
yeah . 
and the silence probabilities also . 
right . 
and things get better when instead of using the silence probability computed by the tandem network we use the silence probability uh given by the v a d network . 
oh . 
um 
the v a d network is 
which is smaller . 
but maybe 
um 
so we have a network for the v a d which has one hundred hidden units . 
and the tandem network has five hundred . 
um 
so it ' s smaller . 
but the silence probability from this network seems uh better . 
okay . 
huh 
uh . 
well it looks strange . 
but 
yeah but 
but it 
okay . 
maybe it ' s has something to do to the fact that we don ' t have infinite training data . 
and 
we don ' t ? 
well 
and 
so well things are not optimal . 
and 
yeah . 
huh 
are you you were going to say why what made you what led you to do that . 
yeah uh there was a problem that we observed um that there was there were like many insertions in the in the system . 
uhhuh . 
huh 
huh 
actually plugging in the tandem network was increasing i i i think the number of insertions . 
uhhuh . 
and um 
so it looked strange . 
and then just using the the other silence probability helps . 
huh . 
um 
yeah the next thing we will do is train this tandem on more data . 
um 
so you know in a way what it might it ' s it ' s a little bit like combining knowledge sources . 
right ? 
because the fact that you have these two nets that are different sizes means they behave a little differently . 
uhhuh . 
they find different things . 
and um 
if you have um the distribution that you have from uh speech sounds is sort of one source of knowledge . 
uhhuh . 
and this is 
and rather than just taking one minus that to get the other 
which is essentially what ' s happening . 
you have this other source of knowledge that you ' re putting in there . 
so you make use of both of them in in what you ' re ending up with . 
maybe it ' s better . 
yeah . 
anyway you can probably justify anything if what ' s 
yeah . 
and and the features are different also . 
yeah . 
i mean the v . a . d . doesn ' t use the same features there are . 
uhhuh . 
huh . 
oh . 
um 
that might be the key actually . 
uhhuh . 
because you were really thinking about speech versus nonspeech for that . 
uhhuh . 
that ' s a good point . 
huh . 
uh well there are other things that we should do . 
but um it requires time . 
and we have ideas . 
like so these things are like having a better v . a . d . 
uh we have some ideas about that . 
it would probably implies working a little bit on features that are more suited to a voice activity detection . 
uhhuh . 
working on the second stream . 
of course we have ideas on this also . 
but we need to try different things . 
and 
uh but their noise estimation . 
um uh 
i mean back on the second stream . 
i mean that ' s something we ' ve talked about for a while . 
i mean i think that ' s certainly a high hope . 
yeah huh . 
um 
so we have this this default idea about just using some sort of purely spectral thing ? 
uh yeah . 
for a second stream . 
but um we we did a first try with this . 
and it it clearly hurts . 
but uh how was the stream combined ? 
uh it was it was just combined um by the acoustic model . 
so there was no neural network for the moment . 
right so i mean if you just had a second stream that was just spectral and had another neural net and combined there that that uh might be good . 
uhhuh . 
yeah uhhuh . 
uhhuh . 
huh . 
yeah . 
um 
yeah and the other thing that noise estimation . 
and um maybe try to train uh the training data for the 
tandem network right now is like is using the noises from the aurora task . 
and i think that people might um try to argue about that . 
because then in some cases we have the same noises in for training the network than the noises that are used for testing . 
right . 
and 
so we have uh to try to get rid of these this problem . 
yeah maybe you just put in some other noise . 
uhhuh yeah . 
something that ' s different . 
i mean it it ' s probably helpful to have have a little noise there . 
uhhuh . 
but it may be something else . 
at least you could say it was 
yeah . 
and then if it doesn ' t hurt too much though . 
uhhuh . 
yeah that ' s a good idea . 
um 
yeah the last thing is that i think we are getting close to human performance . 
well that ' s something i would like to investigate further . 
but 
um 
i did like um i did uh listen to the most noisy utterances of the speechdat car italian . 
and tried to transcribe them . 
and um 
so this is a particular human . 
this is this this is stephane . 
yeah so that ' s that ' s 
stephane . 
yeah . 
that ' s the the flaw of the experiment . 
this is just it ' s just one subject . 
yeah . 
getting close . 
but 
but still uh what happens is is that uh the digit error rate on this is around one percent . 
yeah . 
while our system is currently at seven percent . 
um but what happens also is that if i listen to the um a re synthesized version of the speech 
and i re synthesized this using a white noise that ' s filtered by a l p c uh filter 
yeah . 
um 
well you can argue that uh that this is not speech . 
yeah . 
so the ear is not trained to recognize this . 
but actually it sound like whispering . 
so we are 
well i mean it ' s 
uh 
there ' s two problems there . 
i mean i mean so so the first is that by doing l p c twelve with synthesized speech like you ' re saying uh it ' s you ' re you ' re adding other degradation . 
uhhuh . 
right ? 
so it ' s not just the noise . 
but you ' re adding in fact some degradation . 
because it ' s only an approximation . 
um 
and the second thing is which is maybe more interesting is that um if you do it with whispered speech you get this number . 
what if you had done analysis re synthesis and taken the pitch as well ? 
all right ? 
so now you put the pitch in . 
uhhuh . 
what would the percentage be then ? 
um 
see that ' s the question . 
so you see if it ' s if it ' s if it ' s uh let ' s say it ' s back down to one percent again . 
uhhuh . 
that would say at least for people having the pitch is really really important . 
which would be interesting in itself . 
uh yeah but 
um 
if on the other hand if it stayed up near five percent then i ' d say boy l p c twelve is pretty crummy . 
you know ? 
uhhuh . 
so i ' m not sure i ' m not sure how we can conclude from this anything about that our system is close to the human performance . 
yeah well the point is that the point is that um what i what i listened to when i re synthesized the l the l p c twelve spectrum is in a way what the system uh is hearing . 
because all the all the um excitation all the 
well the excitation is is not taken into account . 
that ' s what we do with our system . 
and 
well you ' re not doing the l p c 
in this case 
i mean so so what if you did a 
well it ' s not l p c sure . 
but 
what if you did l p c twenty ? 
l p c ? 
twenty . 
right ? 
i mean the thing is l p c is not a a really great representation of speech . 
uhhuh . 
uhhuh . 
so all i ' m saying is that you have in addition to the the uh removal of pitch you also are doing uh a particular parameterization . 
uhhuh . 
which 
um uh 
huh 
uh so let ' s see . 
how would you do so 
but that ' s that ' s what we do with our systems . 
and 
no actually we we we don ' t . 
because we do we do uh uh mel filter bank for instance . 
yeah but is it that is it that different i mean ? 
right ? 
um i don ' t know what mel uh based synthesis would sound like . 
uhhuh . 
but certainly the spectra are quite different . 
uhhuh . 
couldn ' t you couldn ' t you um test the human performance on just the original audio ? 
this is the one percent number . 
yeah it ' s one percent . 
uhhuh . 
he ' s trying to remove the pitch information . 
oh oh okay . 
uhhuh . 
and make it closer to what to what we ' re seeing as the feature vectors . 
i see . 
okay so uh your performance was one percent . 
uhhuh . 
and then when you re synthesize with l p c twelve it went to five . 
yeah . 
okay . 
i mean we were we were it it it ' s a little bit still apples and oranges . 
because we are choosing these features in order to be the best for recognition . 
uhhuh . 
and um 
if you listen to them they still might not be very even if you made something closer to what we ' re going to it might not sound very good . 
yeah . 
uh and the degradation from that might might actually make it even harder uh to understand than the l p c twelve . 
so all i ' m saying is that the l p c twelve puts in synthesis . 
puts in some degradation . 
uhhuh . 
that ' s not what we ' re used to hearing . 
and is um 
it ' s not it ' s not just a question of how much information is there as if you will always take maximum advantage of any information that ' s presented to you . 
uhhuh . 
in fact you hear some things better than others . 
and so it it isn ' t 
but 
but i agree that it says that uh the kind of information that we ' re feeding it is probably um um a little bit um minimal . 
there ' s definitely some things that we ' ve thrown away . 
and that ' s why i was saying it might be interesting if you an interesting test of this would be if you if you actually put the pitch back in . 
so you just extract it from the actual speech and put it back in . 
and see does that is that does that make the difference ? 
uhhuh . 
if that if that takes it down to one percent again then you ' d say okay it ' s it ' s in fact having um not just the spectral envelope but also the also the the pitch that uh has the information that people can use anyway . 
huh 
but from this it ' s pretty safe to say that the system is either two to seven percent away from the performance of a human . 
right ? 
so it ' s somewhere in that range . 
well or it ' s it ' s 
yeah so 
two two to six percent . 
it ' s it ' s one point four times uh to uh seven times the error . 
to seven times yeah . 
for stephane . 
um . 
so uh 
uh but i don ' t know . 
but but 
don ' t want to take you away from other things . 
but that ' s that ' s what that ' s the first thing that i would be curious about is you know when you 
but the signal itself is like a mix of um of a a periodic sound and uh unvoiced sound and the noise . 
uhhuh . 
which is mostly uh noise . 
i mean not periodic . 
so what what do you mean exactly by putting back the pitch in 
because 
in the l p c synthesis ? 
yeah you did l p c re synthesis . 
i think 
uhhuh . 
l p c re synthesis . 
so uh and you did it with a noise source . 
uhhuh . 
rather than with with a periodic source . 
right ? 
so if you actually did real re synthesis like you do in an l p c synthesizer where it ' s unvoiced you use noise . 
where it ' s voiced you use uh periodic pulses . 
um 
right ? 
yeah but it ' s neither purely voiced or purely unvoiced . 
especially because there is noise . 
well it might be hard to do it . 
so 
but but but the thing is that if you um if you detect that there ' s periodic strong periodic components then you can use a voiced voice thing . 
oh . 
uhhuh . 
yeah . 
yeah i mean it ' s probably not worth your time . 
it ' s it ' s a side thing . 
and and and there ' s a lot to do . 
uhhuh yeah . 
but i ' m i ' m just saying at least as a thought experiment that ' s what i would want to test . 
uhhuh . 
uh i would want to drive it with a a a two source system rather than a than a one source system . 
uhhuh . 
uhhuh . 
and then that would tell you whether in fact it ' s 
because we ' ve talked about like this harmonic tunneling or other things that people have done based on pitch . 
maybe that ' s really a key element . 
maybe maybe uh uh without that it ' s it ' s not possible to do a whole lot better than we ' re doing . 
that that could be . 
yeah . 
that ' s what i was thinking by doing this experiment . 
like 
yeah . 
huh 
but i mean other than that i don ' t think it ' s 
i mean other than the pitch information it ' s hard to imagine that there ' s a whole lot more in the signal that that uh that we ' re throwing away that ' s important . 
yeah but 
yeah uhhuh yeah right . 
right i mean we ' re using a fair number of filters in the filter bank . 
and uh 
uhhuh . 
uh yeah . 
huh . 
yeah . 
um . 
yeah that ' s it . 
yeah that 
yeah . 
that ' s that ' s i mean one one percent is sort of what i would i would figure . 
if somebody was paying really close attention you might get 
i would actually think that if you looked at people on various times of the day and different amounts of attention you might actually get up to three or four percent error on digits . 
uhhuh . 
uh uh 
um 
so it ' s 
you know we ' re not we ' re not incredibly far off . 
on the other hand with any of these numbers except maybe the one percent it ' s it ' s not actually usable in a commercial system with a full telephone number or something . 
uhhuh . 
yeah at these noise levels . 
yeah uhhuh . 
yeah . 
right . 
well yeah these numbers i mean . 
huh . 
good . 
um while we ' re still on aurora stuff maybe you can talk a little about the status with the uh wall street journal things for it . 
so i ' ve um downloaded uh a couple of things from mississippi state . 
um one is their software . 
their uh l v c s r system . 
downloaded the latest version of that . 
got it compiled and everything . 
um downloaded the scripts . 
they wrote some scripts that sort of make it easy to run the system on the wall street journal uh data . 
um so i haven ' t run the scripts yet . 
uh i ' m waiting there was one problem with part of it . 
and i wrote a note to joe asking him about it . 
so i ' m waiting to hear from him . 
but um i did print something out just to give you an idea about where the system is . 
uh they on their web site they uh did this little table of where their system performs relative to other systems that have done this this task . 
and um the mississippi state system using a bigram grammar uh is at about eight point two percent . 
other comparable systems from uh were getting from uh like six point nine six point eight percent . 
so they ' re 
this is on clean test set ? 
this is on clean on clean stuff yeah . 
they they ' ve started a table where they ' re showing their results on various different noise conditions . 
but they they don ' t have a whole lot of it filled in . 
and and i didn ' t notice until after i ' d printed it out that um they don ' t say here what these different testing conditions are . 
you actually have to click on it on the web site to see them . 
so i i don ' t know what those numbers really mean . 
what kind of numbers are they getting on these on the test conditions ? 
well see i was a little confused . 
because on this table i ' m they ' re showing word error rate . 
but on this one 
i i don ' t know if these are word error rates . 
because they ' re really big . 
so under condition one here it ' s ten percent . 
then under three it goes to sixty four point six percent . 
yeah that ' s probably aurora . 
i mean 
yeah . 
so i guess maybe they ' re error rates . 
but they ' re uh they ' re really high . 
i i i don ' t find that 
so 
i mean we 
what ' s what ' s some of the lower error rates on on on uh some of the higher error rates on uh some of these uh uh highly mismatched difficult conditions ? 
what ' s a 
uh yeah it ' s around fifteen to twenty percent . 
correct ? 
and the baseline uh 
accuracy ? 
uh error rate . 
yeah . 
twenty percent error rate 
yeah so twenty percent error rate on digits . 
and 
so if you ' re doing so if you ' re doing 
and 
oh oh on digits . 
yeah . 
on digits . 
and this is so so still the baseline . 
okay . 
you know 
sixty thousand 
right ? 
yeah . 
yeah . 
and if you ' re saying sixty thousand word recognition getting sixty percent error on some of these noise not at all surprising . 
yeah . 
the baseline is sixty percent also on digits . 
oh is it ? 
on the more mismatched conditions . 
okay . 
so 
yeah . 
so yeah that ' s probably what it is then . 
yeah so they have a lot of different conditions that they ' re going to be filling out . 
it ' s a bad sign when you looking at the numbers you can ' t tell whether it ' s accuracy or error rate ! 
yeah . 
yeah it ' s it ' s going to be hard . 
um 
they ' re i ' m still waiting for them to release the um multi c . p . u . version of their scripts . 
because right now their script only handles processing on a single c . p . u . 
which will take a really long time to run . 
so 
this is for the training ? 
but their 
uh i 
yes for the training also . 
okay . 
and um they ' re supposed to be coming out with it any time . 
the multi c . p . u . one . 
okay . 
so as soon as they get that then i ' ll i ' ll grab those too . 
and so 
yeah because we have to get started . 
because it ' s because uh 
yeah . 
yeah i ' ll go ahead and try to run it though with just the single c . p . u . one . 
if the 
and i they they um released like a smaller data set that you can use that only takes like sixteen hours to train and stuff . 
so i can i can run it on that just to make sure that the the thing works and everything . 
oh good . 
yeah . 
huh . 
because we ' ll 
i guess the actual evaluation will be in six weeks or something . 
so 
is that about right you think ? 
uh we don ' t know yet i i think . 
really we don ' t know ? 
uhhuh . 
um 
huh . 
it wasn ' t on the conference call this morning ? 
no . 
huh . 
did they say anything on the conference call about um how the wall street journal part of the test was going to be run ? 
because i i thought i remembered hearing that some sites were saying that they didn ' t have the compute to be able to run the wall street journal stuff at their place . 
no . 
huh . 
so there was some talk about having mississippi state run the systems for them . 
and i 
did did that come up at all ? 
uh no . 
well this first this was not the point at all of this the meeting today . 
oh okay . 
and 
uh frankly i don ' t know . 
because i didn ' t read also the most recent mails about the large vocabulary task . 
but uh did you do you still uh get the mails ? 
you ' re not on the mailing list or what ? 
huh huh . 
the only um mail i get is from mississippi state . 
uhhuh . 
so 
oh yeah so we should have a look at this . 
about their system . 
i i don ' t get any mail about 
i have to say there ' s uh something funny sounding about saying that one of these big companies doesn ' t have enough compute power do that . 
so they ' re having to have it done by mississippi state . 
yeah . 
it just just sounds funny . 
yeah it does . 
but 
anyway . 
yeah i ' m i ' m wondering about that . 
because there ' s this whole issue about you know simple tuning parameters like word insertion penalties . 
uhhuh . 
and whether or not those are going to be tuned or not . 
and so 
uhhuh . 
i mean it makes a big difference . 
if you change your front end you know the scale is completely can be completely different . 
so 
it seems reasonable that that at least should be tweaked to match the front end . 
but 
you didn ' t get any answer from joe ? 
i did . 
but joe said you know what you ' re saying makes sense . 
uhhuh . 
and i don ' t know . 
uhhuh . 
so he doesn ' t know what the answer is . 
i mean that ' s we had this back and forth a little bit about you know are sites going to are you going to run this data for different sites ? 
and well if if mississippi state runs it then maybe they ' ll do a little optimization on that parameter . 
and uh 
but then he wasn ' t asked to run it for anybody . 
so it ' s it ' s just not clear yet what ' s going to happen . 
uhhuh . 
uh he ' s been putting this stuff out on their web site and for people to grab . 
but i haven ' t heard too much about what ' s happening . 
so it could be i mean chuck and i had actually talked about this a couple times and and over some lunches i think that um one thing that we might want to do 
there ' s this question about you know what do you want to scale ? 
suppose you can ' t adjust these word insertion penalties and so forth . 
so you have to do everything at the level of the features . 
what could you do ? 
and uh one thing i had suggested at an earlier time was maybe some sort of scaling . 
some sort of root or or something of the um uh features . 
but the problem with that is that isn ' t quite the same . 
it occurred to me later . 
because what you really want to do is scale the uh the range of the likelihoods rather than 
nnn the 
yeah . 
but what might get at something similar it just occurred to me is kind of an intermediate thing . 
is because we do this strange thing that we do with the tandem system at least in that system what you could do is take the um uh values that come out of the net . 
which are something like log probabilities . 
and scale those . 
and then uh um then at least those things would have the right values . 
or the right the right range . 
and then that goes into the rest of it and then that ' s used as observations . 
so it ' s it ' s um another way to do it . 
uhhuh . 
uhhuh . 
but these values are not directly used as probabilities anyway . 
i know they ' re not . 
so there are there is 
i know they ' re not . 
but but 
you know 
uhhuh . 
so because what we ' re doing is pretty strange and complicated we don ' t really know what the effect is at the other end . 
uhhuh . 
so um my thought was maybe 
i mean they ' re not used as probabilities . 
but the log probabilities 
we ' re taking advantage of the fact that something like log probabilities has more of a gaussian shape than than probabilities . 
and so we can model them better . 
so in a way we ' re taking advantage of the fact that they ' re probabilities . 
because they ' re this quantity that looks kind of gaussian when you take it ' s log . 
so uh maybe maybe it would have a a reasonable effect to do that . 
uhhuh . 
i i don ' t know . 
but i mean i guess we still haven ' t had a a ruling back on this . 
and we may end up being in a situation where we just you know really can ' t change the word insertion penalty . 
but the other thing we could do is also we could 
i mean this this may not help us uh in the evaluation . 
but it might help us in our understanding at least . 
we might just run it with different insertion penalties . 
and show that uh well okay not changing it playing the rules the way you wanted we did this but in fact if we did that it made a a big difference . 
i wonder if it it might be possible to uh simulate the back end with some other system . 
so we we get our front end features . 
and then 
uh 
as part of the process of figuring out the scaling of these features you know if we ' re going to take it to a root or to a power or something we have some back end that we attach onto our features that sort of simulates what would be happening . 
uhhuh . 
um 
and just adjust it until it ' s the best number ? 
and just adjust it until that our version of the back end uh decides that that 
well we can probably use the real thing . 
can ' t we ? 
and then just uh use it on a reduced test set or something . 
yeah oh yeah . 
that ' s true . 
yeah . 
and then we just use that to determine some scaling factor that we use . 
yeah so i mean i think that that ' s a reasonable thing to do . 
and the only question is what ' s the actual knob that we use ? 
and the knob that we use should 
uhhuh . 
uh uh unfortunately like i say i don ' t know the analytic solution to this . 
because what we really want to do is change the scale of the likelihoods . 
not the not the scale of the the observations . 
uhhuh . 
but but uh 
uhhuh . 
yeah . 
out of curiosity what what kind of recognizer is the one from mississippi state ? 
uh what do you mean when you say what kind ? 
is it 
um is it like a gaussian mixture model ? 
yeah . 
gaussian mixture model . 
okay . 
it ' s the same system that they use when they participate in the hub five evals . 
it ' s a um sort of came out of uh uh looking a lot like h . t . k . 
i mean they started off with um when they were building their system they were always comparing to h . t . k . to make sure they were getting similar results . 
and so it ' s a gaussian mixture system . 
uh 
do they have the same sort of mix down sort of procedure where they start off with a small number of some things ? 
i don ' t know . 
yeah and then divide the mixtures in half . 
and 
yeah . 
i don ' t know if they do that . 
i ' m not really sure . 
yeah . 
huh . 
do you know what kind of tying they use ? 
are they they sort of some sort of a bunch of gaussians that they share across everything ? 
or or if it ' s 
yeah i have i i i don ' t have it up here . 
but i have a the whole system description that describes exactly what their system is . 
okay . 
and i i ' m not sure . 
but um 
okay . 
it ' s some kind of a mixture of gaussians and uh clustering . 
and uh 
they ' re they ' re trying to put in sort of all of the standard features that people use nowadays . 
uhhuh . 
so the other uh aurora thing maybe is 
i don ' t know if any of this is going to come in in time to be relevant . 
but uh we had talked about uh guenter playing around uh uh over in germany . 
uhhuh . 
and and uh possibly coming up with something that would uh uh fit in later . 
uh i saw that other mail where he said that he uh it wasn ' t going to work for him to do c . v . s . 
yeah . 
yeah so now he has a version of the software . 
so he just has it all sitting there . 
yeah . 
yeah . 
um 
uhhuh . 
so if he ' ll 
he might work on improving the noise estimate . 
or on some histogram things . 
yeah . 
or 
uhhuh . 
yeah i just saw the eurospeech 
we we didn ' t talk about it at our meeting . 
but i just saw the just read the paper . 
someone i forget the name and and ney uh about histogram equalization . 
did you see that one ? 
um it was a poster ? 
or 
yeah i mean i just read the paper . 
yeah . 
i didn ' t see the poster . 
yeah . 
um it was something similar to online normalization finally . 
i mean in the idea of of normalizing 
yeah but it ' s a little more it it ' s a little finer . 
right ? 
yeah . 
so they had like ten quantiles . 
and and they adjust the distribution . 
right . 
so you you have the distributions from the training set . 
and then uh 
so this is just a a histogram of of the amplitudes i guess . 
right ? 
and then um people do this in image processing some . 
uhhuh . 
you have this kind of of histogram of of levels of brightness or whatever . 
and and and then when you get a new new thing that you you want to adjust to be better in some way you adjust it so that the histogram of the new data looks like the old data . 
huh . 
you do this kind of piece wise linear or uh some kind of piece wise approximation . 
they did a uh one version that was piece wise linear and another that had a power law thing between them between the points . 
and uh 
they said they they sort of see it in a way as for the speech case as being kind of a generalization of spectral subtraction in a way . 
because you know in spectral subtraction you ' re trying to get rid of this excess energy . 
uh you know it ' s not supposed to be there . 
uh and uh 
this is sort of adjusting it for for a lot of different levels . 
and then they have they have some kind of uh a floor or something . 
huh . 
so if it gets too low you don ' t don ' t do it . 
huh . 
and they they claimed very nice results . 
uhhuh . 
and 
so is this a histogram across different frequency bins ? 
or 
um i think this 
you know i don ' t remember that . 
do you remember 
i think they have yeah different histograms . 
uh 
something like one per frequency band . 
one 
or 
one per critical 
so one histogram per frequency bin . 
but i did 
yeah i guess . 
but i should read the paper . 
and that ' s 
i just went through the poster quickly . 
yeah . 
and i don ' t remember whether it was filter bank things . 
so 
and i didn ' t 
oh . 
or whether it was f . f . t . bins . 
or 
huh . 
and and that that um histogram represents the different energy levels that have been seen at that frequency ? 
i don ' t remember that . 
and how often they you ' ve seen them yeah . 
huh . 
uhhuh . 
yeah and they do they said that they could do it for the test . 
so you don ' t have to change the training . 
you just do a measurement over the training . 
and then uh for testing uh you can do it for one per utterance . 
even relatively short utterances . 
and they claim it it works pretty well . 
so they uh 
is the idea that you you run a test utterance through some histogram generation thing ? 
and then you compare the histograms and that tells you what to do to the utterance to make it more like 
i guess in 
yeah . 
in principle . 
i didn ' t read carefully how they actually implemented it . 
i see . 
huh . 
yeah . 
whether it was some uh online thing or whether it was a second pass or what . 
but but they that that was sort of the idea . 
huh . 
so that that seemed you know different . 
we ' re sort of curious about uh what are some things that are um conceptually quite different from what we ' ve done ? 
because we you know one thing that that . 
uhhuh . 
uh stephane and sunil seemed to find uh was you know they could actually make a unified piece of software that handled a range of different things that people were talking about . 
and it was really just sort of setting of different constants . 
and it would turn you know one thing into another . 
it ' d turn wiener filtering into spectral subtraction or whatever . 
but there ' s other things that we ' re not doing . 
so we ' re not making any use of pitch . 
uh uh which again might might be important . 
uh because the stuff between the harmonics is probably a schmutz . 
and and the uh transcribers will have fun with that . 
uh and um 
the uh stuff at the harmonics isn ' t so much . 
and and uh 
and there ' s this overall idea of really sort of matching the the distributions somehow . 
uh not just 
um um 
not just subtracting off your estimate of the noise . 
so 
so i guess uh guenter ' s going to play around with some of these things now over this next period . 
uh i don ' t know . 
or 
i don ' t have feedback from him . 
but 
yeah . 
i guess he ' s going to maybe 
well he ' s got it anyway . 
so he can . 
yeah . 
uhhuh . 
so potentially if he came up with something that was useful like a a better noise estimation module or something he could ship it to you guys up there . 
yeah . 
and 
we could put it in . 
uhhuh uhhuh . 
yeah . 
yeah . 
so 
that ' s good . 
so why don ' t we just uh um 
i think starting starting a couple weeks from now especially if you ' re not going to be around for a while we ' ll we ' ll be shifting more over to some other other territory . 
but uh uh uh 
not not so much in this meeting about aurora . 
but but uh 
uh maybe just uh quickly today about maybe you could just say a little bit about what you ' ve been talking about with michael . 
and 
and then barry can say something about what what we ' re talking about . 
okay . 
so michael kleinschmidt who ' s a p . h . d . student from germany showed up this week . 
he ' ll be here for about six months . 
and he ' s done some work using an auditory model of um human hearing . 
and using that uh to generate speech recognition features . 
and he did work back in germany with um a toy recognition system using um isolated digit recognition as the task . 
it was actually just a single layer neural network that classified words . 
classified digits in fact . 
um and he tried that on i think on some aurora data and got results that he thought seemed respectable . 
and 
he he ' s coming here to use it on uh a real speech recognition system . 
so i ' ll be working with him on that . 
and um 
maybe i should say a little more about these features . 
although i don ' t understand them that well . 
the i think it ' s a two stage idea . 
and um the first stage of these features correspond to what ' s called the peripheral auditory system . 
and i guess that is like a filter bank with a compressive nonlinearity . 
and i ' m not sure what we have in there that isn ' t already modeled in something like um p . l . p . 
i should learn more about that . 
and then the second stage is um the most different thing i think from what we usually do . 
it ' s um it computes features which are um based on sort of like based on different um wavelet basis functions used to analyze the input . 
so he uses analysis functions called gabor functions . 
um which have a certain extent um in time and in frequency . 
and the idea is these are used to sample um the signal in represented as a time frequency representation . 
so you ' re sampling some piece of this time frequency plane . 
and um that um is is interesting . 
because for for one thing you could use it um in a a multi scale way . 
you could have these 
instead of having everything like we use a twenty five millisecond or so analysis window typically 
um and that ' s our time scale for features . 
but you could using this um basis function idea you could have some basis functions . 
which have a lot longer time scale . 
and um some which have a lot shorter . 
and so it would be like a set of multi scale features . 
so he ' s interested in um 
this is because it ' s um there are these different parameters for the shape of these basis functions um there are a lot of different possible basis functions . 
and so he he actually does an optimization procedure to choose an an optimal set of basis functions out of all the possible ones . 
huh . 
what does he do to choose those ? 
the method he uses is kind of funny . 
is um he starts with he has a set of m . of them . 
um 
he and then he uses that to classify . 
i mean he he tries um using just m . minus one of them . 
so there are m . possible subsets of this length m . vector . 
he tries classifying using each of the m . possible sub - vectors . 
huh . 
whichever sub - vector um works the the best i guess he says the the feature that didn ' t use was the most useless feature . 
yeah . 
gets thrown out . 
yeah . 
so we ' ll throw it out . 
and we ' re going to randomly select another feature from the set of possible basis functions . 
huh . 
yeah . 
so it ' s a 
so so it ' s 
it ' s a little bit like a genetic algorithm or something in a way . 
it ' s like a greedy 
well it ' s it ' s much simpler . 
but it ' s but it ' s uh it ' s there ' s a lot number of things i like about it let me just say . 
greedy . 
so first thing well you ' re absolutely right . 
i mean in truth both pieces of this are have their analogies in stuff we already do . 
but it ' s a different take at how to approach it . 
and potentially one that ' s maybe a bit more systematic than what we ' ve done . 
uh and a a bit more inspiration from from auditory things . 
so it ' s so i think it ' s a neat thing to try . 
the primary features um are in fact 
yeah essentially it ' s it ' s uh you know p . l . p . or or mel cepstrum or something like that . 
you ' ve you ' ve got some uh compression . 
we always have some compression . 
we always have some you know the the the kind of filter bank with a kind of quasi log scaling . 
um if you put in if you also include the rasta in it 
rasta the filtering being done in the log domain has an a . g . c . like uh characteristic which you know people typically put in these kind of uh um uh auditory front ends . 
so it ' s very very similar . 
uh but it ' s not exactly the same . 
um 
i would agree that the second one is is somewhat more different . 
but um it ' s mainly different in that the things that we have been doing like that have been um had a different kind of motivation and have ended up with different kinds of constraints . 
so for instance if you look at the l . d . a . rasta stuff you know basically what they do is they they look at the different eigenvectors out of the l . d . a . and they form filters out of it right ? 
and those filters have different uh kinds of temporal extents and temporal characteristics . 
and so in fact they ' re multi scale . 
but they ' re not sort of systematically multi scale like let ' s start here and go to there and go to there and go to there and so forth . 
it ' s more like you run it on this you do discriminant analysis and you find out what ' s helpful . 
it ' s multi scale because you use several of these in parallel ? 
is that right ? 
yeah they use several of them . 
of 
okay . 
yeah . 
uh i mean you don ' t have to . 
but but but uh hynek has . 
um 
but it ' s also uh 
when hynek ' s had people do this kind of l . d . a . analysis they ' ve done it on frequency direction . 
and they ' ve done it on the time direction . 
i think he may have had people sometimes doing it on both simultaneously . 
some two d . . 
and that would be the closest to these gabor function kind of things . 
uh but i don ' t think they ' ve done that much of that . 
and uh the other thing that ' s interesting the the uh the feature selection thing 
it ' s a simple method . 
but i kind of like it . 
um there ' s a a old old method for feature selection . 
i mean uh uh i remember people referring to it as old when i was playing with it twenty years ago . 
so i know it ' s pretty old . 
uh called stepwise linear discriminant analysis . 
in which you which 
i think it ' s used in social sciences a lot . 
so you you you you pick the best feature . 
and then you take you find the next feature that ' s the best in combination with it . 
and then so on and so on . 
and what what michael ' s describing seems to me much much better . 
because the problem with the stepwise discriminant analysis is that you don ' t know that you know if you ' ve picked the right set of features . 
just because something ' s a good feature doesn ' t mean that you should be adding it . 
so um uh 
here at least you ' re starting off with all of them . 
and you ' re throwing out useless features . 
i think that ' s that seems uh that seems like a lot better idea . 
uh you ' re always looking at things in combination with other features . 
um 
so the only thing is of course there ' s this this artificial question of of uh exactly how you how you how you assess it . 
and if if your order had been different in throwing them out . 
i mean it still isn ' t necessarily really optimal . 
but it seems like a pretty good heuristic . 
huh . 
so i i think it ' s it ' s i think it ' s kind of neat stuff . 
and and and uh 
the thing that i wanted to to add to it also was to have us use this in a multi stream way . 
huh . 
um 
so so that um when you come up with these different things and these different functions you don ' t necessarily just put them all into one huge vector . 
but perhaps you have some of them in one stream and some of them in another stream and so forth . 
and um um um 
and we ' ve also talked a little bit about uh uh shihab shamma ' s stuff . 
in which you the way you look at it is that there ' s these different mappings . 
and some of them emphasize uh upward moving uh energy and and frequency . 
and some are emphasizing downward . 
and fast things and slow things and and so forth . 
so 
so there ' s a bunch of stuff to look at . 
but uh i think we ' re sort of going to start off with what he uh came here with . 
and branch out branch out from there . 
and his advisor is here too at the same time . 
so 
he ' ll be another interesting source of wisdom . 
huh . 
so 
as as we were talking about this i was thinking um whether there ' s a relationship between um between michael ' s approach to uh some some sort of optimal brain damage or optimal brain surgeon on the neural nets . 
yeah . 
so like if we have 
huh . 
um 
we have our we have our rasta features and 
and presumably the neural nets are are learning some sort of a nonlinear mapping uh from the the the features to to this this probability posterior space . 
uhhuh . 
right ? 
and um and each of the hidden units is learning some sort of some sort of some sort of pattern . 
right . 
and it could be like like these um these auditory patterns that michael is looking at . 
and then when you ' re looking at the the uh um the best features you know you can take out you can do the do this uh brain surgery by taking out um hidden units that don ' t really help at all . 
uhhuh . 
and this is sort of like 
or the or features . 
right ? 
yeah . 
i mean actually you make me think a a very important point here is that um if we again try to look at how is this different from what we ' re already doing uh there ' s a a uh a nasty argument that could be made that it ' s it ' s not different at at all . 
because uh if you ignore the the selection part . 
because we are going into a a very powerful uh nonlinearity . 
that uh in fact is combining over time and frequency . 
and is coming up with its own you know better than gabor functions . 
uhhuh . 
its you know neural net functions . 
its whatever it finds to be best . 
um so you could argue that in fact it 
but i i don ' t actually believe that argument . 
because i know that um you can uh 
computing features is useful . 
even though in principle you haven ' t added anything . 
in fact you subtracted something from the original waveform . 
you know uh if you ' ve you ' ve processed it in some way you ' ve typically lost something some information . 
and so you ' ve lost information and yet it does better with with features than it does with the waveform . 
so 
uh i i know that sometimes it ' s useful to to constrain things . 
so that ' s why it really seems like the constraint in in all this stuff it ' s the constraints that are actually what matters . 
because if it wasn ' t the constraints that mattered then we would ' ve completely solved this problem long ago . 
because long ago we already knew how to put waveforms into powerful statistical mechanisms . 
so 
yeah well if we had infinite processing power and data i guess using the waveform could 
right . 
yeah 
uh 
then it would work . 
yeah i agree . 
yeah there ' s the problem . 
so that ' s 
yeah then it would work . 
but but i mean it ' s with finite of those things . 
i mean uh we we have done experiments where we literally have put waveforms in . 
and and and uh 
uhhuh . 
we kept the number of parameters the same and so forth . 
and it used a lot of training data . 
and it and it it uh 
not infinite . 
but a lot and then compared to the number parameters . 
and it it uh it just doesn ' t do nearly as well . 
uhhuh . 
so anyway the point is that you want to suppress 
it ' s not just having the maximum information . 
you want to suppress uh the aspects of the input signal that are not helpful for for the discrimination you ' re trying to make . 
so 
so maybe just briefly uh 
well that sort of segues into what what i ' m doing . 
yeah . 
um so uh the big picture is um come up with a set of uh intermediate categories . 
then build intermediate category classifiers then do recognition . 
and um improve speech recognition in that way . 
um so right now i ' m in in the phase where i ' m looking at at um deciding on a initial set of intermediate categories . 
and i ' m looking for data driven methods that can help me find um a set of intermediate categories of speech that uh will help me to discriminate later down the line . 
and one of the ideas um that was to take a take a neural net . 
train train an ordinary neural net to uh to learn the posterior probabilities of phones . 
and so 
um at the end of the day you have this neural net . 
and it has hidden hidden units . 
and each of these hidden units is um is learning some sort of pattern . 
and so um what what are these patterns ? 
huh . 
i don ' t know . 
um and i ' m going to to try to to look at those patterns to to see um from those patterns 
uh presumably those are important patterns for discriminating between phone classes . 
and maybe maybe some uh intermediate categories can come from just looking at the patterns of um that the neural net learns . 
before you get on the next part let me just point out that there ' s there ' s a a pretty nice relationship between what you ' re talking about doing and what you ' re talking about doing there right ? 
yeah . 
so it seems to me that you know if you take away the the the difference of this primary features and say you use as we had talked about maybe doing you use p . rasta p . l . p . or something for the the primary features um then this feature discovery uh uh thing is just what he ' s talking about doing too . 
except that he ' s talking about doing them in order to discover intermediate categories that correspond to these uh uh what these sub features are are are are showing you . 
and um the other difference is that um he ' s doing this in a in a multi band setting . 
which means that he ' s constraining himself to look across time in some relatively limited uh uh spectral extent right ? 
and whereas in in this case you ' re saying let ' s just do it unconstrained . 
so they ' re they ' re really pretty related . 
and maybe they ' ll be at some point where we ' ll see the the connections a little better . 
huh . 
and connect them . 
uhhuh . 
um 
yeah so so that ' s the that ' s the first part uh one one of the ideas to get at some some patterns of intermediate categories . 
um the other one was um to uh come up with a a a model um a graphical model that treats the intermediate categories as hidden hidden variables latent variables that we don ' t know anything about . 
but that through um statistical training and the e . m . algorithm um at the end of the day we have um we have learned something about these these latent um latent variables . 
which happen to correspond to intermediate categories . 
um yeah and so those are the the two directions that i ' m i ' m looking into right now . 
and uh um yeah 
i guess that ' s that ' s it . 
okay . 
should we do our digits ? 
and get get our treats . 
oh tea time ? 
yeah it ' s kind of like you know the little rats with the little thing dropping down to them . 
that ' s 
we do the digits and then we get our treats . 
oops ! 
okay . 
okay . 
okay we ' re on . 
okay . 
what are we talking about today ? 
i don ' t know . 
do you have news from the conference talk ? 
uh 
that was programmed for yesterday i guess . 
uh 
yesterday . 
uh 
yesterday morning on video conference . 
uh 
well 
oh . 
oh conference call . 
i ' m sorry . 
i know now i know what you ' re talking about . 
no nobody ' s told me anything . 
all right . 
oh this was the uh talk where they were supposed to try to decide 
to to decide what to do . 
yeah . 
yeah . 
uh right . 
yeah . 
no that would have been a good thing to find out before this meeting . 
that ' s 
no i have no i have no idea . 
um 
uh 
so 
i mean let ' s let ' s assume for right now that we ' re just kind of plugging on ahead . 
yeah . 
because even if they tell us that uh the rules are different uh we ' re still interested in doing what we ' re doing . 
so what are you doing ? 
uhhuh . 
uh well we ' ve a little bit worked on trying to see uh what were the bugs and the problem with the latencies . 
to improve . 
so 
we took first we took the l d a filters . 
and uh we designed new filters . 
using uh recursive filters actually . 
so when you say we is that something sunil is doing ? 
or is that 
i ' m sorry ? 
who is doing that ? 
uh us . 
oh oh . 
yeah . 
oh okay . 
but 
so we took the filters the fir filters and we designed uh i i r filters that have the same frequency response . 
uhhuh . 
well similar but that have shorter delays . 
uhhuh . 
so they had two filters . 
one for the low frequency bands . 
and another for the high frequency bands . 
and so we redesigned two filters . 
and the low frequency band has sixty four milliseconds of delay . 
and the high frequency band filter has something like eleven milliseconds compared to the two hundred milliseconds of the i i r filters . 
but it ' s not yet test . 
so we have the filters . 
but we still have to implement a routine that does recursive filtering . 
okay . 
and 
you you had a discussion with sunil about this though ? 
no . 
no . 
uh huh . 
yeah you should talk with him . 
yeah yeah . 
yeah . 
no i mean because the the the the whole problem that happened before was coordination . 
right ? 
uhhuh . 
so so you need to discuss with him what we ' re doing . 
yeah . 
uh because they could be doing the same thing and or something . 
uhhuh . 
uh 
i 
yeah . 
i don ' t know if that ' s what they were trying to 
right . 
they were trying to do something different like taking uh well using filter that takes only a past . 
and 
this is just a little bit different . 
but i i will send him an email and tell him exactly what we are doing . 
so 
yeah . 
yeah . 
um 
i mean 
um 
we just we just have to be in contact more . 
i think that the the fact that we we did that with had that thing with the latencies was indicative of the fact that there wasn ' t enough communication . 
uhhuh . 
so 
okay . 
all right . 
um 
yeah . 
well there is one um remark about these filters that they don ' t have a linear phase . 
so 
right . 
well i don ' t know . 
perhaps it perhaps it doesn ' t hurt . 
because the phase is almost linear . 
but 
um 
and so yeah for the delay i gave you here it ' s it ' s uh computed on the five hertz modulation frequency . 
which is the huh well the most important for speech . 
so 
uh 
this is the first thing . 
the low 
so that would be uh a reduction of a hundred and thirty six milliseconds . 
yeah . 
which uh 
what was the total we ended up with through the whole system ? 
three hundred and thirty . 
so that would be within 
yeah . 
but there are other points actually . 
uh 
which will perhaps add some more delay . 
is that some other other stuff in the process were perhaps not very um well not very correct . 
like the downsampling which was simply dropping frames . 
yeah . 
um 
so we will try also to add a nice downsampling . 
having a filter that that 
uhhuh . 
well a low pass filter at at twenty five hertz . 
uh because when when we look at the l d a filters well they are basically low pass . 
but they leave a lot of what ' s above twenty five hertz . 
yeah . 
um 
and so yeah . 
this will be another filter which would add ten milliseconds again . 
yeah . 
um 
yeah . 
and then there ' s a third thing . 
is that um basically the way online normalization was done uh is just using this recursion on on the um um on the feature stream . 
yeah . 
and but this is a filter . 
so it has also a delay . 
uh 
and when we look at this filter actually it has a delay of eighty five milliseconds . 
so if we 
eighty five ? 
yeah . 
if we want to be very correct . 
so if we want to the estimation of the mean to to be well the right estimation of the mean we have to to take eighty five milliseconds in the future . 
huh 
huh ! 
that ' s a little bit of a problem . 
yeah . 
um 
but well when we add up everything it ' s it will be all right . 
we would be at 
so sixty five plus ten plus for the downsampling . 
plus eighty five for the online normalization . 
so it ' s 
uh 
yeah but then there ' s 
plus plus eighty for the neural net and p c a . 
oh . 
so it would be around two hundred and forty . 
so well 
just just barely in there . 
plus plus the frames . 
but it ' s okay . 
what ' s the allowable ? 
two fifty . 
unless they changed the rules . 
huh . 
which there is there ' s some discussion of . 
but 
what were they thinking of changing it to ? 
yeah . 
uh well the people who had very low latency want it to be low uh very very narrow uh latency bound . 
and the people who have longer latency don ' t . 
so 
huh . 
so yeah . 
unfortunately we ' re the main ones with long latency . 
but 
uh . 
but uh 
you know it ' s 
yeah . 
and basically the best proposal had something like thirty or forty milliseconds of latency . 
yeah . 
so 
well . 
yeah . 
so they were basically 
i mean 
they were more or less trading computation for performance . 
and we were uh trading latency for performance . 
and they were dealing with noise explicitly and we weren ' t . 
and so i think of it as complementary . 
that if we can put the 
think of it as what ? 
complementary . 
huh . 
i think the best systems 
so uh everything that we did in a way it was it was just adamantly insisting on going in with a brain damaged system . 
which is something actually we ' ve done a lot over the last thirteen years . 
uh which is we say well this is the way we should do it . 
and then we do it . 
and then someone else does something that ' s straight forward . 
so this was a test that largely had additive noise . 
and we did we did absolutely nothing explicitly to handle additive noise . 
right . 
we just uh you know trained up systems to be more discriminant . 
and uh we did this uh rasta like filtering . 
which was done in the log domain . 
and was tending to handle convolutional noise . 
we did we actually did nothing about additive noise . 
so um 
the uh spectral subtraction schemes a couple places did seem seem to do a nice job . 
and so 
uh 
we ' re talking about putting putting some of that in while still keeping some of our stuff . 
i think you should be able to end up with a system that ' s better than both . 
but clearly the way that we ' re operating for this other stuff does involved some latency to to get rid of most of that latency . 
to get down to forty or fifty milliseconds we ' d have to throw out most of what we ' re doing . 
and and uh i don ' t think there ' s any good reason for it in the application actually . 
i mean you ' re you ' re you ' re speaking to a recognizer on a remote server . 
and uh having a a a quarter second for some processing to clean it up it doesn ' t seem like it ' s that big a deal . 
uhhuh . 
these aren ' t large vocabulary things . 
so the decoder shouldn ' t take a really long time and . 
so 
and i don ' t think anybody ' s going to notice the difference between a quarter of a second of latency and thirty milliseconds of latency . 
no . 
what what does was your experience when you were doing this stuff with uh the the the surgical uh uh microscopes and so forth ? 
um how long was it from when somebody uh finished an utterance to when uh something started happening ? 
um we had a silence detector . 
so 
we would look for the end of an utterance based on the silence detector . 
uhhuh . 
and i i can ' t remember now off the top of my head how many frames of silence we had to detect before we would declare it to be the end of an utterance . 
uhhuh . 
uhhuh . 
um 
but it was 
uh 
i would say it was probably around the order of two hundred and fifty milliseconds . 
yeah . 
and that ' s when you ' d start doing things . 
yeah . 
we did the back trace at that point . 
yeah . 
to get the answer . 
of course that didn ' t take too long at that point . 
no . 
no it was pretty quick . 
yeah . 
yeah . 
so 
so you you so you had a 
so you had a a quarter second delay before uh plus some little processing time . 
this 
right . 
and then the the microscope would start moving or something . 
right . 
yeah . 
right . 
and there ' s physical inertia there . 
so probably the the motion itself was all 
and it felt to uh the users that it was instantaneous . 
i mean as fast as talking to a person . 
it i don ' t think anybody ever complained about the delay . 
yeah . 
so you would think as long as it ' s under half a second or something . 
yeah . 
uh i ' m not an expert on that . 
but 
yeah . 
i don ' t remember the exact numbers . 
but 
yeah . 
it was something like that . 
i don ' t think you can really tell . 
a person i don ' t think a person can tell the difference between uh you know a quarter of a second and a hundred milliseconds . 
and 
yeah . 
i ' m not even sure if we can tell the difference between a quarter of a second and half a second . 
yeah . 
i mean it just it feels so quick . 
i mean basically if you yeah if you said uh um what ' s the uh uh what ' s the shortest route to the opera . 
and it took half a second to get back to you . 
yeah . 
i mean it would be 
i mean it might even be too abrupt . 
you might have to put in a a a delay . 
yeah . 
i mean it may feel different than talking to a person . 
yeah . 
because when we talk to each other we tend to step on each other ' s utterances . 
so like if i ' m asking you a question you may start answering before i ' m even done . 
yeah . 
so it it would probably feel different . 
right . 
but i don ' t think it would feel slow . 
right . 
well anyway 
i mean i think 
we could cut we know what else we could cut down on the neural net time . 
by by uh playing around a little bit . 
going more into the past . 
or something like that . 
we we talked about that . 
so is the latency from the neural net caused by how far ahead you ' re looking ? 
uhhuh . 
uhhuh . 
and there ' s also 
well there ' s the neural net and there ' s also this uh uh multi frame uh uh k l t . 
wasn ' t there 
was it in the uh recurrent neural nets where they weren ' t looking ahead at all ? 
they weren ' t looking ahead much . 
they they looked ahead a little bit . 
a little bit . 
okay . 
yeah . 
yeah . 
i mean you could do this with a recurrent net . 
and and then 
but you also could just um 
i mean we haven ' t experimented with this . 
but i imagine you could um uh predict a uh um a label uh from more in the past than in than than in the future . 
i mean we ' ve we ' ve done some stuff with that before . 
i think it it works okay . 
uhhuh . 
so 
we ' ve always had usually we used the symmetric windows . 
but 
yeah . 
i don ' t think 
but we ' ve but we played a little bit with with asymmetric guys . 
yeah . 
you can do it . 
so 
so that ' s what that ' s what you ' re busy with . 
messing around with this . 
uh yeah . 
yeah . 
and uh 
also we were thinking to to uh apply the uh spectral subtraction from ericsson . 
yeah . 
uhhuh . 
and to to change the contextual k l t for l d a . 
change the what ? 
the contextual k l t . 
i ' m missing that last word . 
k k l t . 
oh k l t . 
k l t . 
k l t . 
oh k l t . 
uhhuh . 
k l t . 
uhhuh . 
i ' m sorry . 
uh to change and use l d a discriminative . 
yeah . 
but 
uh huh . 
i don ' t know . 
uh 
what is the advantage of that ? 
uh 
well it ' s that by for the moment we have uh something that ' s discriminant and nonlinear . 
and the other is linear but it ' s not discriminant at all . 
well it ' s it ' s a linear transformation that 
uh 
so at least just to understand maybe what the difference was between how much you were getting from just putting the frames together and how much you ' re getting from the discriminative . 
what the nonlinearity does for you or doesn ' t do for you . 
just to understand it a little better i guess . 
huh . 
well 
uh 
yeah . 
actually what we want to do perhaps it ' s to replace to to have something that ' s discriminant but linear also . 
and to see if it if it improves over over the non discriminant linear transformation . 
and if the neural net is better than this . 
huh . 
or well 
yeah well that ' s what i meant is to see whether whether it having the neural net really buys you anything . 
so 
huh . 
uh i mean it did look like it buys you something over just the k l t . 
yeah . 
but maybe it ' s just the discrimination . 
and and maybe yeah maybe the nonlinear discrimination isn ' t necessary . 
maybe . 
yeah . 
uhhuh . 
maybe . 
could be . 
good good to know . 
but the other part you were saying was the spectral subtraction . 
so you just kind of uh 
yeah . 
at what stage do you do that ? 
do you you ' re doing that 
um 
so it would be on the 
um 
we was 
on on the mel frequency bands . 
so yeah . 
yeah . 
we no nnn 
before everything . 
okay . 
so just do that on the mel 
we we was thinking to do before after v a d . 
oh we don ' t know exactly when it ' s better . 
yeah . 
um 
before after v a d . 
or 
and then 
so so you know that that that the way that they ' re 
um . 
uh one thing that would be no good to find out about from this conference call is that what they were talking about what they ' re proposing doing was having a third party um run a good v a d and and determine boundaries . 
yeah . 
and then given those boundaries then have everybody do the recognition . 
begin to work . 
the reason for that was that um uh if one one group put in the v a d and another didn ' t . 
uh or one had a better v a d than the other . 
since that they ' re not viewing that as being part of the the task . 
and that any any manufacturer would put a bunch of effort into having some kind of good speech silence detection . 
it still wouldn ' t be perfect . 
but i mean 
the argument was let ' s not have that be part of this test . 
let ' s let ' s separate that out . 
and so 
uh i guess they argued about that yesterday . 
and 
yeah i ' m sorry . 
i don ' t don ' t know the answer . 
but we should find out . 
i ' m sure we ' ll find out soon . 
what they uh what they decided . 
so uh 
yeah so there ' s the question of the v a d . 
but otherwise it ' s it ' s on the the uh the mel filter bank uh energies i guess . 
uhhuh . 
you do doing the 
huh yeah . 
uhhuh . 
and you ' re you ' re subtracting in the in the in the i guess it ' s power power domain . 
uh or or magnitude domain . 
probably power domain right ? 
why 
i guess it ' s power domain yeah . 
i don ' t remember exactly . 
i don ' t remember . 
yeah . 
but 
yeah . 
so it ' s before everything else . 
yep . 
and 
i mean if you look at the theory it ' s it should be in the power domain . 
but but uh i ' ve seen implementations where people do it in the magnitude domain . 
yeah . 
and 
huh . 
i have asked people why . 
and they shrug their shoulders and say oh it works . 
so 
yeah . 
uh 
and there ' s this 
i guess there ' s this mysterious 
i mean people who do this a lot i guess have developed little tricks of the trade . 
i mean there ' s there ' s this um 
you don ' t just subtract the the estimate of the noise spectrum . 
you subtract that times 
a little bit more . 
and 
or or less . 
yeah . 
or 
really ? 
yeah . 
huh ! 
yeah . 
and generated this this 
uh . 
um 
so you have the estimation of the power spectra of the noise . 
and you multiply this by a factor which is dependent on the s n r . 
huh maybe . 
so well . 
huh ! 
when the speech when the signal level is more important compared to this noise level the coefficient is small and around one . 
but when the power the signal level is uh small compared to the noise level the coefficient is more important . 
and this reduce actually the musical noise . 
uh 
oh ! 
which is more important during silence portions . 
when the the energy ' s small . 
uhhuh . 
huh ! 
so there are tricks like this . 
but huh 
huh ! 
yeah . 
so 
yeah . 
is the estimate of the noise spectrum a running estimate ? 
yeah . 
yeah . 
or 
yeah . 
well that ' s i mean that ' s what differs from different different tasks and different uh spectral subtraction methods . 
i mean if if you have uh fair assurance that uh the noise is is quite stationary then the smartest thing to do is use as much data as possible to estimate the noise . 
huh ! 
get a much better estimate and subtract it off . 
uhhuh . 
but if it ' s varying at all which is going to be the case for almost any real situation you have to do it online uh with some forgetting factor or something . 
so do you is there some long window that extends into the past over which you calculate the average ? 
well there ' s a lot of different ways of computing the noise spectrum . 
so one of the things that uh hans guenter hirsch did uh and and other people 
actually he ' s he wasn ' t the only one i guess . 
was to uh take some period of of of speech and in each band uh develop a histogram . 
so to get a decent histogram of these energies takes at least a few seconds really . 
but uh i mean you can do it with a smaller amount . 
but it ' s pretty rough . 
and um in fact i think the nist standard method of determining signal to noise ratio is based on this . 
so 
a couple seconds ? 
no no . 
it ' s based on this kind of method . 
this histogram method . 
huh . 
so you have a histogram . 
now if you have signal and you have noise you basically have these two bumps in the histogram . 
which you could approximate as two gaussians . 
but don ' t they overlap sometimes ? 
oh yeah . 
okay . 
so you have a mixture of two gaussians . 
yeah . 
right ? 
and you can use e m to figure out what it is you know . 
yeah . 
so so basically now you have this mixture of two gaussians . 
you you know what they are . 
and uh 
i mean sorry . 
you estimate what they are . 
and uh 
so this gives you what the signal is and what the noise energy is in that band in the spectrum . 
and then you look over the whole thing . 
and now you have a noise spectrum . 
so uh hans guenter hirsch and others have used that kind of method . 
and the other thing to do is which is sort of more trivial and obvious is to uh uh determine through magical means that that uh there ' s no speech in some period . 
and then see what the spectrum is . 
uhhuh . 
uh 
but 
you know it ' s that that that ' s tricky to do . 
it has mistakes . 
uh and if you ' ve got enough time uh this other method appears to be somewhat more reliable . 
uh a variant on that for just determining signal to noise ratio is to just uh you can do a a uh an iterative thing e . m . like thing to determine means only . 
i guess it is e m still . 
but just just determine the means only . 
don ' t worry about the variances . 
uhhuh . 
and then you just use those mean values as being the the uh uh signal to noise ratio in that band . 
but what is the 
it seems like this kind of thing could add to the latency . 
i mean depending on where the window was that you used to calculate the signal to noise ratio . 
yeah . 
sure . 
but 
huh 
not necessarily . 
because if you don ' t look into the future . 
right ? 
okay . 
well that i guess that was my question . 
if you just 
yeah . 
i mean if you just 
yeah . 
if you 
you uh 
at the beginning you have some 
guess . 
some guess . 
and and uh uh 
yeah but it 
it ' s an interesting question . 
i wonder how they did do it . 
actually it ' s a huh if you want to have a good estimation on non stationary noise you have to look in the in the future . 
i mean so if you take your window and build your histogram in this window um what you can expect is to have an estimation of of the noise in in the middle of the window . 
not at the end . 
so 
uhhuh . 
well yeah . 
but what does what what what does alcatel do ? 
the but but people 
and and france telecom ? 
they just look in the past . 
i guess it works because the noise are uh uh almost stationary . 
pretty stationary . 
pretty stationary . 
but 
yeah . 
um 
well the thing 
yeah i mean you ' re talking about non stationary noise . 
but i think that spectral subtraction is rarely is is not going to work really well for for non stationary noise . 
well if if you have a good estimation of the noise . 
you know ? 
yeah . 
because 
well . 
it has to work . 
but it ' s hard to 
but that ' s hard to do . 
yeah . 
that ' s hard to do . 
yeah . 
yeah . 
so so i think that that what what is what ' s more common is that you ' re going to be helped with slowly varying or stationary noise . 
but 
uhhuh . 
that ' s what spectral subtraction will help with practically speaking . 
uhhuh . 
uhhuh . 
if it varies a lot to get if if to get a good estimate you need a few seconds of speech . 
even if it ' s centered . 
right ? 
if you need a few seconds to get a decent estimate but it ' s changed a lot in a few seconds then it you know it ' s kind of a problem . 
uhhuh . 
yeah . 
i mean imagine five hertz is the middle of the of the speech modulation spectrum . 
huh . 
right ? 
so imagine a jack hammer going at five hertz . 
yeah . 
i mean good good luck . 
that ' s 
so 
so in this case yeah sure you cannot 
yeah . 
but i think um hirsch does experiment with windows of like between five hundred milliseconds and one second . 
and 
well five hundred was not so bad . 
i mean 
and he worked on non stationary noises . 
like noise modulated with well with amplitude modulations . 
and 
things like that . 
and 
were his uh windows centered around the 
but 
um 
yeah . 
well . 
i think 
yeah . 
well in in the paper he showed that actually the estimation of the noise is is delayed . 
well it ' s there is 
you you have to center the window . 
yeah . 
yeah . 
huh . 
no i understand it ' s better to do . 
but i just think that that uh for real noises what what ' s most likely to happen is that there ' ll be some things that are relatively stationary . 
huh . 
where you can use one or another spectral subtraction thing . 
and other things where it ' s not so stationary . 
yeah . 
and 
i mean you can always pick something that that falls between your methods . 
uh 
huh . 
uh 
but i don ' t know if you know if sinusoidally uh amplitude modulated noise is is sort of a big problem in in in practice . 
i think that it ' s uh 
yeah . 
we could probably get a really good estimate of the noise if we just went to the noise files . 
and built the averages from them . 
yeah . 
well . 
what 
what do you mean ? 
just cheat . 
you ' re saying cheat . 
but if the if the noise is stationary perhaps you don ' t even need some kind of noise estimation algorithm . 
yeah . 
yeah . 
we just take the beginning of the utterance . 
and 
oh yeah . 
sure . 
it ' s the same . 
i know i don ' t know if people tried this for aurora . 
well everybody seems to use some kind of adaptive well scheme . 
yeah . 
but but 
a dictionary . 
but 
you know stationary 
is it very useful . 
very slow adaptation . 
and is the 
right . 
the word stationary is has a very precise statistical meaning . 
but you know in in signal processing really what we ' re talking about i think is things that change slowly uh compared with our our processing techniques . 
so if you ' re driving along in a car i i would think that most of the time the nature of the noise is going to change relatively slowly . 
uhhuh . 
it ' s not going to stay absolute the same . 
if you if you check it out uh five minutes later you may be in a different part of the road . 
or whatever . 
uhhuh . 
but it ' s it ' s 
using the local characteristics in time is probably going to work pretty well . 
uhhuh . 
but you could get hurt a lot if you just took something from the beginning of all the speech of you know an hour of speech . 
and then later 
yeah . 
uh so they may be you know may be overly uh complicated for for this test . 
but 
but but uh 
i don ' t know . 
but what you ' re saying you know makes sense though . 
i mean if possible you shouldn ' t you should you should make it uh the center of the center of the window . 
but 
uh we ' re already having problems with these delay uh delay issues . 
yeah so . 
so 
uh we ' ll have to figure ways without it . 
um 
if they ' re going to provide a uh voice activity detector that will tell you the boundaries of the speech then couldn ' t you just go outside those boundaries and do your estimate there ? 
oh yeah . 
you bet . 
yeah . 
so i i imagine that ' s what they ' re doing . 
right ? 
is they ' re 
they ' re probably looking in nonspeech sections . 
and getting some uh 
yeah . 
they have some kind of threshold on on the previous estimate . 
and 
so 
yeah . 
i think yeah i think ericsson used this kind of threshold yeah . 
so they they have an estimate of the noise level . 
and they put a threshold like six or ten d b above . 
and 
what ' s under this threshold is used to update the estimate . 
is is that right ? 
yeah . 
or 
i think so . 
i have not here the proposal . 
so it ' s it ' s 
yeah . 
does france telecom do this ? 
it ' s like saying what ' s under the threshold is silence . 
and 
huh . 
does france telecom do do the same thing ? 
more or less ? 
i i 
you know perhaps ? 
no . 
i i have not here the proposal . 
okay . 
um 
okay . 
if we ' re we ' re done done with that 
uh 
let ' s see . 
uh maybe we can talk about a couple other things briefly . 
just uh things that that we ' ve been chatting about . 
but haven ' t made it into these meetings yet . 
so you ' re coming up with your quals proposal . 
and uh want to just give a two three minute summary of what you ' re planning on doing ? 
oh . 
um 
two three . 
it can be shorter than that . 
um 
yeah . 
well i ' ve i ' ve talked to some of you already . 
um but i ' m uh looking into extending the work done by larry saul and john allen and uh mazin rahim . 
um they they have a system that ' s uh a multi band um system . 
but their multi band is is a little different than the way that we ' ve been doing multi band in the past . 
where um where we ' ve been uh taking um sub band features and training up these neural nets and on on phonetic targets . 
and then combining them somehow down the line . 
um 
they ' re they ' re taking sub band features and um training up a detector that detects for um these phonetic features . 
for example um he presents um uh a detector to detect sonorance . 
and so what what it basically is is um it ' s there ' s 
at the lowest level there it ' s it ' s an or i mean it ' s an and gate . 
so uh on each sub band you have several independent tests . 
to test whether um there ' s the existence of sonorance in a sub band . 
and then um it it ' s combined by a soft and gate . 
and at the at the higher level 
for every if 
um 
the higher level there ' s a soft or gate . 
uh so if if this detector detects um the presence of of sonorance in any of the sub bands then the uh the or gate at the top says okay well this frame has evidence of sonorance . 
and these are all 
what are what are some of the low level detectors that they use ? 
oh okay . 
well the low level detectors are logistic regressions . 
um 
and 
the uh 
the one 
so that by the way basically is a is one of the units in our in our our neural network . 
so that ' s all it is . 
it ' s a it ' s a sigmoid . 
yeah . 
uh with weighted sum at the input . 
huh . 
right . 
which you train by gradient descent . 
yeah . 
so he uses um an e m algorithm to to um train up these um parameters for the logistic regression . 
the 
well actually 
yeah . 
so i was using e m to get the targets . 
so so you have this this this and gate what we were calling an and gate but it ' s a product product rule thing at the output . 
and then he uses uh and then feeding into that are 
i ' m sorry . 
there ' s it ' s an or at the output isn ' t it ? 
yeah . 
uhhuh . 
so that ' s the product . 
and then 
um 
then he has each of these and things . 
and 
um 
but 
so they ' re little neural neural units . 
um 
and um 
they have to have targets . 
and so the targets come from e m . 
and so are each of these low level detectors are they 
uh 
are these something that you decide ahead of time ? 
like i ' m going to look for this particular feature ? 
or i ' m going to look at this frequency ? 
or 
what what what are they looking at ? 
um 
what are their inputs ? 
right . 
so the 
okay . 
so at for each sub band there are basically uh several measures of s n r and and correlation . 
uh . 
okay . 
um 
okay . 
um and he said there ' s like twenty of these per per sub band . 
um 
and for for every every sub band you you just pick ahead of time um i ' m going to have like five independent logistic tests . 
uhhuh . 
and you initialize these parameters um in some some way . 
and use e m to come up with your training targets for a for the the low level detectors . 
uhhuh . 
and then once you get that done you you you train the whole whole thing on maximum likelihood . 
um 
and he shows that using this this method to detect sonorance is it ' s very robust compared to um to typical uh full band gaussian mixtures um estimations of of sonorance . 
uhhuh . 
uhhuh . 
and uh 
so 
so that ' s just that ' s just one detector . 
so you can imagine building many of these detectors on different features . 
you get enough of these detectors together um then you have enough information to do um higher level discrimination . 
for example discriminating between phones . 
uhhuh . 
and then you keep working your way up until you you build a full recognizer . 
uhhuh . 
so um that ' s that ' s the direction which i ' m i ' m thinking about going in my quals . 
cool . 
you know it has a number of properties that i really liked . 
i mean one is the going towards um using narrow band information for uh phonetic features of some sort . 
rather than just uh immediately going for the the typical sound units . 
right . 
another thing i like about it is that you this thing is going to be trained explicitly trained for a product of errors rule . 
which is what uh allen keeps pointing out that fletcher observed in the twenties . 
uhhuh . 
uh for people listening to narrow band stuff that ' s friday ' s talk by the way . 
and then um 
uh the third thing i like about it is 
uh and we ' ve played around with this in a different kind of way a little bit . 
but it hasn ' t been our dominant way of of operating anything . 
um this issue of where the targets come from . 
so in our case when we ' ve been training it multi band things the way we get the targets for the individual bands is uh that we get the phonetic label for the sound there . 
uhhuh . 
and we say okay we train every 
what this is saying is okay that ' s maybe what our ultimate goal is . 
or not ultimate but penultimate goal is getting these these small sound units . 
but but um 
along the way how much should we uh 
uh what should we be training these intermediate things for ? 
i mean because uh we don ' t know uh that this is a particularly good feature . 
i mean there ' s no way uh 
someone in the audience yesterday was asking well couldn ' t you have people go through and mark the individual bands and say where the where it was sonorant or not . 
uhhuh . 
but you know i think having a bunch of people listening to critical band wide uh chunks of speech trying to determine whether i think it ' d be impossible . 
ouch . 
it ' s all going to sound like like sine waves to you more or less . 
uhhuh . 
i mean 
well 
i mean it ' s all 
narrow band . 
uh 
i i think it ' s very hard for someone to to a person to make that determination . 
so um 
um we don ' t really know how those should be labeled . 
it could be that you should um not be paying that much attention to uh certain bands for certain sounds uh in order to get the best result . 
uhhuh . 
so um what we have been doing there just sort of mixing it all together is certainly much much cruder than that . 
we trained these things up on the on the the final label . 
now we have i guess done experiments . 
you ' ve probably done stuff where you have um done separate uh viterbis on the different 
yeah . 
forced alignment on the sub band labels . 
yeah . 
yeah . 
you ' ve done that . 
did did that help at all ? 
um it helps for one or one iteration . 
but um anything after that it doesn ' t help . 
so so that may or may it that aspect of what he ' s doing may or may not be helpful . 
because in a sense that ' s the same sort of thing you ' re taking global information and determining what you how you should 
but this is this is uh i i think a little more direct . 
how did they measure the performance of their detector ? 
and 
well he ' s he ' s just actually looking at uh the confusions between sonorant and non sonorant . 
uhhuh . 
so he hasn ' t applied it to recognition . 
or if he did he didn ' t talk about it . 
it ' s it ' s just 
and one of the concerns in the audience actually was that that um the uh 
uh he he did a comparison to uh you know our old foil . 
the the nasty old standard recognizer with mel mel filter bank at the front and h m ms and and so forth . 
and um it didn ' t do nearly as well . 
especially in in noise . 
but the 
one of the good questions in the audience was well yeah but that wasn ' t trained for that . 
i mean this use of a very smooth uh spectral envelope is something that you know has evolved as being generally a good thing for speech recognition . 
but if you knew that what you were going to do is detect sonorants or not 
so sonorants and non sonorants is is is almost like voiced unvoiced except i guess that the voiced stops are are also called obstruents . 
uh 
so it ' s 
it ' s uh but with the exception of the stops i guess it ' s pretty much the same as voiced unvoiced . 
right ? 
uhhuh . 
so so 
um 
so um 
if you knew you were doing that 
if you were doing something say for a a uh a a vocoder you wouldn ' t use the same kind of features . 
you would use something that was sensitive to the periodicity and and not just the envelope . 
uh and so in that sense it was an unfair test . 
um 
so i think that the questioner was right . 
it it was in that sense an unfair test . 
nonetheless it was one that was interesting because uh this is what we are actually using for speech recognition . 
these smooth envelopes . 
and this says that perhaps even you know trying to use them in the best way that we can that that that we ordinarily do with you know gaussian mixtures and h m ms and so forth you you don ' t uh actually do that well on determining whether something is sonorant or not . 
didn ' t they 
which means you ' re going to make errors between similar sounds that are sonorant or obstruent . 
didn ' t they also do some kind of an oracle experiment ? 
where they said if we could detect the sonorants perfectly and then show how it would improve speech recognition ? 
i thought i remember hearing about an experiment like that . 
these same people ? 
uhhuh . 
i don ' t remember that . 
huh . 
that would that ' s 
you ' re right . 
that ' s exactly the question to follow up this discussion is . 
suppose you did that uh got that right . 
um 
yeah . 
huh . 
what could be the other low level detectors i mean for other kind of features ? 
or 
in addition to detecting sonorants . 
or 
um 
that ' s what you want to to to go for also ? 
what 
or 
oh build other other detectors on different phonetic features ? 
other low level detectors ? 
yeah . 
um 
uh let ' s see . 
um 
yeah . 
i i don ' t know . 
um 
um 
i mean easiest thing would be to go go do some voicing stuff . 
but that ' s very similar to sonorance . 
uhhuh . 
um 
when we when we talked with john ohala the other day we made a list of some of the things that 
yeah . 
oh okay . 
like frication . 
uhhuh . 
abrupt closure . 
uhhuh . 
r coloring . 
nasality . 
voicing . 
yeah . 
so there ' s a half dozen like that that are 
uh . 
yeah . 
nasality . 
now this was coming at it from a different angle . 
but maybe it ' s a good way to start . 
uh these are things which uh john felt that a a uh a human annotator would be able to reliably mark . 
oh okay . 
so the sort of things he felt would be difficult for a human annotator to reliably mark would be tongue position kinds of things . 
placing stuff . 
uhhuh . 
yeah . 
yeah . 
uh 
there ' s also things like stress . 
you can look at stress . 
uhhuh . 
but stress doesn ' t uh fit in this thing of coming up with features that will distinguish words from one another . 
right ? 
it ' s a it ' s a good thing to mark . 
and will probably help us ultimate with recognition . 
yeah . 
there ' s a few cases where it can like permit and permit . 
but 
but that ' s not very common in english . 
in other languages it ' s more uh important . 
well yeah . 
but either case you ' d write p e r m i t . 
right ? 
so you ' d get the word right . 
no i ' m saying i thought you were saying that stress doesn ' t help you distinguish between words . 
um 
oh i see what you ' re saying . 
as long as you get the sequence . 
we ' re if we ' re doing if we ' re talking about transcription as opposed to something else . 
right ? 
yeah . 
yeah yeah yeah yeah . 
yeah . 
right . 
so where it could help is maybe at a higher level . 
like a understanding application . 
right . 
yeah . 
understanding . 
yeah . 
yeah . 
yeah . 
exactly . 
but that ' s this afternoon ' s meeting . 
yeah . 
we don ' t understand anything in this meeting . 
yeah . 
so that ' s 
yeah . 
that ' s you know a neat neat thing . 
and 
and uh 
so um ohala ' s going to help do these uh transcriptions of the meeting data ? 
so 
uh 
well i don ' t know . 
we we sort of didn ' t get that far . 
um we just talked about some possible features that could be marked by humans . 
and um 
huh . 
because of having maybe some extra transcriber time we thought we could go through and mark some portion of the data for that . 
and uh 
huh . 
yeah . 
i mean that ' s not an immediate problem that we don ' t immediately have a lot of extra transcriber time . 
yeah . 
but but uh in the long term i guess chuck is going to continue the dialogue with john . 
right . 
and and uh 
and we ' ll we ' ll end up doing some i think . 
i ' m definitely interested in this area too . 
uh acoustic feature stuff . 
uhhuh . 
okay . 
so 
yeah i think it ' s an interesting interesting way to go . 
cool . 
um 
i say it like said int i think it has a number of good things . 
um 
so uh you want to talk maybe a two or three minutes about what we ' ve been talking about today and other days ? 
yeah . 
okay . 
so um 
we ' re interested in um methods for far mike speech recognition . 
um mainly uh methods that deal with the reverberation in the far mike signal . 
so um 
one approach would be um say m s g and p l p like was used in aurora one . 
and um there are other approaches which actually attempt to remove the reverberation instead of being robust to it like m s g . 
and so we ' re interested in um comparing the performance of um a robust approach like m s g with these um speech enhancement or de reverber de reverberation approaches . 
uhhuh . 
and um it looks like we ' re going to use the meeting recorder digits data for that . 
and the de reverberation algorithm . 
do you have can you give some more details on this ? 
or does it use one microphone ? 
several microphones ? 
does it 
okay . 
well um 
there was something that was done by um a guy named carlos i forget his last name who worked with hynek who um 
avendano . 
okay . 
who um 
yeah . 
uhhuh . 
um it was like rasta in the sense that of it was um de convolution by filtering . 
um except he used a longer time window . 
uhhuh . 
like a second maybe . 
and the reason for that is rasta ' s time window is too short to um include the whole um reverberation . 
um i don ' t know what you call it . 
the reverberation response . 
if you see if you see what i mean . 
the reverberation filter from my mouth to that mike is like it ' s it ' s too long in the in the time domain for the um for the rasta filtering to take care of it . 
and um 
then there are a couple of other speech enhancement approaches which haven ' t been tried for speech recognition yet . 
but have just been tried for enhancement . 
which um have the assumption that um you can do l p c um analysis of of the signal you get at the far microphone . 
and the um all pole filter that you get out of that should be good . 
it ' s just the um excitation signal that is going to be distorted by the reverberation . 
and so you can try and reconstruct a better excitation signal . 
and um feed that through the um all pole filter and get enhanced speech with reverberation reduced . 
uhhuh . 
uhhuh . 
there ' s also this uh um uh echo cancellation stuff that we ' ve sort of been chasing . 
so uh 
we have uh 
and when we ' re saying these digits now we do have a close microphone signal . 
and then there ' s the distant microphone signal . 
and you could as a kind of baseline say okay given that we have both of these uh we should be able to do uh a cancellation . 
so that uh um we we uh essentially identify the system in between the linear time invariant system between the microphones and and and and and invert it . 
uh or or cancel it out to to some some reasonable approximation . 
uhhuh . 
through one method or another . 
uh that ' s not a practical thing . 
uh if you have a distant mike you don ' t have a close mike ordinarily . 
but we thought that might make also might make a good baseline . 
uh it still won ' t be perfect because there ' s noise . 
uh but 
and then there are uh there are single microphone methods that i think people have done for uh for this kind of de reverberation . 
do do you know any references to any ? 
because i i i was i i lead him down a a bad path on that . 
uh 
i i guess i guess when people are working with single microphones they are more trying to do 
but 
well not not very 
well there is the avendano work . 
right . 
but also trying to huh uh trying to find the de - convolution filter . 
but in the 
um 
not in the time domain . 
but in the uh the stream of features uh i guess . 
yeah . 
okay . 
well there there ' s someone working on this on in mons . 
so perhaps 
yeah . 
we should try to 
he ' s working on this . 
on trying to 
yeah . 
on reverberation . 
um 
the first paper on this is going to have great references . 
i can tell already . 
uhhuh . 
it ' s always good to have references . 
especially when reviewers read it . 
or or one of the authors and feel they ' ll you ' re okay . 
you ' ve you cited me . 
so yeah . 
well he did echo cancellation . 
and he did some fancier things . 
like uh uh training different network on different reverberation conditions . 
and then trying to find the best one . 
but well . 
yeah . 
yeah . 
the the other thing uh that dave was talking about earlier was uh uh multiple mike things . 
uh where they ' re all distant . 
so um i mean there ' s there ' s all this work on arrays . 
but the other thing is uh what can we do that ' s cleverer that can take some advantage of only two mikes . 
uh particularly if there ' s an obstruction between them . 
as we as we have over there . 
if there is 
an obstruction between them . 
uh yeah . 
it creates a shadow . 
which is is helpful . 
it ' s part of why you have such good directionality with with two ears . 
even though they ' re not several feet apart . 
uhhuh . 
for most for most people ' s heads . 
that could help though . 
so that 
yeah the 
the head in the way is really 
that ' s what it ' s for . 
it ' s basically 
that ' s what the head ' s for ? 
yeah . 
it ' s to separate the ears . 
to separate the ears ? 
that ' s right . 
yeah . 
yeah . 
uh 
so 
anyway . 
uh i think that ' s that ' s all we have this week . 
oh . 
o k . 
and uh i think it ' s digit time . 
actually the um for some reason the digit forms are blank . 
yeah ? 
uh i think that may be due to the fact that adam ran out of digits uh and didn ' t have time to regenerate any . 
oh ! 
oh ! 
i guess it ' s 
well there ' s no real reason to write our names on here then . 
yeah . 
if you want to put your credit card numbers and uh 
is there ? 
oh no 
or do did any do we need the names for the other stuff ? 
or 
uh yeah . 
i do need your names and and the time and all that . 
oh okay . 
because we put that into the key files . 
oh okay . 
um 
but 
okay . 
that ' s why we have the forms . 
uh even if there are no digits . 
okay . 
yeah . 
i didn ' t notice this . 
i ' m sitting here . 
and i was i was about to read them too . 
it ' s a uh blank sheet of paper . 
so i guess we ' re we ' re done . 
yeah . 
yeah . 
i ' ll do my credit card number later . 
okay . 
okay . 
uh 
okay so there is kind of summary of what has been done . 
go ahead . 
it ' s this . 
oh okay . 
summary of experiments since well since last week . 
and also since the we ' ve started to run work on this . 
um so since last week we ' ve started to fill the column with um uh features with nets trained on p l p with online normalization . 
but with delta also . 
because the column was not completely 
huh huh . 
uhhuh . 
uhhuh . 
well it ' s still not completely filled . 
but we have more results to compare with network using without p l p . 
and finally um uh p uh delta seems very important . 
uh i don ' t know . 
if you take um let ' s say anyway aurora two b . 
so the next the second uh part of the table . 
uhhuh . 
uh when we use the large training set using french spanish and english you have one hundred and six without delta . 
and eighty nine with the delta . 
and again all of these numbers are with a hundred per cent being uh the baseline performance . 
yeah uhhuh . 
on the baseline yeah . 
but with a mel cepstra system going straight into the h t k . 
so 
yeah yeah . 
yes . 
so now we see that the gap between the different training set is much uh uh much smaller . 
it ' s out of the way . 
um 
but actually um for english training on timit is still better than the other languages . 
and 
uh 
yeah . 
and also for italian actually . 
if you take the second set of experiment for italian 
so the mismatched condition . 
uhhuh . 
um when we use the training on timit . 
so it ' s multi english . 
we have a ninety one number . 
uhhuh . 
and training with other languages is a little bit worse . 
um oh i see . 
down near the bottom of this sheet . 
uh yes . 
so 
yeah . 
okay . 
and yeah and here the gap is still more important between using delta and not using delta . 
yes . 
if if i take the training the large training set it ' s we have one hundred and seventy two . 
yeah . 
and one hundred and four when we use delta . 
uhhuh . 
uh even if the contexts used is quite the same . 
because without delta we use seventeenths seventeen frames . 
uh 
yeah um so the second point is that we have no single cross language experiments uh that we did not have last week . 
uh so this is training the net on french only . 
or on english only . 
and testing on italian . 
uhhuh . 
and training the net on french only . 
and spanish only . 
and testing on uh t i digits . 
uhhuh . 
and 
um 
yeah . 
what we see is that these nets are not as good . 
except for the multi english which is always one of the best . 
yeah . 
then we started to work on a large database containing uh sentences from the french from the spanish from the timit from spine uh from uh english digits and from italian digits . 
so this is the another line another set of lines in the table . 
uh yes . 
uh with spine . 
uhhuh . 
and uh actually we did this before knowing the result of all the data . 
uh so we have to redo the uh the experiment training the net with uh p l p but with delta . 
uhhuh . 
but with delta . 
but um this this net performed quite well . 
well 
it ' s it ' s better than the net using french spanish and english only . 
uh . 
so 
uh yeah . 
we have also started feature combination experiments . 
uh many experiments using features and net outputs together . 
and this is the results are on the other document . 
uh we can discuss this after perhaps well just another few minutes . 
yeah so basically there are four four kind of systems . 
the first one yeah is combining um two feature streams uh using 
and each feature stream has its own m . p . l . 
so it ' s the kind of similar to the tandem that was proposed for the first . 
the multi stream tandem for the first proposal . 
the second is using features and k l t transformed m l p outputs . 
and the third one is to use a single k l t transform features as well as m l p outputs . 
um 
yeah . 
huh . 
you know you can you can comment these results also . 
yes i can 
i would like to say that for example um huh if we doesn ' t use the delta delta uh we have an improve when we use some combination . 
but when 
yeah just to be clear the numbers here are uh recognition accuracy . 
yeah this yeah this number recognition 
so it ' s not the again we switch to another . 
yes and the baseline the baseline have is eighty two . 
baseline is eighty two . 
yeah . 
so it ' s experiment only on the italian mismatched for the moment for this . 
uh this is italian mismatched . 
yeah by the moment . 
um 
okay . 
huh . 
and first in the experiment one i i do i i use different m l p . 
uhhuh . 
and is obviously that the multi english m l p is the better . 
um for the ne rest of experiment i use multi english . 
only multi english . 
and i try to combine different type of feature . 
but the result is that the m s g three feature doesn ' t work for the italian database . 
because never help to increase the accuracy . 
yeah uh actually if we look at the table 
the huge table 
uhhuh . 
um we see that for t i digits m s g perform as well as the p l p . 
but this is not the case for italian what where the error rate is is almost uh twice the error rate of p l p . 
uhhuh . 
so um uh well i don ' t think this is a bug . 
but this this is something in probably in the m s g um process that 
uh 
i don ' t know what exactly . 
perhaps the fact that the the there ' s no low pass filter . 
well 
or no pre pre emphasis filter . 
and that there is some d c offset in the italian . 
or well 
something simple like that . 
but that we need to sort out if want to uh get improvement by combining p l p and m s g . 
uhhuh . 
because for the moment m s g doesn ' t bring much information . 
uhhuh . 
and as carmen said if we combine the two we have the result basically of p l p . 
i 
um the uh baseline system 
when you said the baseline system was uh uh eighty two per cent that was trained on what and tested on what ? 
that was uh italian mismatched uh uh digits uh is the testing . 
yeah . 
and the training is italian digits ? 
yeah . 
so the mismatch just refers to the noise and and uh microphone and so forth . 
yeah . 
right ? 
yeah . 
so um did we have 
so would that then correspond to the first line here of where the training is is the uh italian digits ? 
the the training of the h t k ? 
yes . 
yes . 
uh yes . 
this 
yes . 
yes . 
yes . 
training of the net . 
yeah . 
yeah . 
so um so what that says is that in a matched condition we end up with a fair amount worse putting in the uh p l p . 
now would do we have a number i suppose for the matched 
i i don ' t mean matched . 
but uh use of italian training in italian digits for p l p only ? 
uh yes . 
uh yeah . 
so this is basically this is in the table . 
uh so the number is fifty two . 
another table . 
uh 
fifty two per cent . 
so no it ' s it ' s the 
no . 
no fifty two per cent of eighty two ? 
of of of uh eighteen . 
eighty . 
eighty . 
of eighteen . 
so it ' s it ' s error rate basically . 
it ' s plus six . 
error rate ratio . 
so 
so 
oh this is accuracy ! 
huh . 
yeah . 
okay . 
uh so we have nine nine let ' s say ninety per cent . 
ninety . 
yeah . 
um which is uh what we have also if use p l p and m s g together . 
yeah . 
eighty nine point seven . 
okay so even just p l p uh it is not in the matched condition 
um i wonder if it ' s a difference between p l p and mel cepstra or whether it ' s that the net half for some reason is not helping . 
uh . 
p l p and mel cepstra give the same same results . 
same result pretty much . 
well we have these results . 
i don ' t know . 
it ' s not 
so 
do you have this result with p l p alone feeding h t k ? 
that that ' s what you mean . 
yeah . 
just p l p at the input of h t k . 
yeah yeah yeah yeah . 
at the first and the 
yeah . 
yeah . 
so p l p 
eighty eight point six . 
yeah . 
um so adding m s g 
um 
um well but that ' s yeah that ' s without the neural net . 
right ? 
yeah that ' s without the neural net . 
and that ' s the result basically that o g i has also with the m f c c with online normalization . 
but she had said eighty two . 
this is the well but this is without online normalization . 
right ? 
oh this the eighty two ? 
yeah . 
eighty two is the it ' s the aurora baseline . 
so m f c c . 
then we can use 
well o g i they use m f c c the baseline m f c c plus online normalization . 
oh i ' m sorry . 
i i keep getting confused . 
because this is accuracy . 
yeah sorry . 
yeah . 
yeah . 
okay all right . 
yeah . 
all right so this is i was thinking all this was worse . 
okay so this is all better . 
because eighty nine is bigger than eighty two . 
yes better . 
uhhuh . 
okay . 
yeah . 
i ' m i ' m all better now . 
okay go ahead . 
so what what happens is that when we apply online normalization we jump to almost ninety per cent . 
yeah . 
uhhuh . 
uh when we apply a neural network is the same . 
we jump to ninety per cent . 
nnn we don ' t know exactly . 
yeah . 
and and um 
whatever the normalization actually . 
if we use neural network even if the features are not correctly normalized we jump to ninety per cent . 
so we go from eighty eighty eight point six to to ninety or something . 
so 
well ninety 
no i i mean ninety 
it ' s around eighty nine . 
ninety . 
eighty nine . 
eighty eight . 
yeah . 
well there are minor minor differences . 
and then adding the m s g does nothing basically . 
no . 
yeah okay . 
uh for italian yeah . 
for this case right . 
um 
all right . 
so um so actually the answer for experiments with one is that adding m s g if you uh does not help in that case 
uhhuh . 
um 
yeah . 
but 
the other ones we ' d have to look at it . 
yeah . 
but 
and the multi english does . 
uh 
so if we think of this in error rates we start off with uh eighteen per cent error rate roughly . 
uhhuh . 
um and we uh almost uh cut that in half by um putting in the online normalization and the neural net . 
yeah . 
and the m s g doesn ' t however particularly affect things . 
no . 
and we cut off i guess about twenty five per cent of the error . 
uh no not quite that . 
is it ? 
uh two point six out of eighteen . 
about um sixteen per cent or something of the error um if we use multi english instead of the matching condition . 
uhhuh . 
not matching condition . 
yeah . 
but uh the uh italian training . 
yeah . 
uhhuh . 
okay . 
huh . 
we select these these these tasks . 
because it ' s the more difficult . 
yes good . 
okay . 
so then you ' re assuming multi english is closer to the kind of thing that you could use . 
since you ' re not going to have matching uh data for the uh for the new for the other languages and so forth . 
um one thing is that 
uh i think i asked you this before . 
but i want to double check . 
when you say m e in these other tests that ' s the multi english . 
that ' s it ' s a part it ' s 
but it is not all of the multi english . 
right ? 
it is some piece of part of it . 
or one million frames . 
and the multi english is how much ? 
you have here the information . 
it ' s one million and a half . 
yeah . 
oh so you used almost all . 
you used two thirds of it . 
yeah . 
you think . 
so it ' s still it hurts you seems to hurt you a fair amount to add in this french and spanish . 
huh . 
yeah . 
i wonder why . 
uh 
well stephane was saying that they weren ' t hand labeled . 
yeah . 
yeah it ' s 
yeah . 
the french and the spanish . 
the spanish . 
maybe for that . 
huh . 
huh . 
still . 
okay . 
all right go ahead . 
and then then 
um 
huh with the experiment type two . 
i first i tried to combine nnn some feature from the m l p and other feature . 
another feature . 
uhhuh . 
and we we can 
first the feature are without delta and delta delta . 
and we can see that in the situation uh the m s g three the same help nothing . 
uhhuh . 
and then i do the same . 
but with the delta and delta delta p l p delta and delta delta . 
and they all but they all put off the m l p is it without delta and delta delta . 
uhhuh . 
and we have a little bit less result than the the the baseline p l p with delta and delta delta . 
maybe if when we have the new the new neural network trained with p l p delta and delta delta 
maybe the final result must be better . 
i don ' t know . 
uh 
actually just to be some more 
do 
this number this eighty seven point one number has to be compared with the 
yes yeah i mean it can ' t be compared with the other . 
which number ? 
because this is uh with multi english uh training . 
uhhuh . 
so you have to compare it with the one over that you ' ve got in a box . 
which is that uh the eighty four point six . 
uhhuh . 
right ? 
uh 
so 
yeah but i mean in this case for the eighty seven point one we used m l p outputs for the p l p net . 
yeah . 
and straight features with delta delta . 
yeah . 
uhhuh . 
and straight features with delta delta gives you what ' s on the first sheet . 
not not 
it ' s eighty eight point six . 
no no no . 
yes . 
not trained with multi english . 
no but they they feature without 
uh yeah but this is the second configuration . 
so we use feature uh net outputs together with features . 
so yeah . 
this is not perhaps not clear here . 
but in this table the first column is for m l p and the second for the features . 
uh oh i see . 
uh so you ' re saying so asking the question what what has adding the m l p done to improve over the 
so just 
yeah 
so actually it it it decreased the the accuracy . 
uh 
yeah . 
yes . 
uhhuh . 
because we have eighty eight point six . 
and even the m l p alone 
what gives the m l p alone ? 
multi english p l p . 
oh no . 
it gives eighty three point six . 
so we have eighty three point six and eighty eighty point six . 
but 
that gives eighty seven point one . 
uhhuh . 
eighty 
i thought it was eighty 
oh okay . 
eighty three point six and eighty eighty eight point six . 
eighty three point six . 
eighty 
okay . 
is is that right ? 
yeah . 
yeah . 
but i don ' t know . 
but maybe if we have the neural network trained with the p l p delta and delta delta maybe this can help . 
perhaps yeah . 
well that ' s that ' s one thing . 
but see the other thing is that 
um i mean it ' s good to take the difficult case . 
but let ' s let ' s consider what that means . 
what what we ' re saying is that one one of the things that 
i mean my interpretation of your your original suggestion is something like this as motivation . 
when we train on data that is in one sense or another similar to the testing data then we get a win by having discriminant training . 
uhhuh . 
when we train on something that ' s quite different we have a potential to have some problems . 
uhhuh . 
and um if we get something that helps us when it ' s somewhat similar and doesn ' t hurt us too much when it when it ' s quite different that ' s maybe not so bad . 
yeah . 
so the question is if you took the same combination and you tried it out on uh on say digits 
huh . 
on t i digits ? 
okay . 
you know . 
was that experiment done ? 
no not yet . 
yeah okay . 
uh then does that uh you know maybe with similar noise conditions and so forth does it does it then look much better ? 
uhhuh . 
and so what is the range over these different kinds of uh of tests ? 
so anyway . 
okay go ahead . 
yeah . 
and with this type of configuration which i do on experiment using the new neural net with name broad klatt twenty seven . 
uhhuh . 
uh i have found more or less the same result . 
so it ' s slightly better . 
little bit better . 
yeah . 
slightly better . 
yeah . 
slightly better . 
yes better . 
and and you know again maybe if you use the uh delta there uh you would bring it up to where it was uh you know at least about the same for a difficult case . 
yeah maybe maybe maybe . 
yeah . 
oh yeah . 
yeah . 
so 
yeah . 
well so perhaps let ' s let ' s jump at the last experiment . 
it ' s either less information from the neural network if we use only the silence output . 
uhhuh . 
it ' s again better . 
so it ' s eighty nine point point one . 
uhhuh . 
yeah . 
yeah and we have only forty forty feature . 
so 
because in this situation we have one hundred and three feature . 
yeah . 
yeah . 
and then with the first configuration i i am found that work uh doesn ' t work 
yeah . 
uh well work . 
but is better the second configuration . 
because i for the p l p delta and delta delta here i have eighty five point three accuracy . 
and with the second configuration i have eighty seven point one . 
um by the way there is another uh suggestion that would apply uh to the second configuration . 
um which uh was made uh by uh hari . 
and that was that um if you have uh feed two streams into h t k um and you uh change the uh variances 
if you scale the variances associated with uh these streams um you can effectively scale the streams . 
right ? 
so um you know without changing the scripts for h t k . 
which is the rule here uh you can still change the variances . 
uhhuh . 
uhhuh . 
which would effectively change the scale of these these uh two streams that come in . 
uh yeah . 
and um so um if you do that for instance it may be the case that um the m l p should not be considered as strongly for instance . 
huh . 
and um so this is just setting them to be 
excuse me . 
of equal equal weight . 
maybe it shouldn ' t be equal weight . 
maybe . 
right you know i ' m sorry to say that gives more experiments if we wanted to look at that . 
but but uh um you know on the other hand it ' s just experiments at the level of the h t k recognition . 
huh . 
it ' s not even the h t k . 
uh uh 
yeah . 
yeah yeah . 
well i guess you have to do the h t k training also . 
so this is what we decided to do . 
uh do you ? 
let me think . 
maybe you don ' t . 
uh 
yeah you have to change the 
no you can just do it in as once you ' ve done the training 
and then you can vary it . 
yeah the training is just coming up with the variances . 
yeah . 
so i guess you could could just scale them all . 
scale them ? 
variances . 
yeah . 
but 
is it i mean the h t k models are diagonal covariances . 
so i is it 
that ' s uh exactly the point i think . 
that if you change um change what they are 
huh . 
it ' s diagonal covariance matrices . 
uhhuh . 
but you say what those variances are . 
uhhuh . 
so that you know it ' s diagonal but the diagonal means that then you ' re going to it ' s going to it ' s going to internally multiply it and and uh uh it uh implicitly exponentiated to get probabilities and so it ' s it ' s going to it ' s it ' s going to affect the range of things if you change the change the variances of some of the features . 
huh . 
huh . 
do 
so it ' s precisely given that model you can very simply affect uh the the strength that you apply the features . 
that was that was uh hari ' s suggestion . 
yeah yeah . 
so um 
yeah . 
yeah . 
so 
so it could just be that treating them equally treating two streams equally is just just not the right thing to do . 
of course it ' s potentially opening a can of worms . 
because you you know maybe it should be a different number for for each kind of test set or something . 
uhhuh . 
but 
okay . 
yeah . 
so i guess the other thing is to take you know if one were to take uh you know a couple of the most successful of these . 
yeah and test across everything . 
and uh 
yeah try all these different tests . 
huh . 
yeah . 
yeah . 
all right . 
uh 
so the next point . 
yeah . 
we ' ve had some discussion with steve and shawn . 
um about um articulatory stuff . 
um 
so we ' ll perhaps start something next week . 
uhhuh . 
um discussion with hynek sunil and pratibha for trying to plug in their our our networks with their within their block diagram . 
uh where to plug in the the network uh after the the feature . 
before as um as a plugin or as another path . 
discussion about multi band and traps . 
um 
actually hynek would like to see 
perhaps if you remember the block diagram there is uh temporal l d a followed by a spectral l d a for each uh critical band . 
and he would like to replace these by a network . 
which would uh make the system look like a trap . 
well basically it would be a trap system . 
basically this is a trap system . 
kind of trap system i mean . 
but where the neural network are replaced by l d a . 
um yeah . 
and about multi band . 
uh i started multi band m l p trainings . 
um 
actually i i prefer to do exactly what i did when i was in belgium . 
so i take exactly the same configurations . 
seven bands with nine frames of context . 
and we just train on timit . 
and on the large database . 
so with spine and everything . 
and uh 
i ' m starting to train also networks with larger contexts . 
so this would would be something between traps and multi band . 
because we still have quite large bands . 
and but with a lot of context also . 
so um 
yeah . 
we still have to work on finnish . 
um basically to make a decision on which m l p can be the best across the different languages . 
for the moment it ' s the timit network and perhaps the network trained on everything . 
so now we can test these two networks on with with delta and large networks . 
well test them also on finnish . 
huh . 
and see which one is the the the best . 
uh well the next part of the document is well basically a kind of summary of what everything that has been done . 
so we have seventy nine m l p ' s trained on 
one two three four uh three four five six seven . 
ten on ten different databases . 
uhhuh . 
uh 
the number of frames is bad also . 
so we have one million and a half for some . 
three million for other . 
and six million for the last one . 
uh 
yeah as we mentioned timit is the only that ' s hand labeled . 
and perhaps this is what makes the difference . 
um 
yeah the other are just viterbi aligned . 
so these seventy nine m l p differ on different things . 
first um with respect to the online normalization . 
there are that use bad online normalization . 
and other good online normalization . 
um 
with respect to the features . 
with respect to the use of delta . 
or no . 
uh with respect to to the hidden layer size and to the targets . 
uh but of course we don ' t have all the combination of these different parameters . 
um 
what ' s this ? 
we only have two hundred eighty six different tests . 
and not two thousand . 
uh . 
i was impressed . 
boy ! 
two thousand . 
yeah . 
okay . 
uh yes . 
all right now i ' m just slightly impressed . 
i say this morning that thought it was the 
okay . 
um 
yeah basically the observation is what we discussed already . 
the m s g problem . 
um 
the fact that the m l p trained on target task decreased the error rate . 
but when the m m l p is trained on the is not trained on the target task it increased the error rate compared to using straight features . 
except if the features are bad . 
uh actually except if the features are not correctly online normalized . 
in this case the tandem is still better . 
even if it ' s trained on not on the target digits . 
yeah so it sounds like yeah the net corrects some of the problems with some poor normalization . 
yeah . 
but if you can do good normalization it ' s it ' s uh okay . 
yeah . 
yeah . 
uh so the fourth point is yeah the timit plus noise seems to be the training set that gives better the best network . 
so let me before you go on to possible issues . 
uhhuh . 
so on the m s g uh problem 
um i think that in in the um in the short time solution 
um that is um trying to figure out what we can proceed forward with to make the greatest progress 
uhhuh . 
uh much as i said with j rasta . 
even though i really like j rasta . 
and i really like m s g . 
huh . 
i think it ' s kind of in category that it ' s it it may be complicated . 
yeah . 
and uh it might be if someone ' s interested in it uh certainly encourage anybody to look into it in the longer term . 
once we get out of this particular rush uh for results . 
huh . 
but in the short term unless you have some some strong idea of what ' s wrong 
i don ' t know at all . 
but i ' ve perhaps i have the feeling that it ' s something that ' s quite quite simple . 
or just like nnn no high pass filter . 
yeah probably . 
or huh 
yeah my but i don ' t know . 
there ' s supposed to well m s g is supposed to have an online normalization though . 
right ? 
it ' s there is yeah an a . g . kind of a . g . c . 
yeah yeah yeah . 
yeah but also there ' s an online besides the a g c there ' s an online normalization that ' s supposed to be . 
uh 
yeah . 
huh . 
taking out means and variances and so forth . 
so 
yeah . 
in in fact the online normalization that we ' re using came from the m s g design . 
so it ' s 
um 
yeah but 
yeah . 
but this was the bad online normalization actually . 
maybe may 
are your results are still with the bad the bad 
no . 
with the better 
no . 
with the o l n two . 
uh yeah you have you have o l n two . 
oh ! 
yeah yeah yeah ! 
with two with online two . 
yeah . 
yeah yeah . 
online two is good . 
so it ' s is the good yeah . 
yep . 
two is good . 
it ' s a good . 
and 
no two is bad . 
yeah . 
okay . 
well actually it ' s good with the with the good . 
yeah . 
so yeah i i agree . 
it ' s probably something simple . 
uh if if uh someone you know uh wants to play with it for a little bit . 
i mean you ' re going to do what you ' re going to do . 
huh . 
but but my my guess would be that it ' s something that is a simple thing that could take a while to find . 
but 
yeah . 
huh . 
i see . 
yeah . 
yeah . 
and 
and the other the results uh observations two and three um is 
huh . 
uh 
yeah that ' s pretty much what we ' ve seen . 
that ' s that what we were concerned about is that if it ' s not on the target task 
if it ' s on the target task then it it it helps to have the m l p transforming it . 
huh . 
if it uh if it ' s not on the target task then depending on how different it is uh you can get uh a reduction in performance . 
huh . 
and the question is now how to how to get one and not the other ? 
or how to how to ameliorate the the problems . 
huh . 
um because it it certainly does is nice to have in there when it when there is something like the training data . 
uhhuh . 
um 
yeah so the the reason yeah the reason is that perhaps the target the task dependency the language dependency and the noise dependency 
so that ' s what you say there . 
i see . 
well the but this is still not clear . 
because 
um 
i i i don ' t think we have enough result to talk about the the language dependency . 
well the timit network is still the best . 
but there is also the other difference . 
the fact that it ' s it ' s hand labeled . 
hey ! 
um just you can just sit here . 
uh i i don ' t think we want to mess with the microphones . 
but it ' s uh 
just uh have a seat . 
um 
summary of the first uh uh forty five minutes is that some stuff work and works and some stuff doesn ' t . 
okay . 
we still have uh this . 
one of these perhaps ? 
yeah . 
yeah i guess we can do a little better than that . 
huh . 
uhhuh . 
but i think if you if you start off with the other one actually that sort of has it in words . 
and then that has it the associated results . 
um 
okay . 
so you ' re saying that um um although from what we see 
yes there ' s what you would expect in terms of a language dependency and a noise dependency that is uh when the neural net is trained on one of those and tested on something different we don ' t do as well as in the target thing . 
but you ' re saying that uh it is although that general thing is observable so far there ' s something you ' re not completely convinced about . 
and and what is that ? 
i mean you say not clear yet . 
what what do you mean ? 
uh i mean the the fact that well for for t i digits the timit net is the best . 
huh uh . 
which is the english net . 
uhhuh . 
but the other are slightly worse . 
but you have two two effects the effect of changing language . 
and the effect of training on something that ' s viterbi aligned instead of hand hand labeled . 
yeah . 
so um 
yeah . 
do you think the alignments are bad ? 
i mean have you looked at the alignments at all ? 
what the viterbi alignment ' s doing . 
huh 
i don ' t i don ' t know . 
did did you look at the spanish alignments carmen ? 
huh no . 
might be interesting to look at it . 
because i mean that is just looking . 
but um um it ' s not clear to me you necessarily would do so badly from a viterbi alignment . 
it depends how good the recognizer is . 
huh . 
that ' s that the the engine is that ' s doing the alignment . 
yeah but but perhaps it ' s not really the the alignment that ' s bad . 
but the just the phoneme string that ' s used for the alignment . 
aha ! 
yeah . 
huh . 
the pronunciation models and so forth . 
i mean for we 
it ' s single pronunciation . 
uh 
aha ! 
i see . 
french french uh phoneme strings were corrected manually . 
so we asked people to listen to the the sentence . 
and we gave the phoneme string and they kind of correct them . 
but still . 
there there might be errors just in the in in the string of phonemes . 
huh 
um 
yeah so this is not really the viterbi alignment . 
in fact 
yeah . 
um the third the third uh issue is the noise dependency perhaps . 
but well this is not clear yet . 
because all our nets are trained on the same noises . 
and 
i thought some of the nets were trained with spine and so forth . 
so it and that has other noise . 
yeah . 
so 
yeah . 
but 
yeah . 
results are only coming for for this net . 
huh . 
okay yeah just don ' t just need more more results there with that that . 
yeah . 
um 
so uh from these results we have some questions with answers . 
what should be the network input ? 
um p l p work as well as m f c c i mean . 
um 
but it seems important to use the delta . 
uh with respect to the network size 
there ' s one experiment that ' s still running . 
and we should have the result today . 
comparing network with five hundred and one thousand units . 
so 
still no answer actually . 
huh huh . 
uh the training set 
well some kind of answer 
we can we can tell which training set gives the best result . 
but we don ' t know exactly why . 
uh right i mean the multi english so far is is the best . 
uh so 
yeah . 
multi multi english just means timit . 
right ? 
yeah . 
yeah . 
so uh that ' s 
yeah . 
so and and when you add other things in to to broaden it it gets worse uh typically . 
huh . 
yeah . 
uhhuh . 
then uh some questions without answers . 
okay . 
uh training set . 
um 
uhhuh . 
uh training targets 
i like that . 
the training set is both questions with answers and without answers . 
it ' s 
yeah . 
yeah . 
it ' s sort of yes it ' s it ' s multi uh purpose . 
yeah . 
okay . 
uh training 
right so yeah the training targets actually 
the two of the main issues perhaps are still the language dependency and the noise dependency . 
and perhaps to try to reduce the language dependency we should focus on finding some other kind of training targets . 
uhhuh . 
and labeling labeling seems important . 
because of timit results . 
uhhuh . 
uh 
for moment you use we use phonetic targets . 
but we could also use articulatory targets soft targets . 
and perhaps even um use networks that doesn ' t do classification . 
but just regression . 
so uh train to have neural networks that 
um um uh 
uhhuh . 
does a regression 
and well basically compute features and not nnn features without noise i mean uh transform the noisy features in other features that are not noisy . 
but continuous features . 
not uh uh hard targets . 
uhhuh . 
uhhuh . 
uh 
yeah that seems like a good thing to do probably . 
yeah . 
not uh again a short term sort of thing . 
yeah . 
i mean one of the things about that is that um it ' s 
the i guess the major risk you have there of being is being dependent on very dependent on the kind of noise and and so forth . 
yeah . 
but yeah . 
uh but it ' s another thing to try . 
so this is this is one thing this this could be could help could help perhaps to reduce language dependency . 
and for the noise part um we could combine this with other approaches like well the kleinschmidt approach . 
so the the idea of putting all the noise that we can find inside a database . 
uhhuh . 
yeah . 
i think kleinschmidt was using more than fifty different noises to train his network . 
and so this is one approach . 
uhhuh . 
and the other is multi band uh that i think is more robust to the noisy changes . 
uhhuh . 
so perhaps i think something like multi band trained on a lot of noises with uh features based targets could could could help . 
yeah if you it ' s interesting thought . 
maybe if you just trained up 
i mean yeah one one fantasy would be you have something like articulatory targets . 
and you have um some reasonable database . 
um 
but then which is um copied over many times with a range of different noises . 
uhhuh . 
and uh if because what you ' re trying to do is come up with a a core reasonable feature set which is then going to be used uh by the the uh h m m system . 
huh . 
so 
yeah okay . 
so 
um yeah . 
the future work is well try to connect to the to make to plug in the system to the o g i . 
system 
um there are still open questions there . 
uhhuh . 
where to put the m l p basically . 
um 
and i guess you know the the the real open question 
i mean there ' s lots of open questions . 
but one of the core quote open questions for that is um um if we take the uh you know the best ones here 
maybe not just the best one . 
but the best few or something . 
you want the most promising group from these other experiments . 
um how well do they do over a range of these different tests not just the italian ? 
huh . 
um 
and 
right ? 
huh yeah yeah . 
and then um then see again how 
we know that there ' s a there ' s a uh a a loss in performance when the neural net is trained on conditions that are different than than uh we ' re going to test on . 
but well if you look over a range of these different tests um how well do these different ways of combining the straight features with the m l p features uh stand up over that range ? 
uhhuh . 
that ' s that that seems like the the the real question . 
and if you know that 
so if you just take p l p with uh the double deltas . 
assume that ' s the the feature . 
look at these different ways of combining it . 
and uh take let ' s say just take uh multi english . 
cause that works pretty well for the training . 
uhhuh . 
and just take that case and then look over all the different things . 
how does that how does that compare between the ? 
so all the all the test sets you mean ? 
yeah . 
yeah . 
all the different test sets . 
and 
and for and for the couple different ways that you have of of of combining them . 
yeah . 
um how well do they stand up over the 
uhhuh . 
huh . 
and perhaps doing this for changing the variance of the streams and so on getting different scaling . 
that ' s another possibility if you have time . 
yeah . 
yeah . 
um 
yeah so this would be more working on the m l p as an additional path instead of an insert to the to their diagram . 
because 
yeah . 
perhaps the insert idea is kind of strange . 
because they they make l d a . 
and then we will again add a network does discriminate that discriminates . 
yeah it ' s a little strange . 
or 
but on the other hand they did it before . 
huh . 
um 
huh . 
and and and 
yeah . 
and because also perhaps we know that the when we have very good features the m l p doesn ' t help . 
so i don ' t know . 
um the other thing though is that 
um 
so uh we we want to get their path running here . 
right ? 
if so we can add this other stuff . 
um 
as an additional path . 
right ? 
yeah the the way we want to do 
because they ' re doing l d a rasta ? 
the 
what ? 
they ' re doing l d a rasta . 
yeah the way we want to do it perhaps is to just to get the v a d labels and the final features . 
yeah ? 
so they will send us the well provide us with the feature files . 
i see . 
i see . 
and with v a d binary labels . 
so that we can uh get our m l p features . 
and filter them with the v a d . 
and then combine them with their feature stream . 
i see . 
so 
so we so first thing of course we ' d want to do there is to make sure that when we get those labels of final features is that we get the same results as them . 
without putting in a second path . 
uh you mean 
oh yeah ! 
just retraining retraining the h t k . 
yeah just just to make sure that we have we understand properly what things are our very first thing to do is to is to double check that we get the exact same results as them on h t k . 
well 
oh yeah . 
yeah okay . 
huh . 
uh i mean i don ' t know that we need to 
yeah . 
yeah . 
um do we need to retrain ? 
i mean we can just take the their training files also . 
but but uh 
just for the testing just make sure that we get the same results so we can duplicate it before we add in another 
huh . 
okay . 
because otherwise you know we won ' t know what things mean . 
oh yeah . 
okay . 
and um 
yeah so lograsta 
i don ' t know if we want to 
we can try networks with log rasta filtered features . 
maybe . 
huh . 
i ' m sorry ? 
yeah well 
yeah . 
oh you know the other thing is when you say 
but 
i ' m i ' m sorry i ' m interrupting that . 
um uh when you ' re talking about combining multiple features 
um suppose we said okay we ' ve got these different features and so forth . 
but p l p seems pretty good . 
if we take the approach that mike did and have 
huh . 
i mean one of the situations we have is we have these different conditions . 
we have different languages . 
we have different different noises . 
um if we have some drastically different conditions and we just train up different m l ps with them . 
uhhuh . 
and put put them together . 
what what what mike found for the reverberation case at least i mean 
i mean who knows if it ' ll work for these other ones . 
that you did have nice interpolative effects . 
that is that yes if you knew what the reverberation condition was going to be and you trained for that then you got the best results . 
but if you had say a heavily reverberation heavy reverberation case and a no reverberation case uh and then you fed the thing uh something that was a modest amount of reverberation then you ' d get some result in between the two . 
so it was sort of behaved reasonably . 
is that a fair 
yeah . 
yeah . 
so you you think it ' s perhaps better to have several m l ps ? 
yeah . 
but 
it works better if what ? 
i see . 
well see 
you were doing something that was 
so maybe the analogy isn ' t quite right . 
you were doing something that was in way a little better behaved . 
you had for a single variable . 
which was uh uh reverberation . 
here the problem seems to be is that we don ' t have a a really huge net with a really huge amount of training data . 
but we have for this kind of task i would think sort of a modest amount . 
i mean a million frames actually isn ' t that much . 
we have a modest amount of of uh training data from a couple different conditions . 
and then uh in yeah that and the real situation is that there ' s enormous variability that we anticipate in the test set in terms of language . 
and noise type . 
uh and uh uh channel characteristic . 
sort of all over the map . 
a bunch of different dimensions . 
and so i ' m just concerned that we don ' t really have um the data to train up 
i mean one of the things that we were seeing is that when we added in we still don ' t have a good explanation for this . 
but we are seeing that we ' re adding in uh a few different databases . 
and uh the performance is getting worse . 
and uh when we just take one of those databases that ' s a pretty good one it actually is is is is is better . 
and uh that says to me yes that you know there might be some problems with the pronunciation models that some of the databases we ' re adding in or something like that . 
but one way or another we don ' t have uh seemingly the ability to represent in the neural net of the size that we have um all of the variability that we ' re going to be covering . 
so that i ' m i ' m i ' m hoping that 
um this is another take on the efficiency argument you ' re making . 
which i ' m hoping that with moderate size neural nets uh that uh if we if they look at more constrained conditions they they ' ll have enough parameters to really represent them . 
uhhuh . 
uhhuh . 
uhhuh . 
yeah . 
so doing both is is not is not right you mean . 
or 
yeah . 
yeah . 
i i just sort of have a feeling 
but yeah . 
huh . 
yeah . 
uhhuh . 
i mean the um i think it ' s true that the o g i folk found that using l d a rasta 
which is a kind of log rasta . 
it ' s just that they have the 
i mean it ' s done in the log domain as i recall . 
and it ' s it uh it ' s just that they it ' s trained up . 
right ? 
that that um benefitted from online normalization . 
so they did at least in their case it did seem to be somewhat complimentary . 
so will it be in our case where we ' re using the neural net ? 
i mean they they were not not using the neural net . 
uh i don ' t know . 
okay so the other things you have here are uh trying to improve results from a single 
yeah . 
make stuff better . 
okay . 
uh yeah . 
and c p u memory issues . 
yeah . 
we ' ve been sort of ignoring that . 
haven ' t we ? 
but 
yeah so i don ' t know . 
yeah but i 
but we have to address the problem of c p u and memory we 
well i think my impression 
you you folks have been looking at this more than me . 
but my impression was that uh there was a a a a strict constraint on the delay . 
yeah . 
but beyond that it was kind of that uh using less memory was better . 
and using less c p u was better . 
something like that . 
right ? 
yeah but 
yeah . 
so yeah but we ' ve 
i don ' t know . 
we have to get some reference point to where we 
well what ' s a reasonable number ? 
perhaps because if it ' s if it ' s too large or large . 
or 
um well i don ' t think we ' re um completely off the wall . 
i mean i think that if we if we have 
uh i mean the ultimate fall back that we could do 
if we find 
uh 
i mean we may find that we we ' re not really going to worry about the m l p . 
you know if the m l p ultimately after all is said and done doesn ' t really help then we won ' t have it in . 
huh . 
if m l p does we find help us enough in some conditions uh we might even have more than one m l p . 
we could simply say that is uh done on the uh server . 
huh . 
and it ' s 
uh 
we do the other manipulations that we ' re doing before that . 
so i i i think i think that ' s that ' s okay . 
and yeah . 
so i think the key thing was um this plug into o g i . 
um 
what what are they what are they going to be working 
do we know what they ' re going to be working on while we take their features ? 
they ' re they ' re starting to work on some kind of multi band . 
and 
so um 
this that was pratibha . 
sunil 
what was he doing ? 
do you remember ? 
sunil ? 
yeah . 
he was doing something new ? 
or 
i i don ' t i didn ' t remember . 
maybe he ' s working with neural network . 
i don ' t think so . 
trying to tune 
networks ? 
yeah i think so . 
i think they were also mainly 
well working a little bit of new things like networks and multi band . 
but mainly trying to tune their their system as it is now . 
just trying to get the best from this this architecture . 
yeah . 
okay . 
uh 
so i guess the way it would work is that you ' d get 
there ' d be some point where you say okay this is their version one or whatever . 
and we get these v a d labels and features and so forth for all these test sets from them . 
uhhuh . 
and then um uh that ' s what we work with . 
we have a certain level we try to improve it with this other path . 
and then um uh when it gets to be uh january 
some point 
uh we say okay we we have shown that we can improve this in this way . 
so now uh um what ' s your newest version . 
and then maybe they ' ll have something that ' s better . 
and then we we ' d combine it . 
this is always hard . 
i mean i i i used to work with uh folks who were trying to improve a good uh h m m system with uh with a neural net system . 
and uh it was common problem that you ' d 
oh and this actually this is true not just for neural nets . 
but just for in general if people were working with uh rescoring uh n best lists or lattices that come came from uh a mainstream recognizer . 
uh you get something from the the other site at one point and you work really hard on making it better with rescoring . 
but they ' re working really hard too . 
so by the time you have uh improved their score they have also improved their score . 
huh . 
and now there isn ' t any difference . 
yeah . 
because the other 
yeah . 
so um i guess at some point we ' ll have to 
so it ' s 
uh uh 
i i don ' t know . 
i think we ' re we ' re integrated a little more tightly than happens in a lot of those cases . 
i think at the moment they they say that they have a better thing we can we 
what takes all the time here is that we ' re trying so many things . 
huh . 
presumably uh in a in a day we could turn around . 
uh taking a new set of things from them and and rescoring it . 
huh huh . 
right ? 
so 
yeah perhaps we could . 
yeah . 
well okay . 
no this is i think this is good . 
i think that the most wide open thing is the issues about the uh you know different trainings . 
you know training targets and noises and so forth . 
huh . 
that ' s sort of wide open . 
so we we can for we we can forget combining multiple features and m l g perhaps ? 
or focus more on the targets and on the training data ? 
and 
yeah i think for right now um i i i really liked m s g . 
and i think that you know one of the things i liked about it is has such different temporal properties . 
and um i think that there is ultimately a really good uh potential for you know bringing in things with different temporal properties . 
um but um uh 
we only have limited time . 
and there ' s a lot of other things we have to look at . 
huh . 
and it seems like much more core questions are issues about the training set . 
and the training targets . 
and fitting in uh what we ' re doing with what they ' re doing . 
and you know with limited time . 
yeah . 
i think we have to start cutting down . 
so uh 
huh . 
i think so . 
yeah . 
and then you know once we 
um having gone through this process and trying many different things i would imagine that certain things uh come up that you are curious about . 
uh that you ' d not getting to . 
and so when the dust settles from the evaluation uh i think that would time to go back and take whatever intrigued you most . 
you know got you most interested . 
uh and uh and and work with it you know for the next round . 
uh as you can tell from these numbers uh nothing that any of us is going to do is actually going to completely solve the problem . 
so 
huh . 
so there ' ll still be plenty to do . 
barry you ' ve been pretty quiet . 
just listening . 
well i figured that . 
but that what what what were you involved in in this primarily ? 
um helping out uh preparing . 
well they ' ve been kind of running all the experiments and stuff . 
and i ' ve been uh uh doing some work on the on the preparing all all the data for them to to um train and to test on . 
um 
yeah right now i ' m i ' m focusing mainly on this final project i ' m working on in jordan ' s class . 
uh . 
i see . 
yeah . 
right . 
what ' s what ' s that ? 
um i ' m trying to 
um so there was a paper in i c s l p about um this this multi band um belief net structure this guy did . 
uhhuh . 
uh basically it was two h m ms with with a with a dependency arrow between the two h m ms . 
uhhuh . 
and so i want to try try coupling them instead of having an arrow that that flows from one sub band to another sub band . 
i want to try having the arrows go both ways . 
and um i ' m just going to see if if that that better models um uh asynchrony in any way . 
or um yeah . 
oh . 
okay . 
well that sounds interesting . 
yeah . 
okay . 
all right . 
anything to you wanted to 
no . 
okay . 
silent partner in the in the meeting . 
we got a laugh out of him . 
that ' s good . 
okay everyone must contribute to the our our sound sound files here . 
okay so speaking of which if we don ' t have anything else that we need 
you happy with where we are ? 
know know know where we ' re going ? 
huh . 
uh 
i think so yeah . 
yeah yeah . 
you you happy ? 
uhhuh . 
you ' re happy . 
okay everyone should be happy . 
okay . 
you don ' t have to be happy . 
you ' re almost done . 
yeah yeah . 
okay . 
actually i should mention 
so if um about the linux machine . 
swede . 
yeah . 
so it looks like the um normal neural net tools are installed there . 
huh . 
and um dan ellis i believe knows something about using that machine . 
so 
if people are interested in in getting jobs running on that maybe i could help with that . 
huh . 
yeah but i don ' t know if we really need now a lot of machines . 
well we could start computing another huge table . 
but 
yeah we 
well yeah i think we want a different table at least . 
yeah sure . 
right ? 
i mean there ' s there ' s some different things that we ' re trying to get at now . 
but 
but 
yeah . 
huh . 
so yeah as far as you can tell you ' re actually okay on on c p u uh for training and so on ? 
yeah . 
uh yeah i think so . 
well more is always better . 
but huh 
i don ' t think we have to train a lot of networks now that we know . 
we just select what works fine . 
okay . 
okay . 
yeah . 
and try to improve this . 
and we ' re okay on and we ' re okay on disk ? 
to work 
and 
it ' s okay yeah . 
well sometimes we have some problems . 
some problems with the 
but they ' re correctable uh problems . 
you know . 
yeah restarting the script basically . 
and 
yes . 
yeah i ' m familiar with that one . 
okay . 
all right . 
so uh since uh we didn ' t get a channel on for you you don ' t have to read any digits . 
but the rest of us will . 
uh is it on ? 
well we didn ' t . 
uh 
i think i won ' t touch anything . 
because i ' m afraid of making the driver crash . 
which it seems to do pretty easily . 
okay thanks . 
okay so we ' ll uh i ' ll start off the 
uh um 
connect the 
my battery is low . 
well let ' s hope it works . 
maybe you should go first and see . 
so that you ' re okay . 
batteries . 
yeah your battery ' s going down too . 
okay . 
so 
uh today we ' re looking at a number of uh things we ' re trying . 
and uh fortunately for listeners to this uh we lost some of it ' s visual . 
but um got tables in front of us . 
um what is what does combo mean ? 
so combo is um a system where we have these features that go through a network . 
and then this same string of features but low pass filtered with the low pass filter used in the m s g features . 
and so these low pass filtered goes through m uh another m l p . 
and then the linear output of these two m l p ' s are combined just by adding the values and then there is this k l t . 
um the output is used as uh features as well . 
um so let me try to restate this and see if i have it right . 
there is uh there is the features uh there ' s the o g i features and then um those features um go through a contextual uh 
l l let ' s take this bottom one pointed to by the bottom arrow . 
um those features go through a contextualized k l t . 
yeah . 
then these features also uh get um low pass filtered . 
yeah . 
so 
yeah i could perhaps draw this on the blackboard . 
sure . 
yeah . 
yeah . 
yeah . 
the graph . 
yeah another one . 
thank you . 
yeah that ' s good . 
so we have these features from o g i that goes through the three paths . 
yeah . 
three okay . 
the first is a k l t using several frames of the features . 
yeah . 
yeah . 
the second path is uh m l p also using nine frames several frames of features . 
yeah . 
uhhuh . 
the third path is this low pass filter . 
uhhuh . 
uh m l p . 
aha ! 
aha ! 
adding the outputs just like in the second the the proposal from for the first evaluation . 
yeah . 
yeah . 
yeah . 
and then the k l t and then the two together again . 
no the k l t . 
and those two together . 
two h t k . 
that ' s it . 
um so this is 
okay so that ' s that ' s this bottom one . 
yeah . 
and so uh and then the the the one at the top . 
and i presume these things that uh are in yellow are in yellow because overall they ' re the best ? 
yeah . 
that ' s the reason yeah . 
oh let ' s focus on them then . 
so what ' s the block diagram for the one above it ? 
for the the first yellow line you mean ? 
yeah . 
yeah . 
so it ' s uh basically the same except that we don ' t have this uh low pass filtering so we have only two streams . 
step . 
well . 
there ' s there ' s no low low pass processing used as additional feature stream . 
uhhuh . 
uhhuh . 
um 
do you um they mentioned made some uh when i was on the phone with sunil they they mentioned some weighting scheme that was used to evaluate all of these numbers . 
yeah . 
uh actually the way things seems to 
um well it ' s uh forty percent for t i digit sixty for all the speechdat cars . 
well all these languages . 
um the well match is forty medium thirty five and high mismatch twenty five . 
yeah . 
um and we don ' t have the t i digits part yet ? 
uh no . 
okay . 
but yeah . 
generally what you observe with t i digits is that the result are very close whatever the the system . 
okay . 
and so have you put all these numbers together into a single number representing that ? 
yeah . 
i mean not 
uh not yet . 
no . 
okay so that should be pretty easy to do and that would be good . 
huh yeah yeah . 
then we could compare the two and say what was better . 
huh . 
yeah . 
um and how does this compare to the numbers ? 
oh so o g i two is just the top top row ? 
yeah . 
so yeah to 
actually o g i two is the the baseline with the o g i features . 
but this is not exactly the result that they have because they ' ve they ' re still made some changes in the features . 
okay . 
and well but uh actually our results are better than their results . 
um i don ' t know by how much because they did not send us the new results . 
okay . 
uh okay so the one one place where it looks like we ' re messing things up a bit is in the highly mismatched italian . 
yeah . 
yeah . 
yeah . 
there is something funny happening here because 
yeah . 
yeah . 
but there are thirty six and then sometimes we are we are we are around forty two and 
now up . 
uh so one of the ideas that you had mentioned last time was having a a second um silence detection . 
yeah . 
so there are some results here . 
for the italian . 
uh so the third and the fifth line of the table 
for this one . 
so filt is what that is ? 
filt yeah . 
yeah . 
um yeah so it seems for the the well match and mismatched condition . 
it ' s uh it brings something . 
uh but uh actually apparently there are there ' s no room left for any silence detector at the server side because of the delay . 
uh well 
oh we can ' t do it . 
oh okay . 
no . 
for that for that we 
oh . 
uh 
too bad . 
good idea but can ' t do it . 
yeah . 
okay . 
except i don ' t know because they i think they are still working well . 
uhhuh . 
uh two days ago they were still working on this trying to reduce the delay of the silence detector . 
so but 
yeah . 
if we had time perhaps we could try to find uh some kind of compromise between the delay that ' s on the handset and on the server side . 
perhaps try to reduce the delay on the handset . 
and 
but well huh for the moment they have this large delay on the the feature computation and so we don ' t 
okay . 
so 
all right so for now at least that ' s not there . 
you have some results with low pass filter cepstrum . 
doesn ' t have a huge effect but it but it looks like it you know maybe could help in a couple places . 
i 
yeah . 
uh little bit . 
um and um um 
yeah . 
and uh let ' s see . 
what else did we have in there ? 
uh i guess it makes a um at this point this is 
i i guess i should probably look at these others a little bit . 
uh and you you yellowed these out . 
uh but uh uh 
oh i see yeah that that one you can ' t use because of the delay . 
those look pretty good . 
um let ' s see that one . 
well even the just the the second row doesn ' t look that bad right ? 
that ' s just uh 
yep . 
yeah ? 
and and that looks like an interesting one too . 
huh yeah . 
uh 
actually the yeah the second line is uh pretty much like the first line in yellow . 
except that we don ' t have this k l t on the first on the left part of the diagram . 
we just have the features as they are . 
uhhuh . 
um 
yeah . 
yeah so when we do this weighted measure we should compare the two because it might even come out better . 
uhhuh . 
and it ' s it ' s it ' s a little slightly simpler . 
yeah . 
so so there ' s so i i would put that one also as a as a maybe . 
uh and it 
yeah and it ' s actually does does significantly better on the uh uh highly mismatched italian . 
so 
and little worse on the on the m m case . 
but 
uh well yeah it ' s worse than a few things . 
uhhuh . 
so uh let ' s see how that that see how that comes out on their their measure . 
and are are we running this uh for t i digits ? 
or uh 
yeah . 
yeah . 
now is t i di is that part of the result that they get for the uh development the results that they ' re supposed to get at the end of end of the month the t i digits are there also ? 
yeah . 
it ' s included yeah . 
oh okay . 
okay . 
and see what else there is here . 
um oh i see . 
the one i was looking down here at the the the row below the lower yellowed one . 
uh that ' s uh that ' s with the reduced uh k l t size reduced dimensionality . 
yeah . 
yeah . 
what happens there is it ' s around the same . 
and so you could reduce the dimension as you were saying before a bit perhaps . 
yeah it ' s it ' s significantly worse well but uhhuh . 
it ' s significantly worse . 
it ' s it ' s uh it ' s it ' s mostly worse . 
except for the h m . 
for many a mismatch it ' s worse . 
but 
yeah . 
but it is little . 
i mean not not by a huge amount . 
i don ' t know . 
what are what are the sizes of any of these sets ? 
i i ' m i ' m sure you told me before but i ' ve forgotten . 
so you know how many words are in uh one of these test sets ? 
uh 
i don ' t remember . 
um it ' s it depends well the well matched is generally larger than the other sets . 
about ? 
and i think it ' s around two thousand or three thousand words perhaps at least . 
but words well word i don ' t know . 
huh ? 
the words yeah . 
sentences . 
sentences . 
some sets have five hundred sentences . 
so 
yeah . 
huh . 
so the so the sets so the test sets are between five hundred and two thousand sentences let ' s say . 
and each sentence on the average has four or five digits ? 
or is it most of them longer or 
yeah . 
for the italian even seven digits more or less . 
yeah . 
it it 
but sometime the sentence have only one digit . 
seven digits . 
and sometime uh like uh the number of uh credit cards something like that . 
uhhuh . 
right so between one and sixteen . 
see the i mean the reason i ' m asking is is is we have all these small differences and i don ' t know how seriously to take them right ? 
so uh if if you had uh just you know to give an example if you had uh um if you had a thousand words then uh a a tenth of a percent would just be one word . 
yeah . 
right ? 
so so it wouldn ' t mean anything . 
yeah . 
yeah . 
oh . 
um so um yeah it be kind of i ' d kind of like to know what the sizes of these test sets were actually . 
the size that we have ? 
yeah . 
we could we could run run some kind of significance tests . 
yeah since these 
well also just to know the numbers . 
or 
yeah . 
right . 
so these these are word error rates . 
yeah . 
so this is on how many words ? 
yep . 
yeah we have the result that the output of the h t k . 
yeah . 
the number of of sentences no it ' s the number isn ' t . 
yeah sure sure . 
yeah sure . 
yeah . 
yeah . 
so anyway if you could just mail out what those numbers are and then then that that be great . 
yeah . 
um what else is there here ? 
um see the second second from the bottom it says s i l . 
but this is some different kind of silence or thing or 
what was that ? 
uh 
it the the output silence of the m l p . 
oh yeah . 
i see . 
it ' s only one small experiment to know what happened . 
to apply also to include also the the silence of the m l p we have the fifty six form and the silence to pick up the silence and we include those . 
yes . 
uhhuh uhhuh . 
the silence plus the k l t output ? 
oh so you ' re only using the silence . 
yeah . 
yeah because when we apply the k l t 
no they ' re i think there is this silence in addition to the um k l t outputs . 
no . 
in addition yes . 
in addition 
it is because we we we just keep uh we don ' t keep all the dimensions after the k l t . 
and yeah . 
and we not we are not sure if we pick we have the silence . 
so we try to add the silence also in addition to the these twenty eight dimensions . 
i see . 
okay . 
and what and what ' s o g i forty five ? 
uh it ' s it ' s o g i two . 
the bottom one there ? 
it ' s so the it ' s the features from the first line . 
it ' s in fact o g i two . 
and yeah . 
right but i mean what ' s the what does the last row mean ? 
so it ' s uh basically this but without the k l t on the from the left path . 
i thought that was the one i thought that was the second row . 
so what ' s the difference between the second 
uh the second line you don ' t have this combo stuff so you just 
oh . 
uh 
so this is like the second line but with with the combo stuff . 
yeah . 
and with the all the output of the combo . 
yeah . 
okay . 
yeah . 
yeah . 
uh 
okay so 
all right . 
so it looks to me i guess the same . 
given that we have to take the filt ones out of the the running because of this delay problem so it looks to me like the ones you said i agree are are the ones to look at . 
uhhuh . 
but i just would add the the the second row one . 
yeah . 
and then um if we can um 
huh . 
oh yeah also when when they ' re using this weighting scheme of forty thirty five twenty five is that on the percentages or on the raw errors ? 
i guess it ' s probably on the percentages right ? 
uh i guess yeah . 
yeah okay . 
i guess yeah . 
huh . 
all right . 
it ' s not clear here . 
okay . 
maybe maybe they ' ll argue about it . 
um okay . 
so if we can know what how many words are in each . 
and then um dave uh dave promised to get us something tomorrow which will be there as far as they ' ve gotten friday . 
uhhuh . 
yeah . 
and then we ' ll operate with that . 
and uh how long did it 
i guess if we ' re not doing all these things if we ' re only doing um 
um i guess since this is development data it ' s legitimate to do more than one . 
right ? 
i mean ordinarily if in final test data you don ' t want to do several and and take the best . 
yeah . 
huh . 
that ' s that ' s that ' s not proper . 
but if this is development data we could still look at a couple . 
yeah . 
we can . 
yeah . 
sure . 
but we have to decide . 
i mean we have to fix the system on this on this data to choose the best . 
yeah . 
and these 
right . 
but the question is when when do we fix the system . 
but we could . 
do we fix the system uh tomorrow or do we fix the system on tuesday ? 
it 
i think we fixed on tuesday yeah . 
i yeah okay except that we do have to write it up . 
yeah . 
uhhuh . 
uhhuh . 
yeah . 
also so 
yeah . 
um 
uh yeah well . 
well basically it ' s this with perhaps some kind of printing and some some other . 
right . 
so maybe what we do is we we we uh as soon as we get the data from them we start the training and so forth . 
yeah but 
uhhuh . 
but we start the write up right away because as you say there there ' s only minor differences between these . 
i think you we could we could start soon yeah . 
yeah . 
write up something . 
yeah and and i i would you know i would i ' d kind of like to see it . 
um yeah . 
uhhuh . 
maybe i can i can edit it a bit . 
uh sure . 
the my what in this in this situation is my forte which is english . 
yeah . 
uh so 
huh . 
uh yeah . 
have have you seen do they have a format for how they want the system descriptions or anything ? 
uh not really . 
okay . 
um there is the format of the table which is quite impressive . 
uh i see . 
yes for those who are listening to this and not looking at it uh it ' s not really that impressive it ' s just tiny . 
it ' s all these little categories set a set b set c multi condition clean . 
uh no mitigation . 
wow . 
do you know what no what no mitigation means here ? 
um it should be the the problem with the error channel error . 
oh that ' s probably the 
or 
this is probably channel error stuff . 
yeah . 
huh ? 
oh this is right it says right above here channel channel error resilience . 
yeah . 
yeah . 
so recognition performance is just the top part actually . 
uh and they have yes split between seen data bases and non seen so basically between development and and evaluation . 
yeah . 
and so 
right . 
it ' s presumed there ' s all sorts of tuning that ' s gone on on the what they call seen databases . 
and there won ' t be tuning for the uh unseen . 
multi condition multi condition . 
so they have looks like they have 
uhhuh . 
uh uh 
so they splitting up between the t i digits and everything else i see . 
so the everything else is the speechdat car that ' s the multilingual 
yeah so it ' s not divided between languages you mean or 
well it is . 
it just 
it is . 
but there ' s also there ' s these tables over here for the for the t i digits and these tables over here for the car data . 
oh yeah . 
which is which is i guess all the multilingual stuff . 
and then uh there ' s they also split up between multi condition and clean only . 
yeah . 
for t i digits . 
yes . 
yeah actually yeah . 
for the t i digits they want to train on clean and on noisy . 
yeah . 
and yeah . 
so we ' re doing that also i guess . 
uh yeah . 
but uh we actually 
do we have the features ? 
yeah . 
for the clean t i digits but we did not test it yet . 
uh the clean training stuff . 
okay . 
huh . 
well anyway sounds like there ' ll be a lot to do just to work with our partners to fill out the tables over the next uh next few days . 
uhhuh . 
yes . 
i guess they have to send it out 
let ' s see the thirty first is uh uh wednesday . 
and i think the it has to be there by some hour uh european time on wednesday . 
huh huh . 
so i think basically 
we lost time uh wednesday maybe because that the difference in the time may be is a long different of the time . 
excuse me ? 
maybe the thursday the twelfth of the night of the thirty one is is not valid in europe . 
yeah . 
we don ' t know is happening . 
yes so i mean i think we have to actually get it done tuesday . 
tuesday . 
yeah well . 
right . 
because i i think 
except if if it ' s the thirty one at midnight . 
uh uh 
or i don ' t know . 
we can still do some work on wednesday morning . 
yeah well . 
yeah well . 
is but is is it i thought it was actually something like five p m on 
yeah . 
yeah . 
uhhuh . 
was like i thought it was five p m or something . 
i didn ' t think it was midnight . 
i thought they said they wanted everything by 
yeah five p m . 
well so five p m their time is is 
not five p m three p m . 
if 
three p m . 
three p m . 
all right that ' s six in the morning here . 
it ' s 
uh no . 
no . 
three three three p m ? 
no we are wondering about the the the hour that we have to 
uh i don ' t know if it ' s three p m it ' s 
oh yeah yeah yeah yeah . 
three p m here is in europe midnight . 
yeah it ' s it ' s midnight but 
yes yes but i didn ' t think it was midnight that it was due . 
oh okay . 
i thought it was due at some hour during the day like five p m or something . 
huh huh . 
uhhuh . 
maybe . 
in which case 
so i i uh well we should look . 
but my assumption is that we basically have to be done tuesday . 
um so then next thursday we can sort of have a little aftermath . 
yeah . 
but then then we ' ll actually have the new data which is the german and the danish . 
yeah . 
but that really will be much less work because uh the system will be fixed . 
yeah . 
so all we ' ll do is take whatever they have and and uh and run it through the process . 
yeah . 
uhhuh . 
uh we won ' t be changing the training on anything . 
so there ' ll be no new training there ' ll just be new h t k runs . 
so that ' s means in some sense we can kind of relax from this after after tuesday . 
and and uh maybe next meeting we can start talking a little bit about where we want to go from here uh in terms of uh the research . 
uhhuh . 
um you know what things uh did you think of when you were uh doing this process that uh you just didn ' t really have time to adequately work on ? 
uh uh so 
uhhuh . 
yeah . 
what ? 
oh stephane always has these great ideas . 
and 
oh but uh we don ' t have time . 
sure . 
yeah . 
yeah . 
yeah . 
i ' m not sure these are great ideas . 
but they ' re ideas . 
yeah ? 
oh that was good . 
yeah . 
yeah . 
and and uh also it ' s still true that uh i think it ' s true that that we we at least got fairly consistent improved results by running uh the uh neural net transformation in parallel with the features . 
but 
rather than uh in sequence which was was your suggestion and that that that seems to have been borne out . 
uhhuh . 
uhhuh . 
the fact that none of these are are you know enormous is is is not too surprising . 
most improvements aren ' t enormous . 
and uh 
yeah . 
some of them are . 
but uh i mean you have something really really wrong and you fix it you can get big and really enormous improvements . 
uhhuh . 
but uh um because our best improvements over the years that we ' ve gotten from finding bugs . 
but 
anyway . 
okay . 
well i i think i see where we are and everybody knows what they ' re doing and is there is there anything else we should talk about ? 
or or are we done ? 
uhhuh . 
i think it ' s okay . 
um we 
so basically we will i think we ' ll try to to focus on these three architectures . 
and and perhaps i was thinking also a fourth one with just just a single k l t . 
because we did not really test that . 
removing all these k l t ' s and putting one single k l t at the end . 
uhhuh . 
yeah i mean that would be pretty low maintenance to try it . 
yeah . 
uh if you can fit it in . 
uhhuh . 
oh i have yeah i do have one other piece of information which uh i should tell people outside of this group too . 
uh i don ' t know if we ' re going to need it uh but uh jeff up at the uh university of washington has uh gotten a hold of a uh uh some kind of server farm of uh of ten uh uh multiprocessor uh i b m machines r s six thousands . 
uhhuh . 
and and uh so i think each one is four processors or something or i don ' t know eight hundred megahertz or something . 
and there ' s four processors in a box and there ' s ten boxes and there ' s some kind of 
so if you know he ' s got a lot of processing power . 
and um 
we ' d have to schedule it . 
but if we have some big jobs and we want to want to want to run them he ' s he ' s offering it . 
uhhuh . 
so 
it ' s uh 
when he was here uh uh he he used not only every machine here but every machine on campus as far as i could tell . 
so 
so in some ways he just got his payback . 
but uh again i i don ' t know if we ' ll end up with if we ' re going to be c p u limited on anything that we ' re doing in this group . 
uhhuh . 
but but if if we are that ' s an offer . 
okay . 
well uh you guys doing great stuff so that ' s that that ' s really neat . 
and uh 
we ' ll uh uh don ' t think we need to uh 
um oh well the other thing i guess that i will say is that uh the digits that we ' re going to record momentarily is starting to get are starting to get into a pretty good size collection . 
and um in addition to the speechdat stuff we will have those to work with really pretty soon now . 
so that ' s that ' s another source of data . 
um which is under somewhat better control and that we can we can make measurements of the room . 
the uh that you know if we feel there ' s other measurements we don ' t have that we ' d like to have we can make them . 
and 
uh dave and i were just talking about that a little while ago . 
uhhuh . 
so uh that ' s another another possibility for this this kind of work . 
k uh if nobody has anything else maybe we should go around do do our digits do our digits duty . 
okay . 
okay i ' ll start . 
okay . 
so 
um what are we talking about today ? 
uh well first there are perhaps these uh meeting recorder digits that we tested . 
oh yeah that was kind of uh interesting . 
so 
the both the uh the s r i system and the 
um 
and for one thing that that sure shows the difference between having a lot of uh training data or not . 
of data ? 
yeah . 
uh the uh the best kind of number we have on the english uh on near microphone only is is uh three or four percent . 
uhhuh . 
and uh it ' s significantly better than that using fairly simple front ends on on the uh uh with the s r i system . 
uhhuh . 
so i i think that the 
uh 
but that ' s that ' s using uh a a pretty huge amount of data . 
mostly not digits of course . 
but but then again 
well yeah . 
in fact mostly not digits for the actual training the h m m ' s whereas uh in this case we ' re just using digits for training the h m m ' s . 
yeah . 
right . 
did anybody mention about whether the the s r i system is a is is doing the digits um the as a word model or as uh a sub phone states ? 
i guess it ' s it ' s uh allophone models . 
yeah . 
so well 
probably . 
huh ? 
yeah i think so . 
because it ' s their very huge their huge system . 
yeah . 
and 
but 
so there is one difference . 
well the s r i system the result for the s r i system that are represented here are with adaptation . 
so there is 
it ' s their complete system and including online uh unsupervised adaptation . 
that ' s true . 
and if you don ' t use adaptation the error rate is around fifty percent worse i think if i remember . 
yeah . 
okay . 
it ' s it ' s that much huh ? 
it ' s 
yeah . 
it ' s quite significant . 
yeah . 
oh . 
okay . 
still . 
uhhuh . 
but but uh what what i think i ' d be interested to do given that is that we we should uh take 
i guess that somebody ' s going to do this . 
right ? 
is to take some of these tandem things and feed it into the s r i system . 
right ? 
yeah . 
yeah . 
we can do something like that . 
yeah . 
yeah because 
but 
but i guess the main point is the data because 
uh i am not sure . 
our back end is is fairly simple . 
but until now well the attempts to improve it or have 
uh well i mean uh what chuck tried to to to do 
yeah . 
but he ' s doing it with the same data right ? 
yeah . 
i mean so to so there ' s there ' s there ' s two things being affected . 
so it ' s 
yeah . 
i mean one is that that you know there ' s something simple that ' s wrong with the back end . 
we ' ve been playing a number of states . 
uhhuh . 
uh i i don ' t know if he got to the point of playing with the uh number of gaussians yet . 
uhhuh . 
but but uh 
uh you know . 
but yeah so far he hadn ' t gotten any big improvement . 
uhhuh . 
but that ' s all with the same amount of data which is pretty small . 
yeah . 
huh . 
and um 
so yeah we could retrain some of these tandem on on huge 
well you could do that but i ' m saying even with it not with that part not retrained . 
uh yeah . 
just just using having the h m m ' s much better h m m ' s . 
just 
for the h m m models . 
yeah . 
yeah . 
uhhuh . 
uhhuh . 
um but just train those h m m ' s using different features . 
the features coming from our aurora stuff . 
yeah . 
yeah . 
but what would be interesting to see also is what what 
perhaps it ' s not related the amount of data but the um recording conditions . 
i don ' t know . 
because it ' s probably not a problem of noise because our features are supposed to be robust to noise . 
it ' s not a problem of channel because there is um normalization with respect to the channel . 
well yeah . 
so 
i i i ' m sorry . 
what what is the problem that you ' re trying to explain ? 
the the fact that the result with the tandem and aurora system are uh so much worse . 
that the 
oh . 
so much worse ? 
yeah . 
oh . 
i uh but i ' m i ' m almost certain that it it i mean that it has to do with the um amount of training data . 
it 
it it ' s it ' s orders of magnitude off . 
yeah but 
yeah . 
yeah but we train only on digits and it ' s it ' s a digit task . 
so 
well 
but but having a huge 
it 
if if you look at what commercial places do they use a huge amount of data . 
uhhuh . 
all right . 
this is a modest amount of data . 
yeah . 
uhhuh . 
so i mean ordinarily you would say well given that you have enough occurrences of the digits you can just train with digits rather than with you know 
uhhuh . 
but the thing is if you have a huge 
in other words do word models 
but if you have a huge amount of data then you ' re going to have many occurrences of similar uh allophones . 
right . 
huh . 
yeah . 
and that ' s just a huge amount of training for it . 
so it ' s um i i think it has to be that because as you say this is you know this is near microphone . 
uhhuh . 
it ' s really pretty clean data . 
uhhuh . 
um 
now some of it could be the fact that 
uh 
let ' s see in the in these multi train things did we include noisy data in the training ? 
yeah . 
i mean that could be hurting us actually for the clean case . 
yeah . 
well actually we see that the clean train for the aurora proposals are are better than the multi train . 
it is if 
yeah . 
yeah . 
yeah . 
because this is clean data . 
and so that ' s not too surprising . 
uhhuh . 
but um uh 
so 
well i guess what i meant is that 
well let ' s say if we if we add enough data to train on the um on the meeting recorder digits i guess we could have better results than this . 
uhhuh . 
uhhuh . 
and 
what i meant is that perhaps we can learn something uh from this . 
what ' s what ' s wrong uh what what is different between t i digits and these digits . 
and 
what kind of numbers are we getting on t i digits ? 
it ' s point eight percent . 
so 
oh . 
i see . 
fourier . 
so in the actual t i digits database we ' re getting point eight percent . 
yeah . 
yeah . 
and here we ' re getting three or four three . 
uhhuh . 
let ' s see three for this ? 
yeah . 
sure but i mean 
um point eight percent is something like double uh or triple what people have gotten who ' ve worked very hard at doing that . 
uhhuh . 
and and also as you point out there ' s adaptation in these numbers also . 
huh . 
so if you you know put the take the adaptation off then it for the english near you get something like two percent . 
and here you had you know something like three point four . 
uhhuh . 
and i could easily see that difference coming from this huge amount of data that it was trained on . 
uhhuh . 
so it ' s 
you know i don ' t think there ' s anything magical here . 
yeah . 
it ' s you know we used a simple h t k system with a modest amount of data . 
and this is a a you know modern uh system . 
yeah . 
uh has has a lot of nice points to it . 
uhhuh . 
um 
so i mean the h t k is an older h t k even . 
so 
uhhuh . 
yeah it it ' s not that surprising . 
but to me it just it just meant a practical point that um if we want to publish results on digits that that people pay attention to we probably should uh 
because we ' ve had the problem before that you get show some nice improvement on something that ' s that ' s uh uh it seems like too large a number . 
uhhuh . 
and uh uh people don ' t necessarily take it so seriously . 
um 
yeah . 
yeah . 
so the three point four percent for this uh is is 
uh 
so why is it 
it ' s an interesting question though still . 
why is why is it three point four percent for the the digits recorded in this environment as opposed to the uh point eight percent for for for the original t i digits database ? 
um 
yeah . 
that ' s that ' s my point . 
given given the same 
i i i don ' t i 
yeah so ignore ignoring the the the s r i system for a moment . 
uhhuh . 
just looking at the t i the uh tandem system . 
if we ' re getting point eight percent which yes it ' s high . 
it ' s you know it it ' s not awfully high . 
uhhuh . 
but it ' s you know it ' s it ' s high . 
um why is it uh four times as high or more ? 
yeah i guess . 
right ? 
i mean there ' s even though it ' s close miked there ' s still there really is background noise . 
uhhuh . 
um and uh i suspect when the t i digits were recorded if somebody fumbled or said something wrong or something that they probably made them take it over . 
uhhuh . 
it was not i mean there was no attempt to have it be realistic in any in any sense at all . 
well . 
yeah . 
and acoustically it ' s it ' s 
i listened . 
it ' s quite different . 
t i digit is it ' s very very clean and it ' s like studio recording . 
uhhuh . 
whereas these meeting recorder digits sometimes you have breath noise . 
and 
huh . 
right . 
yeah . 
so i think they were 
it ' s not controlled at all i mean . 
bless you . 
thanks . 
i yeah i think it ' s it ' s 
uhhuh . 
so yes . 
but 
it ' s i think it ' s it ' s the indication it ' s harder . 
yeah . 
uh yeah and again you know that ' s true either way . 
i mean so take a look at the uh um the s r i results . 
i mean they ' re much much better . 
but still you ' re getting something like one point three percent for uh things that are same data as in t t i digits the same same text . 
uhhuh . 
uh and uh i ' m sure the same same system would would get you know point point three or point four or something on the actual t i digits . 
so this i think on both systems the these digits are showing up as harder . 
huh . 
um 
uhhuh . 
which i find sort of interesting cause i think this is closer to 
uh i mean it ' s still read . 
but i still think it ' s much closer to to what what people actually face um when they ' re they ' re dealing with people saying digits over the telephone . 
i mean i don ' t think uh 
i mean i ' m sure they wouldn ' t release the numbers . 
but i don ' t think that uh the uh the the companies that that do telephone speech get anything like point four percent on their digits . 
i ' m i ' m i ' m sure they get 
uh i mean for one thing people do phone up who don ' t have uh uh middle america accents and 
uhhuh . 
it ' s a we it ' s it ' s it ' s u s . 
it has has many people who sound in many different ways . 
so 
um 
i mean . 
okay . 
that was that topic . 
what else we got ? 
um 
did we end up giving up on on any eurospeech submissions ? 
but 
or 
i know thilo and dan ellis are are submitting something . 
but uh 
yeah . 
i i guess the only thing with these the meeting recorder and well 
so i think yeah i think we basically gave up . 
um now actually for the for the uh 
we do have stuff for aurora right ? 
because because we have an extra month or something . 
yeah . 
yeah . 
yeah . 
so 
yeah for sure we will do something for the special session . 
yeah . 
well that ' s fine . 
so so so we have a couple a couple little things on meeting recorder . 
yeah . 
uhhuh . 
and we have we don ' t we don ' t have to flood it with papers . 
we ' re not trying to prove anything to anybody . 
so 
that ' s fine . 
um 
anything else ? 
yeah . 
well so 
perhaps the point is that we ' ve been working on is 
yeah we have put the um the good v a d in the system . 
and it really makes a huge difference . 
um 
so 
yeah . 
i think yeah this is perhaps one of the reason why our system was not not the best . 
because with the new v a d it ' s very the results are similar to the france telecom results and perhaps even better sometimes . 
huh . 
huh . 
um so there is this point . 
uh the problem is that it ' s very big and we still have to think how to where to put it . 
and um 
uhhuh . 
because it it 
well this v a d 
uh either some delay 
and we if we put it on the server side it doesn ' t work . 
because on the server side features you already have l d a applied from the from the terminal side . 
and so you accumulate the delay . 
so the v a d should be before the l d a . 
which means perhaps on the terminal side . 
and then smaller and 
so where did this good v a d come from ? 
so 
it ' s um from o g i . 
so it ' s the network trained it ' s the network with the huge amounts on hidden of hidden units . 
and um nine input frames compared to the v a d that was in the proposal which has a very small amount of hidden units and fewer inputs . 
this is the one they had originally ? 
yeah . 
oh . 
yeah but they had to get rid of it because of the space . 
didn ' t they ? 
yeah . 
so 
yeah . 
but the assumption is that we will be able to make a v a d that ' s small and that works fine . 
and so we can 
well so that ' s a problem . 
yeah . 
yeah but 
but the other thing is uh to use a different v a d entirely . 
i mean uh if if there ' s a if if 
i i don ' t know what the thinking was amongst the the the the etsi folk . 
but um if everybody agreed sure let ' s use this v a d and take that out of there 
uhhuh . 
uhhuh . 
they just want apparently they don ' t want to fix the v a d because they think there is some interaction between feature extraction and and v a d or frame dropping . 
but they still want to just to give some um requirement for this v a d . 
because it ' s it will not be part of they don ' t want it to be part of the standard . 
okay . 
so so it must be at least uh somewhat fixed but not completely . 
so there just will be some requirements that are still not uh not yet uh ready i think . 
determined . 
i see . 
but i was thinking that that uh sure there may be some interaction . 
but i don ' t think we need to be stuck on using our or o g i ' s v a d . 
we could use somebody else ' s if it ' s smaller . 
or 
yeah . 
you know as long as it did the job . 
uhhuh . 
so that ' s good . 
uh so there is this thing . 
there is 
um 
yeah . 
uh i designed a new a new filter . 
because when i designed other filters with shorter delay from the l d a filters there was one filter with sixty millisecond delay and the other with ten milliseconds . 
and uh hynek suggested that both could have sixty five sixty 
right . 
i think it ' s sixty five . 
yeah . 
yeah . 
both should have sixty five because 
yeah . 
you didn ' t gain anything right ? 
and so i did that . 
and uh it ' s running . 
so let ' s see what will happen . 
uh but the filter is of course closer to the reference filter . 
uhhuh . 
huh . 
um yeah . 
i think 
so that means logically in principle it should be better . 
so probably it ' ll be worse ? 
yeah . 
or in the basic perverse nature uh of reality . 
yeah . 
okay . 
yeah . 
sure . 
yeah . 
yeah and then we ' ve started to work with this of um voiced unvoiced stuff . 
uhhuh . 
and next week i think we will perhaps try to have um a new system with uh uh m s g stream also . 
see what what happens . 
so something that ' s similar to the proposal too but with m s g stream . 
uhhuh . 
uhhuh . 
huh . 
okay . 
no i i begin to play with matlab and to found some parameter robust for voiced unvoiced decision . 
but only to play . 
and we they we found that maybe is a classical parameter the the variance between the um f f t of the signal and the small spectrum of time we after the um mel filter bank . 
uhhuh . 
and well is more or less robust . 
is good for clean speech . 
is quite good for noisy speech . 
huh . 
uhhuh . 
but um we must to have bigger statistic with timit . 
uhhuh . 
and is not ready yet to use on 
yeah . 
well i don ' t know . 
yeah . 
yeah . 
so basically we want to look at something like the the excitation signal and 
right . 
uhhuh . 
which are the variance of it and 
i have here . 
i have here for one signal for one frame . 
huh . 
yeah . 
the the mix of the two noise and unnoise and the signal is this . 
uhhuh . 
clean and this noise . 
uh . 
these are the two . 
the mixed the big signal is for clean . 
well i ' m uh 
there ' s 
none of these axes are labeled . 
so i don ' t know what this 
what ' s this axis ? 
uh this is uh this axis is nnn frame . 
frame . 
uhhuh . 
and what ' s what this ? 
uh this is uh energy log energy of the spectrum . 
of the 
this is the variance . 
the difference between the spectrum of the signal and f f t of each frame of the signal . 
and this mouth spectrum of time after the may fit for the two . 
for this one . 
for the 
this big to here they are to signal . 
this is for clean and this is for noise . 
oh . 
there ' s two things on the same graph . 
yeah . 
i don ' t know . 
i i think that i have another graph . 
but i ' m not sure . 
yeah . 
so which is clean and which is noise ? 
i think the lower one is noise . 
the lower is noise and the height is clean . 
okay . 
so it ' s harder to distinguish . 
it ' s height . 
but it but it 
yeah . 
with noise of course . 
but but 
oh i must to have . 
uh 
pity but i don ' t have two different 
and presumably when there ' s a a 
so this should the the the voiced portions . 
uhhuh . 
yeah it is the height is voiced portion . 
the the peaks should be voiced portion . 
and this is the noise portion . 
uhhuh . 
and this is more or less like this . 
but i meant to have see two two the picture . 
yeah . 
yeah . 
this is for example for one frame . 
yeah . 
the the spectrum of the signal . 
and this is the small version of the spectrum after m l mel filter bank . 
yeah . 
and this is the difference ? 
and this is 
i don ' t know . 
this is not the different . 
this is trying to obtain with l p c model the spectrum . 
but using matlab without going factor and 
no pre emphasis . 
yeah ? 
not pre emphasis . 
nothing . 
yeah so it ' s 
and the 
doesn ' t do too well there . 
i think that this is good . 
this is quite similar . 
this is this is another frame . 
how i obtained the envelope this envelope with the mel filter bank . 
right . 
so now i wonder 
i mean do you want to 
i know you want to get at something orthogonal from what you get with the smooth spectrum . 
um but if you were to really try and get a voiced unvoiced do you do you want to totally ignore that ? 
i mean do you do you 
i mean clearly a a very big very big cues for voiced unvoiced come from uh spectral slope and so on . 
uhhuh . 
right ? 
um 
yeah . 
well this would be this would be perhaps an additional parameter . 
simply isn ' t 
yeah . 
i see . 
yeah . 
yeah because when did noise clear in these section is clear . 
uh . 
uhhuh . 
if value is indicative that is a voice frame and it ' s low values . 
yeah . 
yeah . 
well you probably want 
i mean certainly if you want to do good voiced unvoiced detection you need a few features . 
each each feature is by itself not enough . 
but you know people look at at slope and uh first auto correlation coefficient divided by power . 
huh . 
or or uh 
um 
there ' s uh 
i guess we probably don ' t have enough computation to do a simple pitch detector or something ? 
i mean with a pitch detector you could have a have a an estimate of of what the 
huh . 
uh 
or maybe you could you just do it going through the p f f t ' s figuring out some um probable um harmonic structure . 
right ? 
huh . 
and and uh 
you have read up and you have a paper the paper that you give me yesterday . 
oh yeah . 
they say that yesterday they are some problem . 
but 
yeah but it ' s not 
it ' s 
yeah it ' s it ' s another problem . 
yeah . 
is another problem . 
um 
yeah there is this fact actually . 
if you look at this um spectrum . 
yeah . 
what ' s this again ? 
is it the mel filters ? 
yeah like this . 
yeah . 
of kind like this . 
okay . 
so the envelope here is the output of the mel filters . 
uhhuh . 
and what we clearly see is that in some cases 
and it clearly appears here . 
and the the harmonics are resolved by the 
well there are still appear after mel filtering . 
uhhuh . 
and it happens for high pitched voice because the width of the lower frequency mel filters is sometimes even smaller than the pitch . 
yeah . 
it ' s around one hundred one hundred and fifty hertz nnn . 
right . 
and so what happens is that this uh additional variability to this envelope . 
and um 
yeah . 
so we were thinking to modify the mel spectrum to have something that that ' s smoother on low frequencies . 
that ' s as as a separate thing . 
yeah . 
yeah . 
this is a separate thing . 
yeah . 
separate thing ? 
yeah . 
and 
yeah . 
maybe so . 
um 
yeah . 
so what 
yeah . 
what i was talking about was just starting with the f f t . 
you could you could uh do a very rough thing to estimate estimate uh pitch . 
yeah . 
uhhuh . 
and uh uh given you know given that uh you could uh uh come up with some kind of estimate of how much of the low frequency energy was was explained by by uh uh those harmonics . 
uhhuh . 
uh 
it ' s uh a variant on what you ' re what you ' re doing . 
the i mean the the the does give a smooth thing . 
but as you say it ' s not that smooth here . 
and and so if you if you just you know subtracted off uh your guess of the harmonics then something like this would end up with quite a bit lower energy in the first fifteen hundred hertz or so . 
and and our first kilohertz even . 
uhhuh . 
and um if was uh noisy the proportion that it would go down would be 
uhhuh . 
if it was if it was unvoiced or something . 
so you ought to be able to pick out voiced segments . 
at least it should be another another cue . 
uhhuh . 
so anyway 
okay . 
that ' s what ' s going on . 
uh 
what ' s up with you ? 
um our i went to talk with uh mike jordan this this week . 
uhhuh . 
um and uh shared with him the ideas about um extending the larry saul work . 
and um i asked him some questions about factorial h m m ' s . 
so like later down the line when we ' ve come up with these these feature detectors how do we how do we uh you know uh model the time series that that happens . 
um and and we talked a little bit about factorial h m m ' s and how um when you ' re doing inference or when you ' re doing recognition there ' s like simple viterbi stuff that you can do for for these h m m ' s . 
and the uh the great advantages that um a lot of times the factorial h m m ' s don ' t um don ' t over alert the problem . 
there they have a limited number of parameters and they focus directly on on uh the sub problems at hand . 
so you can imagine um five or so parallel um features um transitioning independently . 
and then at the end you you uh couple these factorial h m m ' s with uh with uh undirected links um based on based on some more data . 
huh . 
so he he seemed he seemed like really interested in in um in this . 
and said said this is this is something very do able and can learn a lot . 
and um 
yeah i ' ve just been continue reading um about certain things . 
uhhuh . 
um 
thinking of maybe using um um modulation spectrum stuff to um as features um also in the in the sub bands . 
uhhuh . 
because it seems like the modulation um spectrum tells you a lot about the intelligibility of of certain um words and stuff . 
so um 
yeah . 
just 
that ' s about it . 
okay . 
okay . 
and 
um 
so i ' ve been looking at avendano ' s work . 
and um 
uh i ' ll try to write up in my next status report a nice description of what he ' s doing . 
but it ' s it ' s an approach to deal with reverberation or that the aspect of his work that i ' m interested in . 
the idea is that um normally analysis frames are um too short to encompass reverberation effects um in full . 
you miss most of the reverberation tail in a ten millisecond window . 
and so you you ' d like it to be that um the reverberation responses um simply convolved um in . 
but it ' s not really with these ten millisecond frames . 
because you 
but if you take say a two millisecond um window 
i ' m sorry . 
a two second window . 
then in a room like this most of the reverberation response is included in the window . 
and the then it um then things are more linear . 
it is it is more like the reverberation response is simply convolved . 
and um and you can use channel normalization techniques like 
uh in his thesis he ' s assuming that the reverberation response is fixed . 
he just does um mean subtraction . 
which is like removing the d c component of the modulation spectrum . 
and that ' s supposed to um deal uh deal pretty well with the um reverberation . 
and um the neat thing is you can ' t take these two second frames and feed them to a speech recognizer . 
um so he does this um method training trading the um the spectral resolution for time resolution and um come uh synthesizes a new representation which is with say ten second frames but a lower um frequency resolution . 
so i don ' t really know the theory . 
i guess it ' s these are called time frequency representations . 
and he ' s making the the time um finer grained and the frequency resolution um less fine grained . 
uhhuh . 
so i ' m i guess my first stab actually in continuing his work is to um re implement this this thing which um changes the time and frequency resolutions . 
because he doesn ' t have code for me . 
so that that ' ll take some reading about the theory . 
i don ' t really know the theory . 
uhhuh . 
oh and um another first step is 
um 
so the the way i want to extend his work is make it able to deal with a time varying reverberation response . 
um and um 
we don ' t really know how fast the um the reverberation response is varying the meeting recorder data . 
um so um we we have this um block least squares um echo canceller implementation . 
and um i want to try finding the the response say between a near mike and the table mike for someone using the echo canceller . 
and looking at the echo canceller taps and then see how fast that varies from block to block . 
uhhuh . 
that should give an idea of how fast the reverberation response is changing . 
uhhuh . 
okay . 
um i think we ' re sort of done . 
yeah . 
so let ' s read our digits and go home . 
um 
so um 
you do i think you read some of the the zeros as o s and some as zeros . 
yeah . 
is there a particular way we ' re supposed to read them ? 
there are only zeros here . 
well 
no . 
o o o and zero are two ways that we say that digit . 
eee . 
yeah . 
so it ' s 
but 
ha ! 
so it ' s 
perhaps in the sheets there should be another sign for the 
if we want to the the guy to say o . 
or 
no . 
i mean i think people will do what they say . 
it ' s 
yeah . 
it ' s okay . 
okay . 
all right . 
i mean in digit recognition we ' ve done before you have you have two pronunciations for that value o and zero . 
okay . 
but it ' s perhaps more difficult for the people to prepare the database then if 
because here you only have zeros . 
no they just write 
and and people pronounce o or zero . 
they they write down o h . 
or they write down z e r o . 
and they and they each have their own pronunciation . 
yeah but if the the sheet was prepared with a different sign for the o . 
but people wouldn ' t know what that 
i mean there is no convention for it . 
okay . 
yeah . 
see i mean you ' d have to tell them okay when we write this say it 
you know ? 
and you just they just want people to read the digits as you ordinarily would . 
uhhuh . 
yeah . 
yep . 
and and people say it different ways . 
okay . 
is this a change from the last batch of of um forms ? 
because in the last batch it was spelled out which one you should read . 
yeah it was orthographic . 
so 
yes . 
that ' s right . 
it was it was spelled out and they decided they wanted to get at more the way people would really say things . 
oh okay . 
that ' s also why they ' re they ' re bunched together in these different groups . 
okay . 
so so it ' s 
yeah . 
so it ' s it ' s 
everything ' s fine . 
okay . 
okay . 
actually let me just since since you brought it up i was just it was hard not to be self conscious about that when it after we since we just discussed it . 
but i realized that that um when i ' m talking on the phone certainly and and saying these numbers i almost always say zero . 
and uh because because uh it ' s two syllables . 
it ' s it ' s more likely they ' ll understand what i said . 
so that that that ' s the habit i ' m in . 
but some people say o and 
yeah i normally say o because it ' s easier to say . 
yeah it ' s shorter . 
yeah . 
so it ' s so so uh 
o 
now don ' t think about it . 
oh no ! 
okay . 
we ' re done . 
okay we ' re on . 
okay so uh had some interesting mail from uh dan ellis . 
actually i think he he redirected it to everybody also . 
so uh the p d a mikes uh have a big bunch of energy at at uh five hertz . 
uh 
where this came up was that uh i was showing off these wave forms that we have on the web . 
and and uh i just sort of hadn ' t noticed this but that the major major component in the wave in the second wave form in that pair of wave forms is actually the air conditioner . 
so 
so 
i i have to be more careful about using that as a as a as a good illustration . 
uh in fact it ' s not of uh of the effects of room reverberation . 
it isn ' t a bad illustration of the effects of uh room noise on on uh some mikes . 
uh but 
so 
and then we had this other discussion about um whether this affects the dynamic range . 
because i know although we start off with thirty two bits you end up with uh sixteen bits . 
and you know are we getting hurt there ? 
but uh dan is pretty confident that we ' re not that that quantization error is not is still not a significant factor there . 
so 
so there was a question of whether we should change things here . 
whether we should change a capacitor on the input box for that . 
or whether we should 
yeah he suggested a smaller capacitor . 
right ? 
for the p d a ' s ? 
right . 
but then i had some other uh discussions with him . 
and the feeling was once we start monkeying with that uh many other problems could happen . 
and additionally we we already have a lot of data that ' s been collected with that . 
so 
yeah . 
a simple thing to do is 
he he he has a i forget if it this was in that mail or in the following mail . 
but he has a a simple filter a digital filter that he suggested . 
we just run over the data before we deal with it . 
uhhuh . 
um the other thing that i don ' t know the answer to but when people are using feacalc here uh whether they ' re using it with the high pass filter option or not . 
and i don ' t know if anybody knows . 
um i could go check . 
but 
yeah . 
so when we ' re doing all these things using our software there is 
um if it ' s if it ' s based on the rasta p l p program which does both p l p and rasta p l p um then uh there is an option there which then comes up through to feacalc which um allows you to do high pass filtering . 
and in general we like to do that because of things like this . 
and it ' s it ' s pretty it ' s not a very severe . 
filter doesn ' t affect speech frequencies . 
even pretty low speech frequencies at all . 
but it ' s 
what ' s the cutoff frequency it used ? 
oh . 
i don ' t know . 
i wrote this a while ago . 
is it like twenty ? 
something like that . 
yeah . 
yeah . 
i mean i think there ' s some effect above twenty . 
but it ' s it ' s it ' s it ' s mild . 
so i mean it probably there ' s probably some effect up to a hundred hertz or something but it ' s it ' s pretty mild . 
i don ' t know in the in the strut implementation of the stuff is there a high pass filter or a pre emphasis or something in the 
uh i think we use a pre emphasis . 
yeah . 
yeah . 
so we we we want to go and check that in for anything that we ' re going to use the p d a mike for . 
uh he says that there ' s a pretty good roll off in the p z m mikes . 
so we don ' t need need to worry about them one way or the other . 
but if we do make use of the cheap mikes uh we want to be sure to do that that filtering before we process it . 
and then again if it ' s 
uh depending on the option that the our our software is being run with it ' s it ' s quite possible that ' s already being taken care of . 
uh but i also have to pick a different picture to show the effects of reverberation . 
uh 
did somebody notice it during your talk ? 
uh no . 
huh . 
well 
uh 
well if they made output . 
they were they were you know they were nice . 
didn ' t say anything ? 
but i mean the thing is it was 
since i was talking about reverberation and showing this thing that was noise it wasn ' t a good match . 
but it certainly was still uh an indication of the fact that you get noise with distant mikes . 
uhhuh . 
uh it ' s just not a great example because not only isn ' t it reverberation but it ' s a noise that we definitely know what to do . 
so i mean it doesn ' t take deep a new bold new methods to get rid of uh five hertz noise . 
so 
yeah . 
um uh but 
so it was it was a bad example in that way . 
but it ' s it still is it ' s the real thing that we did get out of the microphone at distance . 
so it wasn ' t it it wasn ' t wrong it was inappropriate . 
so so uh but uh 
yeah someone noticed it later pointed it out to me and i went oh man . 
why didn ' t i notice that . 
huh . 
um so um 
so i think we ' ll change our our picture on the web when we ' re 
one of the things i was i mean i was trying to think about what what ' s the best way to show the difference and i had a couple of thoughts . 
one was that spectrogram that we show is okay . 
but the thing is the eyes uh and the the brain behind them are so good at picking out patterns from from noise that in first glance . 
you look at them it doesn ' t seem like it ' s that bad . 
uh because there ' s many features that are still preserved . 
so one thing to do might be to just take a piece of the uh of the spectrogram where you can see that something looks different . 
and blow it up and have that be the part that ' s just to show as well . 
uhhuh uhhuh . 
you know . 
some things are going to be hurt . 
um another i was thinking of was um taking some spectral slices . 
like uh like we look at with the recognizer . 
and look at the spectrum or cepstrum that you get out of there . 
and the the uh um the reverberation uh does make it does change that . 
huh . 
and so maybe maybe that would be more obvious . 
spectral slices ? 
yeah . 
what what do you mean ? 
well i mean um all the recognizers look at frames . 
so like one instant in time . 
so they they look at 
okay . 
yeah look at a 
so it ' s 
yeah . 
at one point in time or uh twenty over twenty milliseconds or something you have a spectrum or a cepstrum . 
okay . 
that ' s what i meant by a slice . 
i see . 
yeah . 
and if you look at 
you could just you could just throw up you know uh the uh some m f c c feature vectors . 
you know one from one one from the other and then you know you can look and see how different the numbers are . 
right well that ' s why i saying . 
i ' m just kidding . 
either well either spectrum or cepstrum . 
but but i think the thing is you want to 
i don ' t mean a graph . 
oh . 
i mean the actual numbers . 
oh i see . 
oh . 
that would be lovely . 
yeah . 
yeah . 
see how different these sequences of numbers are . 
yeah . 
or i could just add them up and get a different total . 
yeah . 
it ' s not the square . 
okay . 
what else what ' s what else is going on ? 
uh yeah . 
yeah at first i had a remark . 
why i am wondering why the p d a is always so far . 
i mean we are always meeting at the beginning of the table and the p d a ' s there . 
uh i guess because we haven ' t wanted to move it . 
we we could we could move us . 
yeah ? 
and 
okay . 
that ' s right . 
well anyway . 
um 
yeah so 
uh since the last meeting we ' ve we ' ve tried to put together um the clean low pass um downsampling upsampling i mean . 
uh the new filter that ' s replacing the l d a filters . 
and also the um delay issue . 
so that 
we considered the the delay issue on the for the online normalization . 
huh . 
so we ' ve put together all this . 
and then we have results that are not um very impressive . 
well there is no real improvement . 
but it ' s not worse . 
it ' s not 
and it ' s better better latency . 
right ? 
yeah . 
yeah . 
well actually it ' s better . 
it seems better when we look at the mismatched case . 
but i think we are like like cheated here by the this problem . 
that uh in some cases when you modify slight slightly modify the initial condition you end up completely somewhere somewhere else in the in the space the parameters . 
yeah . 
so 
well the other system are for instance 
for italian is at seventy eight percent recognition rate on the mismatch . 
and this new system has eighty nine . 
but i don ' t think it indicates something really . 
i don ' t i don ' t think it means that the new system is more robust 
uhhuh . 
or 
it ' s simply the fact that 
well 
well the test would be if you then tried it on one of the other test sets if if it was 
right so this was italian . 
right ? 
yeah yeah . 
so then if you take your changes . 
it ' s similar for other test sets . 
and then 
but i mean from this seventy eight um percent recognition rate system i could change the transition probabilities for the the first h m m and it will end up to eighty nine also . 
uhhuh . 
by using point five instead of point six point four as in the the h t k script . 
uhhuh . 
yeah . 
so well that ' s 
yeah . 
yeah i looked at um looked at the results when stephane did that . 
well 
uh uh 
and it ' s it ' s really really happens . 
this really happens . 
i mean the only difference is you change the self loop transition probability by a tenth of a percent . 
yeah . 
yeah . 
and it causes ten percent difference in the word error rate . 
a tenth of a per cent . 
even tenth of a percent ? 
yeah . 
from point 
well we tried we tried point one . 
i i ' m sorry . 
for point from you change at point one . 
yeah . 
huh . 
oh . 
and not tenth of a percent one tenth . 
all right ? 
yeah . 
um so from point five 
so from point six to point five and you get ten percent better . 
uhhuh . 
uhhuh . 
and it ' s i think it ' s what you basically hypothesized in the last meeting about uh it just being very 
and i think you mentioned this in your e mail too 
huh yeah . 
it ' s just very um 
you know get stuck in some local minimum . 
and this thing throws you out of it i guess . 
uhhuh . 
well what ' s what are according to the rules what what are we supposed to do about the transition probabilities ? 
are they supposed to be point five or point six ? 
i think you ' re not allowed to 
yeah . 
that ' s supposed to be point six for the self loop . 
yeah . 
point it ' s supposed to be point six . 
yeah . 
but changing it to point five i think is 
which gives you much better results . 
but that ' s not allowed . 
but not allowed . 
yeah okay . 
yeah . 
yeah but even if you use point five i ' m not sure it will always give you the better results . 
on other test set or it 
yeah . 
right we only tested it on the the medium mismatch . 
on the other training set i mean . 
right ? 
yeah . 
you said on the other cases you didn ' t notice 
but i think 
yeah . 
i think the reason is 
yeah i i 
it was in my mail i think also is the fact that the mismatch is trained only on the far microphone . 
well in for the mismatched case everything is um using the far microphone training and testing . 
whereas for the highly mismatched training is done on the close microphone . 
so it ' s it ' s clean speech basically . 
so you don ' t have this problem of local minima probably . 
and for the well match it ' s a mix of close microphone and distant microphone . 
and 
well 
i did notice uh something 
so i think the mismatch is the more difficult for the training part . 
somebody i think it was morgan suggested at the last meeting that i actually count to see how many parameters and how many frames . 
uhhuh . 
uhhuh . 
and there are uh almost one point eight million frames of training data . 
and less than forty thousand parameters in the baseline system . 
huh . 
yeah . 
so it ' s very very few parameters compared to how much training data . 
uhhuh . 
well yes . 
so 
and that that says that we could have lots more parameters actually . 
yeah . 
uhhuh . 
yeah . 
i did one quick experiment just to make sure i had everything worked out . 
and i just uh for most of the um 
for for all of the digit models they end up at three mixtures per state . 
and so i just did a quick experiment where i changed it so it went to four . 
and um it it it didn ' t have a any significant effect at the uh medium mismatch and high mismatch cases . 
and it had it was just barely significant for the well matched . 
better . 
uh so i ' m going to run that again but um with many more uh mixtures per state . 
yeah because at forty i mean you could you could have 
uh 
yeah easily four times as many parameters . 
uhhuh . 
and i think also just seeing what we saw uh in terms of the expected duration of the silence model 
when we did this tweaking of the self loop 
yeah . 
the silence model expected duration was really different . 
and so in the case where um it had a better score the silence model expected duration was much longer . 
yeah . 
so it was like it was a better match . 
i think you know if we make a better silence model i think that will help a lot too . 
um for a lot of these cases . 
so 
but one one thing i i wanted to check out before i increased the um number of mixtures per state was uh in their default training script they do an initial set of three re estimations . 
and then they built the silence model . 
and then they do seven iterations then the add mixtures . 
and they do another seven then they add mixtures . 
then they do a final set of seven and they quit . 
seven seems like a lot to me . 
and it also makes the experiments go take a really long time . 
i mean to do one turnaround of the well matched case takes like a day . 
uhhuh . 
uhhuh . 
and so you know in trying to run these experiments i notice you know it ' s difficult to find machines you know compute the run on . 
and so one of the things i did was i compiled h t k for the linux machines . 
uhhuh . 
because we have this one from i b m that ' s got like five processors in it . 
right . 
and so now i ' m you can run stuff on that and that really helps a lot because now we ' ve got you know extra machines that we can use for compute . 
uhhuh . 
and if i ' m running an experiment right now where i ' m changing the number of iterations from seven to three . 
yeah . 
just to see how it affects the baseline system . 
and so if we can get away with just doing three we can do many more experiments more quickly . 
and if it ' s not a a huge difference from running with seven iterations um you know we should be able to get a lot more experiments done . 
huh . 
and so i ' ll let you know what what happens with that . 
but if we can you know run all of these back ends with many fewer iterations and on linux boxes we should be able to get a lot more experimenting done . 
uhhuh . 
so 
so i wanted to experiment with cutting down the number of iterations before i increased the number of gaussians . 
right . 
sorry . 
so um how ' s it going on the 
um 
so you you did some things . 
they didn ' t improve things in a way that convinced you you ' d substantially improved anything . 
yeah . 
but they ' re not making things worse and we have reduced latency . 
right ? 
yeah . 
but actually um actually it seems to do a little bit worse for the well matched case . 
and we just noticed that 
yeah actually the way the final score is computed is quite funny . 
it ' s not a mean of word error rate . 
it ' s not a weighted mean of word error rate . 
it ' s a weighted mean of improvements . 
uhhuh . 
so 
which means that actually the weight on the well matched is 
well i well what what what happened is that if you have a small improvement or a small if on the well matched case it will have uh huge influence on the improvement compared to the reference . 
because the reference system is is is quite good for for the well well matched case also . 
so it it weights the improvement on the well matched case really heavily compared to the improvement on the other cases ? 
no but it ' s the weighting of the of the improvement . 
not of the error rate . 
yeah . 
yeah and it ' s hard to improve on the on the best case . 
because it ' s already so good . 
right ? 
yeah but what i mean is that you can have a huge improvement on the h h m k ' s . 
uh like five percent uh absolute . 
and this will not affect the final score almost . 
uh this will almost not affect the final score because this improvement because the improvement uh relative to the the baseline is small . 
uh 
so they do improvement in terms of uh accuracy rather than word error rate ? 
uh improvement 
no it ' s compared to the word it ' s improvement on the word error rate . 
so 
yeah . 
sorry . 
okay . 
so if you have uh ten percent error and you get five percent absolute uh improvement then that ' s fifty percent . 
uhhuh . 
okay so what you ' re saying then is that if it ' s something that has a small word error rate then uh a even a relatively small improvement on it in absolute terms will show up as quite quite large in this . 
uhhuh . 
is that what you ' re saying ? 
yeah . 
yes . 
yeah . 
okay . 
but yeah that ' s that ' s it ' s the notion of relative improvement . 
yeah . 
word error rate . 
sure but when we think about the weighting which is point five point three point two it ' s on absolute on on relative figures . 
not 
yeah . 
so when we look at this error rate 
yeah . 
no . 
uh 
that ' s why i ' ve been saying we should be looking at word error rate uh and and not not at at accuracies . 
huh yeah . 
huh yeah . 
it ' s 
uhhuh . 
i mean uh we probably should have standardized on that all the way through . 
it ' s just 
well 
uhhuh . 
i mean it ' s not it ' s not that different . 
right ? 
i mean just subtract the accuracy . 
yeah . 
i mean 
but you ' re but when you look at the numbers your sense of the relative size of things is quite different . 
oh oh i see . 
yeah . 
if you had ninety percent uh correct and five percent 
five over ninety doesn ' t look like it ' s a big difference . 
but five over ten is is big . 
uhhuh . 
uhhuh . 
so just when we were looking at a lot of numbers and getting sense of what was important . 
i see i see . 
yeah . 
that makes sense . 
um 
huh . 
um 
well anyway 
uh 
so 
yeah so it hurts a little bit on the well match . 
and 
yeah . 
what ' s a little bit ? 
like 
like it ' s difficult to say . 
because again 
um i ' m not sure i have the 
um 
hey morgan . 
do you remember that signif program that we used to use for testing 
is that still valid ? 
i i ' ve been using that . 
yeah . 
yeah it was actually updated . 
okay . 
uh jeff updated it some years ago . 
oh it was ? 
oh i 
and and uh cleaned it up made some things better in it . 
okay . 
so 
i should find that new one . 
i just use my old one from ninety two or whatever . 
yeah i ' m sure it ' s not that different . 
but but he he uh he was a little more rigorous as i recall . 
okay . 
right . 
so it ' s around like point five . 
no point six uh percent absolute on italian . 
worse . 
worse yep . 
out of what ? 
i mean 
uh well we start from ninety four point sixty four . 
and we go to ninety four point o four . 
uhhuh . 
so that ' s six six point 
uh 
ninety three point six four . 
right ? 
is the baseline . 
oh no i ' ve ninety four . 
oh the baseline you mean . 
yeah . 
well i don ' t i ' m not talking about the baseline here . 
oh oh . 
i 
i ' m sorry . 
uh 
my baseline is the submitted system . 
uh okay uh uh . 
huh . 
sorry . 
yeah . 
uh 
yeah . 
for finnish we start to ninety three point eight four . 
and we go to ninety three point seventy four . 
and for spanish we are we were at ninety five point o five . 
and we go to point sixty one . 
okay so we are getting hurt somewhat . 
so 
and is that 
what 
do you know what piece 
you ' ve done several changes here . 
uh 
do you know what 
yeah . 
i guess i guess it ' s it ' s the filter . 
because nnn well uh we don ' t have complete result . 
but the filter so the filter with the shorter delay hurts on italian well matched . 
which 
and 
yeah . 
and the other things like um downsampling upsampling don ' t seem to hurt . 
and the new online normalization neither . 
i ' m 
so 
i ' m really confused about something . 
if we saw that making a small change like you know a tenth to the self loop had a huge effect can we really make any conclusions about differences in this stuff ? 
uhhuh . 
yeah that ' s 
yeah . 
i mean especially when they ' re this small . 
i mean 
i think we can be completely fooled by this thing . 
but 
i don ' t know . 
well yeah . 
so there is first this thing . 
and then the 
yeah i computed the um like the confidence level on the different test sets . 
and for the well matched they are around um point six uh percent . 
for the mismatched they are around like let ' s say one point five percent . 
and for the well uh h m they are also around one point five . 
but okay so you these these degradations you were talking about were on the well matched case . 
so 
yeah . 
uh do the does the new filter make things uh better or worse for the other cases ? 
but 
uh about the same . 
it doesn ' t hurt . 
yeah . 
doesn ' t hurt but doesn ' t get a little better or something . 
no . 
no . 
okay so um i guess the argument one might make is that yeah if you looked at one of these cases and you jiggle something and it changes then uh you ' re not quite sure what to make of it . 
but when you look across a bunch of these and there ' s some some pattern 
um 
i mean so uh here ' s all the if if in all these different cases it never gets better and there ' s significant number of cases where it gets worse then you ' re probably hurting things i would say . 
so um i mean at the very least that would be a reasonably prediction of what would happen with with a different test set that you ' re not jiggling things with . 
so i guess the question is if you can do better than this ? 
if you can if we can approximate the old numbers while still keeping the latency down . 
huh . 
yeah . 
uh so 
um what i was asking though is uh are what ' s what ' s the level of communication with uh the o g i gang now about this ? 
and 
well we are exchanging mail as soon as we we have significant results . 
yeah . 
um 
yeah . 
for the moment they are working on integrating the um spectral subtraction apparently from ericsson . 
uhhuh . 
um 
yeah . 
and so 
yeah . 
we are working on our side on other things like uh also trying a spectral subtraction . 
but of of our own i mean another spectral subtraction . 
uhhuh . 
um 
yeah . 
so i think it ' s it ' s okay . 
it ' s going 
is there any further discussion about this this idea of of having some sort of source code control ? 
yeah . 
well for the moment they ' re 
uh everybody ' s quite 
um 
there is this eurospeech deadline . 
so 
i see . 
um and 
yeah . 
but yeah . 
as soon as we have something that ' s significant and that ' s better than than what was submitted . 
we will fix fix the system . 
and 
but we ' ve not discussed it it it this yet . 
yeah . 
yeah . 
sounds like a great idea . 
but but i think that that um he ' s saying people are sort of scrambling for a eurospeech deadline . 
huh . 
but that ' ll be uh uh done in a week . 
so maybe after this next one . 
yeah . 
wow ! 
already a week ! 
man ! 
yeah . 
you ' re right . 
that ' s amazing . 
yeah . 
anybody in the in this group doing anything for eurospeech ? 
or is that what is that 
yeah we are we are trying to to do something with the meeting recorder digits . 
right . 
and 
but yeah . 
yeah . 
and the good thing is that there is this first deadline . 
yeah . 
and well some people from o g i are working on a paper for this . 
but there is also the um special session about aurora . 
which is uh which has an extended deadline . 
so 
the deadline is in may . 
for uh oh for eurospeech ? 
for 
yeah . 
so only for the experiments on aurora . 
oh ! 
so it it ' s good . 
yeah . 
oh a special dispensation . 
that ' s great . 
uhhuh . 
where is eurospeech this year ? 
it ' s in denmark . 
aalborg . 
aalborg 
uh 
oh . 
so the deadline 
when ' s the deadline ? 
huh ? 
when ' s the deadline ? 
i think it ' s the thirteenth of may . 
that ' s great . 
it ' s great . 
so we should definitely get something in for that . 
yeah . 
but on meeting digits maybe there ' s 
maybe . 
yeah . 
so it would be for the first deadline . 
maybe . 
yeah . 
nnn . 
yeah so i mean i i think that you could certainly start looking at at the issue . 
uh but but uh i think it ' s probably on from what stephane is saying it ' s it ' s unlikely to get sort of active participation from the two sides until after they ' ve 
well i could at least 
well i ' m going to be out next week . 
but i could try to look into like this uh c v s over the web . 
that seems to be a very popular way of people distributing changes and over you know multiple sites and things . 
uhhuh . 
so maybe if i can figure out how do that easily and then pass the information on to everybody so that it ' s you know as easy to do as possible . 
and and people don ' t it won ' t interfere with their regular work . 
then maybe that would be good . 
and i think we could use it for other things around here too . 
so 
good . 
that ' s cool . 
and if you ' re interested in using c v s i ' ve set it up here . 
so 
oh great . 
okay . 
um 
i used it a long time ago . 
but it ' s been a while . 
so maybe i can ask you some questions . 
oh . 
so i ' ll be away tomorrow and monday but i ' ll be back on tuesday or wednesday . 
okay . 
yeah . 
dave the other thing actually is is this business about this wave form . 
maybe you and i can talk a little bit at some point about coming up with a better uh demonstration of the effects of reverberation for our web page . 
because 
uh the uh um 
i mean actually the the 
uh 
it made a good good audio demonstration because when we could play that clip the the the really obvious difference is that you can hear two voices and in the second one and only hear 
maybe we could just like talk into a cup . 
yeah . 
some good reverb . 
no i mean it sound it sounds pretty reverberant . 
but i mean you can ' t when you play it back in a room with a you know a big room nobody can hear that difference really . 
yeah . 
uhhuh . 
they hear that it ' s lower amplitude and they hear there ' s a second voice . 
um but uh 
that actually that makes for a perfectly good demo . 
because that ' s a real obvious thing that you hear two voices . 
but not of reverberation . 
yeah . 
a boom . 
well that that that ' s okay . 
but for the the visual just you know i ' d like to have uh uh you know the spectrogram again . 
yeah . 
because you ' re you ' re you ' re visual uh abilities as a human being are so good you can pick out 
you know you you look at the good one you look at the the screwed up one and and you can see the features in it without trying to . 
i noticed that in the pictures . 
yeah . 
i thought hey you know i 
my initial thought was this is not too bad . 
right . 
but you have to you know if you look at it closely you see well here ' s a place where this one has a big formant . 
uh uh formant major formants here are are moving quite a bit . 
and then you look in the other one and they look practically flat . 
uhhuh . 
so i mean you could that ' s why i was thinking in a section like that you could take a look look at just that part of the spectrogram and you could say oh yeah . 
this this really distorted it quite a bit . 
yeah . 
the main thing that struck me in looking at those two spectrograms was the difference in the high frequencies . 
it looked like for the one that was farther away you know it really everything was attenuated . 
and 
right . 
i mean that was the main visual thing that i noticed . 
right . 
but it ' s it ' s 
uh 
so 
yeah . 
so there are clearly are spectral effects . 
since you ' re getting all this indirect energy then a lot of it does have have uh reduced high frequencies . 
but um the other thing is the temporal courses of things really are changed and and uh we want to show that in some obvious way . 
the reason i put the wave forms in there was because uh they they do look quite different . 
uh a nd so i thought oh this is good . 
but i i just 
uh 
after after uh they were put in there i didn ' t really look at them anymore . 
because i just they were different . 
so i want something that has a is a more interesting explanation for why they ' re different . 
um 
oh . 
so maybe we can just substitute one of these wave forms . 
and um then do some kind of zoom in on the spectrogram on an interesting area . 
something like that . 
yeah . 
uhhuh . 
the other thing that we had in there that i didn ' t like was that um the most obvious characteristic of the difference uh when you listen to it is that there ' s a second voice . 
and the the the the the uh cuts that we have there actually don ' t correspond to the full wave form . 
it ' s just the first 
i think there was something where he was having some trouble getting so much in . 
or 
i i forget the reason behind it . 
but it it ' s um it ' s the first six seconds or something of it . 
and it ' s in the seventh or eighth second or something where the second voice comes in . 
so we we would like to actually see the voice coming in too i think . 
uhhuh . 
since that ' s the most obvious thing when you listen to it . 
so 
um 
uh yeah . 
yeah . 
i brought some i don ' t know if some figures here . 
well i start we started to work on spectral subtraction . 
and um the preliminary results were very bad . 
so the thing that we did is just to add spectral subtraction before this the wall uh process which contains l d a online normalization . 
uhhuh . 
and it hurts uh a lot . 
uhhuh . 
and so we started to look at at um things like this . 
which is 
well it ' s 
yeah . 
so you have the c zero parameters for one uh italian utterance . 
you can . 
and i plotted this for two channels . 
channel zero is the close microphone . 
and channel one is the distant microphone . 
and it ' s perfectly synchronized . 
so 
and the sentence contain only one word which is due . 
and it can ' t clearly be seen . 
where where is it ? 
where is the word ? 
uhhuh . 
this is this is 
huh . 
oh a plot of c zero . 
so 
the energy . 
this is a plot of c zero uh when we don ' t use spectral subtraction . 
and when there is no online normalization . 
so 
uhhuh . 
there is just some filtering with the l d a . 
and and some downsampling upsampling . 
c zero is the close talking ? 
so 
uh the close channel ? 
yeah yeah . 
and channel one is the 
yeah . 
so c zero is very clean actually . 
yeah . 
uh then when we apply mean normalization it looks like the second figure . 
though it is not . 
which is good . 
well the noise part is around zero . 
and and then the third figure is what happens when we apply mean normalization and variance normalization . 
uhhuh . 
so 
what we can clearly see is that on the speech portion the two channel come becomes very close . 
but also what happens on the noisy portion is that the variance of the noise is 
uhhuh . 
this is still being a plot of c zero ? 
yeah this is still c zero . 
okay . 
can i ask um what does variance normalization do ? 
what is the effect of that ? 
normalizes the variance . 
so it it 
yeah . 
it normalized the standard deviation . 
i mean 
so it 
yeah . 
you you get an estimate of the standard deviation . 
no i understand that . 
but i mean 
that ' s 
um 
no . 
no i understand what it is . 
but i mean what does it what ' s what is 
yeah but 
uh 
what ' s the rationale ? 
yeah . yeah . 
why why do it ? 
uh 
well i mean because everything uh if you have a system based on gaussians everything is based on means and variances . 
yeah . 
so if there ' s an overall reason 
you know it ' s like uh if you were doing uh image processing . 
and in some of the pictures you were looking at uh there was a lot of light . 
and and in some there was low light . 
uhhuh . 
you know you would want to adjust for that in order to compare things . 
uhhuh . 
and the variance is just sort of like the next moment . 
you know . 
so uh what if um one set of pictures was taken uh so that throughout the course it was went through daylight and night uh um um ten times ? 
another time it went 
i mean is you know how how much how much 
oh okay . 
or no . 
i guess a better example would be how much of the light was coming in from outside ? 
rather than artificial light . 
so if it was a lot if more was coming from outside then there ' d be the bigger effect of the of the of the change in the 
so every mean every all all of the the parameters that you have especially the variances are going to be affected by the overall variance . 
oh okay . 
uhhuh . 
and so in principle you if you remove that source then you know you can 
i see okay . 
so would the major effect is that you ' re going to get is by normalizing the means . 
but it may help 
that ' s the first order but thing . 
first order effects . 
and it may help to do the variance . 
but then the second order is is the variances . 
okay . 
okay . 
because again if you if you ' re trying to distinguish between e and b 
uhhuh . 
if it just so happens that the e s were a more you know were recorded when when the energy was was was larger or something 
huh huh . 
uhhuh . 
uhhuh . 
or the variation in it was larger uh than with the b s then this will be give you some some bias . 
so the it ' s removing these sources of variability in the data that have nothing to do with the linguistic component . 
okay . 
huh . 
gotcha okay . 
sorry to interrupt . 
yep . 
but the the uh but let me ask ask you something . 
and it and this 
is if if you have a good voice activity detector isn ' t isn ' t it going to pull that out ? 
yeah . sure . 
if they are good . 
yeah . 
well what it it shows is that yeah perhaps a good voice activity detector is is good before online normalization . 
and that ' s what uh we ' ve already observed . 
but uh 
yeah . 
voice activity detection is not an easy thing neither . 
but after you do this after you do the variance normalization 
uhhuh . 
i mean 
i don ' t know it seems like this would be a lot easier than this signal to work with . 
yeah . 
so what i notice is that while i prefer to look at the second figure than at the third one . 
well because you clearly see where speech is . 
yeah . 
yeah . 
but the problem is that on the speech portion channel zero and channel one are more different . than when you use variance normalization where channel zero and channel one become closer . 
right . 
but for the purposes of finding the speech 
and 
yeah but here 
yeah . 
you ' re more interested in the difference between the speech and the non speech ? 
yeah . 
right ? 
so i think 
yeah . 
for i i think that it perhaps it shows that uh the parameters that the voice activity detector should use uh have to use should be different than the parameter that have to be used for speech recognition . 
yeah so basically you want to reduce this effect . 
well 
so you can do that by doing the voice activity detection . 
you also could do it by uh spectral subtraction before the variance normalization . 
right ? 
yeah but it ' s not clear . 
yeah . 
so uh 
so 
well it ' s just to 
yeah . 
the the number that that are here are recognition experiments on italian h m and m m with these two kinds of parameters . 
and well it ' s better with variance normalization . 
yeah . 
yeah . 
so it does get better even though it looks ugly . 
uh 
okay . 
but does this have the voice activity detection in it ? 
yeah . 
okay . 
um 
okay . 
so 
where ' s 
but the fact is that the voice activity detector doesn ' t work on channel one . 
so 
yeah . 
uhhuh . 
where at what stage is the voice activity detector applied ? 
is it applied here or after the variance normalization ? 
huh ? 
spectral subtraction i guess . 
it ' s applied before variance normalization . 
or 
so it ' s a good thing . 
because i guess voice activity detection on this should could be worse . 
oh . 
yeah . 
is it applied all the way back here ? 
it ' s applied the 
um on 
yeah . 
something like this . 
yeah . 
maybe that ' s why it doesn ' t work for channel one . 
perhaps yeah . 
can i 
so we could perhaps do just mean normalization before v a d . 
uhhuh . 
uhhuh . 
can i ask a i mean a sort of top level question ? 
which is um if if most of what the o g i folk are working with is trying to integrate this other other uh spectral subtraction why are we worrying about it ? 
uhhuh . 
about ? 
spectral subtraction ? 
yeah . 
it ' s just uh well it ' s another 
they are trying to to use the um the ericsson . 
and we ' re trying to use something something else . 
and 
yeah and also to understand what happens because 
okay . 
uh fff 
well when we do spectral subtraction actually i think that this is the the two last figures . 
yeah . 
um it seems that after spectral subtraction speech is more emerging now uh than than before . 
uhhuh . 
speech is more what ? 
well the difference between the energy of the speech and the energy of the spectral subtracted noise portion is is larger . 
uhhuh . 
well if you compare the first figure to this one 
actually the scale is not the same . 
but if you look at the the numbers um you clearly see that the difference between the c zero of the speech and c zero of the noise portion is larger . 
uh but what happens is that after spectral subtraction you also increase the variance of this of c zero . 
and so if you apply variance normalization on this it completely screw everything . 
uhhuh . 
well 
uhhuh . 
um uh yeah . 
so yeah . 
and what they did at o g i is just uh they don ' t use online normalization for the moment on spectral subtraction . 
and i think 
yeah . 
i think as soon as they will try online normalization there will be a problem . 
so yeah we ' re working on the same thing but i think 
uh 
with different different system . 
and 
right . 
i mean the 
intellectually it ' s interesting to work on things uh one way or the other . 
uhhuh . 
but i ' m i ' m just wondering if um on the list of things that there are to do 
if there are things that we won ' t do because we ' ve got two groups doing the same thing . 
uhhuh . 
um 
uhhuh . 
that ' s 
um 
just just asking . 
uh i mean it ' s 
yeah well 
uh 
there also could be i mean i can maybe see a reason for both working on it too . 
if um you know if if if you work on something else and and you ' re waiting for them to give you spectral subtraction 
i mean it ' s hard to know whether the effects that you get from the other experiments you do will carry over once you then bring in their spectral subtraction module . 
so it ' s it ' s almost like everything ' s held up waiting for this one thing . 
i don ' t know if that ' s true or not . 
but i could see how 
huh . 
maybe that ' s what you were thinking . 
i don ' t know i don ' t know . 
i mean we still evidently have a latency reduction plan which which isn ' t quite what you ' d like it to be . 
that that seems like one prominent thing . 
and then uh weren ' t issues of of having a a second stream or something ? 
that was 
was it 
there was this business that you know we we could use up the full forty eight hundred bits . 
and 
yeah but i think 
i think we want to work on this . 
they also want to work on this . 
so 
uh yeah . 
we we will try m s g . 
but um 
yeah . 
and they are 
i think they want to work on the second stream also . 
but more with some kind of multi band . 
or well what they call trap or generalized trap . 
uhhuh . 
um so 
okay . 
do you remember when the next meeting is supposed to be ? 
it ' s uh in june . 
the next uh 
in june . 
okay . 
yeah . 
yeah . 
um yeah the other thing is that you saw that that mail about uh the v a d v a d ' s performing quite differently . 
that that 
uh 
so um 
this there was this experiment of uh what if we just take the baseline ? 
huh . 
set uh of features . 
just mel cepstra . 
and you incorporate the different v a d ' s . 
and it looks like the the french v a d is actually uh better significantly better . 
improves the baseline ? 
yeah . 
yeah . 
yeah but i don ' t know which v a d they use . 
uh if the use the small v a d 
i i think it ' s on 
i think it ' s easy to do better . 
because it doesn ' t work at all . 
so 
i i don ' t know which which one . 
it ' s pratibha that that did this experiment . 
yeah . 
um we should ask which v a d she used . 
i don ' t . 
he actually i think that he say with the good v a d of from ogi . 
and with the alcatel v a d . 
and the experiment was sometime better sometime worse . 
yeah but i it ' s uh i think you were talking about the other mail that used v a d on the reference features . 
yes . 
yeah . 
i don ' t remember . 
and on that one uh the french one is was better . 
it was just better . 
uhhuh . 
i mean it was enough better that that it would uh account for a fair amount of the difference between our performance actually . 
uhhuh . 
uhhuh . 
so uh 
so if they have a better one we should use it . 
i mean 
you know ? 
it ' s 
you can ' t work on everything . 
yeah . 
uh uh yeah . 
yeah so we should find out if it ' s really better . 
i mean if it 
the compared to the small or the big network . 
uhhuh . 
yeah . 
and perhaps we can easily improve if if we put like mean normalization before the before the v a d . 
because as as you ' ve mentioned 
yeah . 
huh . 
hynek will be back in town uh the week after next . 
back back in the country . 
so 
and start start organizing uh more visits and connections and so forth . 
uhhuh . 
and 
uh 
working towards june . 
yeah . 
uhhuh . 
also is stephane was thinking that maybe it was useful to to think about uh voiced unvoiced 
to work uh here in voiced unvoiced detection . 
yeah . 
and we are looking in the uh signal . 
yeah . 
yeah my feeling is that um actually when we look at all the proposals everybody is still using some kind of spectral envelope . 
and um it ' s 
right . 
no use of pitch uh basically . 
yeah . 
yeah well not pitch . 
but to look at the um fine at the at the high high resolution spectrum . 
yeah . 
so we don ' t necessarily want to find the the pitch of the of the sound . 
well it 
but 
uh 
because i have a feeling that when we look when we look at the just at the envelope there is no way you can tell if it ' s voiced and unvoiced . 
if there is some 
it ' s it ' s easy in clean speech because voiced sound are more low frequency . 
and 
so there would be more 
yeah . 
uh there is the first formant which is the larger . 
and then voiced sound are more high frequencies . 
because it ' s frication . 
and 
right . 
but 
yeah . 
when you have noise there is no 
um if if you have a low frequency noise it could be taken for for voiced speech . 
and 
yeah you can make these mistakes . 
so 
but but 
isn ' t there some other 
uh 
so i think that it it would be good 
yeah yeah . 
well go go on . 
uh i was just going to say isn ' t there aren ' t aren ' t there lots of ideas for doing voice activity or speech - nonspeech rather um by looking at um you know uh i guess harmonics 
or looking across time 
well i think he was talking about the voiced unvoiced though . 
huh . 
right ? 
yeah . 
so not the speech - nonspeech . 
well even with 
uh uh 
yeah . 
you know uh even with the voiced voiced unvoiced . 
huh . 
um 
i thought that you or somebody was talking about 
well 
so 
uh yeah we should let him finish what he he was going to say . 
okay . 
and 
so go ahead . 
um yeah so yeah i think if we try to develop a second stream 
well there would be one stream that is the envelope and the second it could be interesting to have . 
that ' s something that ' s more related to the fine structure of the spectrum . 
and 
yeah so i don ' t know . 
we were thinking about like using ideas from from larry saul . 
have a good voice detector 
have a good 
well voiced speech detector that ' s working on on the f f t . 
and uh 
larry saul could be an idea . 
we were are thinking about just kind of uh taking the spectrum . 
and computing the variance of of the high resolution spectrum and things like this . 
so 
okay . 
so so many tell you something about that . 
uh we had a guy here some years ago who did some work on um making use of voicing information uh to help in reducing the noise . 
yeah . 
uhhuh . 
so what he was doing is basically you you do estimate the pitch . 
and 
um 
you from that you you estimate 
or you estimate fine harmonic structure . 
either way . 
it ' s more or less the same . 
but uh the thing is that um you then can get rid of things that are not 
if there is strong harmonic structure you can throw away stuff that ' s that ' s non harmonic . 
uhhuh . 
uhhuh . 
and that that is another way of getting rid of part of the noise . 
yeah . 
yeah . 
so um that ' s something that is sort of finer . 
brings in a little more information than just spectral subtraction . 
um 
uhhuh . 
and he had some i mean he did that sort of in combination with rasta . 
it was kind of like rasta was taking care of convolutional stuff . 
huh . 
uhhuh . 
and he was 
and and got some some decent results doing that . 
so that that ' s another another way . 
yeah . 
but yeah there ' s there ' s 
huh . 
right . 
there ' s all these cues . 
we ' ve 
but 
actually back when chuck was here we did some voiced unvoiced uh classification using a bunch of these . 
and and 
uh 
works okay . 
obviously it ' s not perfect . 
but 
uhhuh . 
um 
but the thing is that you can ' t 
given the constraints of this task we can ' t in a very nice way feed forward to the recognizer the information . 
the probabilistic information that you might get about whether it ' s voiced or unvoiced 
uhhuh . 
where we can ' t you know affect the the uh distributions or anything . 
but we what we 
uh 
i guess we could 
yeah . 
didn ' t the head dude send around that message ? 
yeah i think you sent us all a copy of the message . 
where he was saying that 
i ' m not sure exactly what the gist of what he was saying . 
but something having to do with the voice activity detector . 
and that it will that people shouldn ' t put their own in or something . 
it was going to be a 
that but 
okay . 
so that ' s voice activity detector as opposed to voicing detector . 
they didn ' t . 
so we ' re talking about something a little different . 
huh . 
oh i ' m sorry . 
huh . 
i i missed that . 
right ? 
i guess what you could do maybe 
this would be useful if if you have if you view the second stream 
yeah before you before you do k l t ' s and so forth 
if you do view it as probabilities 
and if it ' s an independent 
so if it ' s if it ' s uh not so much envelope based by fine structure based 
uh looking at harmonicity or something like that 
um if you get a probability from that information . 
and then multiply it by you know multiply by all the voiced outputs and all the unvoiced outputs . 
you know then use that as the 
uhhuh . 
uh take the log of that 
or uh uh pre nonlinearity 
yeah . 
if 
uh and do the k l t on the on on that . 
yeah . 
then that would that would i guess be uh a reasonable use of independent information . 
so maybe that ' s what you meant . 
and then that would be 
yeah well i was not thinking this 
yeah this could be 
yeah . 
so you mean have some kind of probability for the the voicing ? 
and then use a tandem system . 
right so you have a second neural net . 
it could be pretty small . 
yeah if you have a tandem system . 
and then you have some kind of it can be pretty small net . 
uhhuh . 
we used we did some of this stuff . 
uh i i did some years ago . 
yeah . 
and the and and you use the thing is to use information primarily that ' s different . 
as you say it ' s more fine structure based than than envelope based . 
uhhuh . 
uh so then it you you you can pretty much guarantee it ' s stuff that you ' re not looking at very well with the other one . 
and uh then you only use for this one distinction . 
all right . 
and and so now you ' ve got a probability of the cases . 
and you ' ve got uh the probability of the finer uh categories on the other side . 
you multiply them where appropriate . 
and 
uh um 
i see yeah uhhuh . 
if they really are from independent information sources then they should have different kinds of errors . 
uhhuh . 
and roughly independent errors . 
uhhuh . 
and it ' s a good choice for 
uhhuh . 
yeah . 
uh 
yeah that ' s a good idea . 
yeah . 
because yeah well spectral subtraction is good . 
and we could we could use the fine structure to to have a better estimate of the noise . 
but still there is this issue with spectral subtraction that it seems to increase the variance of of of 
yeah . 
um 
well it ' s this musical noise which is annoying if you you do some kind of online normalization after . 
right . 
so 
um 
yeah . 
well spectral subtraction and online normalization don ' t seem to to go together very well . 
i 
or if you do a spectral subtraction do some spectral subtraction first 
and then do some online normalization . 
then do some more spectral subtraction ! 
i mean maybe maybe you can do it layers or something . 
so it doesn ' t doesn ' t hurt too much or something . 
uh yeah . 
but it but uh anyway i think i was sort of arguing against myself there by giving that example . 
yeah . 
uh i mean because i was already sort of suggesting that we should be careful about not spending too much time on exactly what they ' re doing . 
in fact if you get if you go into uh a uh harmonics related thing it ' s definitely going to be different than what they ' re doing . 
and uh uh 
uhhuh . 
should have some interesting properties in noise . 
um i know that when have people have done um sort of the obvious thing of taking uh your feature vector and adding in some variables which are pitch related . 
or 
uh that it hasn ' t my impression it hasn ' t particularly helped . 
it it 
uh has not . 
has not . 
yeah . 
yeah . 
oh . 
but i think uh that ' s that ' s a question for this uh you know extending the feature vector versus having different streams . 
was it noisy condition ? 
the example that you you just 
and and it may not have been noisy conditions . 
yeah . 
yeah . 
i i don ' t remember the example . 
but it was it was on some darpa data and some years ago . 
and so it probably wasn ' t actually . 
uhhuh . 
uhhuh . 
yeah . 
but we were thinking we discussed with barry about this . 
and perhaps thinking we were thinking about some kind of cheating experiment where we would use timit . 
uhhuh . 
and see if giving the uh this voicing bit would help in in terms of uh frame classification . 
why don ' t you why don ' t you just do it with aurora ? 
huh . 
yeah but but but we cannot do the cheating this cheating thing . 
just any in in each in each frame 
we ' re 
uh 
we need labels . 
well because we don ' t have 
why not ? 
well for italian perhaps we have . 
but we don ' t have this labeling for aurora . 
we just have a labeling with word models . 
but not for phonemes . 
i see . 
not for foreigners . 
we don ' t have frame frame level transcriptions . 
right . 
um 
um yeah . 
but you could i mean you can you can align so that it ' s not perfect . 
but if you if you know what was said . 
and 
but the problem is that their models are all word level models . 
so there ' s no phone models that you get alignments for . 
uhhuh . 
oh . 
you so you could find out where the word boundaries are . 
but that ' s about it . 
yeah . 
i see . 
but we could use uh the the noisy version that timit . 
which you know is similar to the the noises found in the t i digits um portion of aurora . 
yeah . 
noise yeah . 
yeah that ' s right yep . 
huh . 
well i guess i guess we can we can say that it will help . 
yeah . 
but i don ' t know . 
if this voicing bit doesn ' t help uh i think we don ' t have to to work more about this . 
because 
uh it ' s just to know if it how much it will help . 
uh . 
yeah . 
and to have an idea of how much we can gain . 
right . 
i mean in experiments that we did a long time ago 
huh . 
and different 
it was probably resource management or something . 
um i think you were getting something like still eight or nine percent error on the voicing as i recall . 
and um so um 
another person ' s voice . 
what that said is that sort of left to its own devices like without the a strong language model and so forth that you would you would make significant number of errors just with your uh probabilistic machinery in deciding . 
it also 
one oh 
yeah the though i think uh there was one problem with that in that you know we used canonical mapping . 
so our truth may not have really been true to the acoustics . 
uhhuh . 
huh . 
so 
huh . 
yeah . 
well back twenty years ago when i did this voiced unvoiced stuff we were getting more like ninety seven or ninety eight percent correct in voicing . 
but that was speaker dependent actually . 
we were doing training on a particular announcer . 
uhhuh . 
and and getting a very good handle on the features . 
uhhuh . 
and we did this complex feature selection thing where we looked at all the different possible features one could have for voicing . 
and and and uh and exhaustively searched all size subsets . 
wow ! 
and and uh for for that particular speaker and you ' d find you know the five or six features which really did well on them . 
uhhuh . 
and then doing doing all of that we could get down to two or three per cent error . 
uhhuh . 
but that again was speaker dependent with lots of feature selection . 
and a very complex sort of thing . 
huh . 
so i would i would believe that uh it was quite likely that 
um 
looking at envelope only that we ' d be significantly worse than that . 
uhhuh . 
uh 
and the all the the speechcorders ? 
what ' s the idea behind 
because they they have to 
oh they don ' t even have to detect voiced speech . 
the modern ones don ' t do a a simple switch . 
they just work on the code book ? 
and find out the best excitation . 
they work on the code book excitation . 
yeah they do analysis by synthesis . 
they try they they try every every possible excitation they have in their code book and find the one that matches best . 
yeah . 
huh . 
all right . 
yeah . 
so it would not help . 
yeah . 
huh . 
uh 
okay . 
can i just mention one other interesting thing ? 
yeah . 
um one of the ideas that we had come up with last week for things to try to improve the system 
um 
actually i i we didn ' t i guess i wrote this in after the meeting . 
but the thought i had was um looking at the language model that ' s used in the h t k recognizer . 
which is basically just a big loop . 
uhhuh . 
right ? 
so you it goes digit . 
uhhuh . 
and then that can be either go to silence or go to another digit . 
which 
that model would allow for the production of infinitely long sequences of digits . 
right ? 
right . 
so i thought well i ' m going to just look at the what actual digit strings do occur in the training data . 
right . 
and the interesting thing was it turns out that there are no sequences of two long or three long digit strings in any of the aurora training data . 
so it ' s either one four five six . 
uh up to eleven . 
and then it skips . 
and then there ' s some at sixteen . 
but what about the testing data ? 
um i don ' t know . 
i didn ' t look at the test data yet . 
yeah . 
so 
i mean if there ' s some testing data that has has has two or three 
yeah . 
but i just thought that was a little odd . 
that there were no two or three long 
sorry . 
so i i just for the heck of it i made a little grammar which um you know had it ' s separate path for each length digit string you could get . 
so there was a one long path . 
and there was a four long and a five long . 
uhhuh . 
and i tried that and it got way worse . 
there were lots of deletions . 
so it was you know i i didn ' t have any weights of these paths . 
uhhuh . 
or i didn ' t have anything like that . 
uhhuh . 
and i played with tweaking the word transition penalties a bunch . 
but i couldn ' t go anywhere . 
but um 
huh . 
i thought well if i only allow 
yeah i guess i should have looked at to see how often there was a mistake where a two long or a three long path was actually put out as a hypothesis . 
um but 
huh . 
so to do that right you ' d probably want to have allow for them all . 
but then have weightings and things . 
so i just thought that was a interesting thing about the data . 
okay . 
so we ' re going to read some more digit strings i guess ? 
yeah . 
you want to go ahead morgan ? 
sure . 
